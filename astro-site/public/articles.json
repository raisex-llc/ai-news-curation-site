[
  {
    "title": "Introducing OpenAI",
    "description": "OpenAI is a non-profit artificial intelligence research company. Our goal is to advance digital intelligence in the way that is most likely to benefit humanity as a whole, unconstrained by a need to generate financial return. Since our research is free from financial obligations, we can better focus on a positive human impact.",
    "summary": "OpenAI is a non-profit artificial intelligence research company. Our goal is to advance digital intelligence in the way that is most likely to benefit humanity as a whole, unconstrained by a need to generate financial return. Since our research is free from financial obligations, we can better focus on a positive human impact.",
    "pubDate": "Fri, 11 Dec 2015 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-openai",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Weight normalization: A simple reparameterization to accelerate training of deep neural networks",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 25 Feb 2016 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/weight-normalization",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Team++",
    "description": "We've had some fantastic people join over the past few months (and we're still hiring). Welcome, everyone!",
    "summary": "We've had some fantastic people join over the past few months (and we're still hiring). Welcome, everyone!",
    "pubDate": "Thu, 31 Mar 2016 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/team-plus-plus",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Welcome, Pieter and Shivon!",
    "description": "We have two more team updates.",
    "summary": "We have two more team updates.",
    "pubDate": "Tue, 26 Apr 2016 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/welcome-pieter-and-shivon",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "OpenAI Gym Beta",
    "description": "We’re releasing the public beta of OpenAI Gym, a toolkit for developing and comparing reinforcement learning (RL) algorithms. It consists of a growing suite of environments (from simulated robots to Atari games), and a site for comparing and reproducing results.",
    "summary": "We’re releasing the public beta of OpenAI Gym, a toolkit for developing and comparing reinforcement learning (RL) algorithms. It consists of a growing suite of environments (from simulated robots to Atari games), and a site for comparing and reproducing results.",
    "pubDate": "Wed, 27 Apr 2016 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-gym-beta",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Adversarial training methods for semi-supervised text classification",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 25 May 2016 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/adversarial-training-methods-for-semi-supervised-text-classification",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Team update",
    "description": "We’d like to welcome the latest set of team members to OpenAI (and we’re still hiring!)",
    "summary": "We’d like to welcome the latest set of team members to OpenAI (and we’re still hiring!)",
    "pubDate": "Wed, 25 May 2016 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/team-update",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Generative models",
    "description": "This post describes four projects that share a common theme of enhancing or using generative models, a branch of unsupervised learning techniques in machine learning. In addition to describing our work, this post will tell you a bit more about generative models: what they are, why they are important, and where they might be going.",
    "summary": "This post describes four projects that share a common theme of enhancing or using generative models, a branch of unsupervised learning techniques in machine learning. In addition to describing our work, this post will tell you a bit more about generative models: what they are, why they are important, and where they might be going.",
    "pubDate": "Thu, 16 Jun 2016 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/generative-models",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "OpenAI technical goals",
    "description": "OpenAI’s mission is to build safe AI, and ensure AI’s benefits are as widely and evenly distributed as possible.",
    "summary": "OpenAI’s mission is to build safe AI, and ensure AI’s benefits are as widely and evenly distributed as possible.",
    "pubDate": "Mon, 20 Jun 2016 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-technical-goals",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Concrete AI safety problems",
    "description": "We (along with researchers from Berkeley and Stanford) are co-authors on today’s paper led by Google Brain researchers, Concrete Problems in AI Safety. The paper explores many research problems around ensuring that modern machine learning systems operate as intended.",
    "summary": "We (along with researchers from Berkeley and Stanford) are co-authors on today’s paper led by Google Brain researchers, Concrete Problems in AI Safety. The paper explores many research problems around ensuring that modern machine learning systems operate as intended.",
    "pubDate": "Tue, 21 Jun 2016 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/concrete-ai-safety-problems",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Special projects",
    "description": "Impactful scientific work requires working on the right problems—problems which are not just interesting, but whose solutions matter.",
    "summary": "Impactful scientific work requires working on the right problems—problems which are not just interesting, but whose solutions matter.",
    "pubDate": "Thu, 28 Jul 2016 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/special-projects",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Team update",
    "description": "We’ve hired more great people to help us achieve our goals. Welcome, everyone!",
    "summary": "We’ve hired more great people to help us achieve our goals. Welcome, everyone!",
    "pubDate": "Tue, 16 Aug 2016 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/team-update-august",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Machine Learning Unconference",
    "description": "The latest information about the Unconference is now available at the Unconference wiki, which will be periodically updated with more information for attendees.",
    "summary": "The latest information about the Unconference is now available at the Unconference wiki, which will be periodically updated with more information for attendees.",
    "pubDate": "Thu, 18 Aug 2016 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/machine-learning-unconference",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Infrastructure for deep learning",
    "description": "Deep learning is an empirical science, and the quality of a group’s infrastructure is a multiplier on progress. Fortunately, today’s open-source ecosystem makes it possible for anyone to build great deep learning infrastructure.",
    "summary": "Deep learning is an empirical science, and the quality of a group’s infrastructure is a multiplier on progress. Fortunately, today’s open-source ecosystem makes it possible for anyone to build great deep learning infrastructure.",
    "pubDate": "Mon, 29 Aug 2016 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/infrastructure-for-deep-learning",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Transfer from simulation to real world through learning deep inverse dynamics model",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 11 Oct 2016 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/transfer-from-simulation-to-real-world-through-learning-deep-inverse-dynamics-model",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Report from the self-organizing conference",
    "description": "Last week we hosted over a hundred and fifty AI practitioners in our offices for our first self-organizing conference on machine learning.",
    "summary": "Last week we hosted over a hundred and fifty AI practitioners in our offices for our first self-organizing conference on machine learning.",
    "pubDate": "Thu, 13 Oct 2016 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/report-from-the-self-organizing-conference",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Semi-supervised knowledge transfer for deep learning from private training data",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 18 Oct 2016 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/semi-supervised-knowledge-transfer-for-deep-learning-from-private-training-data",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Extensions and limitations of the neural GPU",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 02 Nov 2016 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/extensions-and-limitations-of-the-neural-gpu",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Variational lossy autoencoder",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 08 Nov 2016 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/variational-lossy-autoencoder",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "RL²: Fast reinforcement learning via slow reinforcement learning",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 09 Nov 2016 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/rl2",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "A connection between generative adversarial networks, inverse reinforcement learning, and energy-based models",
    "description": "",
    "summary": "",
    "pubDate": "Fri, 11 Nov 2016 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/a-connection-between-generative-adversarial-networks-inverse-reinforcement-learning-and-energy-based-models",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "On the quantitative analysis of decoder-based generative models",
    "description": "",
    "summary": "",
    "pubDate": "Mon, 14 Nov 2016 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/on-the-quantitative-analysis-of-decoder-based-generative-models",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "#Exploration: A study of count-based exploration for deep reinforcement learning",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 15 Nov 2016 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/exploration",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "OpenAI and Microsoft",
    "description": "We’re working with Microsoft to start running most of our large-scale experiments on Azure.",
    "summary": "We’re working with Microsoft to start running most of our large-scale experiments on Azure.",
    "pubDate": "Tue, 15 Nov 2016 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-and-microsoft",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Universe",
    "description": "We’re releasing Universe, a software platform for measuring and training an AI’s general intelligence across the world’s supply of games, websites and other applications.",
    "summary": "We’re releasing Universe, a software platform for measuring and training an AI’s general intelligence across the world’s supply of games, websites and other applications.",
    "pubDate": "Mon, 05 Dec 2016 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/universe",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Faulty reward functions in the wild",
    "description": "Reinforcement learning algorithms can break in surprising, counterintuitive ways. In this post we’ll explore one failure mode, which is where you misspecify your reward function.",
    "summary": "Reinforcement learning algorithms can break in surprising, counterintuitive ways. In this post we’ll explore one failure mode, which is where you misspecify your reward function.",
    "pubDate": "Wed, 21 Dec 2016 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/faulty-reward-functions",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "PixelCNN++: Improving the PixelCNN with discretized logistic mixture likelihood and other modifications",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 19 Jan 2017 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/pixelcnn-plus-plus",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Team update",
    "description": "The OpenAI team is now 45 people. Together, we’re pushing the frontier of AI capabilities—whether by validating novel ideas, creating new software systems, or deploying machine learning on robots.",
    "summary": "The OpenAI team is now 45 people. Together, we’re pushing the frontier of AI capabilities—whether by validating novel ideas, creating new software systems, or deploying machine learning on robots.",
    "pubDate": "Mon, 30 Jan 2017 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/team-update-january",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Adversarial attacks on neural network policies",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 08 Feb 2017 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/adversarial-attacks-on-neural-network-policies",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Attacking machine learning with adversarial examples",
    "description": "Adversarial examples are inputs to machine learning models that an attacker has intentionally designed to cause the model to make a mistake; they’re like optical illusions for machines. In this post we’ll show how adversarial examples work across different mediums, and will discuss why securing systems against them can be difficult.",
    "summary": "Adversarial examples are inputs to machine learning models that an attacker has intentionally designed to cause the model to make a mistake; they’re like optical illusions for machines. In this post we’ll show how adversarial examples work across different mediums, and will discuss why securing systems against them can be difficult.",
    "pubDate": "Fri, 24 Feb 2017 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/attacking-machine-learning-with-adversarial-examples",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Third-person imitation learning",
    "description": "",
    "summary": "",
    "pubDate": "Mon, 06 Mar 2017 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/third-person-imitation-learning",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Prediction and control with temporal segment models",
    "description": "",
    "summary": "",
    "pubDate": "Sun, 12 Mar 2017 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/prediction-and-control-with-temporal-segment-models",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Emergence of grounded compositional language in multi-agent populations",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 15 Mar 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/emergence-of-grounded-compositional-language-in-multi-agent-populations",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Learning to communicate",
    "description": "In this post we’ll outline new OpenAI research in which agents develop their own language.",
    "summary": "In this post we’ll outline new OpenAI research in which agents develop their own language.",
    "pubDate": "Thu, 16 Mar 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/learning-to-communicate",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Distill",
    "description": "We’re excited to support today’s launch of Distill, a new kind of journal aimed at excellent communication of machine learning results (novel or existing).",
    "summary": "We’re excited to support today’s launch of Distill, a new kind of journal aimed at excellent communication of machine learning results (novel or existing).",
    "pubDate": "Mon, 20 Mar 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/distill",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "One-shot imitation learning",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 21 Mar 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/one-shot-imitation-learning",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Evolution strategies as a scalable alternative to reinforcement learning",
    "description": "We’ve discovered that evolution strategies (ES), an optimization technique that’s been known for decades, rivals the performance of standard reinforcement learning (RL) techniques on modern RL benchmarks (e.g. Atari/MuJoCo), while overcoming many of RL’s inconveniences.",
    "summary": "We’ve discovered that evolution strategies (ES), an optimization technique that’s been known for decades, rivals the performance of standard reinforcement learning (RL) techniques on modern RL benchmarks (e.g. Atari/MuJoCo), while overcoming many of RL’s inconveniences.",
    "pubDate": "Fri, 24 Mar 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/evolution-strategies",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Spam detection in the physical world",
    "description": "We’ve created the world’s first Spam-detecting AI trained entirely in simulation and deployed on a physical robot.",
    "summary": "We’ve created the world’s first Spam-detecting AI trained entirely in simulation and deployed on a physical robot.",
    "pubDate": "Sat, 01 Apr 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/spam-detection-in-the-physical-world",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Unsupervised sentiment neuron",
    "description": "We’ve developed an unsupervised system which learns an excellent representation of sentiment, despite being trained only to predict the next character in the text of Amazon reviews.",
    "summary": "We’ve developed an unsupervised system which learns an excellent representation of sentiment, despite being trained only to predict the next character in the text of Amazon reviews.",
    "pubDate": "Thu, 06 Apr 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/unsupervised-sentiment-neuron",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Stochastic Neural Networks for hierarchical reinforcement learning",
    "description": "",
    "summary": "",
    "pubDate": "Mon, 10 Apr 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/stochastic-neural-networks-for-hierarchical-reinforcement-learning",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Equivalence between policy gradients and soft Q-learning",
    "description": "",
    "summary": "",
    "pubDate": "Fri, 21 Apr 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/equivalence-between-policy-gradients-and-soft-q-learning",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Roboschool",
    "description": "We are releasing Roboschool: open-source software for robot simulation, integrated with OpenAI Gym.",
    "summary": "We are releasing Roboschool: open-source software for robot simulation, integrated with OpenAI Gym.",
    "pubDate": "Mon, 15 May 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/roboschool",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Robots that learn",
    "description": "We’ve created a robotics system, trained entirely in simulation and deployed on a physical robot, which can learn a new task after seeing it done once.",
    "summary": "We’ve created a robotics system, trained entirely in simulation and deployed on a physical robot, which can learn a new task after seeing it done once.",
    "pubDate": "Tue, 16 May 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/robots-that-learn",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "OpenAI Baselines: DQN",
    "description": "We’re open-sourcing OpenAI Baselines, our internal effort to reproduce reinforcement learning algorithms with performance on par with published results. We’ll release the algorithms over upcoming months; today’s release includes DQN and three of its variants.",
    "summary": "We’re open-sourcing OpenAI Baselines, our internal effort to reproduce reinforcement learning algorithms with performance on par with published results. We’ll release the algorithms over upcoming months; today’s release includes DQN and three of its variants.",
    "pubDate": "Wed, 24 May 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-baselines-dqn",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "UCB exploration via Q-ensembles",
    "description": "",
    "summary": "",
    "pubDate": "Mon, 05 Jun 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/ucb-exploration-via-q-ensembles",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Learning to cooperate, compete, and communicate",
    "description": "Multiagent environments where agents compete for resources are stepping stones on the path to AGI. Multiagent environments have two useful properties: first, there is a natural curriculum—the difficulty of the environment is determined by the skill of your competitors (and if you’re competing against clones of yourself, the environment exactly matches your skill level). Second, a multiagent environment has no stable equilibrium: no matter how smart an agent is, there’s always pressure to get smarter. These environments have a very different feel from traditional environments, and it’ll take a lot more research before we become good at them.",
    "summary": "Multiagent environments where agents compete for resources are stepping stones on the path to AGI. Multiagent environments have two useful properties: first, there is a natural curriculum—the difficulty of the environment is determined by the skill of your competitors (and if you’re competing against clones of yourself, the environment exactly matches your skill level). Second, a multiagent environment has no stable equilibrium: no matter how smart an agent is, there’s always pressure to get smarter. These environments have a very different feel from traditional environments, and it’ll take a lot more research before we become good at them.",
    "pubDate": "Thu, 08 Jun 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/learning-to-cooperate-compete-and-communicate",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Learning from human preferences",
    "description": "One step towards building safe AI systems is to remove the need for humans to write goal functions, since using a simple proxy for a complex goal, or getting the complex goal a bit wrong, can lead to undesirable and even dangerous behavior. In collaboration with DeepMind’s safety team, we’ve developed an algorithm which can infer what humans want by being told which of two proposed behaviors is better.",
    "summary": "One step towards building safe AI systems is to remove the need for humans to write goal functions, since using a simple proxy for a complex goal, or getting the complex goal a bit wrong, can lead to undesirable and even dangerous behavior. In collaboration with DeepMind’s safety team, we’ve developed an algorithm which can infer what humans want by being told which of two proposed behaviors is better.",
    "pubDate": "Tue, 13 Jun 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/learning-from-human-preferences",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Faster physics in Python",
    "description": "We’re open-sourcing a high-performance Python library for robotic simulation using the MuJoCo engine, developed over our past year of robotics research.",
    "summary": "We’re open-sourcing a high-performance Python library for robotic simulation using the MuJoCo engine, developed over our past year of robotics research.",
    "pubDate": "Wed, 28 Jun 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/faster-physics-in-python",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Teacher–student curriculum learning",
    "description": "",
    "summary": "",
    "pubDate": "Sat, 01 Jul 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/teacher-student-curriculum-learning",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Hindsight Experience Replay",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 05 Jul 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/hindsight-experience-replay",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Robust adversarial inputs",
    "description": "We’ve created images that reliably fool neural network classifiers when viewed from varied scales and perspectives. This challenges a claim from last week that self-driving cars would be hard to trick maliciously since they capture images from multiple scales, angles, perspectives, and the like.",
    "summary": "We’ve created images that reliably fool neural network classifiers when viewed from varied scales and perspectives. This challenges a claim from last week that self-driving cars would be hard to trick maliciously since they capture images from multiple scales, angles, perspectives, and the like.",
    "pubDate": "Mon, 17 Jul 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/robust-adversarial-inputs",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Proximal Policy Optimization",
    "description": "We’re releasing a new class of reinforcement learning algorithms, Proximal Policy Optimization (PPO), which perform comparably or better than state-of-the-art approaches while being much simpler to implement and tune. PPO has become the default reinforcement learning algorithm at OpenAI because of its ease of use and good performance.",
    "summary": "We’re releasing a new class of reinforcement learning algorithms, Proximal Policy Optimization (PPO), which perform comparably or better than state-of-the-art approaches while being much simpler to implement and tune. PPO has become the default reinforcement learning algorithm at OpenAI because of its ease of use and good performance.",
    "pubDate": "Thu, 20 Jul 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-baselines-ppo",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Better exploration with parameter noise",
    "description": "We’ve found that adding adaptive noise to the parameters of reinforcement learning algorithms frequently boosts performance. This exploration method is simple to implement and very rarely decreases performance, so it’s worth trying on any problem.",
    "summary": "We’ve found that adding adaptive noise to the parameters of reinforcement learning algorithms frequently boosts performance. This exploration method is simple to implement and very rarely decreases performance, so it’s worth trying on any problem.",
    "pubDate": "Thu, 27 Jul 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/better-exploration-with-parameter-noise",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Gathering human feedback",
    "description": "RL-Teacher is an open-source implementation of our interface to train AIs via occasional human feedback rather than hand-crafted reward functions. The underlying technique was developed as a step towards safe AI systems, but also applies to reinforcement learning problems with rewards that are hard to specify.",
    "summary": "RL-Teacher is an open-source implementation of our interface to train AIs via occasional human feedback rather than hand-crafted reward functions. The underlying technique was developed as a step towards safe AI systems, but also applies to reinforcement learning problems with rewards that are hard to specify.",
    "pubDate": "Thu, 03 Aug 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/gathering-human-feedback",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Dota 2",
    "description": "We’ve created a bot which beats the world’s top professionals at 1v1 matches of Dota 2 under standard tournament rules. The bot learned the game from scratch by self-play, and does not use imitation learning or tree search. This is a step towards building AI systems which accomplish well-defined goals in messy, complicated situations involving real humans.",
    "summary": "We’ve created a bot which beats the world’s top professionals at 1v1 matches of Dota 2 under standard tournament rules. The bot learned the game from scratch by self-play, and does not use imitation learning or tree search. This is a step towards building AI systems which accomplish well-defined goals in messy, complicated situations involving real humans.",
    "pubDate": "Fri, 11 Aug 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/dota-2",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "More on Dota 2",
    "description": "Our Dota 2 result shows that self-play can catapult the performance of machine learning systems from far below human level to superhuman, given sufficient compute. In the span of a month, our system went from barely matching a high-ranked player to beating the top pros and has continued to improve since then. Supervised deep learning systems can only be as good as their training datasets, but in self-play systems, the available data improves automatically as the agent gets better.",
    "summary": "Our Dota 2 result shows that self-play can catapult the performance of machine learning systems from far below human level to superhuman, given sufficient compute. In the span of a month, our system went from barely matching a high-ranked player to beating the top pros and has continued to improve since then. Supervised deep learning systems can only be as good as their training datasets, but in self-play systems, the available data improves automatically as the agent gets better.",
    "pubDate": "Wed, 16 Aug 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/more-on-dota-2",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "OpenAI Baselines: ACKTR & A2C",
    "description": "We’re releasing two new OpenAI Baselines implementations: ACKTR and A2C. A2C is a synchronous, deterministic variant of Asynchronous Advantage Actor Critic (A3C) which we’ve found gives equal performance. ACKTR is a more sample-efficient reinforcement learning algorithm than TRPO and A2C, and requires only slightly more computation than A2C per update.",
    "summary": "We’re releasing two new OpenAI Baselines implementations: ACKTR and A2C. A2C is a synchronous, deterministic variant of Asynchronous Advantage Actor Critic (A3C) which we’ve found gives equal performance. ACKTR is a more sample-efficient reinforcement learning algorithm than TRPO and A2C, and requires only slightly more computation than A2C per update.",
    "pubDate": "Fri, 18 Aug 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-baselines-acktr-a2c",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Learning with opponent-learning awareness",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 13 Sep 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/learning-with-opponent-learning-awareness",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Learning to model other minds",
    "description": "We’re releasing an algorithm which accounts for the fact that other agents are learning too, and discovers self-interested yet collaborative strategies like tit-for-tat in the iterated prisoner’s dilemma. This algorithm, Learning with Opponent-Learning Awareness (LOLA), is a small step towards agents that model other minds.",
    "summary": "We’re releasing an algorithm which accounts for the fact that other agents are learning too, and discovers self-interested yet collaborative strategies like tit-for-tat in the iterated prisoner’s dilemma. This algorithm, Learning with Opponent-Learning Awareness (LOLA), is a small step towards agents that model other minds.",
    "pubDate": "Thu, 14 Sep 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/learning-to-model-other-minds",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Nonlinear computation in deep linear networks",
    "description": "",
    "summary": "",
    "pubDate": "Fri, 29 Sep 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/nonlinear-computation-in-deep-linear-networks",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Competitive self-play",
    "description": "We’ve found that self-play allows simulated AIs to discover physical skills like tackling, ducking, faking, kicking, catching, and diving for the ball, without explicitly designing an environment with these skills in mind. Self-play ensures that the environment is always the right difficulty for an AI to improve. Taken alongside our Dota 2 self-play results, we have increasing confidence that self-play will be a core part of powerful AI systems in the future.",
    "summary": "We’ve found that self-play allows simulated AIs to discover physical skills like tackling, ducking, faking, kicking, catching, and diving for the ball, without explicitly designing an environment with these skills in mind. Self-play ensures that the environment is always the right difficulty for an AI to improve. Taken alongside our Dota 2 self-play results, we have increasing confidence that self-play will be a core part of powerful AI systems in the future.",
    "pubDate": "Wed, 11 Oct 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/competitive-self-play",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Meta-learning for wrestling",
    "description": "We show that for the task of simulated robot wrestling, a meta-learning agent can learn to quickly defeat a stronger non-meta-learning agent, and also show that the meta-learning agent can adapt to physical malfunction.",
    "summary": "We show that for the task of simulated robot wrestling, a meta-learning agent can learn to quickly defeat a stronger non-meta-learning agent, and also show that the meta-learning agent can adapt to physical malfunction.",
    "pubDate": "Wed, 11 Oct 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/meta-learning-for-wrestling",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Domain randomization and generative models for robotic grasping",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 17 Oct 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/domain-randomization-and-generative-models-for-robotic-grasping",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Asymmetric actor critic for image-based robot learning",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 18 Oct 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/asymmetric-actor-critic-for-image-based-robot-learning",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Sim-to-real transfer of robotic control with dynamics randomization",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 18 Oct 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/sim-to-real-transfer-of-robotic-control-with-dynamics-randomization",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Generalizing from simulation",
    "description": "Our latest robotics techniques allow robot controllers, trained entirely in simulation and deployed on physical robots, to react to unplanned changes in the environment as they solve simple tasks. That is, we’ve used these techniques to build closed-loop systems rather than open-loop ones as before.",
    "summary": "Our latest robotics techniques allow robot controllers, trained entirely in simulation and deployed on physical robots, to react to unplanned changes in the environment as they solve simple tasks. That is, we’ve used these techniques to build closed-loop systems rather than open-loop ones as before.",
    "pubDate": "Thu, 19 Oct 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/generalizing-from-simulation",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Learning a hierarchy",
    "description": "We’ve developed a hierarchical reinforcement learning algorithm that learns high-level actions useful for solving a range of tasks, allowing fast solving of tasks requiring thousands of timesteps. Our algorithm, when applied to a set of navigation problems, discovers a set of high-level actions for walking and crawling in different directions, which enables the agent to master new navigation tasks quickly.",
    "summary": "We’ve developed a hierarchical reinforcement learning algorithm that learns high-level actions useful for solving a range of tasks, allowing fast solving of tasks requiring thousands of timesteps. Our algorithm, when applied to a set of navigation problems, discovers a set of high-level actions for walking and crawling in different directions, which enables the agent to master new navigation tasks quickly.",
    "pubDate": "Thu, 26 Oct 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/learning-a-hierarchy",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Interpretable and pedagogical examples",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 02 Nov 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/interpretable-and-pedagogical-examples",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Learning sparse neural networks through L₀ regularization",
    "description": "",
    "summary": "",
    "pubDate": "Mon, 04 Dec 2017 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/learning-sparse-neural-networks-through-l0-regularization",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Block-sparse GPU kernels",
    "description": "We’re releasing highly-optimized GPU kernels for an underexplored class of neural network architectures: networks with block-sparse weights. Depending on the chosen sparsity, these kernels can run orders of magnitude faster than cuBLAS or cuSPARSE. We’ve used them to attain state-of-the-art results in text sentiment analysis and generative modeling of text and images.",
    "summary": "We’re releasing highly-optimized GPU kernels for an underexplored class of neural network architectures: networks with block-sparse weights. Depending on the chosen sparsity, these kernels can run orders of magnitude faster than cuBLAS or cuSPARSE. We’ve used them to attain state-of-the-art results in text sentiment analysis and generative modeling of text and images.",
    "pubDate": "Wed, 06 Dec 2017 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/block-sparse-gpu-kernels",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Scaling Kubernetes to 2,500 nodes",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 18 Jan 2018 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/scaling-kubernetes-to-2500-nodes",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Requests for Research 2.0",
    "description": "We’re releasing a new batch of seven unsolved problems which have come up in the course of our research at OpenAI.",
    "summary": "We’re releasing a new batch of seven unsolved problems which have come up in the course of our research at OpenAI.",
    "pubDate": "Wed, 31 Jan 2018 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/requests-for-research-2",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Discovering types for entity disambiguation",
    "description": "We’ve built a system for automatically figuring out which object is meant by a word by having a neural network decide if the word belongs to each of about 100 automatically-discovered “types” (non-exclusive categories).",
    "summary": "We’ve built a system for automatically figuring out which object is meant by a word by having a neural network decide if the word belongs to each of about 100 automatically-discovered “types” (non-exclusive categories).",
    "pubDate": "Wed, 07 Feb 2018 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/discovering-types-for-entity-disambiguation",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Interpretable machine learning through teaching",
    "description": "We’ve designed a method that encourages AIs to teach each other with examples that also make sense to humans. Our approach automatically selects the most informative examples to teach a concept—for instance, the best images to describe the concept of dogs—and experimentally we found our approach to be effective at teaching both AIs",
    "summary": "We’ve designed a method that encourages AIs to teach each other with examples that also make sense to humans. Our approach automatically selects the most informative examples to teach a concept—for instance, the best images to describe the concept of dogs—and experimentally we found our approach to be effective at teaching both AIs",
    "pubDate": "Thu, 15 Feb 2018 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/interpretable-machine-learning-through-teaching",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "OpenAI supporters",
    "description": "We’re excited to welcome new donors to OpenAI.",
    "summary": "We’re excited to welcome new donors to OpenAI.",
    "pubDate": "Tue, 20 Feb 2018 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-supporters",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Preparing for malicious uses of AI",
    "description": "We’ve co-authored a paper that forecasts how malicious actors could misuse AI technology, and potential ways we can prevent and mitigate these threats. This paper is the outcome of almost a year of sustained work with our colleagues at the Future of Humanity Institute, the Centre for the Study of Existential Risk, the Center for a New American Security, the Electronic Frontier Foundation, and others.",
    "summary": "We’ve co-authored a paper that forecasts how malicious actors could misuse AI technology, and potential ways we can prevent and mitigate these threats. This paper is the outcome of almost a year of sustained work with our colleagues at the Future of Humanity Institute, the Centre for the Study of Existential Risk, the Center for a New American Security, the Electronic Frontier Foundation, and others.",
    "pubDate": "Tue, 20 Feb 2018 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/preparing-for-malicious-uses-of-ai",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "OpenAI hackathon",
    "description": "Come to OpenAI’s office in San Francisco’s Mission District for talks and a hackathon on Saturday, March 3rd.",
    "summary": "Come to OpenAI’s office in San Francisco’s Mission District for talks and a hackathon on Saturday, March 3rd.",
    "pubDate": "Thu, 22 Feb 2018 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-hackathon",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Ingredients for robotics research",
    "description": "We’re releasing eight simulated robotics environments and a Baselines implementation of Hindsight Experience Replay, all developed for our research over the past year. We’ve used these environments to train models which work on physical robots. We’re also releasing a set of requests for robotics research.",
    "summary": "We’re releasing eight simulated robotics environments and a Baselines implementation of Hindsight Experience Replay, all developed for our research over the past year. We’ve used these environments to train models which work on physical robots. We’re also releasing a set of requests for robotics research.",
    "pubDate": "Mon, 26 Feb 2018 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/ingredients-for-robotics-research",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Multi-Goal Reinforcement Learning: Challenging robotics environments and request for research",
    "description": "",
    "summary": "",
    "pubDate": "Mon, 26 Feb 2018 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/multi-goal-reinforcement-learning",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Some considerations on learning to explore via meta-reinforcement learning",
    "description": "",
    "summary": "",
    "pubDate": "Sat, 03 Mar 2018 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/some-considerations-on-learning-to-explore-via-meta-reinforcement-learning",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "OpenAI Scholars",
    "description": "We’re providing 6–10 stipends and mentorship to individuals from underrepresented groups to study deep learning full-time for 3 months and open-source a project.",
    "summary": "We’re providing 6–10 stipends and mentorship to individuals from underrepresented groups to study deep learning full-time for 3 months and open-source a project.",
    "pubDate": "Tue, 06 Mar 2018 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-scholars",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Reptile: A scalable meta-learning algorithm",
    "description": "We’ve developed a simple meta-learning algorithm called Reptile which works by repeatedly sampling a task, performing stochastic gradient descent on it, and updating the initial parameters towards the final parameters learned on that task. Reptile is the application of the Shortest Descent algorithm to the meta-learning setting, and is mathematically similar to first-order MAML (which is a version of the well-known MAML algorithm) that only needs black-box access to an optimizer such as SGD or Adam, with similar computational efficiency and performance.",
    "summary": "We’ve developed a simple meta-learning algorithm called Reptile which works by repeatedly sampling a task, performing stochastic gradient descent on it, and updating the initial parameters towards the final parameters learned on that task. Reptile is the application of the Shortest Descent algorithm to the meta-learning setting, and is mathematically similar to first-order MAML (which is a version of the well-known MAML algorithm) that only needs black-box access to an optimizer such as SGD or Adam, with similar computational efficiency and performance.",
    "pubDate": "Wed, 07 Mar 2018 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/reptile",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "On first-order meta-learning algorithms",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 08 Mar 2018 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/on-first-order-meta-learning-algorithms",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Improving GANs using optimal transport",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 15 Mar 2018 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/improving-gans-using-optimal-transport",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Report from the OpenAI hackathon",
    "description": "On March 3rd, we hosted our first hackathon with 100 members of the artificial intelligence community.",
    "summary": "On March 3rd, we hosted our first hackathon with 100 members of the artificial intelligence community.",
    "pubDate": "Thu, 15 Mar 2018 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/hackathon-follow-up",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Variance reduction for policy gradient with action-dependent factorized baselines",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 20 Mar 2018 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/variance-reduction-for-policy-gradient-with-action-dependent-factorized-baselines",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Retro Contest",
    "description": "We’re launching a transfer learning contest that measures a reinforcement learning algorithm’s ability to generalize from previous experience.",
    "summary": "We’re launching a transfer learning contest that measures a reinforcement learning algorithm’s ability to generalize from previous experience.",
    "pubDate": "Thu, 05 Apr 2018 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/retro-contest",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Gotta Learn Fast: A new benchmark for generalization in RL",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 10 Apr 2018 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/gotta-learn-fast",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Evolved Policy Gradients",
    "description": "We’re releasing an experimental metalearning approach called Evolved Policy Gradients, a method that evolves the loss function of learning agents, which can enable fast training on novel tasks. Agents trained with EPG can succeed at basic tasks at test time that were outside their training regime, like learning to navigate to an object on a different side of the room from where it was placed during training.",
    "summary": "We’re releasing an experimental metalearning approach called Evolved Policy Gradients, a method that evolves the loss function of learning agents, which can enable fast training on novel tasks. Agents trained with EPG can succeed at basic tasks at test time that were outside their training regime, like learning to navigate to an object on a different side of the room from where it was placed during training.",
    "pubDate": "Wed, 18 Apr 2018 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/evolved-policy-gradients",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "AI safety via debate",
    "description": "We’re proposing an AI safety technique which trains agents to debate topics with one another, using a human to judge who wins.",
    "summary": "We’re proposing an AI safety technique which trains agents to debate topics with one another, using a human to judge who wins.",
    "pubDate": "Thu, 03 May 2018 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/debate",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "AI and compute",
    "description": "We’re releasing an analysis showing that since 2012, the amount of compute used in the largest AI training runs has been increasing exponentially with a 3.4-month doubling time (by comparison, Moore’s Law had a 2-year doubling period)[^footnote-correction]. Since 2012, this metric has grown by more than 300,000x (a 2-year doubling period would yield only a 7x increase). Improvements in compute have been a key component of AI progress, so as long as this trend continues, it’s worth preparing for the implications of systems far outside today’s capabilities.",
    "summary": "We’re releasing an analysis showing that since 2012, the amount of compute used in the largest AI training runs has been increasing exponentially with a 3.4-month doubling time (by comparison, Moore’s Law had a 2-year doubling period)[^footnote-correction]. Since 2012, this metric has grown by more than 300,000x (a 2-year doubling period would yield only a 7x increase). Improvements in compute have been a key component of AI progress, so as long as this trend continues, it’s worth preparing for the implications of systems far outside today’s capabilities.",
    "pubDate": "Wed, 16 May 2018 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/ai-and-compute",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Gym Retro",
    "description": "We’re releasing the full version of Gym Retro, a platform for reinforcement learning research on games. This brings our publicly-released game count from around 70 Atari games and 30 Sega games to over 1,000 games across a variety of backing emulators. We’re also releasing the tool we use to add new games to the platform.",
    "summary": "We’re releasing the full version of Gym Retro, a platform for reinforcement learning research on games. This brings our publicly-released game count from around 70 Atari games and 30 Sega games to over 1,000 games across a variety of backing emulators. We’re also releasing the tool we use to add new games to the platform.",
    "pubDate": "Fri, 25 May 2018 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/gym-retro",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "OpenAI Fellows Fall 2018",
    "description": "We’re now accepting applications for the next cohort of OpenAI Fellows, a program which offers a compensated 6-month apprenticeship in AI research at OpenAI.",
    "summary": "We’re now accepting applications for the next cohort of OpenAI Fellows, a program which offers a compensated 6-month apprenticeship in AI research at OpenAI.",
    "pubDate": "Wed, 30 May 2018 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-fellows",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "GamePad: A learning environment for theorem proving",
    "description": "",
    "summary": "",
    "pubDate": "Sat, 02 Jun 2018 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/gamepad",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Improving language understanding with unsupervised learning",
    "description": "We’ve obtained state-of-the-art results on a suite of diverse language tasks with a scalable, task-agnostic system, which we’re also releasing. Our approach is a combination of two existing ideas: transformers and unsupervised pre-training. These results provide a convincing example that pairing supervised learning methods with unsupervised pre-training works very well; this is an idea that many have explored in the past, and we hope our result motivates further research into applying this idea on larger and more diverse datasets.",
    "summary": "We’ve obtained state-of-the-art results on a suite of diverse language tasks with a scalable, task-agnostic system, which we’re also releasing. Our approach is a combination of two existing ideas: transformers and unsupervised pre-training. These results provide a convincing example that pairing supervised learning methods with unsupervised pre-training works very well; this is an idea that many have explored in the past, and we hope our result motivates further research into applying this idea on larger and more diverse datasets.",
    "pubDate": "Mon, 11 Jun 2018 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/language-unsupervised",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Learning policy representations in multiagent systems",
    "description": "",
    "summary": "",
    "pubDate": "Sun, 17 Jun 2018 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/learning-policy-representations-in-multiagent-systems",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Retro Contest: Results",
    "description": "The first run of our Retro Contest—exploring the development of algorithms that can generalize from previous experience—is now complete.",
    "summary": "The first run of our Retro Contest—exploring the development of algorithms that can generalize from previous experience—is now complete.",
    "pubDate": "Fri, 22 Jun 2018 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/retro-contest-results",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "OpenAI Five",
    "description": "Our team of five neural networks, OpenAI Five, has started to defeat amateur human teams at Dota 2.",
    "summary": "Our team of five neural networks, OpenAI Five, has started to defeat amateur human teams at Dota 2.",
    "pubDate": "Mon, 25 Jun 2018 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-five",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Learning Montezuma’s Revenge from a single demonstration",
    "description": "We’ve trained an agent to achieve a high score of 74,500 on Montezuma’s Revenge from a single human demonstration, better than any previously published result. Our algorithm is simple: the agent plays a sequence of games starting from carefully chosen states from the demonstration, and learns from them by optimizing the game score using PPO, the same reinforcement learning algorithm that underpins OpenAI Five.",
    "summary": "We’ve trained an agent to achieve a high score of 74,500 on Montezuma’s Revenge from a single human demonstration, better than any previously published result. Our algorithm is simple: the agent plays a sequence of games starting from carefully chosen states from the demonstration, and learns from them by optimizing the game score using PPO, the same reinforcement learning algorithm that underpins OpenAI Five.",
    "pubDate": "Wed, 04 Jul 2018 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/learning-montezumas-revenge-from-a-single-demonstration",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Glow: Better reversible generative models",
    "description": "We introduce Glow, a reversible generative model which uses invertible 1x1 convolutions. It extends previous work on reversible generative models and simplifies the architecture. Our model can generate realistic high resolution images, supports efficient sampling, and discovers features that can be used to manipulate attributes of data. We’re releasing code for the model and an online visualization tool so people can explore and build on these results.",
    "summary": "We introduce Glow, a reversible generative model which uses invertible 1x1 convolutions. It extends previous work on reversible generative models and simplifies the architecture. Our model can generate realistic high resolution images, supports efficient sampling, and discovers features that can be used to manipulate attributes of data. We’re releasing code for the model and an online visualization tool so people can explore and build on these results.",
    "pubDate": "Mon, 09 Jul 2018 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/glow",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "OpenAI Five Benchmark",
    "description": "The OpenAI Five Benchmark match is now over!",
    "summary": "The OpenAI Five Benchmark match is now over!",
    "pubDate": "Wed, 18 Jul 2018 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-five-benchmark",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "OpenAI Scholars 2018: Meet our Scholars",
    "description": "Our first class of OpenAI Scholars is underway, and you can now follow along as this group of experienced software developers becomes machine learning practitioners.",
    "summary": "Our first class of OpenAI Scholars is underway, and you can now follow along as this group of experienced software developers becomes machine learning practitioners.",
    "pubDate": "Wed, 25 Jul 2018 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-scholars-2018-meet-our-scholars",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Variational option discovery algorithms",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 26 Jul 2018 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/variational-option-discovery-algorithms",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Learning dexterity",
    "description": "We’ve trained a human-like robot hand to manipulate physical objects with unprecedented dexterity.",
    "summary": "We’ve trained a human-like robot hand to manipulate physical objects with unprecedented dexterity.",
    "pubDate": "Mon, 30 Jul 2018 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/learning-dexterity",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "OpenAI Five Benchmark: Results",
    "description": "Yesterday, OpenAI Five won a best-of-three against a team of 99.95th percentile Dota players: Blitz, Cap, Fogged, Merlini, and MoonMeander—four of whom have played Dota professionally—in front of a live audience and 100,000 concurrent livestream viewers.",
    "summary": "Yesterday, OpenAI Five won a best-of-three against a team of 99.95th percentile Dota players: Blitz, Cap, Fogged, Merlini, and MoonMeander—four of whom have played Dota professionally—in front of a live audience and 100,000 concurrent livestream viewers.",
    "pubDate": "Mon, 06 Aug 2018 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-five-benchmark-results",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Large-scale study of curiosity-driven learning",
    "description": "",
    "summary": "",
    "pubDate": "Mon, 13 Aug 2018 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/large-scale-study-of-curiosity-driven-learning",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "The International 2018: Results",
    "description": "OpenAI Five lost two games against top Dota 2 players at The International in Vancouver this week, maintaining a good chance of winning for the first 20–35 minutes of both games.",
    "summary": "OpenAI Five lost two games against top Dota 2 players at The International in Vancouver this week, maintaining a good chance of winning for the first 20–35 minutes of both games.",
    "pubDate": "Thu, 23 Aug 2018 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/the-international-2018-results",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "OpenAI Scholars 2018: Final projects",
    "description": "Our first cohort of OpenAI Scholars has now completed the program.",
    "summary": "Our first cohort of OpenAI Scholars has now completed the program.",
    "pubDate": "Mon, 10 Sep 2018 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-scholars-2018-final-projects",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "FFJORD: Free-form continuous dynamics for scalable reversible generative models",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 02 Oct 2018 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/ffjord",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "OpenAI Fellows Winter 2019 & Interns Summer 2019",
    "description": "We are now accepting applications for OpenAI Fellows and Interns for 2019.",
    "summary": "We are now accepting applications for OpenAI Fellows and Interns for 2019.",
    "pubDate": "Tue, 09 Oct 2018 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-fellows-interns-2019",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "OpenAI Scholars 2019: Applications open",
    "description": "We are now accepting applications for our second cohort of OpenAI Scholars, a program where we provide 6–10 stipends and mentorship to individuals from underrepresented groups to study deep learning full-time for 3 months and open-source a project.",
    "summary": "We are now accepting applications for our second cohort of OpenAI Scholars, a program where we provide 6–10 stipends and mentorship to individuals from underrepresented groups to study deep learning full-time for 3 months and open-source a project.",
    "pubDate": "Thu, 11 Oct 2018 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-scholars-2019",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Learning complex goals with iterated amplification",
    "description": "We’re proposing an AI safety technique called iterated amplification that lets us specify complicated behaviors and goals that are beyond human scale, by demonstrating how to decompose a task into simpler sub-tasks, rather than by providing labeled data or a reward function. Although this idea is in its very early stages and we have only completed experiments on simple toy algorithmic domains, we’ve decided to present it in its preliminary state because we think it could prove to be a scalable approach to AI safety.",
    "summary": "We’re proposing an AI safety technique called iterated amplification that lets us specify complicated behaviors and goals that are beyond human scale, by demonstrating how to decompose a task into simpler sub-tasks, rather than by providing labeled data or a reward function. Although this idea is in its very early stages and we have only completed experiments on simple toy algorithmic domains, we’ve decided to present it in its preliminary state because we think it could prove to be a scalable approach to AI safety.",
    "pubDate": "Mon, 22 Oct 2018 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/learning-complex-goals-with-iterated-amplification",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Reinforcement learning with prediction-based rewards",
    "description": "We’ve developed Random Network Distillation (RND), a prediction-based method for encouraging reinforcement learning agents to explore their environments through curiosity, which for the first time exceeds average human performance on Montezuma’s Revenge.",
    "summary": "We’ve developed Random Network Distillation (RND), a prediction-based method for encouraging reinforcement learning agents to explore their environments through curiosity, which for the first time exceeds average human performance on Montezuma’s Revenge.",
    "pubDate": "Wed, 31 Oct 2018 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/reinforcement-learning-with-prediction-based-rewards",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Plan online, learn offline: Efficient learning and exploration via model-based control",
    "description": "",
    "summary": "",
    "pubDate": "Mon, 05 Nov 2018 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/plan-online-learn-offline",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Learning concepts with energy functions",
    "description": "We’ve developed an energy-based model that can quickly learn to identify and generate instances of concepts, such as near, above, between, closest, and furthest, expressed as sets of 2d points. Our model learns these concepts after only five demonstrations. We also show cross-domain transfer: we use concepts learned in a 2d particle environment to solve tasks on a 3-dimensional physics-based robot.",
    "summary": "We’ve developed an energy-based model that can quickly learn to identify and generate instances of concepts, such as near, above, between, closest, and furthest, expressed as sets of 2d points. Our model learns these concepts after only five demonstrations. We also show cross-domain transfer: we use concepts learned in a 2d particle environment to solve tasks on a 3-dimensional physics-based robot.",
    "pubDate": "Wed, 07 Nov 2018 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/learning-concepts-with-energy-functions",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Spinning Up in Deep RL",
    "description": "We’re releasing Spinning Up in Deep RL, an educational resource designed to let anyone learn to become a skilled practitioner in deep reinforcement learning. Spinning Up consists of crystal-clear examples of RL code, educational exercises, documentation, and tutorials.",
    "summary": "We’re releasing Spinning Up in Deep RL, an educational resource designed to let anyone learn to become a skilled practitioner in deep reinforcement learning. Spinning Up consists of crystal-clear examples of RL code, educational exercises, documentation, and tutorials.",
    "pubDate": "Thu, 08 Nov 2018 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/spinning-up-in-deep-rl",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Quantifying generalization in reinforcement learning",
    "description": "We’re releasing CoinRun, a training environment which provides a metric for an agent’s ability to transfer its experience to novel situations and has already helped clarify a longstanding puzzle in reinforcement learning. CoinRun strikes a desirable balance in complexity: the environment is simpler than traditional platformer games like Sonic the Hedgehog but still poses a worthy generalization challenge for state of the art algorithms.",
    "summary": "We’re releasing CoinRun, a training environment which provides a metric for an agent’s ability to transfer its experience to novel situations and has already helped clarify a longstanding puzzle in reinforcement learning. CoinRun strikes a desirable balance in complexity: the environment is simpler than traditional platformer games like Sonic the Hedgehog but still poses a worthy generalization challenge for state of the art algorithms.",
    "pubDate": "Thu, 06 Dec 2018 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/quantifying-generalization-in-reinforcement-learning",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "How AI training scales",
    "description": "We’ve discovered that the gradient noise scale, a simple statistical metric, predicts the parallelizability of neural network training on a wide range of tasks. Since complex tasks tend to have noisier gradients, increasingly large batch sizes are likely to become useful in the future, removing one potential limit to further growth of AI systems. More broadly, these results show that neural network training need not be considered a mysterious art, but can be rigorized and systematized.",
    "summary": "We’ve discovered that the gradient noise scale, a simple statistical metric, predicts the parallelizability of neural network training on a wide range of tasks. Since complex tasks tend to have noisier gradients, increasingly large batch sizes are likely to become useful in the future, removing one potential limit to further growth of AI systems. More broadly, these results show that neural network training need not be considered a mysterious art, but can be rigorized and systematized.",
    "pubDate": "Fri, 14 Dec 2018 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/how-ai-training-scales",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "OpenAI Fellows Summer 2018: Final projects",
    "description": "Our first cohort of OpenAI Fellows has concluded, with each Fellow going from a machine learning beginner to core OpenAI contributor in the course of a 6-month apprenticeship.",
    "summary": "Our first cohort of OpenAI Fellows has concluded, with each Fellow going from a machine learning beginner to core OpenAI contributor in the course of a 6-month apprenticeship.",
    "pubDate": "Wed, 19 Dec 2018 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-summer-fellows-2018",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Computational limitations in robust classification and win-win results",
    "description": "",
    "summary": "",
    "pubDate": "Mon, 04 Feb 2019 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/computational-limitations-in-robust-classification-and-win-win-results",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Better language models and their implications",
    "description": "We’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task-specific training.",
    "summary": "We’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task-specific training.",
    "pubDate": "Thu, 14 Feb 2019 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/better-language-models",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "AI safety needs social scientists",
    "description": "We’ve written a paper arguing that long-term AI safety research needs social scientists to ensure AI alignment algorithms succeed when actual humans are involved. Properly aligning advanced AI systems with human values requires resolving many uncertainties related to the psychology of human rationality, emotion, and biases. The aim of this paper is to spark further collaboration between machine learning and social science researchers, and we plan to hire social scientists to work on this full time at OpenAI.",
    "summary": "We’ve written a paper arguing that long-term AI safety research needs social scientists to ensure AI alignment algorithms succeed when actual humans are involved. Properly aligning advanced AI systems with human values requires resolving many uncertainties related to the psychology of human rationality, emotion, and biases. The aim of this paper is to spark further collaboration between machine learning and social science researchers, and we plan to hire social scientists to work on this full time at OpenAI.",
    "pubDate": "Tue, 19 Feb 2019 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/ai-safety-needs-social-scientists",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Spinning Up in Deep RL: Workshop review",
    "description": "On February 2, we held our first Spinning Up Workshop as part of our new education initiative at OpenAI.",
    "summary": "On February 2, we held our first Spinning Up Workshop as part of our new education initiative at OpenAI.",
    "pubDate": "Tue, 26 Feb 2019 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/spinning-up-in-deep-rl-workshop-review",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Neural MMO: A massively multiagent game environment",
    "description": "We’re releasing a Neural MMO, a massively multiagent game environment for reinforcement learning agents. Our platform supports a large, variable number of agents within a persistent and open-ended task. The inclusion of many agents and species leads to better exploration, divergent niche formation, and greater overall competence.",
    "summary": "We’re releasing a Neural MMO, a massively multiagent game environment for reinforcement learning agents. Our platform supports a large, variable number of agents within a persistent and open-ended task. The inclusion of many agents and species leads to better exploration, divergent niche formation, and greater overall competence.",
    "pubDate": "Mon, 04 Mar 2019 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/neural-mmo",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Introducing Activation Atlases",
    "description": "We’ve created activation atlases (in collaboration with Google researchers), a new technique for visualizing what interactions between neurons can represent. As AI systems are deployed in increasingly sensitive contexts, having a better understanding of their internal decision-making processes will let us identify weaknesses and investigate failures.",
    "summary": "We’ve created activation atlases (in collaboration with Google researchers), a new technique for visualizing what interactions between neurons can represent. As AI systems are deployed in increasingly sensitive contexts, having a better understanding of their internal decision-making processes will let us identify weaknesses and investigate failures.",
    "pubDate": "Wed, 06 Mar 2019 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-activation-atlases",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "OpenAI LP",
    "description": "We’ve created OpenAI LP, a new “capped-profit” company that allows us to rapidly increase our investments in compute and talent while including checks and balances to actualize our mission.",
    "summary": "We’ve created OpenAI LP, a new “capped-profit” company that allows us to rapidly increase our investments in compute and talent while including checks and balances to actualize our mission.",
    "pubDate": "Mon, 11 Mar 2019 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-lp",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "OpenAI Scholars 2019: Meet our Scholars",
    "description": "Our class of eight scholars (out of 550 applicants) brings together collective expertise in literature, philosophy, cell biology, statistics, economics, quantum physics, and business innovation.",
    "summary": "Our class of eight scholars (out of 550 applicants) brings together collective expertise in literature, philosophy, cell biology, statistics, economics, quantum physics, and business innovation.",
    "pubDate": "Wed, 13 Mar 2019 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-scholars-2019-meet-our-scholars",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Implicit generation and generalization methods for energy-based models",
    "description": "We’ve made progress towards stable and scalable training of energy-based models (EBMs) resulting in better sample quality and generalization ability than existing models. Generation in EBMs spends more compute to continually refine its answers and doing so can generate samples competitive with GANs at low temperatures, while also having mode coverage guarantees of likelihood-based models. We hope these findings stimulate further research into this promising class of models.",
    "summary": "We’ve made progress towards stable and scalable training of energy-based models (EBMs) resulting in better sample quality and generalization ability than existing models. Generation in EBMs spends more compute to continually refine its answers and doing so can generate samples competitive with GANs at low temperatures, while also having mode coverage guarantees of likelihood-based models. We hope these findings stimulate further research into this promising class of models.",
    "pubDate": "Thu, 21 Mar 2019 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/energy-based-models",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "OpenAI Five Finals",
    "description": "We’ll be holding our final live event for OpenAI Five at 11:30am PT on April 13.",
    "summary": "We’ll be holding our final live event for OpenAI Five at 11:30am PT on April 13.",
    "pubDate": "Tue, 26 Mar 2019 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-five-finals",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "OpenAI Five defeats Dota 2 world champions",
    "description": "OpenAI Five is the first AI to beat the world champions in an esports game, having won two back-to-back games versus the world champion Dota 2 team, OG, at Finals this weekend. Both OpenAI Five and DeepMind’s AlphaStar had previously beaten good pros privately but lost their live pro matches, making this also the first time an AI has beaten esports pros on livestream.",
    "summary": "OpenAI Five is the first AI to beat the world champions in an esports game, having won two back-to-back games versus the world champion Dota 2 team, OG, at Finals this weekend. Both OpenAI Five and DeepMind’s AlphaStar had previously beaten good pros privately but lost their live pro matches, making this also the first time an AI has beaten esports pros on livestream.",
    "pubDate": "Mon, 15 Apr 2019 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-five-defeats-dota-2-world-champions",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Generative modeling with sparse transformers",
    "description": "We’ve developed the Sparse Transformer, a deep neural network which sets new records at predicting what comes next in a sequence—whether text, images, or sound. It uses an algorithmic improvement of the attention mechanism to extract patterns from sequences 30x longer than possible previously.",
    "summary": "We’ve developed the Sparse Transformer, a deep neural network which sets new records at predicting what comes next in a sequence—whether text, images, or sound. It uses an algorithmic improvement of the attention mechanism to extract patterns from sequences 30x longer than possible previously.",
    "pubDate": "Tue, 23 Apr 2019 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/sparse-transformer",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "MuseNet",
    "description": "We’ve created MuseNet, a deep neural network that can generate 4-minute musical compositions with 10 different instruments, and can combine styles from country to Mozart to the Beatles. MuseNet was not explicitly programmed with our understanding of music, but instead discovered patterns of harmony, rhythm, and style by learning to predict the next token in hundreds of thousands of MIDI files. MuseNet uses the same general-purpose unsupervised technology as GPT-2, a large-scale transformer model trained to predict the next token in a sequence, whether audio or text.",
    "summary": "We’ve created MuseNet, a deep neural network that can generate 4-minute musical compositions with 10 different instruments, and can combine styles from country to Mozart to the Beatles. MuseNet was not explicitly programmed with our understanding of music, but instead discovered patterns of harmony, rhythm, and style by learning to predict the next token in hundreds of thousands of MIDI files. MuseNet uses the same general-purpose unsupervised technology as GPT-2, a large-scale transformer model trained to predict the next token in a sequence, whether audio or text.",
    "pubDate": "Thu, 25 Apr 2019 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/musenet",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Transfer of adversarial robustness between perturbation types",
    "description": "",
    "summary": "",
    "pubDate": "Fri, 03 May 2019 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/transfer-of-adversarial-robustness-between-perturbation-types",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "OpenAI Fellows Fall 2018: Final projects",
    "description": "Our second class of OpenAI Fellows has wrapped up, with each Fellow going from a machine learning beginner to core OpenAI contributor in the course of a 6-month apprenticeship. We are currently reviewing applications on a rolling basis for our next round of OpenAI Fellows Summer 2019.",
    "summary": "Our second class of OpenAI Fellows has wrapped up, with each Fellow going from a machine learning beginner to core OpenAI contributor in the course of a 6-month apprenticeship. We are currently reviewing applications on a rolling basis for our next round of OpenAI Fellows Summer 2019.",
    "pubDate": "Fri, 17 May 2019 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-fellows-fall-2018",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "OpenAI Scholars 2019: Final projects",
    "description": "Our second class of OpenAI Scholars has concluded, with all eight scholars producing an exciting final project showcased at Scholars Demo Day at OpenAI.",
    "summary": "Our second class of OpenAI Scholars has concluded, with all eight scholars producing an exciting final project showcased at Scholars Demo Day at OpenAI.",
    "pubDate": "Thu, 23 May 2019 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-scholars-2019-final-projects",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "OpenAI Robotics Symposium 2019",
    "description": "We hosted the first OpenAI Robotics Symposium on April 27, 2019.",
    "summary": "We hosted the first OpenAI Robotics Symposium on April 27, 2019.",
    "pubDate": "Wed, 05 Jun 2019 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/symposium-2019",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Why responsible AI development needs cooperation on safety",
    "description": "We’ve written a policy research paper identifying four strategies that can be used today to improve the likelihood of long-term industry cooperation on safety norms in AI: communicating risks and benefits, technical collaboration, increased transparency, and incentivizing standards. Our analysis shows that industry cooperation on safety will be instrumental in ensuring that AI systems are safe and beneficial, but competitive pressures could lead to a collective action problem, potentially causing AI companies to under-invest in safety. We hope these strategies will encourage greater cooperation on the safe development of AI and lead to better global outcomes of AI.",
    "summary": "We’ve written a policy research paper identifying four strategies that can be used today to improve the likelihood of long-term industry cooperation on safety norms in AI: communicating risks and benefits, technical collaboration, increased transparency, and incentivizing standards. Our analysis shows that industry cooperation on safety will be instrumental in ensuring that AI systems are safe and beneficial, but competitive pressures could lead to a collective action problem, potentially causing AI companies to under-invest in safety. We hope these strategies will encourage greater cooperation on the safe development of AI and lead to better global outcomes of AI.",
    "pubDate": "Wed, 10 Jul 2019 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/cooperation-on-safety",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Microsoft invests in and partners with OpenAI to support us building beneficial AGI",
    "description": "Microsoft is investing $1 billion in OpenAI to support us building artificial general intelligence (AGI) with widely distributed economic benefits. We’re partnering to develop a hardware and software platform within Microsoft Azure which will scale to AGI. We’ll jointly develop new Azure AI supercomputing technologies, and Microsoft will become our exclusive cloud provider—so we’ll be working hard together to further extend Microsoft Azure’s capabilities in large-scale AI systems.",
    "summary": "Microsoft is investing $1 billion in OpenAI to support us building artificial general intelligence (AGI) with widely distributed economic benefits. We’re partnering to develop a hardware and software platform within Microsoft Azure which will scale to AGI. We’ll jointly develop new Azure AI supercomputing technologies, and Microsoft will become our exclusive cloud provider—so we’ll be working hard together to further extend Microsoft Azure’s capabilities in large-scale AI systems.",
    "pubDate": "Mon, 22 Jul 2019 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/microsoft-invests-in-and-partners-with-openai",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Learning Day",
    "description": "At OpenAI, each Thursday is Learning Day: a day where employees have the option to self-study technical skills that will make them better at their job but which aren’t being learned from daily work.",
    "summary": "At OpenAI, each Thursday is Learning Day: a day where employees have the option to self-study technical skills that will make them better at their job but which aren’t being learned from daily work.",
    "pubDate": "Thu, 01 Aug 2019 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/learning-day",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "GPT-2: 6-month follow-up",
    "description": "We’re releasing the 774 million parameter GPT-2 language model after the release of our small 124M model in February, staged release of our medium 355M model in May, and subsequent research with partners and the AI community into the model’s potential for misuse and societal benefit. We’re also releasing an open-source legal agreement to make it easier for organizations to initiate model-sharing partnerships with each other, and are publishing a technical report about our experience in coordinating with the wider AI research community on publication norms.",
    "summary": "We’re releasing the 774 million parameter GPT-2 language model after the release of our small 124M model in February, staged release of our medium 355M model in May, and subsequent research with partners and the AI community into the model’s potential for misuse and societal benefit. We’re also releasing an open-source legal agreement to make it easier for organizations to initiate model-sharing partnerships with each other, and are publishing a technical report about our experience in coordinating with the wider AI research community on publication norms.",
    "pubDate": "Tue, 20 Aug 2019 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/gpt-2-6-month-follow-up",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Testing robustness against unforeseen adversaries",
    "description": "We’ve developed a method to assess whether a neural network classifier can reliably defend against adversarial attacks not seen during training. Our method yields a new metric, UAR (Unforeseen Attack Robustness), which evaluates the robustness of a single model against an unanticipated attack, and highlights the need to measure performance across a more diverse range of unforeseen attacks.",
    "summary": "We’ve developed a method to assess whether a neural network classifier can reliably defend against adversarial attacks not seen during training. Our method yields a new metric, UAR (Unforeseen Attack Robustness), which evaluates the robustness of a single model against an unanticipated attack, and highlights the need to measure performance across a more diverse range of unforeseen attacks.",
    "pubDate": "Thu, 22 Aug 2019 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/testing-robustness",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Emergent tool use from multi-agent interaction",
    "description": "We’ve observed agents discovering progressively more complex tool use while playing a simple game of hide-and-seek. Through training in our new simulated hide-and-seek environment, agents build a series of six distinct strategies and counterstrategies, some of which we did not know our environment supported. The self-supervised emergent complexity in this simple environment further suggests that multi-agent co-adaptation may one day produce extremely complex and intelligent behavior.",
    "summary": "We’ve observed agents discovering progressively more complex tool use while playing a simple game of hide-and-seek. Through training in our new simulated hide-and-seek environment, agents build a series of six distinct strategies and counterstrategies, some of which we did not know our environment supported. The self-supervised emergent complexity in this simple environment further suggests that multi-agent co-adaptation may one day produce extremely complex and intelligent behavior.",
    "pubDate": "Tue, 17 Sep 2019 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/emergent-tool-use",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Fine-tuning GPT-2 from human preferences",
    "description": "We’ve fine-tuned the 774M parameter GPT-2 language model using human feedback for various tasks, successfully matching the preferences of the external human labelers, though those preferences did not always match our own. Specifically, for summarization tasks the labelers preferred sentences copied wholesale from the input (we’d only asked them to ensure accuracy), so our models learned to copy. Summarization required 60k human labels; simpler tasks which continue text in various styles required only 5k. Our motivation is to move safety techniques closer to the general task of “machines talking to humans,” which we believe is key to extracting information about human values.",
    "summary": "We’ve fine-tuned the 774M parameter GPT-2 language model using human feedback for various tasks, successfully matching the preferences of the external human labelers, though those preferences did not always match our own. Specifically, for summarization tasks the labelers preferred sentences copied wholesale from the input (we’d only asked them to ensure accuracy), so our models learned to copy. Summarization required 60k human labels; simpler tasks which continue text in various styles required only 5k. Our motivation is to move safety techniques closer to the general task of “machines talking to humans,” which we believe is key to extracting information about human values.",
    "pubDate": "Thu, 19 Sep 2019 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/fine-tuning-gpt-2",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "OpenAI Scholars 2020: Applications open",
    "description": "We are now accepting applications for our third class of OpenAI Scholars.",
    "summary": "We are now accepting applications for our third class of OpenAI Scholars.",
    "pubDate": "Fri, 11 Oct 2019 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-scholars-2020",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Solving Rubik’s Cube with a robot hand",
    "description": "We’ve trained a pair of neural networks to solve the Rubik’s Cube with a human-like robot hand. The neural networks are trained entirely in simulation, using the same reinforcement learning code as OpenAI Five paired with a new technique called Automatic Domain Randomization (ADR). The system can handle situations it never saw during training, such as being prodded by a stuffed giraffe. This shows that reinforcement learning isn’t just a tool for virtual tasks, but can solve physical-world problems requiring unprecedented dexterity.",
    "summary": "We’ve trained a pair of neural networks to solve the Rubik’s Cube with a human-like robot hand. The neural networks are trained entirely in simulation, using the same reinforcement learning code as OpenAI Five paired with a new technique called Automatic Domain Randomization (ADR). The system can handle situations it never saw during training, such as being prodded by a stuffed giraffe. This shows that reinforcement learning isn’t just a tool for virtual tasks, but can solve physical-world problems requiring unprecedented dexterity.",
    "pubDate": "Tue, 15 Oct 2019 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/solving-rubiks-cube",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "GPT-2: 1.5B release",
    "description": "As the final model release of GPT-2’s staged release, we’re releasing the largest version (1.5B parameters) of GPT-2 along with code and model weights to facilitate detection of outputs of GPT-2 models. While there have been larger language models released since August, we’ve continued with our original staged release plan in order to provide the community with a test case of a full staged release process. We hope that this test case will be useful to developers of future powerful models, and we’re actively continuing the conversation with the AI community on responsible publication.",
    "summary": "As the final model release of GPT-2’s staged release, we’re releasing the largest version (1.5B parameters) of GPT-2 along with code and model weights to facilitate detection of outputs of GPT-2 models. While there have been larger language models released since August, we’ve continued with our original staged release plan in order to provide the community with a test case of a full staged release process. We hope that this test case will be useful to developers of future powerful models, and we’re actively continuing the conversation with the AI community on responsible publication.",
    "pubDate": "Tue, 05 Nov 2019 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/gpt-2-1-5b-release",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Benchmarking safe exploration in deep reinforcement learning",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 21 Nov 2019 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/benchmarking-safe-exploration-in-deep-reinforcement-learning",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Safety Gym",
    "description": "We’re releasing Safety Gym, a suite of environments and tools for measuring progress towards reinforcement learning agents that respect safety constraints while training.",
    "summary": "We’re releasing Safety Gym, a suite of environments and tools for measuring progress towards reinforcement learning agents that respect safety constraints while training.",
    "pubDate": "Thu, 21 Nov 2019 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/safety-gym",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Procgen Benchmark",
    "description": "We’re releasing Procgen Benchmark, 16 simple-to-use procedurally-generated environments which provide a direct measure of how quickly a reinforcement learning agent learns generalizable skills.",
    "summary": "We’re releasing Procgen Benchmark, 16 simple-to-use procedurally-generated environments which provide a direct measure of how quickly a reinforcement learning agent learns generalizable skills.",
    "pubDate": "Tue, 03 Dec 2019 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/procgen-benchmark",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Deep double descent",
    "description": "We show that the double descent phenomenon occurs in CNNs, ResNets, and transformers: performance first improves, then gets worse, and then improves again with increasing model size, data size, or training time. This effect is often avoided through careful regularization. While this behavior appears to be fairly universal, we don’t yet fully understand why it happens, and view further study of this phenomenon as an important research direction.",
    "summary": "We show that the double descent phenomenon occurs in CNNs, ResNets, and transformers: performance first improves, then gets worse, and then improves again with increasing model size, data size, or training time. This effect is often avoided through careful regularization. While this behavior appears to be fairly universal, we don’t yet fully understand why it happens, and view further study of this phenomenon as an important research direction.",
    "pubDate": "Thu, 05 Dec 2019 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/deep-double-descent",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Dota 2 with large scale deep reinforcement learning",
    "description": "",
    "summary": "",
    "pubDate": "Fri, 13 Dec 2019 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/dota-2-with-large-scale-deep-reinforcement-learning",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Scaling laws for neural language models",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 23 Jan 2020 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/scaling-laws-for-neural-language-models",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "OpenAI standardizes on PyTorch",
    "description": "We are standardizing OpenAI’s deep learning framework on PyTorch.",
    "summary": "We are standardizing OpenAI’s deep learning framework on PyTorch.",
    "pubDate": "Thu, 30 Jan 2020 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-pytorch",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "How to train a new language model from scratch using Transformers and Tokenizers",
    "description": "",
    "summary": "",
    "pubDate": "Fri, 14 Feb 2020 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/how-to-train",
    "thumbnail": "https://huggingface.co/blog/assets/01_how-to-train/how-to-train_blogpost.png"
  },
  {
    "title": "How to generate text: using different decoding methods for language generation with Transformers",
    "description": "",
    "summary": "",
    "pubDate": "Sun, 01 Mar 2020 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/how-to-generate",
    "thumbnail": "https://huggingface.co/blog/assets/02_how-to-generate/thumbnail.png"
  },
  {
    "title": "OpenAI Microscope",
    "description": "We’re introducing OpenAI Microscope, a collection of visualizations of every significant layer and neuron of eight vision “model organisms” which are often studied in interpretability. Microscope makes it easier to analyze the features that form inside these neural networks, and we hope it will help the research community as we move towards understanding these complicated systems.",
    "summary": "We’re introducing OpenAI Microscope, a collection of visualizations of every significant layer and neuron of eight vision “model organisms” which are often studied in interpretability. Microscope makes it easier to analyze the features that form inside these neural networks, and we hope it will help the research community as we move towards understanding these complicated systems.",
    "pubDate": "Tue, 14 Apr 2020 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/microscope",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Improving verifiability in AI development",
    "description": "We’ve contributed to a multi-stakeholder report by 58 co-authors at 30 organizations, including the Centre for the Future of Intelligence, Mila, Schwartz Reisman Institute for Technology and Society, Center for Advanced Study in the Behavioral Sciences, and Center for Security and Emerging Technologies. This report describes 10 mechanisms to improve the verifiability of claims made about AI systems. Developers can use these tools to provide evidence that AI systems are safe, secure, fair, or privacy-preserving. Users, policymakers, and civil society can use these tools to evaluate AI development processes.",
    "summary": "We’ve contributed to a multi-stakeholder report by 58 co-authors at 30 organizations, including the Centre for the Future of Intelligence, Mila, Schwartz Reisman Institute for Technology and Society, Center for Advanced Study in the Behavioral Sciences, and Center for Security and Emerging Technologies. This report describes 10 mechanisms to improve the verifiability of claims made about AI systems. Developers can use these tools to provide evidence that AI systems are safe, secure, fair, or privacy-preserving. Users, policymakers, and civil society can use these tools to evaluate AI development processes.",
    "pubDate": "Thu, 16 Apr 2020 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/improving-verifiability",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Jukebox",
    "description": "We’re introducing Jukebox, a neural net that generates music, including rudimentary singing, as raw audio in a variety of genres and artist styles. We’re releasing the model weights and code, along with a tool to explore the generated samples.",
    "summary": "We’re introducing Jukebox, a neural net that generates music, including rudimentary singing, as raw audio in a variety of genres and artist styles. We’re releasing the model weights and code, along with a tool to explore the generated samples.",
    "pubDate": "Thu, 30 Apr 2020 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/jukebox",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "AI and efficiency",
    "description": "We’re releasing an analysis showing that since 2012 the amount of compute needed to train a neural net to the same performance on ImageNet classification has been decreasing by a factor of 2 every 16 months. Compared to 2012, it now takes 44 times less compute to train a neural network to the level of AlexNet (by contrast, Moore’s Law would yield an 11x cost improvement over this period). Our results suggest that for AI tasks with high levels of recent investment, algorithmic progress has yielded more gains than classical hardware efficiency.",
    "summary": "We’re releasing an analysis showing that since 2012 the amount of compute needed to train a neural net to the same performance on ImageNet classification has been decreasing by a factor of 2 every 16 months. Compared to 2012, it now takes 44 times less compute to train a neural network to the level of AlexNet (by contrast, Moore’s Law would yield an 11x cost improvement over this period). Our results suggest that for AI tasks with high levels of recent investment, algorithmic progress has yielded more gains than classical hardware efficiency.",
    "pubDate": "Tue, 05 May 2020 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/ai-and-efficiency",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Language models are few-shot learners",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 28 May 2020 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/language-models-are-few-shot-learners",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "OpenAI API",
    "description": "We’re releasing an API for accessing new AI models developed by OpenAI.",
    "summary": "We’re releasing an API for accessing new AI models developed by OpenAI.",
    "pubDate": "Thu, 11 Jun 2020 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-api",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Image GPT",
    "description": "We find that, just as a large transformer model trained on language can generate coherent text, the same exact model trained on pixel sequences can generate coherent image completions and samples. By establishing a correlation between sample quality and image classification accuracy, we show that our best generative model also contains features competitive with top convolutional nets in the unsupervised setting.",
    "summary": "We find that, just as a large transformer model trained on language can generate coherent text, the same exact model trained on pixel sequences can generate coherent image completions and samples. By establishing a correlation between sample quality and image classification accuracy, we show that our best generative model also contains features competitive with top convolutional nets in the unsupervised setting.",
    "pubDate": "Wed, 17 Jun 2020 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/image-gpt",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Procgen and MineRL Competitions",
    "description": "We’re excited to announce that OpenAI is co-organizing two NeurIPS 2020 competitions with AIcrowd, Carnegie Mellon University, and DeepMind, using Procgen Benchmark and MineRL.",
    "summary": "We’re excited to announce that OpenAI is co-organizing two NeurIPS 2020 competitions with AIcrowd, Carnegie Mellon University, and DeepMind, using Procgen Benchmark and MineRL.",
    "pubDate": "Sat, 20 Jun 2020 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/procgen-minerl-competitions",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "The Reformer - Pushing the limits of language modeling",
    "description": "",
    "summary": "",
    "pubDate": "Fri, 03 Jul 2020 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/reformer",
    "thumbnail": "https://huggingface.co/blog/assets/03_reformer/thumbnail.png"
  },
  {
    "title": "OpenAI Scholars 2020: Final projects",
    "description": "Our third class of OpenAI Scholars presented their final projects at virtual Demo Day, showcasing their research results from over the past five months.",
    "summary": "Our third class of OpenAI Scholars presented their final projects at virtual Demo Day, showcasing their research results from over the past five months.",
    "pubDate": "Thu, 09 Jul 2020 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-scholars-2020-final-projects",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Learning to summarize with human feedback",
    "description": "We’ve applied reinforcement learning from human feedback to train language models that are better at summarization.",
    "summary": "We’ve applied reinforcement learning from human feedback to train language models that are better at summarization.",
    "pubDate": "Fri, 04 Sep 2020 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/learning-to-summarize-with-human-feedback",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Generative language modeling for automated theorem proving",
    "description": "",
    "summary": "",
    "pubDate": "Mon, 07 Sep 2020 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/generative-language-modeling-for-automated-theorem-proving",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Block Sparse Matrices for Smaller and Faster Language Models",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 10 Sep 2020 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/pytorch_block_sparse",
    "thumbnail": "https://huggingface.co/blog/assets/04_pytorch_block_sparse/thumbnail.png"
  },
  {
    "title": "OpenAI licenses GPT-3 technology to Microsoft",
    "description": "OpenAI has agreed to license GPT-3 to Microsoft for their own products and services.",
    "summary": "OpenAI has agreed to license GPT-3 to Microsoft for their own products and services.",
    "pubDate": "Tue, 22 Sep 2020 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-licenses-gpt-3-technology-to-microsoft",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Transformer-based Encoder-Decoder Models",
    "description": "",
    "summary": "",
    "pubDate": "Sat, 10 Oct 2020 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/encoder-decoder",
    "thumbnail": "https://huggingface.co/blog/assets/05_encoder_decoder/thumbnail.png"
  },
  {
    "title": "Hyperparameter Search with Transformers and Ray Tune",
    "description": "",
    "summary": "",
    "pubDate": "Mon, 02 Nov 2020 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/ray-tune",
    "thumbnail": "https://huggingface.co/blog/assets/06_ray_tune/ray-hf.jpg"
  },
  {
    "title": "Porting fairseq wmt19 translation system to transformers",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 03 Nov 2020 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/porting-fsmt",
    "thumbnail": "https://huggingface.co/blog/assets/07_porting_fsmt/thumbnail.png"
  },
  {
    "title": "Leveraging Pre-trained Language Model Checkpoints for Encoder-Decoder Models",
    "description": "",
    "summary": "",
    "pubDate": "Mon, 09 Nov 2020 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/warm-starting-encoder-decoder",
    "thumbnail": "https://huggingface.co/blog/assets/08_warm_starting_encoder_decoder/thumbnail.png"
  },
  {
    "title": "Organizational update from OpenAI",
    "description": "It’s been a year of dramatic change and growth at OpenAI.",
    "summary": "It’s been a year of dramatic change and growth at OpenAI.",
    "pubDate": "Tue, 29 Dec 2020 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/organizational-update",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "CLIP: Connecting text and images",
    "description": "We’re introducing a neural network called CLIP which efficiently learns visual concepts from natural language supervision. CLIP can be applied to any visual classification benchmark by simply providing the names of the visual categories to be recognized, similar to the “zero-shot” capabilities of GPT-2 and GPT-3.",
    "summary": "We’re introducing a neural network called CLIP which efficiently learns visual concepts from natural language supervision. CLIP can be applied to any visual classification benchmark by simply providing the names of the visual categories to be recognized, similar to the “zero-shot” capabilities of GPT-2 and GPT-3.",
    "pubDate": "Tue, 05 Jan 2021 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/clip",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "DALL·E: Creating images from text",
    "description": "We’ve trained a neural network called DALL·E that creates images from text captions for a wide range of concepts expressible in natural language.",
    "summary": "We’ve trained a neural network called DALL·E that creates images from text captions for a wide range of concepts expressible in natural language.",
    "pubDate": "Tue, 05 Jan 2021 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/dall-e",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "How we sped up transformer inference 100x for 🤗 API customers",
    "description": "",
    "summary": "",
    "pubDate": "Mon, 18 Jan 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/accelerated-inference",
    "thumbnail": "https://huggingface.co/blog/assets/09_accelerated_inference/thumbnail.png"
  },
  {
    "title": "Fit More and Train Faster With ZeRO via DeepSpeed and FairScale",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 19 Jan 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/zero-deepspeed-fairscale",
    "thumbnail": "https://huggingface.co/blog/assets/11_zero_deepspeed_fairscale/zero-partitioning.png"
  },
  {
    "title": "Scaling Kubernetes to 7,500 nodes",
    "description": "We’ve scaled Kubernetes clusters to 7,500 nodes, producing a scalable infrastructure for large models like GPT-3, CLIP, and DALL·E, but also for rapid small-scale iterative research such as Scaling Laws for Neural Language Models.",
    "summary": "We’ve scaled Kubernetes clusters to 7,500 nodes, producing a scalable infrastructure for large models like GPT-3, CLIP, and DALL·E, but also for rapid small-scale iterative research such as Scaling Laws for Neural Language Models.",
    "pubDate": "Mon, 25 Jan 2021 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/scaling-kubernetes-to-7500-nodes",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Faster TensorFlow models in Hugging Face Transformers",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 26 Jan 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/tf-serving",
    "thumbnail": "https://huggingface.co/blog/assets/10_tf-serving/thumbnail.png"
  },
  {
    "title": "Understanding the capabilities, limitations, and societal impact of large language models",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 04 Feb 2021 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/understanding-the-capabilities-limitations-and-societal-impact-of-large-language-models",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Hugging Face on PyTorch / XLA TPUs",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 09 Feb 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/pytorch-xla",
    "thumbnail": "https://huggingface.co/blog/assets/13_pytorch_xla/pytorch_xla_thumbnail.png"
  },
  {
    "title": "Retrieval Augmented Generation with Huggingface Transformers and Ray",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 10 Feb 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/ray-rag",
    "thumbnail": "https://huggingface.co/blog/assets/12_ray_rag/ray_arch_updated.png"
  },
  {
    "title": "Simple considerations for simple people building fancy neural networks",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 25 Feb 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/simple-considerations",
    "thumbnail": "https://huggingface.co/blog/assets/13_simple-considerations/henry-co-3coKbdfnAFg-unsplash.jpg"
  },
  {
    "title": "Multimodal neurons in artificial neural networks",
    "description": "We’ve discovered neurons in CLIP that respond to the same concept whether presented literally, symbolically, or conceptually. This may explain CLIP’s accuracy in classifying surprising visual renditions of concepts, and is also an important step toward understanding the associations and biases that CLIP and similar models learn.",
    "summary": "We’ve discovered neurons in CLIP that respond to the same concept whether presented literally, symbolically, or conceptually. This may explain CLIP’s accuracy in classifying surprising visual renditions of concepts, and is also an important step toward understanding the associations and biases that CLIP and similar models learn.",
    "pubDate": "Thu, 04 Mar 2021 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/multimodal-neurons",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Hugging Face Reads, Feb. 2021 - Long-range Transformers",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 09 Mar 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/long-range-transformers",
    "thumbnail": "https://huggingface.co/blog/assets/14_long_range_transformers/EfficientTransformerTaxonomy.png"
  },
  {
    "title": "Fine-Tune Wav2Vec2 for English ASR with 🤗 Transformers",
    "description": "",
    "summary": "",
    "pubDate": "Fri, 12 Mar 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/fine-tune-wav2vec2-english",
    "thumbnail": "https://huggingface.co/blog/assets/15_fine_tune_wav2vec2/wav2vec2.png"
  },
  {
    "title": "My Journey to a serverless transformers pipeline on Google Cloud",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 18 Mar 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/how-to-deploy-a-pipeline-to-google-clouds",
    "thumbnail": "https://huggingface.co/blog/assets/14_how_to_deploy_a_pipeline_to_google_clouds/thumbnail.png"
  },
  {
    "title": "The Partnership: Amazon SageMaker and Hugging Face",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 23 Mar 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/the-partnership-amazon-sagemaker-and-hugging-face",
    "thumbnail": "https://huggingface.co/blog/assets/17_the_partnership_amazon_sagemaker_and_hugging_face/thumbnail.png"
  },
  {
    "title": "GPT-3 powers the next generation of apps",
    "description": "Over 300 applications are delivering GPT-3–powered search, conversation, text completion, and other advanced AI features through our API.",
    "summary": "Over 300 applications are delivering GPT-3–powered search, conversation, text completion, and other advanced AI features through our API.",
    "pubDate": "Thu, 25 Mar 2021 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/gpt-3-apps",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Understanding BigBird's Block Sparse Attention",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 31 Mar 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/big-bird",
    "thumbnail": "https://huggingface.co/blog/assets/18_big_bird/attn.png"
  },
  {
    "title": "Distributed Training: Train BART/T5 for Summarization using 🤗 Transformers and Amazon SageMaker",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 08 Apr 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/sagemaker-distributed-training-seq2seq",
    "thumbnail": "https://huggingface.co/blog/assets/19_sagemaker_distributed_training_seq2seq/thumbnail.png"
  },
  {
    "title": "Introducing 🤗 Accelerate",
    "description": "",
    "summary": "",
    "pubDate": "Fri, 16 Apr 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/accelerate-library",
    "thumbnail": "https://huggingface.co/blog/assets/20_accelerate_library/accelerate_diff.png"
  },
  {
    "title": "Scaling-up BERT Inference on CPU (Part 1)",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 20 Apr 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/bert-cpu-scaling-part-1",
    "thumbnail": "https://huggingface.co/blog/assets/21_bert_cpu_scaling_part_1/imgs/numa_set.png"
  },
  {
    "title": "Will Hurd joins OpenAI’s board of directors",
    "description": "OpenAI is committed to developing general-purpose artificial intelligence that benefits all humanity, and we believe that achieving our goal requires expertise in public policy as well as technology. So, we’re delighted to announce that Congressman Will Hurd has joined our board of directors.",
    "summary": "OpenAI is committed to developing general-purpose artificial intelligence that benefits all humanity, and we believe that achieving our goal requires expertise in public policy as well as technology. So, we’re delighted to announce that Congressman Will Hurd has joined our board of directors.",
    "pubDate": "Mon, 03 May 2021 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/will-hurd-joins",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "OpenAI Scholars 2021: Final projects",
    "description": "We’re proud to announce that the 2021 class of OpenAI Scholars has completed our six-month mentorship program and have produced an open-source research project with stipends and support from OpenAI.",
    "summary": "We’re proud to announce that the 2021 class of OpenAI Scholars has completed our six-month mentorship program and have produced an open-source research project with stipends and support from OpenAI.",
    "pubDate": "Mon, 10 May 2021 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-scholars-2021-final-projects",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Using & Mixing Hugging Face Models with Gradio 2.0",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 25 May 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/gradio",
    "thumbnail": "https://huggingface.co/blog/assets/22_gradio/gradio.png"
  },
  {
    "title": "Few-shot learning in practice: GPT-NEO and the 🤗 Accelerated Inference API",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 03 Jun 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/few-shot-learning-gpt-neo-and-inference-api",
    "thumbnail": "https://huggingface.co/front/thumbnails/v2-2.png"
  },
  {
    "title": "Improving language model behavior by training on a curated dataset",
    "description": "Our latest research finds we can improve language model behavior with respect to specific behavioral values by fine-tuning on a small, curated dataset.",
    "summary": "Our latest research finds we can improve language model behavior with respect to specific behavioral values by fine-tuning on a small, curated dataset.",
    "pubDate": "Thu, 10 Jun 2021 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/improving-language-model-behavior",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Sentence Transformers in the 🤗 Hub",
    "description": "",
    "summary": "",
    "pubDate": "Mon, 28 Jun 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/sentence-transformers-in-the-hub",
    "thumbnail": "https://huggingface.co/front/thumbnails/v2-2.png"
  },
  {
    "title": "Evaluating large language models trained on code",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 07 Jul 2021 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/evaluating-large-language-models-trained-on-code",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Deploy Hugging Face models easily with Amazon SageMaker",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 08 Jul 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/deploy-hugging-face-models-easily-with-amazon-sagemaker",
    "thumbnail": "https://huggingface.co/blog/assets/17_the_partnership_amazon_sagemaker_and_hugging_face/thumbnail.png"
  },
  {
    "title": "Welcome spaCy to the 🤗 Hub",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 13 Jul 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/spacy",
    "thumbnail": "https://huggingface.co/blog/assets/23_spacy/thumbnail.png"
  },
  {
    "title": "Deep Learning over the Internet: Training Language Models Collaboratively",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 15 Jul 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/collaborative-training",
    "thumbnail": "https://huggingface.co/blog/assets/24_sahajBERT/thumbnail.png"
  },
  {
    "title": "Introducing Triton: Open-source GPU programming for neural networks",
    "description": "We’re releasing Triton 1.0, an open-source Python-like programming language which enables researchers with no CUDA experience to write highly efficient GPU code—most of the time on par with what an expert would be able to produce.",
    "summary": "We’re releasing Triton 1.0, an open-source Python-like programming language which enables researchers with no CUDA experience to write highly efficient GPU code—most of the time on par with what an expert would be able to produce.",
    "pubDate": "Wed, 28 Jul 2021 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/triton",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "OpenAI Codex",
    "description": "We’ve created an improved version of OpenAI Codex, our AI system that translates natural language to code, and we are releasing it through our API in private beta starting today.",
    "summary": "We’ve created an improved version of OpenAI Codex, our AI system that translates natural language to code, and we are releasing it through our API in private beta starting today.",
    "pubDate": "Tue, 10 Aug 2021 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-codex",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Helen Toner joins OpenAI’s board of directors",
    "description": "Today, we’re excited to announce the appointment of Helen Toner to our board of directors.",
    "summary": "Today, we’re excited to announce the appointment of Helen Toner to our board of directors.",
    "pubDate": "Wed, 08 Sep 2021 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/helen-toner-joins",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "TruthfulQA: Measuring how models mimic human falsehoods",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 08 Sep 2021 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/truthfulqa",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Hugging Face and Graphcore partner for IPU-optimized Transformers",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 14 Sep 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/graphcore",
    "thumbnail": "https://huggingface.co/blog/assets/26_graphcore-ipu/thumbnail.png"
  },
  {
    "title": "Introducing Optimum: The Optimization Toolkit for Transformers at Scale",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 14 Sep 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/hardware-partners-program",
    "thumbnail": "https://huggingface.co/front/thumbnails/v2-2.png"
  },
  {
    "title": "Summarizing books with human feedback",
    "description": "Scaling human oversight of AI systems for tasks that are difficult to evaluate.",
    "summary": "Scaling human oversight of AI systems for tasks that are difficult to evaluate.",
    "pubDate": "Thu, 23 Sep 2021 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/summarizing-books",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Summer at Hugging Face ☀️",
    "description": "",
    "summary": "",
    "pubDate": "Fri, 24 Sep 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/summer-at-huggingface",
    "thumbnail": "https://huggingface.co/blog/assets/27_summer_at_huggingface/summer_intro.gif"
  },
  {
    "title": "Hosting your Models and Datasets on Hugging Face Spaces using Streamlit",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 05 Oct 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/streamlit-spaces",
    "thumbnail": "https://huggingface.co/blog/assets/29_streamlit-spaces/thumbnail.png"
  },
  {
    "title": "Showcase Your Projects in Spaces using Gradio",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 05 Oct 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/gradio-spaces",
    "thumbnail": "https://huggingface.co/blog/assets/28_gradio-spaces/thumbnail.png"
  },
  {
    "title": "Fine tuning CLIP with Remote Sensing (Satellite) images and captions",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 13 Oct 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/fine-tune-clip-rsicd",
    "thumbnail": "https://huggingface.co/blog/assets/30_clip_rsicd/clip_schematic.png"
  },
  {
    "title": "The Age of Machine Learning As Code Has Arrived",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 20 Oct 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/the-age-of-ml-as-code",
    "thumbnail": "https://huggingface.co/blog/assets/31_age_of_ml_as_code/05_vision_transformer.png"
  },
  {
    "title": "Train a Sentence Embedding Model with 1B Training Pairs",
    "description": "",
    "summary": "",
    "pubDate": "Mon, 25 Oct 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/1b-sentence-embeddings",
    "thumbnail": "https://huggingface.co/front/thumbnails/v2-2.png"
  },
  {
    "title": "Course Launch Community Event",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 26 Oct 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/course-launch-event",
    "thumbnail": "https://huggingface.co/blog/assets/34_course_launch/speakers_day1_thumb.png"
  },
  {
    "title": "Large Language Models: A New Moore's Law?",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 26 Oct 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/large-language-models",
    "thumbnail": "https://huggingface.co/blog/assets/33_large_language_models/01_model_size.jpg"
  },
  {
    "title": "Solving math word problems",
    "description": "We’ve trained a system that solves grade school math problems with nearly twice the accuracy of a fine-tuned GPT-3 model. It solves about 90% as many problems as real kids: a small sample of 9-12 year olds scored 60% on a test from our dataset, while our system scored 55% on those same problems.",
    "summary": "We’ve trained a system that solves grade school math problems with nearly twice the accuracy of a fine-tuned GPT-3 model. It solves about 90% as many problems as real kids: a small sample of 9-12 year olds scored 60% on a test from our dataset, while our system scored 55% on those same problems.",
    "pubDate": "Fri, 29 Oct 2021 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/solving-math-word-problems",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Scaling up BERT-like model Inference on modern CPU - Part 2",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 04 Nov 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/bert-cpu-scaling-part-2",
    "thumbnail": "https://huggingface.co/front/thumbnails/v2-2.png"
  },
  {
    "title": "Fine-tuning XLS-R for Multi-Lingual ASR with 🤗 Transformers",
    "description": "",
    "summary": "",
    "pubDate": "Mon, 15 Nov 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/fine-tune-xlsr-wav2vec2",
    "thumbnail": "https://huggingface.co/blog/assets/xlsr_wav2vec2.png"
  },
  {
    "title": "OpenAI’s API now available with no waitlist",
    "description": "Wider availability made possible by safety progress.",
    "summary": "Wider availability made possible by safety progress.",
    "pubDate": "Thu, 18 Nov 2021 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/api-no-waitlist",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Accelerating PyTorch distributed fine-tuning with Intel technologies",
    "description": "",
    "summary": "",
    "pubDate": "Fri, 19 Nov 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/accelerating-pytorch",
    "thumbnail": "https://huggingface.co/blog/assets/36_accelerating_pytorch/04_four_nodes.png"
  },
  {
    "title": "Introducing the Data Measurements Tool: an Interactive Tool for Looking at Datasets",
    "description": "",
    "summary": "",
    "pubDate": "Mon, 29 Nov 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/data-measurements-tool",
    "thumbnail": "https://huggingface.co/blog/assets/37_data-measurements-tool/datametrics.png"
  },
  {
    "title": "Getting Started with Hugging Face Transformers for IPUs with Optimum",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 30 Nov 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/graphcore-getting-started",
    "thumbnail": "https://huggingface.co/blog/assets/38_getting_started_graphcore/graphcore_1.png"
  },
  {
    "title": "OpenAI Residency",
    "description": "As part of our effort to support and develop AI talent, we’re excited to announce the OpenAI Residency.",
    "summary": "As part of our effort to support and develop AI talent, we’re excited to announce the OpenAI Residency.",
    "pubDate": "Tue, 30 Nov 2021 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-residency",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Introducing Snowball Fight ☃️, our First ML-Agents Environment",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 02 Dec 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/snowball-fight",
    "thumbnail": "https://huggingface.co/blog/assets/39_introducing_snowball_fight/thumbnail.png"
  },
  {
    "title": "Training CodeParrot 🦜 from Scratch",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 08 Dec 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/codeparrot",
    "thumbnail": "https://huggingface.co/blog/assets/40_codeparrot/thumbnail.png"
  },
  {
    "title": "Customizing GPT-3 for your application",
    "description": "Fine-tune with a single command.",
    "summary": "Fine-tune with a single command.",
    "pubDate": "Tue, 14 Dec 2021 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/customizing-gpt-3",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Perceiver IO: a scalable, fully-attentional model that works on any modality",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 15 Dec 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/perceiver",
    "thumbnail": "https://huggingface.co/blog/assets/41_perceiver/thumbnail.png"
  },
  {
    "title": "WebGPT: Improving the factual accuracy of language models through web browsing",
    "description": "We’ve fine-tuned GPT-3 to more accurately answer open-ended questions using a text-based web browser.",
    "summary": "We’ve fine-tuned GPT-3 to more accurately answer open-ended questions using a text-based web browser.",
    "pubDate": "Thu, 16 Dec 2021 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/webgpt",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Gradio joins Hugging Face!",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 21 Dec 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/gradio-joins-hf",
    "thumbnail": "https://huggingface.co/blog/assets/42_gradio_joins_hf/thumbnail.png"
  },
  {
    "title": "Active Learning with AutoNLP and Prodigy",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 23 Dec 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/autonlp-prodigy",
    "thumbnail": "https://huggingface.co/blog/assets/43_autonlp_prodigy/thumbnail.png"
  },
  {
    "title": "Deploy GPT-J 6B for inference using Hugging Face Transformers and Amazon SageMaker",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 11 Jan 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/gptj-sagemaker",
    "thumbnail": "https://huggingface.co/blog/assets/45_gptj_sagemaker/thumbnail.png"
  },
  {
    "title": "Boost Wav2Vec2 with n-gram LM in 🤗 Transformers",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 12 Jan 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/wav2vec2-with-ngram",
    "thumbnail": "https://huggingface.co/blog/assets/44_boost_wav2vec2_ngram/wav2vec2_ngram.png"
  },
  {
    "title": "Case Study: Millisecond Latency using Hugging Face Infinity and modern CPUs",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 13 Jan 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/infinity-cpu-performance",
    "thumbnail": "https://huggingface.co/blog/assets/46_infinity_cpu_performance/thumbnail.png"
  },
  {
    "title": "Welcome Stable-baselines3 to the Hugging Face Hub 🤗",
    "description": "",
    "summary": "",
    "pubDate": "Fri, 21 Jan 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/sb3",
    "thumbnail": "https://huggingface.co/blog/assets/47_sb3/thumbnail.png"
  },
  {
    "title": "Text and code embeddings by contrastive pre-training",
    "description": "",
    "summary": "",
    "pubDate": "Mon, 24 Jan 2022 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/text-and-code-embeddings-by-contrastive-pre-training",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Introducing text and code embeddings",
    "description": "We are introducing embeddings, a new endpoint in the OpenAI API that makes it easy to perform natural language and code tasks like semantic search, clustering, topic modeling, and classification.",
    "summary": "We are introducing embeddings, a new endpoint in the OpenAI API that makes it easy to perform natural language and code tasks like semantic search, clustering, topic modeling, and classification.",
    "pubDate": "Tue, 25 Jan 2022 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-text-and-code-embeddings",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Supercharged Searching on the Hugging Face Hub",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 25 Jan 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/searching-the-hub",
    "thumbnail": "https://huggingface.co/blog/assets/48_hubsearch/thumbnail.png"
  },
  {
    "title": "Aligning language models to follow instructions",
    "description": "We’ve trained language models that are much better at following user intentions than GPT-3 while also making them more truthful and less toxic, using techniques developed through our alignment research. These InstructGPT models, which are trained with humans in the loop, are now deployed as the default language models on our API.",
    "summary": "We’ve trained language models that are much better at following user intentions than GPT-3 while also making them more truthful and less toxic, using techniques developed through our alignment research. These InstructGPT models, which are trained with humans in the loop, are now deployed as the default language models on our API.",
    "pubDate": "Thu, 27 Jan 2022 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/instruction-following",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Making automatic speech recognition work on large files with Wav2Vec2 in 🤗 Transformers",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 01 Feb 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/asr-chunking",
    "thumbnail": "https://huggingface.co/blog/assets/49_asr_chunking/thumbnail.png"
  },
  {
    "title": "Getting Started with Sentiment Analysis using Python",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 02 Feb 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/sentiment-analysis-python",
    "thumbnail": "https://huggingface.co/blog/assets/50_sentiment_python/thumbnail.png"
  },
  {
    "title": "Solving (some) formal math olympiad problems",
    "description": "We built a neural theorem prover for Lean that learned to solve a variety of challenging high-school olympiad problems, including problems from the AMC12 and AIME competitions, as well as two problems adapted from the IMO.",
    "summary": "We built a neural theorem prover for Lean that learned to solve a variety of challenging high-school olympiad problems, including problems from the AMC12 and AIME competitions, as well as two problems adapted from the IMO.",
    "pubDate": "Wed, 02 Feb 2022 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/formal-math",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Fine-Tune ViT for Image Classification with 🤗 Transformers",
    "description": "",
    "summary": "",
    "pubDate": "Fri, 11 Feb 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/fine-tune-vit",
    "thumbnail": "https://huggingface.co/blog/assets/51_fine_tune_vit/vit-thumbnail.jpg"
  },
  {
    "title": "BERT 101 🤗 State Of The Art NLP Model Explained",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 02 Mar 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/bert-101",
    "thumbnail": "https://huggingface.co/blog/assets/52_bert_101/thumbnail.jpg"
  },
  {
    "title": "A research agenda for assessing the economic impacts of code generation models",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 03 Mar 2022 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/economic-impacts-research",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Economic impacts research at OpenAI",
    "description": "Call for expressions of interest to study the economic impacts of large language models.",
    "summary": "Call for expressions of interest to study the economic impacts of large language models.",
    "pubDate": "Thu, 03 Mar 2022 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/economic-impacts",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Lessons learned on language model safety and misuse",
    "description": "We describe our latest thinking in the hope of helping other AI developers address safety and misuse of deployed models.",
    "summary": "We describe our latest thinking in the hope of helping other AI developers address safety and misuse of deployed models.",
    "pubDate": "Thu, 03 Mar 2022 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/language-model-safety-and-misuse",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Guiding Text Generation with Constrained Beam Search in 🤗 Transformers",
    "description": "",
    "summary": "",
    "pubDate": "Fri, 11 Mar 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/constrained-beam-search",
    "thumbnail": "https://huggingface.co/blog/assets/53_constrained_beam_search/thumbnail.png"
  },
  {
    "title": "New GPT-3 capabilities: Edit & insert",
    "description": "We’ve released new versions of GPT-3 and Codex which can edit or insert content into existing text, rather than just completing existing text.",
    "summary": "We’ve released new versions of GPT-3 and Codex which can edit or insert content into existing text, rather than just completing existing text.",
    "pubDate": "Tue, 15 Mar 2022 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/gpt-3-edit-insert",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Accelerate BERT inference with Hugging Face Transformers and AWS inferentia",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 16 Mar 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/bert-inferentia-sagemaker",
    "thumbnail": "https://huggingface.co/blog//assets/55_bert_inferentia_sagemaker/thumbnail.png"
  },
  {
    "title": "Image search with 🤗 datasets",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 16 Mar 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/image-search-datasets",
    "thumbnail": "https://huggingface.co/blog/assets/54_image_search_datasets/spaces_image_search.jpg"
  },
  {
    "title": "Fine-Tune a Semantic Segmentation Model with a Custom Dataset",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 17 Mar 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/fine-tune-segformer",
    "thumbnail": "https://huggingface.co/blog/assets/56_fine_tune_segformer/thumb.png"
  },
  {
    "title": "Announcing the 🤗 AI Research Residency Program",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 22 Mar 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/ai-residency",
    "thumbnail": "https://huggingface.co/blog/assets/57_ai_residency/residency-thumbnail.jpg"
  },
  {
    "title": "Machine Learning Experts - Meg Mitchell Interview",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 23 Mar 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/meg-mitchell-interview",
    "thumbnail": "https://huggingface.co/blog/assets/57_meg_mitchell_interview/thumbnail.png"
  },
  {
    "title": "Introducing Decision Transformers on Hugging Face 🤗",
    "description": "",
    "summary": "",
    "pubDate": "Mon, 28 Mar 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/decision-transformers",
    "thumbnail": "https://huggingface.co/blog/assets/58_decision-transformers/thumbnail.jpg"
  },
  {
    "title": "Don't repeat yourself - 🤗 Transformers Design Philosophy",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 05 Apr 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/transformers-design-philosophy",
    "thumbnail": "https://huggingface.co/blog/assets/59_transformers_philosophy/transformers.png"
  },
  {
    "title": "Habana Labs and Hugging Face Partner to Accelerate Transformer Model Training",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 12 Apr 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/habana",
    "thumbnail": "https://huggingface.co/blog/assets/60_habana/habana.png"
  },
  {
    "title": "Hierarchical text-conditional image generation with CLIP latents",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 13 Apr 2022 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/hierarchical-text-conditional-image-generation-with-clip-latents",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Machine Learning Experts - Lewis Tunstall Interview",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 13 Apr 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/lewis-tunstall-interview",
    "thumbnail": "https://huggingface.co/blog/assets/60_lewis_tunstall_interview/thumbnail.png"
  },
  {
    "title": "Measuring Goodhart’s law",
    "description": "Goodhart’s law famously says: “When a measure becomes a target, it ceases to be a good measure.” Although originally from economics, it’s something we have to grapple with at OpenAI when figuring out how to optimize objectives that are difficult or costly to measure.",
    "summary": "Goodhart’s law famously says: “When a measure becomes a target, it ceases to be a good measure.” Although originally from economics, it’s something we have to grapple with at OpenAI when figuring out how to optimize objectives that are difficult or costly to measure.",
    "pubDate": "Wed, 13 Apr 2022 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/measuring-goodharts-law",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "CO2 Emissions and the 🤗 Hub: Leading the Charge",
    "description": "",
    "summary": "",
    "pubDate": "Fri, 22 Apr 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/carbon-emissions-on-the-hub",
    "thumbnail": "https://huggingface.co/blog/assets/60_carbon_emissions_on_the_hub/thumbnail.jpg"
  },
  {
    "title": "Introducing Hugging Face for Education",
    "description": "",
    "summary": "",
    "pubDate": "Mon, 25 Apr 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/education",
    "thumbnail": "https://huggingface.co/blog/assets/61_education/thumbnail.png"
  },
  {
    "title": "Supercharged Customer Service with Machine Learning",
    "description": "",
    "summary": "",
    "pubDate": "Mon, 25 Apr 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/supercharge-customer-service-with-machine-learning",
    "thumbnail": "https://huggingface.co/blog/assets/61_supercharged_customer_service_with_nlp/thumbnail.png"
  },
  {
    "title": "Getting Started with Transformers on Habana Gaudi",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 26 Apr 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/getting-started-habana",
    "thumbnail": "https://huggingface.co/blog/assets/61_getting_started_habana/habana01.png"
  },
  {
    "title": "Director of Machine Learning Insights [Series]",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 27 Apr 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/ml-director-insights",
    "thumbnail": "https://huggingface.co/blog/assets/61_ml_director_insights/thumbnail.png"
  },
  {
    "title": "Opinion Classification with Kili and HuggingFace AutoTrain",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 28 Apr 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/opinion-classification-with-kili",
    "thumbnail": "https://huggingface.co/blog/assets/59_opinion-classification-with-kili/thumbnail.png"
  },
  {
    "title": "Accelerate Large Model Training using PyTorch Fully Sharded Data Parallel",
    "description": "",
    "summary": "",
    "pubDate": "Mon, 02 May 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/pytorch-fsdp",
    "thumbnail": "https://huggingface.co/blog/assets/62_pytorch_fsdp/fsdp-thumbnail.png"
  },
  {
    "title": "An Introduction to Deep Reinforcement Learning",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 04 May 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/deep-rl-intro",
    "thumbnail": "https://huggingface.co/blog/assets/63_deep_rl_intro/thumbnail.png"
  },
  {
    "title": "OpenAI leadership team update",
    "description": "We’re happy to announce several executive role changes that reflect our recent progress and will ensure continued momentum toward our next major milestones.",
    "summary": "We’re happy to announce several executive role changes that reflect our recent progress and will ensure continued momentum toward our next major milestones.",
    "pubDate": "Thu, 05 May 2022 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/leadership-team-update",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Welcome fastai to the Hugging Face Hub",
    "description": "",
    "summary": "",
    "pubDate": "Fri, 06 May 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/fastai",
    "thumbnail": "https://huggingface.co/blog/assets/64_fastai/fastai_hf_blog.png"
  },
  {
    "title": "We Raised $100 Million for Open & Collaborative Machine Learning 🚀",
    "description": "",
    "summary": "",
    "pubDate": "Mon, 09 May 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/series-c",
    "thumbnail": "https://huggingface.co/blog/assets/65_series_c/thumbnail.jpg"
  },
  {
    "title": "Accelerated Inference with Optimum and Transformers Pipelines",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 10 May 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/optimum-inference",
    "thumbnail": "https://huggingface.co/blog/assets/66_optimum_inference/thumbnail.png"
  },
  {
    "title": "Director of Machine Learning Insights [Part 2: SaaS Edition]",
    "description": "",
    "summary": "",
    "pubDate": "Fri, 13 May 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/ml-director-insights-2",
    "thumbnail": "https://huggingface.co/blog/assets/67_ml_director_insights/thumbnail.png"
  },
  {
    "title": "Student Ambassador Program's call for applications is open!",
    "description": "",
    "summary": "",
    "pubDate": "Fri, 13 May 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/ambassadors",
    "thumbnail": "https://huggingface.co/blog/assets/67_ambassadors/thumbnail.png"
  },
  {
    "title": "Gradio 3.0 is Out!",
    "description": "",
    "summary": "",
    "pubDate": "Mon, 16 May 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/gradio-blocks",
    "thumbnail": "https://huggingface.co/blog/assets/68_gradio_blocks/block-party.png"
  },
  {
    "title": "Announcing the Hugging Face Fellowship Program",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 17 May 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/fellowship",
    "thumbnail": "https://huggingface.co/blog/assets/62_fellowship/fellowship-thumbnail.png"
  },
  {
    "title": "Machine Learning Experts - Sasha Luccioni Interview",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 17 May 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/sasha-luccioni-interview",
    "thumbnail": "https://huggingface.co/blog/assets/69_sasha_luccioni_interview/thumbnail.png"
  },
  {
    "title": "An Introduction to Q-Learning Part 1",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 18 May 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/deep-rl-q-part1",
    "thumbnail": "https://huggingface.co/blog/assets/70_deep_rl_q_part1/thumbnail.gif"
  },
  {
    "title": "DALL·E 2 research preview update",
    "description": "Early users have created over 3 million images to date and helped us improve our safety processes. We’re excited to begin adding up to 1,000 new users from our waitlist each week.",
    "summary": "Early users have created over 3 million images to date and helped us improve our safety processes. We’re excited to begin adding up to 1,000 new users from our waitlist each week.",
    "pubDate": "Wed, 18 May 2022 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/dall-e-2-update",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "How Sempre Health is leveraging the Expert Acceleration Program to accelerate their ML roadmap",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 19 May 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/sempre-health-eap-case-study",
    "thumbnail": "https://huggingface.co/blog/assets/70_sempre_health/thumbnail.jpg"
  },
  {
    "title": "Putting ethical principles at the core of research lifecycle",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 19 May 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/ethical-charter-multimodal",
    "thumbnail": "https://huggingface.co/blog/assets/71_ethical-charter/thumbnail.jpg"
  },
  {
    "title": "An Introduction to Q-Learning Part 2",
    "description": "",
    "summary": "",
    "pubDate": "Fri, 20 May 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/deep-rl-q-part2",
    "thumbnail": "https://huggingface.co/blog/assets/73_deep_rl_q_part2/thumbnail.gif"
  },
  {
    "title": "Efficient Table Pre-training without Real Data: An Introduction to TAPEX",
    "description": "",
    "summary": "",
    "pubDate": "Mon, 23 May 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/tapex",
    "thumbnail": "https://huggingface.co/blog/assets/74_tapex/thumbnail.png"
  },
  {
    "title": "Powering next generation applications with OpenAI Codex",
    "description": "Codex is now powering 70 different applications across a variety of use cases through the OpenAI API.",
    "summary": "Codex is now powering 70 different applications across a variety of use cases through the OpenAI API.",
    "pubDate": "Tue, 24 May 2022 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/codex-apps",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Introducing Pull Requests and Discussions 🥳",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 25 May 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/community-update",
    "thumbnail": "https://huggingface.co/blog/assets/76_community_update/thumbnail.png"
  },
  {
    "title": "Graphcore and Hugging Face Launch New Lineup of IPU-Ready Transformers",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 26 May 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/graphcore-update",
    "thumbnail": "https://huggingface.co/blog/assets/77_graphcore-update/graphcore_update.png"
  },
  {
    "title": "Teaching models to express their uncertainty in words",
    "description": "",
    "summary": "",
    "pubDate": "Sat, 28 May 2022 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/teaching-models-to-express-their-uncertainty-in-words",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Best practices for deploying language models",
    "description": "Cohere, OpenAI, and AI21 Labs have developed a preliminary set of best practices applicable to any organization developing or deploying large language models.",
    "summary": "Cohere, OpenAI, and AI21 Labs have developed a preliminary set of best practices applicable to any organization developing or deploying large language models.",
    "pubDate": "Thu, 02 Jun 2022 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/best-practices-for-deploying-language-models",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Deep Q-Learning with Atari",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 07 Jun 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/deep-rl-dqn",
    "thumbnail": "https://huggingface.co/blog/assets/78_deep_rl_dqn/thumbnail.gif"
  },
  {
    "title": "The Annotated Diffusion Model",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 07 Jun 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/annotated-diffusion",
    "thumbnail": "https://huggingface.co/blog/assets/78_annotated-diffusion/thumbnail.png"
  },
  {
    "title": "Techniques for training large neural networks",
    "description": "Large neural networks are at the core of many recent advances in AI, but training them is a difficult engineering and research challenge which requires orchestrating a cluster of GPUs to perform a single synchronized calculation.",
    "summary": "Large neural networks are at the core of many recent advances in AI, but training them is a difficult engineering and research challenge which requires orchestrating a cluster of GPUs to perform a single synchronized calculation.",
    "pubDate": "Thu, 09 Jun 2022 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/techniques-for-training-large-neural-networks",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "AI-written critiques help humans notice flaws",
    "description": "We trained “critique-writing” models to describe flaws in summaries. Human evaluators find flaws in summaries much more often when shown our model’s critiques. Larger models are better at self-critiquing, with scale improving critique-writing more than summary-writing. This shows promise for using AI systems to assist human supervision of AI systems on difficult tasks.",
    "summary": "We trained “critique-writing” models to describe flaws in summaries. Human evaluators find flaws in summaries much more often when shown our model’s critiques. Larger models are better at self-critiquing, with scale improving critique-writing more than summary-writing. This shows promise for using AI systems to assist human supervision of AI systems on difficult tasks.",
    "pubDate": "Mon, 13 Jun 2022 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/critiques",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Director of Machine Learning Insights [Part 3: Finance Edition]",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 14 Jun 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/ml-director-insights-3",
    "thumbnail": "https://huggingface.co/blog/assets/78_ml_director_insights/thumbnail.png"
  },
  {
    "title": "Intel and Hugging Face Partner to Democratize Machine Learning Hardware Acceleration",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 15 Jun 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/intel",
    "thumbnail": "https://huggingface.co/blog/assets/80_intel/01.png"
  },
  {
    "title": "Evolution through large models",
    "description": "",
    "summary": "",
    "pubDate": "Fri, 17 Jun 2022 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/evolution-through-large-models",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Convert Transformers to ONNX with Hugging Face Optimum",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 22 Jun 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/convert-transformers-to-onnx",
    "thumbnail": "https://huggingface.co/blog/assets/81_convert_transformers_to_onnx/thumbnail.png"
  },
  {
    "title": "Getting Started With Embeddings",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 23 Jun 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/getting-started-with-embeddings",
    "thumbnail": "https://huggingface.co/blog/assets/80_getting_started_with_embeddings/thumbnail.png"
  },
  {
    "title": "Learning to play Minecraft with Video PreTraining",
    "description": "We trained a neural network to play Minecraft by Video PreTraining (VPT) on a massive unlabeled video dataset of human Minecraft play, while using only a small amount of labeled contractor data. With fine-tuning, our model can learn to craft diamond tools, a task that usually takes proficient humans over 20 minutes (24,000 actions). Our model uses the native human interface of keypresses and mouse movements, making it quite general, and represents a step towards general computer-using agents.",
    "summary": "We trained a neural network to play Minecraft by Video PreTraining (VPT) on a massive unlabeled video dataset of human Minecraft play, while using only a small amount of labeled contractor data. With fine-tuning, our model can learn to craft diamond tools, a task that usually takes proficient humans over 20 minutes (24,000 actions). Our model uses the native human interface of keypresses and mouse movements, making it quite general, and represents a step towards general computer-using agents.",
    "pubDate": "Thu, 23 Jun 2022 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/vpt",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Accelerate Large Model Training using DeepSpeed",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 28 Jun 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/accelerate-deepspeed",
    "thumbnail": "https://huggingface.co/blog/assets/83_accelerate_deepspeed/deepspeed-thumbnail.png"
  },
  {
    "title": "Announcing Evaluation on the Hub",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 28 Jun 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/eval-on-the-hub",
    "thumbnail": "https://huggingface.co/blog/assets/82_eval_on_the_hub/thumbnail.png"
  },
  {
    "title": "DALL·E 2 pre-training mitigations",
    "description": "In order to share the magic of DALL·E 2 with a broad audience, we needed to reduce the risks associated with powerful image generation models. To this end, we put various guardrails in place to prevent generated images from violating our content policy.",
    "summary": "In order to share the magic of DALL·E 2 with a broad audience, we needed to reduce the risks associated with powerful image generation models. To this end, we put various guardrails in place to prevent generated images from violating our content policy.",
    "pubDate": "Tue, 28 Jun 2022 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/dall-e-2-pre-training-mitigations",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Liftoff! How to get started with your first ML project 🚀",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 29 Jun 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/your-first-ml-project",
    "thumbnail": "https://huggingface.co/blog/assets/84_first_ml_project/thumbnail.png"
  },
  {
    "title": "Policy Gradient with PyTorch",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 30 Jun 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/deep-rl-pg",
    "thumbnail": "https://huggingface.co/blog/assets/85_policy_gradient/thumbnail.gif"
  },
  {
    "title": "Getting Started with Sentiment Analysis on Twitter",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 07 Jul 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/sentiment-analysis-twitter",
    "thumbnail": "https://huggingface.co/blog/assets/85_sentiment_analysis_twitter/thumbnail.png"
  },
  {
    "title": "Introducing The World's Largest Open Multilingual Language Model: BLOOM",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 12 Jul 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/bloom",
    "thumbnail": "https://huggingface.co/blog/assets/86_bloom/thumbnail.png"
  },
  {
    "title": "Building a Playlist Generator with Sentence Transformers",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 13 Jul 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/playlist-generator",
    "thumbnail": "https://huggingface.co/blog/assets/87_playlist_generator/thumbnail.png"
  },
  {
    "title": "DALL·E 2: Extending creativity",
    "description": "As part of our DALL·E 2 research preview, more than 3,000 artists from more than 118 countries have incorporated DALL·E into their creative workflows. The artists in our early access group have helped us discover new uses for DALL·E and have served as key voices as we’ve made decisions about DALL·E’s features.",
    "summary": "As part of our DALL·E 2 research preview, more than 3,000 artists from more than 118 countries have incorporated DALL·E into their creative workflows. The artists in our early access group have helped us discover new uses for DALL·E and have served as key voices as we’ve made decisions about DALL·E’s features.",
    "pubDate": "Thu, 14 Jul 2022 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/dall-e-2-extending-creativity",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "The Technology Behind BLOOM Training",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 14 Jul 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/bloom-megatron-deepspeed",
    "thumbnail": "https://huggingface.co/blog/assets/86_bloom_megatron_deepspeed/thumbnail.png"
  },
  {
    "title": "How to train your model dynamically using adversarial data",
    "description": "",
    "summary": "",
    "pubDate": "Sat, 16 Jul 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/mnist-adversarial",
    "thumbnail": "https://huggingface.co/blog/assets/88_mnist_adversarial/mnist-adversarial.png"
  },
  {
    "title": "Reducing bias and improving safety in DALL·E 2",
    "description": "Today, we are implementing a new technique so that DALL·E generates images of people that more accurately reflect the diversity of the world’s population.",
    "summary": "Today, we are implementing a new technique so that DALL·E generates images of people that more accurately reflect the diversity of the world’s population.",
    "pubDate": "Mon, 18 Jul 2022 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/reducing-bias-and-improving-safety-in-dall-e-2",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "DALL·E now available in beta",
    "description": "We’ll invite 1 million people from our waitlist over the coming weeks. Users can create with DALL·E using free credits that refill every month, and buy additional credits in 115-generation increments for $15.",
    "summary": "We’ll invite 1 million people from our waitlist over the coming weeks. Users can create with DALL·E using free credits that refill every month, and buy additional credits in 115-generation increments for $15.",
    "pubDate": "Wed, 20 Jul 2022 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/dall-e-now-available-in-beta",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Advantage Actor Critic (A2C)",
    "description": "",
    "summary": "",
    "pubDate": "Fri, 22 Jul 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/deep-rl-a2c",
    "thumbnail": "https://huggingface.co/blog/assets/89_deep_rl_a2c/thumbnail.gif"
  },
  {
    "title": "A hazard analysis framework for code synthesis large language models",
    "description": "",
    "summary": "",
    "pubDate": "Mon, 25 Jul 2022 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/a-hazard-analysis-framework-for-code-synthesis-large-language-models",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Deploying TensorFlow Vision Models in Hugging Face with TF Serving",
    "description": "",
    "summary": "",
    "pubDate": "Mon, 25 Jul 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/tf-serving-vision",
    "thumbnail": "https://huggingface.co/blog/assets/90_tf_serving_vision/thumbnail.png"
  },
  {
    "title": "Faster Text Generation with TensorFlow and XLA",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 27 Jul 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/tf-xla-generate",
    "thumbnail": "https://huggingface.co/blog/assets/91_tf_xla_generate/thumbnail.png"
  },
  {
    "title": "Efficient training of language models to fill in the middle",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 28 Jul 2022 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/efficient-training-of-language-models-to-fill-in-the-middle",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Introducing new audio and vision documentation in 🤗 Datasets",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 28 Jul 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/datasets-docs-update",
    "thumbnail": "https://huggingface.co/blog/assets/87_datasets-docs-update/thumbnail.gif"
  },
  {
    "title": "AI Policy @🤗: Comments on U.S. National AI Research Resource Interim Report",
    "description": "",
    "summary": "",
    "pubDate": "Mon, 01 Aug 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/us-national-ai-research-resource",
    "thumbnail": "https://huggingface.co/blog/assets/92_us_national_ai_research_resource/nairr_thumbnail.png"
  },
  {
    "title": "Nyströmformer, Approximating self-attention in linear time and memory via the Nyström method",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 02 Aug 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/nystromformer",
    "thumbnail": "https://huggingface.co/blog/assets/86_nystromformer/thumbnail.png"
  },
  {
    "title": "Introducing the Private Hub: A New Way to Build With Machine Learning",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 03 Aug 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/introducing-private-hub",
    "thumbnail": "https://huggingface.co/blog/assets/92_introducing_private_hub/thumbnail.png"
  },
  {
    "title": "Proximal Policy Optimization (PPO)",
    "description": "",
    "summary": "",
    "pubDate": "Fri, 05 Aug 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/deep-rl-ppo",
    "thumbnail": "https://huggingface.co/blog/assets/93_deep_rl_ppo/thumbnail.png"
  },
  {
    "title": "New and improved content moderation tooling",
    "description": "We are introducing a new and improved content moderation tool. The Moderation endpoint improves upon our previous content filter, and is available for free today to OpenAI API developers.",
    "summary": "We are introducing a new and improved content moderation tool. The Moderation endpoint improves upon our previous content filter, and is available for free today to OpenAI API developers.",
    "pubDate": "Wed, 10 Aug 2022 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/new-and-improved-content-moderation-tooling",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Train and Fine-Tune Sentence Transformers Models",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 10 Aug 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/how-to-train-sentence-transformers",
    "thumbnail": "https://huggingface.co/blog/assets/95_training_st_models/thumbnail.png"
  },
  {
    "title": "Deploying 🤗 ViT on Kubernetes with TF Serving",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 11 Aug 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/deploy-tfserving-kubernetes",
    "thumbnail": "https://huggingface.co/blog/assets/94_tf_serving_kubernetes/thumb.png"
  },
  {
    "title": "Hugging Face's TensorFlow Philosophy",
    "description": "",
    "summary": "",
    "pubDate": "Fri, 12 Aug 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/tensorflow-philosophy",
    "thumbnail": "https://huggingface.co/blog/assets/96_tensorflow_philosophy/thumbnail.png"
  },
  {
    "title": "Introducing Skops",
    "description": "",
    "summary": "",
    "pubDate": "Fri, 12 Aug 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/skops",
    "thumbnail": "https://huggingface.co/blog/assets/94_skops/introducing_skops.png"
  },
  {
    "title": "A Gentle Introduction to 8-bit Matrix Multiplication for transformers at scale using transformers, accelerate and bitsandbytes",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 17 Aug 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/hf-bitsandbytes-integration",
    "thumbnail": "https://huggingface.co/blog/assets/96_hf_bitsandbytes_integration/Thumbnail_blue.png"
  },
  {
    "title": "Deep Dive: Vision Transformers On Hugging Face Optimum Graphcore",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 18 Aug 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/vision-transformers",
    "thumbnail": "https://huggingface.co/blog/assets/97_vision_transformers/thumbnail.png"
  },
  {
    "title": "Deploying 🤗 ViT on Vertex AI",
    "description": "",
    "summary": "",
    "pubDate": "Fri, 19 Aug 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/deploy-vertex-ai",
    "thumbnail": "https://huggingface.co/blog/assets/97_vertex_ai/image1.png"
  },
  {
    "title": "Pre-Train BERT with Hugging Face Transformers and Habana Gaudi",
    "description": "",
    "summary": "",
    "pubDate": "Mon, 22 Aug 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/pretraining-bert",
    "thumbnail": "https://huggingface.co/blog/assets/99_pretraining_bert/thumbnail.png"
  },
  {
    "title": "Stable Diffusion with 🧨 Diffusers",
    "description": "",
    "summary": "",
    "pubDate": "Mon, 22 Aug 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/stable_diffusion",
    "thumbnail": "https://huggingface.co/blog/assets/98_stable_diffusion/thumbnail.png"
  },
  {
    "title": "Our approach to alignment research",
    "description": "We are improving our AI systems’ ability to learn from human feedback and to assist humans at evaluating AI. Our goal is to build a sufficiently aligned AI system that can help us solve all other alignment problems.",
    "summary": "We are improving our AI systems’ ability to learn from human feedback and to assist humans at evaluating AI. Our goal is to build a sufficiently aligned AI system that can help us solve all other alignment problems.",
    "pubDate": "Wed, 24 Aug 2022 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/our-approach-to-alignment-research",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Visualize proteins on Hugging Face Spaces",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 24 Aug 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/spaces_3dmoljs",
    "thumbnail": "https://huggingface.co/blog/assets/98_spaces_3dmoljs/thumbnail.png"
  },
  {
    "title": "DALL·E: Introducing outpainting",
    "description": "Extend creativity and tell a bigger story with DALL·E images of any size.",
    "summary": "Extend creativity and tell a bigger story with DALL·E images of any size.",
    "pubDate": "Wed, 31 Aug 2022 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/dall-e-introducing-outpainting",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "OpenRAIL: Towards open and responsible AI licensing frameworks",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 31 Aug 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/open_rail",
    "thumbnail": "https://huggingface.co/blog/assets/100_open_rail/100_open-rail.png"
  },
  {
    "title": "How to train a Language Model with Megatron-LM",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 07 Sep 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/megatron-training",
    "thumbnail": "https://huggingface.co/blog/assets/100_megatron_training/thumbnail.png"
  },
  {
    "title": "Train your first Decision Transformer",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 08 Sep 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/train-decision-transformers",
    "thumbnail": "https://huggingface.co/blog/assets/101_train-decision-transformers/thumbnail.gif"
  },
  {
    "title": "What's new in Diffusers? 🎨",
    "description": "",
    "summary": "",
    "pubDate": "Mon, 12 Sep 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/diffusers-2nd-month",
    "thumbnail": "https://huggingface.co/blog/assets/102_diffusers_2nd_month/inpainting.png"
  },
  {
    "title": "Incredibly Fast BLOOM Inference with DeepSpeed and Accelerate",
    "description": "",
    "summary": "",
    "pubDate": "Fri, 16 Sep 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/bloom-inference-pytorch-scripts",
    "thumbnail": "https://huggingface.co/blog/assets/bloom-inference-pytorch-scripts/thumbnail.png"
  },
  {
    "title": "Introducing Whisper",
    "description": "We’ve trained and are open-sourcing a neural net called Whisper that approaches human level robustness and accuracy on English speech recognition.",
    "summary": "We’ve trained and are open-sourcing a neural net called Whisper that approaches human level robustness and accuracy on English speech recognition.",
    "pubDate": "Wed, 21 Sep 2022 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/whisper",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Ethics and Society Newsletter #1",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 22 Sep 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/ethics-soc-1",
    "thumbnail": "https://huggingface.co/blog/assets/103_ethics-soc-1/thumbnail.png"
  },
  {
    "title": "SetFit: Efficient Few-Shot Learning Without Prompts",
    "description": "",
    "summary": "",
    "pubDate": "Mon, 26 Sep 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/setfit",
    "thumbnail": "https://huggingface.co/blog/assets/103_setfit/intel_hf_logo.png"
  },
  {
    "title": "How 🤗 Accelerate runs very large models thanks to PyTorch",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 27 Sep 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/accelerate-large-models",
    "thumbnail": "https://huggingface.co/blog/assets/104_accelerate-large-models/thumbnail.png"
  },
  {
    "title": "DALL·E now available without waitlist",
    "description": "New users can start creating straight away. Lessons learned from deployment and improvements to our safety systems make wider availability possible.",
    "summary": "New users can start creating straight away. Lessons learned from deployment and improvements to our safety systems make wider availability possible.",
    "pubDate": "Wed, 28 Sep 2022 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/dall-e-now-available-without-waitlist",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Image Classification with AutoTrain",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 28 Sep 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/autotrain-image-classification",
    "thumbnail": "https://huggingface.co/blog/assets/105_autotrain-image-classification/thumbnail.png"
  },
  {
    "title": "Very Large Language Models and How to Evaluate Them",
    "description": "",
    "summary": "",
    "pubDate": "Mon, 03 Oct 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/zero-shot-eval-on-the-hub",
    "thumbnail": "https://huggingface.co/blog/assets/106_zero_shot_eval_on_the_hub/thumbnail.png"
  },
  {
    "title": "Japanese Stable Diffusion",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 05 Oct 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/japanese-stable-diffusion",
    "thumbnail": "https://huggingface.co/blog/assets/106_japanese_stable_diffusion/jsd_thumbnail.png"
  },
  {
    "title": "Introducing DOI: the Digital Object Identifier to Datasets and Models",
    "description": "",
    "summary": "",
    "pubDate": "Fri, 07 Oct 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/introducing-doi",
    "thumbnail": "https://huggingface.co/blog/assets/107_launching_doi/thumbnail.jpeg"
  },
  {
    "title": "Optimization story: Bloom inference",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 12 Oct 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/bloom-inference-optimization",
    "thumbnail": "https://huggingface.co/blog/assets/bloom-inference-pytorch-scripts/thumbnail.png"
  },
  {
    "title": "Stable Diffusion in JAX/Flax 🚀",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 13 Oct 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/stable_diffusion_jax",
    "thumbnail": "https://huggingface.co/blog/assets/108_stable_diffusion_jax/thumbnail.png"
  },
  {
    "title": "Stopping malaria in its tracks",
    "description": "Developing a vaccine that could save hundreds of thousands of lives",
    "summary": "Developing a vaccine that could save hundreds of thousands of lives",
    "pubDate": "Thu, 13 Oct 2022 15:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/stopping-malaria-in-its-tracks/",
    "thumbnail": "https://lh3.googleusercontent.com/8EXA5jqukU4EEWDHB9rJG25ir12WetmJlMuErPLe7hJUaGdIjXIA51D-PcxCMjNf9IVu3QxaZRbs4isgJsBsVpaHZjbgK4XM3MCc-8XOgcQ9-sqYWQ=w1200-h630-n-nu"
  },
  {
    "title": "Getting started with Hugging Face Inference Endpoints",
    "description": "",
    "summary": "",
    "pubDate": "Fri, 14 Oct 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/inference-endpoints",
    "thumbnail": "https://huggingface.co/blog/assets/109_inference_endpoints/endpoints05.png"
  },
  {
    "title": "MTEB: Massive Text Embedding Benchmark",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 19 Oct 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/mteb",
    "thumbnail": "https://huggingface.co/blog/assets/110_mteb/thumbnail.png"
  },
  {
    "title": "Scaling laws for reward model overoptimization",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 19 Oct 2022 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/scaling-laws-for-reward-model-overoptimization",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "From PyTorch DDP to 🤗 Accelerate to 🤗 Trainer, mastery of distributed training with ease",
    "description": "",
    "summary": "",
    "pubDate": "Fri, 21 Oct 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/pytorch-ddp-accelerate-transformers",
    "thumbnail": "https://huggingface.co/blog/assets/111_pytorch_ddp_accelerate_transformers/thumbnail.png"
  },
  {
    "title": "Evaluating Language Model Bias with 🤗 Evaluate",
    "description": "",
    "summary": "",
    "pubDate": "Mon, 24 Oct 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/evaluating-llm-bias",
    "thumbnail": "https://huggingface.co/blog/assets/112_evaluating-llm-bias/thumbnail.png"
  },
  {
    "title": "Accelerate your models with 🤗 Optimum Intel and OpenVINO",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 02 Nov 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/openvino",
    "thumbnail": "https://huggingface.co/blog/assets/113_openvino/thumbnail.png"
  },
  {
    "title": "DALL·E API now available in public beta",
    "description": "Starting today, developers can begin building apps with the DALL·E API.",
    "summary": "Starting today, developers can begin building apps with the DALL·E API.",
    "pubDate": "Thu, 03 Nov 2022 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/dall-e-api-now-available-in-public-beta",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Fine-Tune Whisper with 🤗 Transformers",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 03 Nov 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/fine-tune-whisper",
    "thumbnail": "https://huggingface.co/blog/assets/111_fine_tune_whisper/thumbnail.jpg"
  },
  {
    "title": "Training Stable Diffusion with Dreambooth using 🧨 Diffusers",
    "description": "",
    "summary": "",
    "pubDate": "Mon, 07 Nov 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/dreambooth",
    "thumbnail": "https://huggingface.co/blog/assets/sd_dreambooth_training/thumbnail.jpg"
  },
  {
    "title": "Generating Human-level Text with Contrastive Search in Transformers 🤗",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 08 Nov 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/introducing-csearch",
    "thumbnail": "https://huggingface.co/blog/assets/115_introducing_contrastive_search/thumbnail.png"
  },
  {
    "title": "Introducing our new pricing",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 08 Nov 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/pricing-update",
    "thumbnail": "https://huggingface.co/blog/assets/114_pricing-update/thumbnail.png"
  },
  {
    "title": "Best practices for data enrichment",
    "description": "Building a responsible approach to data collection with the Partnership on AI...",
    "summary": "Building a responsible approach to data collection with the Partnership on AI...",
    "pubDate": "Wed, 16 Nov 2022 00:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/best-practices-for-data-enrichment/",
    "thumbnail": "https://lh3.googleusercontent.com/nYvgmCtFKpHCzKOzqvlm-YK_l5qbPvz570PQbWv2ZxKVIoZxraa7euQLCY65a7ecdDRzBQtbQY2jxAoYKO8PC90snL6QvwNAzhp5-8x31cL5cJV-_OY=w1200-h630-n-nu"
  },
  {
    "title": "Hugging Face Machine Learning Demos on arXiv",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 17 Nov 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/arxiv",
    "thumbnail": "https://huggingface.co/blog/assets/arxiv/thumbnail.png"
  },
  {
    "title": "Sentiment Classification with Fully Homomorphic Encryption using Concrete ML",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 17 Nov 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/sentiment-analysis-fhe",
    "thumbnail": "https://huggingface.co/blog/assets/sentiment-analysis-fhe/thumbnail.png"
  },
  {
    "title": "Accelerating Document AI",
    "description": "",
    "summary": "",
    "pubDate": "Mon, 21 Nov 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/document-ai",
    "thumbnail": "https://huggingface.co/blog/assets/112_document-ai/thumbnail.png"
  },
  {
    "title": "An Overview of Inference Solutions on Hugging Face",
    "description": "",
    "summary": "",
    "pubDate": "Mon, 21 Nov 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/inference-update",
    "thumbnail": "https://huggingface.co/blog/assets/116_inference_update/widget.png"
  },
  {
    "title": "Benchmarking the next generation of never-ending learners",
    "description": "Learning how to build upon knowledge by tapping 30 years of computer vision research",
    "summary": "Learning how to build upon knowledge by tapping 30 years of computer vision research",
    "pubDate": "Tue, 22 Nov 2022 00:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/benchmarking-the-next-generation-of-never-ending-learners/",
    "thumbnail": "https://lh3.googleusercontent.com/VEIJiplOab4catyNZs6QjZxwjbqVmrh2fIZF8Gj7Xd7TQRq1q4bqDmbeSuVzHPzDhC8vKYI5nZLft79VWP5Oi7j_ARAzyFVxMdJIMKxDD5VfRpGm=w1200-h630-n-nu"
  },
  {
    "title": "Building interactive agents in video game worlds",
    "description": "Most artificial intelligence (AI) researchers now believe that writing computer code which can capture the nuances of situated interactions is impossible. Alternatively, modern machine learning (ML) researchers have focused on learning about these types of interactions from data. To explore these learning-based approaches and quickly build agents that can make sense of human instructions and safely perform actions in open-ended conditions, we created a research framework within a video game environment.Today, we’re publishing a paper [INSERT LINK] and collection of videos, showing our early steps in building video game AIs that can understand fuzzy human concepts – and therefore, can begin to interact with people on their own terms.",
    "summary": "Most artificial intelligence (AI) researchers now believe that writing computer code which can capture the nuances of situated interactions is impossible. Alternatively, modern machine learning (ML) researchers have focused on learning about these types of interactions from data. To explore these learning-based approaches and quickly build agents that can make sense of human instructions and safely perform actions in open-ended conditions, we created a research framework within a video game environment.Today, we’re publishing a paper [INSERT LINK] and collection of videos, showing our early steps in building video game AIs that can understand fuzzy human concepts – and therefore, can begin to interact with people on their own terms.",
    "pubDate": "Wed, 23 Nov 2022 00:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/building-interactive-agents-in-video-game-worlds/",
    "thumbnail": "https://lh3.googleusercontent.com/6DSrkFaInWqKD1eN4IJJN31ZRa3LW447A1ZYoK19FDzJGSLD5dlVw1rJRf52O_dmQUDq11XqYsiqMR8uFDnWLWGkl8xFY5KXYxD7LvQNPvTEuR_h=w1200-h630-n-nu"
  },
  {
    "title": "Director of Machine Learning Insights [Part 4]",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 23 Nov 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/ml-director-insights-4",
    "thumbnail": "https://huggingface.co/blog/assets/78_ml_director_insights/part4.png"
  },
  {
    "title": "DeepMind’s latest research at NeurIPS 2022",
    "description": "NeurIPS is the world’s largest conference in artificial intelligence (AI) and machine learning (ML), and we’re proud to support the event as Diamond sponsors, helping foster the exchange of research advances in the AI and ML community. Teams from across DeepMind are presenting 47 papers, including 35 external collaborations in virtual panels and poster sessions.",
    "summary": "NeurIPS is the world’s largest conference in artificial intelligence (AI) and machine learning (ML), and we’re proud to support the event as Diamond sponsors, helping foster the exchange of research advances in the AI and ML community. Teams from across DeepMind are presenting 47 papers, including 35 external collaborations in virtual panels and poster sessions.",
    "pubDate": "Fri, 25 Nov 2022 00:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/deepminds-latest-research-at-neurips-2022/",
    "thumbnail": "https://lh3.googleusercontent.com/MFZKdGWHOzJ6nM8NufhIfpts0R-v9D4jQqnC416FT8ArwmNC2Ztke2S50WVtUhO0g1u8AGmYEyWMDC7LO0a16ydHBMei9GmJO4NjykhpLKw1TVtd4Mg=w1200-h630-n-nu"
  },
  {
    "title": "Diffusion Models Live Event",
    "description": "",
    "summary": "",
    "pubDate": "Fri, 25 Nov 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/diffusion-models-event",
    "thumbnail": "https://huggingface.co/blog/assets/diffusion-models-event/thumbnail.png"
  },
  {
    "title": "We are hiring interns!",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 29 Nov 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/interns-2023",
    "thumbnail": "https://huggingface.co/blog/assets/interns-2023/thumbnail.png"
  },
  {
    "title": "Introducing ChatGPT",
    "description": "We’ve trained a model called ChatGPT which interacts in a conversational way. The dialogue format makes it possible for ChatGPT to answer followup questions, admit its mistakes, challenge incorrect premises, and reject inappropriate requests.",
    "summary": "We’ve trained a model called ChatGPT which interacts in a conversational way. The dialogue format makes it possible for ChatGPT to answer followup questions, admit its mistakes, challenge incorrect premises, and reject inappropriate requests.",
    "pubDate": "Wed, 30 Nov 2022 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/chatgpt",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "VQ Diffusion with 🧨 Diffusers",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 30 Nov 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/vq-diffusion",
    "thumbnail": "https://huggingface.co/blog/assets/117_vq_diffusion/thumbnail.png"
  },
  {
    "title": "Mastering Stratego, the classic game of imperfect information",
    "description": "Game-playing artificial intelligence (AI) systems have advanced to a new frontier.",
    "summary": "Game-playing artificial intelligence (AI) systems have advanced to a new frontier.",
    "pubDate": "Thu, 01 Dec 2022 00:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/mastering-stratego-the-classic-game-of-imperfect-information/",
    "thumbnail": "https://lh3.googleusercontent.com/nvWTaah_1s2OEAt4CsxX5gKok_0V6-Q5eH3aW3GF6YyZdEVM0OBdgFxNa4DAbmUCXpvTqTfslfUB7_3ZBYr6kIQuk2u46khXH41IU16EZghstwt72Mk=w1200-h630-n-nu"
  },
  {
    "title": "Probabilistic Time Series Forecasting with 🤗 Transformers",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 01 Dec 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/time-series-transformers",
    "thumbnail": "https://huggingface.co/blog/assets/118_time-series-transformers/thumbnail.png"
  },
  {
    "title": "Using Stable Diffusion with Core ML on Apple Silicon",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 01 Dec 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/diffusers-coreml",
    "thumbnail": "https://huggingface.co/blog/assets/diffusers_coreml/thumbnail.png"
  },
  {
    "title": "Deep Learning with Proteins",
    "description": "",
    "summary": "",
    "pubDate": "Fri, 02 Dec 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/deep-learning-with-proteins",
    "thumbnail": "https://huggingface.co/blog/assets/119_deep_learning_with_proteins/folding_example.png"
  },
  {
    "title": "AI for the board game Diplomacy",
    "description": "Successful communication and cooperation have been crucial for helping societies advance throughout history. The closed environments of board games can serve as a sandbox for modelling and investigating interaction and communication – and we can learn a lot from playing them. In our recent paper, published today in Nature Communications, we show how artificial agents can use communication to better cooperate in the board game Diplomacy, a vibrant domain in artificial intelligence (AI) research, known for its focus on alliance building.",
    "summary": "Successful communication and cooperation have been crucial for helping societies advance throughout history. The closed environments of board games can serve as a sandbox for modelling and investigating interaction and communication – and we can learn a lot from playing them. In our recent paper, published today in Nature Communications, we show how artificial agents can use communication to better cooperate in the board game Diplomacy, a vibrant domain in artificial intelligence (AI) research, known for its focus on alliance building.",
    "pubDate": "Tue, 06 Dec 2022 00:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/ai-for-the-board-game-diplomacy/",
    "thumbnail": "https://lh3.googleusercontent.com/VEIJiplOab4catyNZs6QjZxwjbqVmrh2fIZF8Gj7Xd7TQRq1q4bqDmbeSuVzHPzDhC8vKYI5nZLft79VWP5Oi7j_ARAzyFVxMdJIMKxDD5VfRpGm=w1200-h630-n-nu"
  },
  {
    "title": "Competitive programming with AlphaCode",
    "description": "Solving novel problems and setting a new milestone in competitive programming.",
    "summary": "Solving novel problems and setting a new milestone in competitive programming.",
    "pubDate": "Thu, 08 Dec 2022 00:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/competitive-programming-with-alphacode/",
    "thumbnail": "https://lh3.googleusercontent.com/vQ0Ow6LwCpigfPyTGUhXEfdMBWPyHmaCo7eoQW7bv3QoZXW6EIj18FPiCLI1vlMYlUAOvEXta1KSkl8P2KScquYJb-Dm_QygP9kdlLYkpF4nVyEH=w1200-h630-n-nu"
  },
  {
    "title": "Discovering the minutiae of backend systems",
    "description": "Christian Gibson is an engineer on the Supercomputing team at OpenAI.",
    "summary": "Christian Gibson is an engineer on the Supercomputing team at OpenAI.",
    "pubDate": "Thu, 08 Dec 2022 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/discovering-the-minutiae-of-backend-systems",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "From GPT2 to Stable Diffusion: Hugging Face arrives to the Elixir community",
    "description": "",
    "summary": "",
    "pubDate": "Fri, 09 Dec 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/elixir-bumblebee",
    "thumbnail": "https://huggingface.co/blog/assets/120_elixir-bumblebee/thumbnail.png"
  },
  {
    "title": "Illustrating Reinforcement Learning from Human Feedback (RLHF)",
    "description": "",
    "summary": "",
    "pubDate": "Fri, 09 Dec 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/rlhf",
    "thumbnail": "https://huggingface.co/blog/assets/120_rlhf/thumbnail.png"
  },
  {
    "title": "Faster Training and Inference: Habana Gaudi®2 vs Nvidia A100 80GB",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 14 Dec 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/habana-gaudi-2-benchmark",
    "thumbnail": "https://huggingface.co/blog/assets/habana-gaudi-2-benchmark/thumbnail.png"
  },
  {
    "title": "A Complete Guide to Audio Datasets",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 15 Dec 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/audio-datasets",
    "thumbnail": "https://huggingface.co/blog/assets/116_audio_datasets/thumbnail.jpg"
  },
  {
    "title": "Ethics and Society Newsletter #2: Let's talk about bias!",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 15 Dec 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/ethics-soc-2",
    "thumbnail": "https://huggingface.co/blog/assets/122_ethics_soc_2/thumbnail-solstice.png"
  },
  {
    "title": "New and improved embedding model",
    "description": "We are excited to announce a new embedding model which is significantly more capable, cost effective, and simpler to use.",
    "summary": "We are excited to announce a new embedding model which is significantly more capable, cost effective, and simpler to use.",
    "pubDate": "Thu, 15 Dec 2022 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/new-and-improved-embedding-model",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Point-E: A system for generating 3D point clouds from complex prompts",
    "description": "",
    "summary": "",
    "pubDate": "Fri, 16 Dec 2022 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/point-e",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Model Cards: Introducing HF Model documentation tools",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 20 Dec 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/model-cards",
    "thumbnail": "https://huggingface.co/blog/assets/121_model-cards/thumbnail.png"
  },
  {
    "title": "Zero-shot image segmentation with CLIPSeg",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 21 Dec 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/clipseg-zero-shot",
    "thumbnail": "https://huggingface.co/blog/assets/123_clipseg-zero-shot/thumb.png"
  },
  {
    "title": "The power of continuous learning",
    "description": "Lilian Weng works on Applied AI Research at OpenAI.",
    "summary": "Lilian Weng works on Applied AI Research at OpenAI.",
    "pubDate": "Fri, 23 Dec 2022 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/the-power-of-continuous-learning",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Creating next-gen characters",
    "description": "Using GPT-3 to create the next generation of AI-powered characters.",
    "summary": "Using GPT-3 to create the next generation of AI-powered characters.",
    "pubDate": "Sun, 01 Jan 2023 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/inworld-ai",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Accelerating PyTorch Transformers with Intel Sapphire Rapids, part 1",
    "description": "",
    "summary": "",
    "pubDate": "Mon, 02 Jan 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/intel-sapphire-rapids",
    "thumbnail": "https://huggingface.co/blog/assets/124_intel_sapphire_rapids/02.png"
  },
  {
    "title": "AI for Game Development: Creating a Farming Game in 5 Days. Part 1",
    "description": "",
    "summary": "",
    "pubDate": "Mon, 02 Jan 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/ml-for-games-1",
    "thumbnail": "https://huggingface.co/blog/assets/124_ml-for-games/thumbnail.png"
  },
  {
    "title": "Fine-tuning GPT-3 to scale video creation",
    "description": "Fine-tuning GPT-3 to power and scale done-for-you video creation.",
    "summary": "Fine-tuning GPT-3 to power and scale done-for-you video creation.",
    "pubDate": "Tue, 03 Jan 2023 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/waymark",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Introduction to Graph Machine Learning",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 03 Jan 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/intro-graphml",
    "thumbnail": "https://huggingface.co/blog/assets/125_intro-to-graphml/thumbnail.png"
  },
  {
    "title": "Delivering nuanced insights from customer feedback",
    "description": "Using GPT-3 to deliver fast, nuanced insights from customer feedback.",
    "summary": "Using GPT-3 to deliver fast, nuanced insights from customer feedback.",
    "pubDate": "Wed, 04 Jan 2023 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/yabble",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "AI for Game Development: Creating a Farming Game in 5 Days. Part 2",
    "description": "",
    "summary": "",
    "pubDate": "Mon, 09 Jan 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/ml-for-games-2",
    "thumbnail": "https://huggingface.co/blog/assets/124_ml-for-games/thumbnail2.png"
  },
  {
    "title": "Forecasting potential misuses of language models for disinformation campaigns and how to reduce risk",
    "description": "OpenAI researchers collaborated with Georgetown University’s Center for Security and Emerging Technology and the Stanford Internet Observatory to investigate how large language models might be misused for disinformation purposes. The collaboration included an October 2021 workshop bringing together 30 disinformation researchers, machine learning experts, and policy analysts, and culminated in a co-authored report building on more than a year of research. This report outlines the threats that language models pose to the information environment if used to augment disinformation campaigns and introduces a framework for analyzing potential mitigations. Read the full report here.",
    "summary": "OpenAI researchers collaborated with Georgetown University’s Center for Security and Emerging Technology and the Stanford Internet Observatory to investigate how large language models might be misused for disinformation purposes. The collaboration included an October 2021 workshop bringing together 30 disinformation researchers, machine learning experts, and policy analysts, and culminated in a co-authored report building on more than a year of research. This report outlines the threats that language models pose to the information environment if used to augment disinformation campaigns and introduces a framework for analyzing potential mitigations. Read the full report here.",
    "pubDate": "Wed, 11 Jan 2023 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/forecasting-misuse",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Image Similarity with Hugging Face Datasets and Transformers",
    "description": "",
    "summary": "",
    "pubDate": "Mon, 16 Jan 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/image-similarity",
    "thumbnail": "https://huggingface.co/blog/assets/image_similarity/thumbnail.png"
  },
  {
    "title": "Welcome PaddlePaddle to the Hugging Face Hub",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 17 Jan 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/paddlepaddle",
    "thumbnail": "https://huggingface.co/blog/assets/126_paddlepaddle/thumbnail.jpg"
  },
  {
    "title": "Universal Image Segmentation with Mask2Former and OneFormer",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 19 Jan 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/mask2former",
    "thumbnail": "https://huggingface.co/blog/assets/127_mask2former/thumbnail.png"
  },
  {
    "title": "3D Asset Generation: AI for Game Development #3",
    "description": "",
    "summary": "",
    "pubDate": "Fri, 20 Jan 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/ml-for-games-3",
    "thumbnail": "https://huggingface.co/blog/assets/124_ml-for-games/thumbnail3.png"
  },
  {
    "title": "OpenAI and Microsoft extend partnership",
    "description": "We’re happy to announce that OpenAI and Microsoft are extending our partnership.",
    "summary": "We’re happy to announce that OpenAI and Microsoft are extending our partnership.",
    "pubDate": "Mon, 23 Jan 2023 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-and-microsoft-extend-partnership",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Optimum+ONNX Runtime - Easier, Faster training for your Hugging Face models",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 24 Jan 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/optimum-onnxruntime-training",
    "thumbnail": "https://huggingface.co/blog/assets/optimum_onnxruntime-training/thumbnail.png"
  },
  {
    "title": "What Makes a Dialog Agent Useful?",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 24 Jan 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/dialog-agents",
    "thumbnail": "https://huggingface.co/blog/assets/dialog-agents/thumbnail.png"
  },
  {
    "title": "2D Asset Generation: AI for Game Development #4",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 26 Jan 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/ml-for-games-4",
    "thumbnail": "https://huggingface.co/blog/assets/124_ml-for-games/thumbnail4.png"
  },
  {
    "title": "Using LoRA for Efficient Stable Diffusion Fine-Tuning",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 26 Jan 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/lora",
    "thumbnail": "https://huggingface.co/blog/assets/lora/thumbnail.png"
  },
  {
    "title": "The State of Computer Vision at Hugging Face 🤗",
    "description": "",
    "summary": "",
    "pubDate": "Mon, 30 Jan 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/cv_state",
    "thumbnail": "https://huggingface.co/blog/assets/cv_state/thumbnail.png"
  },
  {
    "title": "New AI classifier for indicating AI-written text",
    "description": "We’re launching a classifier trained to distinguish between AI-written and human-written text.",
    "summary": "We’re launching a classifier trained to distinguish between AI-written and human-written text.",
    "pubDate": "Tue, 31 Jan 2023 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/new-ai-classifier-for-indicating-ai-written-text",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Introducing ChatGPT Plus",
    "description": "We’re launching a pilot subscription plan for ChatGPT, a conversational AI that can chat with you, answer follow-up questions, and challenge incorrect assumptions.",
    "summary": "We’re launching a pilot subscription plan for ChatGPT, a conversational AI that can chat with you, answer follow-up questions, and challenge incorrect assumptions.",
    "pubDate": "Wed, 01 Feb 2023 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/chatgpt-plus",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "A Dive into Pretraining Strategies for Vision-Language Models",
    "description": "",
    "summary": "",
    "pubDate": "Fri, 03 Feb 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/vision_language_pretraining",
    "thumbnail": "https://huggingface.co/blog//assets/128_vision_language_pretraining/thumbnail.png"
  },
  {
    "title": "Accelerating PyTorch Transformers with Intel Sapphire Rapids, part 2",
    "description": "",
    "summary": "",
    "pubDate": "Mon, 06 Feb 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/intel-sapphire-rapids-inference",
    "thumbnail": "https://huggingface.co/blog/assets/129_intel_sapphire_rapids_inference/01.png"
  },
  {
    "title": "Generating Stories: AI for Game Development #5",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 07 Feb 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/ml-for-games-5",
    "thumbnail": "https://huggingface.co/blog/assets/124_ml-for-games/thumbnail5.png"
  },
  {
    "title": "Introducing ⚔️ AI vs. AI ⚔️ a deep reinforcement learning multi-agents competition system",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 07 Feb 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/aivsai",
    "thumbnail": "https://huggingface.co/blog/assets/128_aivsai/thumbnail.png"
  },
  {
    "title": "Speech Synthesis, Recognition, and More With SpeechT5",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 08 Feb 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/speecht5",
    "thumbnail": "https://huggingface.co/blog/assets/speecht5/thumbnail.png"
  },
  {
    "title": "🤗 PEFT: Parameter-Efficient Fine-Tuning of Billion-Scale Models on Low-Resource Hardware",
    "description": "",
    "summary": "",
    "pubDate": "Fri, 10 Feb 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/peft",
    "thumbnail": "https://huggingface.co/blog/assets/130_peft/thumbnail.png"
  },
  {
    "title": "Why we’re switching to Hugging Face Inference Endpoints, and maybe you should too",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 15 Feb 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/mantis-case-study",
    "thumbnail": "https://huggingface.co/blog/assets/78_ml_director_insights/mantis1.png"
  },
  {
    "title": "Zero-shot image-to-text generation with BLIP-2",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 15 Feb 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/blip-2",
    "thumbnail": "https://huggingface.co/blog/assets/blip-2/thumbnail.png"
  },
  {
    "title": "How should AI systems behave, and who should decide?",
    "description": "We’re clarifying how ChatGPT’s behavior is shaped and our plans for improving that behavior, allowing more user customization, and getting more public input into our decision-making in these areas.",
    "summary": "We’re clarifying how ChatGPT’s behavior is shaped and our plans for improving that behavior, allowing more user customization, and getting more public input into our decision-making in these areas.",
    "pubDate": "Thu, 16 Feb 2023 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/how-should-ai-systems-behave",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Hugging Face and AWS partner to make AI more accessible",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 21 Feb 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/aws-partnership",
    "thumbnail": "https://huggingface.co/blog/assets/131_aws-partnership/aws-partnership-thumbnail.png"
  },
  {
    "title": "Fetch Consolidates AI Tools and Saves 30% Development Time with Hugging Face on AWS",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 23 Feb 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/fetch-eap-case-study",
    "thumbnail": "https://huggingface.co/blog/assets/78_ml_director_insights/fetch2.png"
  },
  {
    "title": "Planning for AGI and beyond",
    "description": "Our mission is to ensure that artificial general intelligence—AI systems that are generally smarter than humans—benefits all of humanity.",
    "summary": "Our mission is to ensure that artificial general intelligence—AI systems that are generally smarter than humans—benefits all of humanity.",
    "pubDate": "Fri, 24 Feb 2023 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/planning-for-agi-and-beyond",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Red-Teaming Large Language Models",
    "description": "",
    "summary": "",
    "pubDate": "Fri, 24 Feb 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/red-teaming",
    "thumbnail": "https://huggingface.co/blog/assets/red-teaming/thumbnail.png"
  },
  {
    "title": "Swift Diffusers: Fast Stable Diffusion for Mac",
    "description": "",
    "summary": "",
    "pubDate": "Fri, 24 Feb 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/fast-mac-diffusers",
    "thumbnail": "https://huggingface.co/blog/assets/fast-mac-diffusers/thumbnail.png"
  },
  {
    "title": "How Hugging Face Accelerated Development of Witty Works Writing Assistant",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 01 Mar 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/classification-use-cases",
    "thumbnail": "https://huggingface.co/blog/assets/78_ml_director_insights/witty-works.png"
  },
  {
    "title": "Ethical guidelines for developing the Diffusers library",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 02 Mar 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/ethics-diffusers",
    "thumbnail": "https://huggingface.co/blog/assets/ethics-diffusers/thumbnail.png"
  },
  {
    "title": "ControlNet in Diffusers 🧨",
    "description": "",
    "summary": "",
    "pubDate": "Fri, 03 Mar 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/controlnet",
    "thumbnail": "https://huggingface.co/blog/assets/controlnet/thumbnail.png"
  },
  {
    "title": "Using Machine Learning to Aid Survivors and Race through Time",
    "description": "",
    "summary": "",
    "pubDate": "Fri, 03 Mar 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/using-ml-for-disasters",
    "thumbnail": "https://huggingface.co/blog/assets/using-ml-for-disasters/thumbnail.png"
  },
  {
    "title": "New ViT and ALIGN Models From Kakao Brain",
    "description": "",
    "summary": "",
    "pubDate": "Mon, 06 Mar 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/vit-align",
    "thumbnail": "https://huggingface.co/blog//assets/132_vit_align/thumbnail.png"
  },
  {
    "title": "Fine-tuning 20B LLMs with RLHF on a 24GB consumer GPU",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 09 Mar 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/trl-peft",
    "thumbnail": "https://huggingface.co/blog/trl-peft/assets/133_trl_peft/thumbnail.png"
  },
  {
    "title": "Multivariate Probabilistic Time Series Forecasting with Informer",
    "description": "",
    "summary": "",
    "pubDate": "Fri, 10 Mar 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/informer",
    "thumbnail": "https://huggingface.co/blog/assets/134_informer/thumbnail.png"
  },
  {
    "title": "Filling crucial language learning gaps",
    "description": "GPT-4 deepens the conversation on Duolingo.",
    "summary": "GPT-4 deepens the conversation on Duolingo.",
    "pubDate": "Tue, 14 Mar 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/duolingo",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "GPT-4",
    "description": "We’ve created GPT-4, the latest milestone in OpenAI’s effort in scaling up deep learning. GPT-4 is a large multimodal model (accepting image and text inputs, emitting text outputs) that, while less capable than humans in many real-world scenarios, exhibits human-level performance on various professional and academic benchmarks.",
    "summary": "We’ve created GPT-4, the latest milestone in OpenAI’s effort in scaling up deep learning. GPT-4 is a large multimodal model (accepting image and text inputs, emitting text outputs) that, while less capable than humans in many real-world scenarios, exhibits human-level performance on various professional and academic benchmarks.",
    "pubDate": "Tue, 14 Mar 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/gpt-4-research",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Powering virtual education for the classroom",
    "description": "Khan Academy explores the potential for GPT-4 in a limited pilot program.",
    "summary": "Khan Academy explores the potential for GPT-4 in a limited pilot program.",
    "pubDate": "Tue, 14 Mar 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/khan-academy",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Preserving languages for the future",
    "description": "How Iceland is using GPT-4 to preserve its language.",
    "summary": "How Iceland is using GPT-4 to preserve its language.",
    "pubDate": "Tue, 14 Mar 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/government-of-iceland",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Streamlining financial solutions for safety and growth",
    "description": "Stripe leverages GPT-4 to streamline user experience and combat fraud.",
    "summary": "Stripe leverages GPT-4 to streamline user experience and combat fraud.",
    "pubDate": "Tue, 14 Mar 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/stripe",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Transforming visual accessibility",
    "description": "Be My Eyes uses GPT-4 to transform visual accessibility.",
    "summary": "Be My Eyes uses GPT-4 to transform visual accessibility.",
    "pubDate": "Tue, 14 Mar 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/be-my-eyes",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "GPTs are GPTs: An early look at the labor market impact potential of large language models",
    "description": "",
    "summary": "",
    "pubDate": "Fri, 17 Mar 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/gpts-are-gpts",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "ChatGPT plugins",
    "description": "We’ve implemented initial support for plugins in ChatGPT. Plugins are tools designed specifically for language models with safety as a core principle, and help ChatGPT access up-to-date information, run computations, or use third-party services.",
    "summary": "We’ve implemented initial support for plugins in ChatGPT. Plugins are tools designed specifically for language models with safety as a core principle, and help ChatGPT access up-to-date information, run computations, or use third-party services.",
    "pubDate": "Thu, 23 Mar 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/chatgpt-plugins",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Jupyter X Hugging Face",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 23 Mar 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/notebooks-hub",
    "thumbnail": "https://huggingface.co/blog/assets/135_notebooks-hub/before_after_notebook_rendering.png"
  },
  {
    "title": "March 20 ChatGPT outage: Here’s what happened",
    "description": "An update on our findings, the actions we’ve taken, and technical details of the bug.",
    "summary": "An update on our findings, the actions we’ve taken, and technical details of the bug.",
    "pubDate": "Fri, 24 Mar 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/march-20-chatgpt-outage",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Train your ControlNet with diffusers",
    "description": "",
    "summary": "",
    "pubDate": "Fri, 24 Mar 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/train-your-controlnet",
    "thumbnail": "https://huggingface.co/blog/assets/136_train-your-controlnet/thumbnail.png"
  },
  {
    "title": "Federated Learning using Hugging Face and Flower",
    "description": "",
    "summary": "",
    "pubDate": "Mon, 27 Mar 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/fl-with-flower",
    "thumbnail": "https://huggingface.co/blog/assets/fl-with-flower/thumbnail.png"
  },
  {
    "title": "Accelerating Stable Diffusion Inference on Intel CPUs",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 28 Mar 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/stable-diffusion-inference-intel",
    "thumbnail": "https://huggingface.co/blog/assets/136_stable_diffusion_inference_intel/01.png"
  },
  {
    "title": "Fast Inference on Large Language Models: BLOOMZ on Habana Gaudi2 Accelerator",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 28 Mar 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/habana-gaudi-2-bloom",
    "thumbnail": "https://huggingface.co/blog/assets/habana-gaudi-2-bloom/thumbnail.png"
  },
  {
    "title": "Ethics and Society Newsletter #3: Ethical Openness at Hugging Face",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 30 Mar 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/ethics-soc-3",
    "thumbnail": "https://huggingface.co/blog/assets/137_ethics_soc_3/ethics_3_thumbnail.png"
  },
  {
    "title": "Our approach to AI safety",
    "description": "Ensuring that AI systems are built, deployed, and used safely is critical to our mission.",
    "summary": "Ensuring that AI systems are built, deployed, and used safely is critical to our mission.",
    "pubDate": "Wed, 05 Apr 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/our-approach-to-ai-safety",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "StackLLaMA: A hands-on guide to train LLaMA with RLHF",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 05 Apr 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/stackllama",
    "thumbnail": "https://huggingface.co/blog/assets/138_stackllama/thumbnail.png"
  },
  {
    "title": "Snorkel AI x Hugging Face: unlock foundation models for enterprises",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 06 Apr 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/snorkel-case-study",
    "thumbnail": "https://huggingface.co/blog/assets/78_ml_director_insights/snorkel.png"
  },
  {
    "title": "Announcing OpenAI’s Bug Bounty Program",
    "description": "This initiative is essential to our commitment to develop safe and advanced AI. As we create technology and services that are secure, reliable, and trustworthy, we need your help.",
    "summary": "This initiative is essential to our commitment to develop safe and advanced AI. As we create technology and services that are secure, reliable, and trustworthy, we need your help.",
    "pubDate": "Tue, 11 Apr 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/bug-bounty-program",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Creating Privacy Preserving AI with Substra",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 12 Apr 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/owkin-substra",
    "thumbnail": "https://huggingface.co/blog/assets/139_owkin-substra/thumbnail.png"
  },
  {
    "title": "Graph Classification with Transformers",
    "description": "",
    "summary": "",
    "pubDate": "Fri, 14 Apr 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/graphml-classification",
    "thumbnail": "https://huggingface.co/blog/assets/125_intro-to-graphml/thumbnail_classification.png"
  },
  {
    "title": "Accelerating Hugging Face Transformers with AWS Inferentia2",
    "description": "",
    "summary": "",
    "pubDate": "Mon, 17 Apr 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/accelerate-transformers-with-inferentia2",
    "thumbnail": "https://huggingface.co/blog/assets/140_accelerate_transformers_with_inferentia2/thumbnail.png"
  },
  {
    "title": "Announcing Google DeepMind",
    "description": "DeepMind and the Brain team from Google Research will join forces to accelerate progress towards a world in which AI helps solve the biggest challenges facing humanity.",
    "summary": "DeepMind and the Brain team from Google Research will join forces to accelerate progress towards a world in which AI helps solve the biggest challenges facing humanity.",
    "pubDate": "Thu, 20 Apr 2023 00:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/announcing-google-deepmind/",
    "thumbnail": "https://lh3.googleusercontent.com/MNdJdEO1VpepmU25h9OTpnMr9hxe6NScc1ZWlerWf5WtOYMnHETsPEWKqvG36zQv5CGflTOHAKG_JbADpmLrh8Mrpa91B95U6bs0isMSbTUerT-qT38=w1200-h630-n-nu"
  },
  {
    "title": "How to host a Unity game in a Space",
    "description": "",
    "summary": "",
    "pubDate": "Fri, 21 Apr 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/unity-in-spaces",
    "thumbnail": "https://huggingface.co/blog/assets/124_ml-for-games/unity-in-spaces-thumbnail.png"
  },
  {
    "title": "How can we build human values into AI?",
    "description": "Drawing from philosophy to identify fair principles for ethical AI...",
    "summary": "Drawing from philosophy to identify fair principles for ethical AI...",
    "pubDate": "Mon, 24 Apr 2023 00:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/how-can-we-build-human-values-into-ai/",
    "thumbnail": "https://lh3.googleusercontent.com/jXiO9PpMnNRhxz3kyDP97SVi5c68dQie9V4AHbH_I0Py0EJoOl0fyPhoVljUGETrNmj3BhbAEahqmsq4r-33IgLgGhsuUhN2p384-d8B_vc4asHWB6Q=w1200-h630-n-nu"
  },
  {
    "title": "Introducing HuggingFace blog for Chinese speakers: Fostering Collaboration with the Chinese AI community",
    "description": "",
    "summary": "",
    "pubDate": "Mon, 24 Apr 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/chinese-language-blog",
    "thumbnail": "https://huggingface.co/blog/assets/chinese-language-blog/thumbnail.png"
  },
  {
    "title": "New ways to manage your data in ChatGPT",
    "description": "ChatGPT users can now turn off chat history, allowing you to choose which conversations can be used to train our models.",
    "summary": "ChatGPT users can now turn off chat history, allowing you to choose which conversations can be used to train our models.",
    "pubDate": "Tue, 25 Apr 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/new-ways-to-manage-your-data-in-chatgpt",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Databricks ❤️ Hugging Face: up to 40% faster training and tuning of Large Language Models",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 26 Apr 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/databricks-case-study",
    "thumbnail": "https://huggingface.co/blog/assets/78_ml_director_insights/databricks.png"
  },
  {
    "title": "Running IF with 🧨 diffusers on a Free Tier Google Colab",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 26 Apr 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/if",
    "thumbnail": "https://huggingface.co/blog/assets/if/thumbnail.jpg"
  },
  {
    "title": "DeepMind’s latest research at ICLR 2023",
    "description": "Next week marks the start of the 11th International Conference on Learning Representations (ICLR), taking place 1-5 May in Kigali, Rwanda. This will be the first major artificial intelligence (AI) conference to be hosted in Africa and the first in-person event since the start of the pandemic. Researchers from around the world will gather to share their cutting-edge work in deep learning spanning the fields of AI, statistics and data science, and applications including machine vision, gaming and robotics. We’re proud to support the conference as a Diamond sponsor and DEI champion.",
    "summary": "Next week marks the start of the 11th International Conference on Learning Representations (ICLR), taking place 1-5 May in Kigali, Rwanda. This will be the first major artificial intelligence (AI) conference to be hosted in Africa and the first in-person event since the start of the pandemic. Researchers from around the world will gather to share their cutting-edge work in deep learning spanning the fields of AI, statistics and data science, and applications including machine vision, gaming and robotics. We’re proud to support the conference as a Diamond sponsor and DEI champion.",
    "pubDate": "Thu, 27 Apr 2023 00:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/deepminds-latest-research-at-iclr-2023/",
    "thumbnail": "https://lh3.googleusercontent.com/PH30vPBZLwZXlSFrALk6AT507Qn70LSPLW5a89vsRhDdkje_xaPGvNE2UrhOBy8Gkaasn-FVRuDWlPhEPntzw02gxSAEPygt7djS4URtQZJuaLPw3w=w1200-h630-n-nu"
  },
  {
    "title": "Training a language model with 🤗 Transformers using TensorFlow and TPUs",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 27 Apr 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/tf_tpu",
    "thumbnail": "https://huggingface.co/blog/assets/tf_tpu_training/thumbnail.png"
  },
  {
    "title": "How to Install and Use the Hugging Face Unity API",
    "description": "",
    "summary": "",
    "pubDate": "Mon, 01 May 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/unity-api",
    "thumbnail": "https://huggingface.co/blog/assets/124_ml-for-games/unity-api-thumbnail.png"
  },
  {
    "title": "StarCoder: A State-of-the-Art LLM for Code",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 04 May 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/starcoder",
    "thumbnail": "https://huggingface.co/blog/assets/141_starcoder/starcoder_thumbnail.png"
  },
  {
    "title": "A Dive into Text-to-Video Models",
    "description": "",
    "summary": "",
    "pubDate": "Mon, 08 May 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/text-to-video",
    "thumbnail": "https://huggingface.co/blog/assets/140_text-to-video/thumbnail.png"
  },
  {
    "title": "Creating a Coding Assistant with StarCoder",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 09 May 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/starchat-alpha",
    "thumbnail": "https://huggingface.co/blog/assets/starchat_alpha/thumbnail.png"
  },
  {
    "title": "Language models can explain neurons in language models",
    "description": "We use GPT-4 to automatically write explanations for the behavior of neurons in large language models and to score those explanations. We release a dataset of these (imperfect) explanations and scores for every neuron in GPT-2.",
    "summary": "We use GPT-4 to automatically write explanations for the behavior of neurons in large language models and to score those explanations. We release a dataset of these (imperfect) explanations and scores for every neuron in GPT-2.",
    "pubDate": "Tue, 09 May 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/language-models-can-explain-neurons-in-language-models",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Assisted Generation: a new direction toward low-latency text generation",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 11 May 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/assisted-generation",
    "thumbnail": "https://huggingface.co/blog/assets/assisted-generation/thumbnail.png"
  },
  {
    "title": "Hugging Face Selected for the French Data Protection Agency Enhanced Support Program",
    "description": "",
    "summary": "",
    "pubDate": "Mon, 15 May 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/cnil",
    "thumbnail": "https://huggingface.co/blog/assets/146_cnil-accompaniment/logo.png"
  },
  {
    "title": "Introducing RWKV — An RNN with the advantages of a transformer",
    "description": "",
    "summary": "",
    "pubDate": "Mon, 15 May 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/rwkv",
    "thumbnail": "https://huggingface.co/blog/assets/142_rwkv/rwkv_thumbnail.png"
  },
  {
    "title": "Run a Chatgpt-like Chatbot on a Single GPU with ROCm",
    "description": "",
    "summary": "",
    "pubDate": "Mon, 15 May 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/chatbot-amd-gpu",
    "thumbnail": "https://huggingface.co/blog/assets/chatbot-amd-gpu/thumbnail.png"
  },
  {
    "title": "Large-scale Near-deduplication Behind BigCode",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 16 May 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/dedup",
    "thumbnail": "https://huggingface.co/blog/assets/dedup/thumbnail.png"
  },
  {
    "title": "Smaller is better: Q8-Chat, an efficient generative AI experience on Xeon",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 16 May 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/generative-ai-models-on-intel-cpu",
    "thumbnail": "https://huggingface.co/blog/assets/143_q8chat/thumbnail.png"
  },
  {
    "title": "Introducing the ChatGPT app for iOS",
    "description": "The ChatGPT app syncs your conversations, supports voice input, and brings our latest model improvements to your fingertips.",
    "summary": "The ChatGPT app syncs your conversations, supports voice input, and brings our latest model improvements to your fingertips.",
    "pubDate": "Thu, 18 May 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-the-chatgpt-app-for-ios",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Governance of superintelligence",
    "description": "Now is a good time to start thinking about the governance of superintelligence—future AI systems dramatically more capable than even AGI.",
    "summary": "Now is a good time to start thinking about the governance of superintelligence—future AI systems dramatically more capable than even AGI.",
    "pubDate": "Mon, 22 May 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/governance-of-superintelligence",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Hugging Face and IBM partner on watsonx.ai, the next-generation enterprise studio for AI builders",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 23 May 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/huggingface-and-ibm",
    "thumbnail": "https://huggingface.co/blog/assets/144_ibm/01.png"
  },
  {
    "title": "Instruction-tuning Stable Diffusion with InstructPix2Pix",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 23 May 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/instruction-tuning-sd",
    "thumbnail": "https://huggingface.co/blog/instruction-tuning-sd/assets/instruction_tuning_sd/thumbnail.png"
  },
  {
    "title": "Safetensors audited as really safe and becoming the default",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 23 May 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/safetensors-security-audit",
    "thumbnail": "https://huggingface.co/blog/assets/142_safetensors_official/thumbnail.png"
  },
  {
    "title": "Hugging Face Collaborates with Microsoft to Launch Hugging Face Model Catalog on Azure",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 24 May 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/hugging-face-endpoints-on-azure",
    "thumbnail": "https://huggingface.co/blog/assets/75_hugging_face_endpoints_on_azure/01.jpg"
  },
  {
    "title": "Making LLMs even more accessible with bitsandbytes, 4-bit quantization and QLoRA",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 24 May 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/4bit-transformers-bitsandbytes",
    "thumbnail": "https://huggingface.co/blog/assets/96_hf_bitsandbytes_integration/Thumbnail_blue.png"
  },
  {
    "title": "An early warning system for novel AI risks",
    "description": "New research proposes a framework for evaluating general-purpose models against novel threats",
    "summary": "New research proposes a framework for evaluating general-purpose models against novel threats",
    "pubDate": "Thu, 25 May 2023 00:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/an-early-warning-system-for-novel-ai-risks/",
    "thumbnail": "https://lh3.googleusercontent.com/REkFCC8KEOAocMWBwcHOxKM6K2zRs_qpMeUhnmHYkkGSbPPCLRhPDluhoZzx2k6_b4XvgZmhUqeuko9BXZZIPLmGR1q4BycDjLuDFQ5G5FDYPKD0x08=w1200-h630-n-nu"
  },
  {
    "title": "Democratic inputs to AI",
    "description": "Our nonprofit organization, OpenAI, Inc., is launching a program to award ten $100,000 grants to fund experiments in setting up a democratic process for deciding what rules AI systems should follow, within the bounds defined by the law.",
    "summary": "Our nonprofit organization, OpenAI, Inc., is launching a program to award ten $100,000 grants to fund experiments in setting up a democratic process for deciding what rules AI systems should follow, within the bounds defined by the law.",
    "pubDate": "Thu, 25 May 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/democratic-inputs-to-ai",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Optimizing Stable Diffusion for Intel CPUs with NNCF and 🤗 Optimum",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 25 May 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/train-optimize-sd-intel",
    "thumbnail": "https://huggingface.co/blog/assets/train_optimize_sd_intel/thumbnail.png"
  },
  {
    "title": "Improving mathematical reasoning with process supervision",
    "description": "We've trained a model to achieve a new state-of-the-art in mathematical problem solving by rewarding each correct step of reasoning (“process supervision”) instead of simply rewarding the correct final answer (“outcome supervision”). In addition to boosting performance relative to outcome supervision, process supervision also has an important alignment benefit: it directly trains the model to produce a chain-of-thought that is endorsed by humans.",
    "summary": "We've trained a model to achieve a new state-of-the-art in mathematical problem solving by rewarding each correct step of reasoning (“process supervision”) instead of simply rewarding the correct final answer (“outcome supervision”). In addition to boosting performance relative to outcome supervision, process supervision also has an important alignment benefit: it directly trains the model to produce a chain-of-thought that is endorsed by humans.",
    "pubDate": "Wed, 31 May 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/improving-mathematical-reasoning-with-process-supervision",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Introducing BERTopic Integration with Hugging Face Hub",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 31 May 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/bertopic",
    "thumbnail": "https://huggingface.co/blog/assets/145_bertopic/logo.png"
  },
  {
    "title": "Introducing the Hugging Face LLM Inference Container for Amazon SageMaker",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 31 May 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/sagemaker-huggingface-llm",
    "thumbnail": "https://huggingface.co/blog/assets/145_sagemaker-huggingface-llm/thumbnail.jpg"
  },
  {
    "title": "Announcing the Open Source AI Game Jam 🎮",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 01 Jun 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/game-jam",
    "thumbnail": "https://huggingface.co/blog/assets/145_gamejam/thumbnail.png"
  },
  {
    "title": "OpenAI Cybersecurity Grant Program",
    "description": "Our goal is to facilitate the development of AI-powered cybersecurity capabilities for defenders through grants and other support.",
    "summary": "Our goal is to facilitate the development of AI-powered cybersecurity capabilities for defenders through grants and other support.",
    "pubDate": "Thu, 01 Jun 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-cybersecurity-grant-program",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "AI Speech Recognition in Unity",
    "description": "",
    "summary": "",
    "pubDate": "Fri, 02 Jun 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/unity-asr",
    "thumbnail": "https://huggingface.co/blog/assets/124_ml-for-games/unity-asr-thumbnail.png"
  },
  {
    "title": "The Falcon has landed in the Hugging Face ecosystem",
    "description": "",
    "summary": "",
    "pubDate": "Mon, 05 Jun 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/falcon",
    "thumbnail": "https://huggingface.co/blog/assets/147_falcon/falcon_thumbnail.jpg"
  },
  {
    "title": "Welcome fastText to the 🤗 Hub",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 06 Jun 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/fasttext",
    "thumbnail": "https://huggingface.co/blog/assets/147_fasttext/thumbnail.png"
  },
  {
    "title": "AlphaDev discovers faster sorting algorithms",
    "description": "New algorithms will transform the foundations of computing",
    "summary": "New algorithms will transform the foundations of computing",
    "pubDate": "Wed, 07 Jun 2023 00:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/alphadev-discovers-faster-sorting-algorithms/",
    "thumbnail": "https://lh3.googleusercontent.com/kYAs9KTHdhYZE0BeKMKlphVqU3eQS8oXP_GNrrWBjFbl8r4YFv2FWlRbe6x9L4Q_L-eKZeE7E__GtKVJTLXvW_zGTTzplSJCplN02n_8cz7No815L5M=w1200-h630-n-nu"
  },
  {
    "title": "DuckDB: run SQL queries on 50,000+ datasets on the Hugging Face Hub",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 07 Jun 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/hub-duckdb",
    "thumbnail": "https://huggingface.co/blog/assets/hub_duckdb/hub_duckdb.png"
  },
  {
    "title": "Can foundation models label data like humans?",
    "description": "",
    "summary": "",
    "pubDate": "Mon, 12 Jun 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/open-llm-leaderboard-rlhf",
    "thumbnail": "https://huggingface.co/blog/assets/llm-leaderboard/leaderboard-thumbnail.png"
  },
  {
    "title": "Comment on NTIA AI Accountability Policy",
    "description": "The National Telecommunications and Information Administration (NTIA) request for comments on AI Accountability policy.",
    "summary": "The National Telecommunications and Information Administration (NTIA) request for comments on AI Accountability policy.",
    "pubDate": "Mon, 12 Jun 2023 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/global-affairs/comment-on-ntia-ai-accountability-policy",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "MuZero, AlphaZero, and AlphaDev: Optimizing computer systems",
    "description": "How MuZero, AlphaZero, and AlphaDev are optimizing the computing ecosystem that powers our world of devices.",
    "summary": "How MuZero, AlphaZero, and AlphaDev are optimizing the computing ecosystem that powers our world of devices.",
    "pubDate": "Mon, 12 Jun 2023 14:41:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/muzero-alphazero-and-alphadev-optimizing-computer-systems/",
    "thumbnail": "https://lh3.googleusercontent.com/6tSxHgEgSLR8FSELf3If1M1QBbXTtpsfH6w2ocuruWGnFDTdogbyNA8sHOyKpFYCja4hT7fGCVwl2xyI9biVB1bFNcnTxvYptuVdcT0XHMjn-TzG=w1200-h630-n-nu"
  },
  {
    "title": "The Hugging Face Hub for Galleries, Libraries, Archives and Museums",
    "description": "",
    "summary": "",
    "pubDate": "Mon, 12 Jun 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/hf-hub-glam-guide",
    "thumbnail": "https://huggingface.co/blog/assets/144_hf_hub_glam_guide/thumbnail.png"
  },
  {
    "title": "Function calling and other API updates",
    "description": "We’re announcing updates including more steerable API models, function calling capabilities, longer context, and lower prices.",
    "summary": "We’re announcing updates including more steerable API models, function calling capabilities, longer context, and lower prices.",
    "pubDate": "Tue, 13 Jun 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/function-calling-and-other-api-updates",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Hugging Face and AMD partner on accelerating state-of-the-art models for CPU and GPU platforms",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 13 Jun 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/huggingface-and-amd",
    "thumbnail": "https://huggingface.co/blog/assets/148_huggingface_amd/01.png"
  },
  {
    "title": "Google Cloud: Driving digital transformation",
    "description": "Google Cloud empowers organizations to digitally transform themselves into smarter businesses. It offers cloud computing, data analytics, and the latest artificial intelligence (AI) and machine learning tools.",
    "summary": "Google Cloud empowers organizations to digitally transform themselves into smarter businesses. It offers cloud computing, data analytics, and the latest artificial intelligence (AI) and machine learning tools.",
    "pubDate": "Wed, 14 Jun 2023 14:51:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/google-cloud-driving-digital-transformation/",
    "thumbnail": "https://lh3.googleusercontent.com/xIps-6-tV3GGWQjVrHYTkLGnXAdZwmjG6jOAgECP5aynUXKeAfUhWv7fFfjPaV8Jmn3B3IabKBeDzBtB491hJAozuAhdQ-TUtZ5dzy9dmE1zWC-J=w1200-h630-n-nu"
  },
  {
    "title": "Announcing our new Content Guidelines and Policy",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 15 Jun 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/content-guidelines-update",
    "thumbnail": "https://huggingface.co/blog/assets/content-guidelines-blogpost/thumbnail.png"
  },
  {
    "title": "Deploy Livebook notebooks as apps to Hugging Face Spaces",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 15 Jun 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/livebook-app-deployment",
    "thumbnail": "https://huggingface.co/blog/assets/120_elixir-bumblebee/thumbnail.png"
  },
  {
    "title": "Faster Stable Diffusion with Core ML on iPhone, iPad, and Mac",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 15 Jun 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/fast-diffusers-coreml",
    "thumbnail": "https://huggingface.co/blog/assets/149_fast_diffusers_coreml/thumbnail.png"
  },
  {
    "title": "Yes, Transformers are Effective for Time Series Forecasting (+ Autoformer)",
    "description": "",
    "summary": "",
    "pubDate": "Fri, 16 Jun 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/autoformer",
    "thumbnail": "https://huggingface.co/blog/assets/150_autoformer/thumbnail.png"
  },
  {
    "title": "YouTube: Enhancing the user experience",
    "description": "It’s all about using our technology and research to help enrich people’s lives. Like YouTube — and its mission to give everyone a voice and show them the world.",
    "summary": "It’s all about using our technology and research to help enrich people’s lives. Like YouTube — and its mission to give everyone a voice and show them the world.",
    "pubDate": "Fri, 16 Jun 2023 14:55:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/youtube-enhancing-the-user-experience/",
    "thumbnail": "https://lh3.googleusercontent.com/RAMu-2QAkfHieGDWkYFQOMiATW-wFi6jMLyC-YJ4f6Jj1H5BlhxQBmfQrb4RS6Sc6DFLFJqBahK3_1--XjoFPdGqYsCdSuTNr-pTcLkRO5SqvReblIQ=w1200-h630-n-nu"
  },
  {
    "title": "Fine-tuning MMS Adapter Models for Multi-Lingual ASR",
    "description": "",
    "summary": "",
    "pubDate": "Mon, 19 Jun 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/mms_adapters",
    "thumbnail": "https://huggingface.co/blog/assets/151_mms/mms_map.png"
  },
  {
    "title": "AI Policy @🤗: Response to the U.S. NTIA's Request for Comment on AI Accountability",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 20 Jun 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/policy-ntia-rfc",
    "thumbnail": "https://huggingface.co/blog/assets/151_policy_ntia_rfc/us_policy_thumbnail.png"
  },
  {
    "title": "RoboCat: A self-improving robotic agent",
    "description": "Robots are quickly becoming part of our everyday lives, but they’re often only programmed to perform specific tasks well. While harnessing recent advances in AI could lead to robots that could help in many more ways, progress in building general-purpose robots is slower in part because of the time needed to collect real-world training data. Our latest paper introduces a self-improving AI agent for robotics, RoboCat, that learns to perform a variety of tasks across different arms, and then self-generates new training data to improve its technique.",
    "summary": "Robots are quickly becoming part of our everyday lives, but they’re often only programmed to perform specific tasks well. While harnessing recent advances in AI could lead to robots that could help in many more ways, progress in building general-purpose robots is slower in part because of the time needed to collect real-world training data. Our latest paper introduces a self-improving AI agent for robotics, RoboCat, that learns to perform a variety of tasks across different arms, and then self-generates new training data to improve its technique.",
    "pubDate": "Tue, 20 Jun 2023 00:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/robocat-a-self-improving-robotic-agent/",
    "thumbnail": "https://lh3.googleusercontent.com/Rz9Xv4TXuTe-eO2UDUD6kDElDB5wDE2b2hEU1liUAi0AyiTwQ81mLMigXg3kueWrHoqeNctRO5-EMprZDRnXcaL8snfqHwDqgQpw_qB3VEvoO_jCCzI=w1200-h630-n-nu"
  },
  {
    "title": "Panel on Hugging Face",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 22 Jun 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/panel-on-hugging-face",
    "thumbnail": "https://huggingface.co/blog/assets/panel-on-hugging-face/thumbnail.png"
  },
  {
    "title": "Questions for the Record",
    "description": "The following are the Questions for the Record following Sam Altman's testimony before the U.S. Senate Committee on the Judiciary (Subcommittee on Privacy, Technology, & the Law).",
    "summary": "The following are the Questions for the Record following Sam Altman's testimony before the U.S. Senate Committee on the Judiciary (Subcommittee on Privacy, Technology, & the Law).",
    "pubDate": "Thu, 22 Jun 2023 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/global-affairs/sam-altman-senate-questions-for-the-record",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Testimony before the U.S. Senate",
    "description": "The following is the written testimony of Sam Altman, Chief Executive Officer of OpenAI, before the U.S. Senate Committee on the Judiciary (Subcommittee on Privacy, Technology, & the Law).",
    "summary": "The following is the written testimony of Sam Altman, Chief Executive Officer of OpenAI, before the U.S. Senate Committee on the Judiciary (Subcommittee on Privacy, Technology, & the Law).",
    "pubDate": "Thu, 22 Jun 2023 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/global-affairs/testimony-of-sam-altman-before-the-us-senate",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "What's going on with the Open LLM Leaderboard?",
    "description": "",
    "summary": "",
    "pubDate": "Fri, 23 Jun 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/open-llm-leaderboard-mmlu",
    "thumbnail": "https://huggingface.co/blog/assets/evaluating-mmlu-leaderboard/thumbnail.png"
  },
  {
    "title": "Ethics and Society Newsletter #4: Bias in Text-to-Image Models",
    "description": "",
    "summary": "",
    "pubDate": "Mon, 26 Jun 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/ethics-soc-4",
    "thumbnail": "https://huggingface.co/blog/assets/152_ethics_soc_4/ethics_4_thumbnail.png"
  },
  {
    "title": "Introducing OpenAI London",
    "description": "We are excited to announce OpenAI’s first international expansion with a new office in London, United Kingdom.",
    "summary": "We are excited to announce OpenAI’s first international expansion with a new office in London, United Kingdom.",
    "pubDate": "Wed, 28 Jun 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-openai-london",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Accelerating Vision-Language Models: BridgeTower on Habana Gaudi2",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 29 Jun 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/bridgetower",
    "thumbnail": "https://huggingface.co/blog/assets/bridgetower/thumbnail.png"
  },
  {
    "title": "Insights from global conversations",
    "description": "We are sharing what we learned from our conversations across 22 countries, and how we will be incorporating those insights moving forward.",
    "summary": "We are sharing what we learned from our conversations across 22 countries, and how we will be incorporating those insights moving forward.",
    "pubDate": "Thu, 29 Jun 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/insights-from-global-conversations",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Leveraging Hugging Face for complex generative AI use cases",
    "description": "",
    "summary": "",
    "pubDate": "Sat, 01 Jul 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/writer-case-study",
    "thumbnail": "https://huggingface.co/blog/assets/78_ml_director_insights/writer.png"
  },
  {
    "title": "Making a web app generator with open ML models",
    "description": "",
    "summary": "",
    "pubDate": "Mon, 03 Jul 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/text-to-webapp",
    "thumbnail": "https://huggingface.co/blog/assets/153_text_to_webapp/thumbnail.jpg"
  },
  {
    "title": "Deploy LLMs with Hugging Face Inference Endpoints",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 04 Jul 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/inference-endpoints-llm",
    "thumbnail": "https://huggingface.co/blog/assets/155_inference_endpoints_llm/thumbnail.jpg"
  },
  {
    "title": "Making ML-powered web games with Transformers.js",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 05 Jul 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/ml-web-games",
    "thumbnail": "https://huggingface.co/blog/assets/ml-web-games/thumbnail.png"
  },
  {
    "title": "Frontier AI regulation: Managing emerging risks to public safety",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 06 Jul 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/frontier-ai-regulation",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Accurately analyzing large scale qualitative data",
    "description": "Viable uses GPT-4 to analyze qualitative data at a revolutionary scale with unparalleled accuracy.",
    "summary": "Viable uses GPT-4 to analyze qualitative data at a revolutionary scale with unparalleled accuracy.",
    "pubDate": "Fri, 07 Jul 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/viable",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Exploring institutions for global AI governance",
    "description": "New white paper investigates models and functions of international institutions that could help manage opportunities and mitigate risks of advanced AI.",
    "summary": "New white paper investigates models and functions of international institutions that could help manage opportunities and mitigate risks of advanced AI.",
    "pubDate": "Tue, 11 Jul 2023 00:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/exploring-institutions-for-global-ai-governance/",
    "thumbnail": "https://lh3.googleusercontent.com/Y9dCJWt3ky1gjizSCHb17S3iHZ_Q2v6hoC8SaBgq9f7e5yW15pzg7BGNoCIaklP6f34uioxwHY0gbzehAMe5HhXBvBBKBKNIcOo7ugjFeLENTWMqNQ=w1200-h630-n-nu"
  },
  {
    "title": "Fine-tuning Stable Diffusion models on Intel CPUs",
    "description": "",
    "summary": "",
    "pubDate": "Fri, 14 Jul 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/stable-diffusion-finetuning-intel",
    "thumbnail": "https://huggingface.co/blog/assets/stable-diffusion-finetuning-intel/01.png"
  },
  {
    "title": "Building an AI WebTV",
    "description": "",
    "summary": "",
    "pubDate": "Mon, 17 Jul 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/ai-webtv",
    "thumbnail": "https://huggingface.co/blog/assets/156_ai_webtv/thumbnail.gif"
  },
  {
    "title": "Developing reliable AI tools for healthcare",
    "description": "We’ve published our joint paper with Google Research in Nature Medicine, which proposes CoDoC (Complementarity-driven Deferral-to-Clinical Workflow), an AI system that learns when to rely on predictive AI tools or defer to a clinician for the most accurate interpretation of medical images.",
    "summary": "We’ve published our joint paper with Google Research in Nature Medicine, which proposes CoDoC (Complementarity-driven Deferral-to-Clinical Workflow), an AI system that learns when to rely on predictive AI tools or defer to a clinician for the most accurate interpretation of medical images.",
    "pubDate": "Mon, 17 Jul 2023 00:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/codoc-developing-reliable-ai-tools-for-healthcare/",
    "thumbnail": "https://lh3.googleusercontent.com/JCyH0sgVtuYFCB0n7g6f2NMV19yeAgvxQBqcfy9H_-DP_aW3k5h4i0bcZ9_9KCExs7rXRrCaC6s21uK5Udap6tX3zy96zOdn8YcF5WIxAFzUgru6Nw=w1200-h630-n-nu"
  },
  {
    "title": "Open-Source Text Generation & LLM Ecosystem at Hugging Face",
    "description": "",
    "summary": "",
    "pubDate": "Mon, 17 Jul 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/os-llms",
    "thumbnail": "https://huggingface.co/blog/assets/os_llms/thumbnail.png"
  },
  {
    "title": "Llama 2 is here - get it on Hugging Face",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 18 Jul 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/llama2",
    "thumbnail": "https://huggingface.co/blog/assets/llama2/thumbnail.jpg"
  },
  {
    "title": "Partnership with American Journalism Project to support local news",
    "description": "A new $5+ million partnership aims to explore ways the development of artificial intelligence (AI) can support a thriving, innovative local news field, and ensure local news organizations shape the future of this emerging technology.",
    "summary": "A new $5+ million partnership aims to explore ways the development of artificial intelligence (AI) can support a thriving, innovative local news field, and ensure local news organizations shape the future of this emerging technology.",
    "pubDate": "Tue, 18 Jul 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/partnership-with-american-journalism-project-to-support-local-news",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Custom instructions for ChatGPT",
    "description": "We’re rolling out custom instructions to give you more control over how ChatGPT responds. Set your preferences, and ChatGPT will keep them in mind for all future conversations.",
    "summary": "We’re rolling out custom instructions to give you more control over how ChatGPT responds. Set your preferences, and ChatGPT will keep them in mind for all future conversations.",
    "pubDate": "Thu, 20 Jul 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/custom-instructions-for-chatgpt",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Google DeepMind’s latest research at ICML 2023",
    "description": "Exploring AI safety, adaptability, and efficiency for the real world",
    "summary": "Exploring AI safety, adaptability, and efficiency for the real world",
    "pubDate": "Thu, 20 Jul 2023 00:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/google-deepmind-research-at-icml-2023/",
    "thumbnail": "https://lh3.googleusercontent.com/5UyUwX8KGovLbTZ0Q8Ynf5Nepy-1zyFaVIIwB7ty0Cp1F5wrKrv24aOT91PDo1vpH3T4P0cwtUn1WxxvtU5vqd4J7cBwEK6UsvnTMNL_qramtFbsX28=w1200-h630-n-nu"
  },
  {
    "title": "Happy 1st anniversary 🤗 Diffusers!",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 20 Jul 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/diffusers-turns-1",
    "thumbnail": "https://huggingface.co/blog/assets/diffusers-turns-1/diffusers-turns-1.png"
  },
  {
    "title": "Moving AI governance forward",
    "description": "OpenAI and other leading labs reinforce AI safety, security and trustworthiness through voluntary commitments.",
    "summary": "OpenAI and other leading labs reinforce AI safety, security and trustworthiness through voluntary commitments.",
    "pubDate": "Fri, 21 Jul 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/moving-ai-governance-forward",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Results of the Open Source AI Game Jam",
    "description": "",
    "summary": "",
    "pubDate": "Fri, 21 Jul 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/game-jam-first-edition-results",
    "thumbnail": "https://huggingface.co/blog/assets/game-jam-first-edition-results/thumbnail.jpg"
  },
  {
    "title": "Using AI to fight climate change",
    "description": "AI is a powerful technology that will transform our future, so how can we best apply it to help combat climate change and find sustainable solutions?",
    "summary": "AI is a powerful technology that will transform our future, so how can we best apply it to help combat climate change and find sustainable solutions?",
    "pubDate": "Fri, 21 Jul 2023 00:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/using-ai-to-fight-climate-change/",
    "thumbnail": "https://lh3.googleusercontent.com/_7lNDyMo0JuzMRu0wVUtaJuXaEPDy8ay20vcsv08JvF3fMkEbk20mGBWdI09Wg0USIinNH5urB5nudEGZWRvTeUNOz_WOAwcduNdQQQNGx-JgtQE1aE=w1200-h630-n-nu"
  },
  {
    "title": "AI Policy @🤗: Open ML Considerations in the EU AI Act",
    "description": "",
    "summary": "",
    "pubDate": "Mon, 24 Jul 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/eu-ai-act-oss",
    "thumbnail": "https://huggingface.co/blog/assets/eu_ai_act_oss/thumbnailEU.png"
  },
  {
    "title": "Introducing Agents.js: Give tools to your LLMs using JavaScript",
    "description": "",
    "summary": "",
    "pubDate": "Mon, 24 Jul 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/agents-js",
    "thumbnail": "https://huggingface.co/blog/assets/agents-js/thumbnail.png"
  },
  {
    "title": "Frontier Model Forum",
    "description": "We’re forming a new industry body to promote the safe and responsible development of frontier AI systems: advancing AI safety research, identifying best practices and standards, and facilitating information sharing among policymakers and industry.",
    "summary": "We’re forming a new industry body to promote the safe and responsible development of frontier AI systems: advancing AI safety research, identifying best practices and standards, and facilitating information sharing among policymakers and industry.",
    "pubDate": "Wed, 26 Jul 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/frontier-model-forum",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Stable Diffusion XL on Mac with Advanced Core ML Quantization",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 27 Jul 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/stable-diffusion-xl-coreml",
    "thumbnail": "https://huggingface.co/blog/assets/stable-diffusion-xl-coreml/thumbnail.png"
  },
  {
    "title": "RT-2: New model translates vision and language into action",
    "description": "Robotic Transformer 2 (RT-2) is a novel vision-language-action (VLA) model that learns from both web and robotics data, and translates this knowledge into generalised instructions for robotic control.",
    "summary": "Robotic Transformer 2 (RT-2) is a novel vision-language-action (VLA) model that learns from both web and robotics data, and translates this knowledge into generalised instructions for robotic control.",
    "pubDate": "Fri, 28 Jul 2023 00:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/rt-2-new-model-translates-vision-and-language-into-action/",
    "thumbnail": "https://lh3.googleusercontent.com/ZduBtQRn2mrvSfNqkixe2XktBREieIhekS7NcboCn0E76gFVckUwNLZw74EJ5jIndzxbRoCqCY47iW1-eGi5c_JJV1DFyTmkS91vMnRalgT0rih125s=w1200-h630-n-nu"
  },
  {
    "title": "Confidence-Building Measures for Artificial Intelligence: Workshop proceedings",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 01 Aug 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/confidence-building-measures-for-artificial-intelligence",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Open-sourcing Knowledge Distillation Code and Weights of SD-Small and SD-Tiny",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 01 Aug 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/sd_distillation",
    "thumbnail": "https://huggingface.co/blog/assets/distill_sd/thumbnail.png"
  },
  {
    "title": "Practical 3D Asset Generation: A Step-by-Step Guide",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 01 Aug 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/3d-assets",
    "thumbnail": "https://huggingface.co/blog/assets/124_ml-for-games/thumbnail-3d.jpg"
  },
  {
    "title": "Huggy Lingo: Using Machine Learning to Improve Language Metadata on the Hugging Face Hub",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 02 Aug 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/huggy-lingo",
    "thumbnail": "https://huggingface.co/blog/huggy-lingo/blog/assets/156_huggylingo/Huggy_Lingo.png"
  },
  {
    "title": "Towards Encrypted Large Language Models with FHE",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 02 Aug 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/encrypted-llm",
    "thumbnail": "https://huggingface.co/blog/assets/encrypted-llm/thumbnail.png"
  },
  {
    "title": "Deploy MusicGen in no time with Inference Endpoints",
    "description": "",
    "summary": "",
    "pubDate": "Fri, 04 Aug 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/run-musicgen-as-an-api",
    "thumbnail": "https://huggingface.co/blog/assets/run-musicgen-as-an-api/thumbnail.png"
  },
  {
    "title": "Fine-tune Llama 2 with DPO",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 08 Aug 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/dpo-trl",
    "thumbnail": "https://huggingface.co/blog/assets/157_dpo_trl/dpo_thumbnail.png"
  },
  {
    "title": "Releasing Swift Transformers: Run On-Device LLMs in Apple Devices",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 08 Aug 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/swift-coreml-llm",
    "thumbnail": "https://huggingface.co/blog/assets/swift-coreml-llm/thumbnail.png"
  },
  {
    "title": "Deploying Hugging Face Models with BentoML: DeepFloyd IF in Action",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 09 Aug 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/deploy-deepfloydif-using-bentoml",
    "thumbnail": "https://huggingface.co/blog/assets/deploy-deepfloydif-using-bentoml/thumbnail.png"
  },
  {
    "title": "Optimizing Bark using 🤗 Transformers",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 09 Aug 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/optimizing-bark",
    "thumbnail": "https://huggingface.co/blog/assets/bark_optimization/thumbnail.png"
  },
  {
    "title": "Hugging Face Platform on the AWS Marketplace: Pay with your AWS Account",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 10 Aug 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/aws-marketplace",
    "thumbnail": "https://huggingface.co/blog/assets/158_aws_marketplace/thumbnail.jpg"
  },
  {
    "title": "Using GPT-4 for content moderation",
    "description": "We use GPT-4 for content policy development and content moderation decisions, enabling more consistent labeling, a faster feedback loop for policy refinement, and less involvement from human moderators.",
    "summary": "We use GPT-4 for content policy development and content moderation decisions, enabling more consistent labeling, a faster feedback loop for policy refinement, and less involvement from human moderators.",
    "pubDate": "Tue, 15 Aug 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/using-gpt-4-for-content-moderation",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "OpenAI acquires Global Illumination",
    "description": "The entire team has joined OpenAI.",
    "summary": "The entire team has joined OpenAI.",
    "pubDate": "Wed, 16 Aug 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-acquires-global-illumination",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "GPT-3.5 Turbo fine-tuning and API updates",
    "description": "Developers can now bring their own data to customize GPT-3.5 Turbo for their use cases.",
    "summary": "Developers can now bring their own data to customize GPT-3.5 Turbo for their use cases.",
    "pubDate": "Tue, 22 Aug 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/gpt-3-5-turbo-fine-tuning-and-api-updates",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Introducing IDEFICS: An Open Reproduction of State-of-the-art Visual Language Model",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 22 Aug 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/idefics",
    "thumbnail": "https://huggingface.co/blog/assets/idefics/thumbnail.png"
  },
  {
    "title": "Introducing SafeCoder",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 22 Aug 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/safecoder",
    "thumbnail": "https://huggingface.co/blog/assets/159_safecoder/thumbnail.jpg"
  },
  {
    "title": "Making LLMs lighter with AutoGPTQ and transformers",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 23 Aug 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/gptq-integration",
    "thumbnail": "https://huggingface.co/blog/assets/159_autogptq_transformers/thumbnail.jpg"
  },
  {
    "title": "OpenAI partners with Scale to provide support for enterprises fine-tuning models",
    "description": "OpenAI’s customers can leverage Scale’s AI expertise to customize our most advanced models.",
    "summary": "OpenAI’s customers can leverage Scale’s AI expertise to customize our most advanced models.",
    "pubDate": "Thu, 24 Aug 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-partners-with-scale-to-provide-support-for-enterprises-fine-tuning-models",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Code Llama: Llama 2 learns to code",
    "description": "",
    "summary": "",
    "pubDate": "Fri, 25 Aug 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/codellama",
    "thumbnail": "https://huggingface.co/blog/assets/160_codellama/thumbnail.jpg"
  },
  {
    "title": "Deprecation of Git Authentication using password",
    "description": "",
    "summary": "",
    "pubDate": "Fri, 25 Aug 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/password-git-deprecation",
    "thumbnail": "https://huggingface.co/blog/assets/password-git-deprecation/thumbnail.png"
  },
  {
    "title": "Introducing ChatGPT Enterprise",
    "description": "Get enterprise-grade security & privacy and the most powerful version of ChatGPT yet.",
    "summary": "Get enterprise-grade security & privacy and the most powerful version of ChatGPT yet.",
    "pubDate": "Mon, 28 Aug 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-chatgpt-enterprise",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Identifying AI-generated images with SynthID",
    "description": "New tool helps watermark and identify synthetic images created by Imagen",
    "summary": "New tool helps watermark and identify synthetic images created by Imagen",
    "pubDate": "Tue, 29 Aug 2023 00:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/identifying-ai-generated-images-with-synthid/",
    "thumbnail": "https://lh3.googleusercontent.com/wUgtK2GBt2yZJ3dJkXtvAK84G93j6idOOalyihOMfwBxY0lR650fZZYIi3bXdgkKbBcitbUZ0ILbaIPg_-vDTgAJLlP1DO3h_UnyoZ27wl3mYSzKtw=w1200-h630-n-nu"
  },
  {
    "title": "AudioLDM 2, but faster ⚡️",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 30 Aug 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/audioldm2",
    "thumbnail": "https://huggingface.co/blog/assets/161_audioldm2/thumbnail.png"
  },
  {
    "title": "Teaching with AI",
    "description": "We’re releasing a guide for teachers using ChatGPT in their classroom—including suggested prompts, an explanation of how ChatGPT works and its limitations, the efficacy of AI detectors, and bias.",
    "summary": "We’re releasing a guide for teachers using ChatGPT in their classroom—including suggested prompts, an explanation of how ChatGPT works and its limitations, the efficacy of AI detectors, and bias.",
    "pubDate": "Thu, 31 Aug 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/teaching-with-ai",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Fetch Cuts ML Processing Latency by 50% Using Amazon SageMaker & Hugging Face",
    "description": "",
    "summary": "",
    "pubDate": "Fri, 01 Sep 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/fetch-case-study",
    "thumbnail": "https://huggingface.co/blog/assets/78_ml_director_insights/fetch.png"
  },
  {
    "title": "Join us for OpenAI’s first developer conference on November 6 in San Francisco",
    "description": "Developer registration for in-person attendance will open in the coming weeks and developers everywhere will be able to livestream the keynote.",
    "summary": "Developer registration for in-person attendance will open in the coming weeks and developers everywhere will be able to livestream the keynote.",
    "pubDate": "Wed, 06 Sep 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/announcing-openai-devday",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Spread Your Wings: Falcon 180B is here",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 06 Sep 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/falcon-180b",
    "thumbnail": "https://huggingface.co/blog/assets/162_falcon_180b/thumbnail.jpg"
  },
  {
    "title": "Efficient Controllable Generation for SDXL with T2I-Adapters",
    "description": "",
    "summary": "",
    "pubDate": "Fri, 08 Sep 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/t2i-sdxl-adapters",
    "thumbnail": "https://huggingface.co/blog/assets/t2i-sdxl-adapters/thumbnail.png"
  },
  {
    "title": "SafeCoder vs. Closed-source Code Assistants",
    "description": "",
    "summary": "",
    "pubDate": "Mon, 11 Sep 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/safecoder-vs-closed-source-code-assistants",
    "thumbnail": "https://huggingface.co/blog/assets/safecoder-vs-closed-source-code-assistants/image.png"
  },
  {
    "title": "Overview of natively supported quantization schemes in 🤗 Transformers",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 12 Sep 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/overview-quantization-transformers",
    "thumbnail": "https://huggingface.co/blog/assets/163_overview_quantization_transformers/thumbnail.jpg"
  },
  {
    "title": "Fine-tuning Llama 2 70B using PyTorch FSDP",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 13 Sep 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/ram-efficient-pytorch-fsdp",
    "thumbnail": "https://huggingface.co/blog/assets/160_fsdp_llama/thumbnail.jpg"
  },
  {
    "title": "Introducing OpenAI Dublin",
    "description": "We’re growing our presence in Europe with an office in Dublin, Ireland.",
    "summary": "We’re growing our presence in Europe with an office in Dublin, Ireland.",
    "pubDate": "Wed, 13 Sep 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-openai-dublin",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Introducing Würstchen: Fast Diffusion for Image Generation",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 13 Sep 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/wuerstchen",
    "thumbnail": "https://huggingface.co/blog/assets/wuerstchen/thumbnail.jpg"
  },
  {
    "title": "Optimizing your LLM in production",
    "description": "",
    "summary": "",
    "pubDate": "Fri, 15 Sep 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/optimize-llm",
    "thumbnail": "https://huggingface.co/blog/assets/163_optimize_llm/optimize_llm.png"
  },
  {
    "title": "Introduction to 3D Gaussian Splatting",
    "description": "",
    "summary": "",
    "pubDate": "Mon, 18 Sep 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/gaussian-splatting",
    "thumbnail": "https://huggingface.co/blog/assets/124_ml-for-games/thumbnail-gaussian-splatting.png"
  },
  {
    "title": "Object Detection Leaderboard",
    "description": "",
    "summary": "",
    "pubDate": "Mon, 18 Sep 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/object-detection-leaderboard",
    "thumbnail": "https://huggingface.co/blog/assets/object-detection-leaderboard/thumbnail.png"
  },
  {
    "title": "A catalogue of genetic mutations to help pinpoint the cause of diseases",
    "description": "New AI tool classifies the effects of 71 million ‘missense’ mutations.",
    "summary": "New AI tool classifies the effects of 71 million ‘missense’ mutations.",
    "pubDate": "Tue, 19 Sep 2023 13:37:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/a-catalogue-of-genetic-mutations-to-help-pinpoint-the-cause-of-diseases/",
    "thumbnail": "https://lh3.googleusercontent.com/JySjDTZvGqEzUfDic5QOU6Rne3r6RWpiw5JZQ9VdzK1O5C20EbAkSPURGoCmAhea_U-gyyRu4KdCZmeWSCtYjGHHMvM0jVK5fWiqOwa0rpcC5uzM=w1200-h630-n-nu"
  },
  {
    "title": "OpenAI Red Teaming Network",
    "description": "We’re announcing an open call for the OpenAI Red Teaming Network and invite domain experts interested in improving the safety of OpenAI’s models to join our efforts.",
    "summary": "We’re announcing an open call for the OpenAI Red Teaming Network and invite domain experts interested in improving the safety of OpenAI’s models to join our efforts.",
    "pubDate": "Tue, 19 Sep 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/red-teaming-network",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Rocket Money x Hugging Face: Scaling Volatile ML Models in Production",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 19 Sep 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/rocketmoney-case-study",
    "thumbnail": "https://huggingface.co/blog/assets/78_ml_director_insights/rocketmoney.png"
  },
  {
    "title": "Inference for PROs",
    "description": "",
    "summary": "",
    "pubDate": "Fri, 22 Sep 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/inference-pro",
    "thumbnail": "https://huggingface.co/blog/assets/inference_pro/thumbnail.png"
  },
  {
    "title": "ChatGPT can now see, hear, and speak",
    "description": "We are beginning to roll out new voice and image capabilities in ChatGPT. They offer a new, more intuitive type of interface by allowing you to have a voice conversation or show ChatGPT what you’re talking about.",
    "summary": "We are beginning to roll out new voice and image capabilities in ChatGPT. They offer a new, more intuitive type of interface by allowing you to have a voice conversation or show ChatGPT what you’re talking about.",
    "pubDate": "Mon, 25 Sep 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/chatgpt-can-now-see-hear-and-speak",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "GPT-4V(ision) system card",
    "description": "",
    "summary": "",
    "pubDate": "Mon, 25 Sep 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/gpt-4v-system-card",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Llama 2 on Amazon SageMaker a Benchmark",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 26 Sep 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/llama-sagemaker-benchmark",
    "thumbnail": "https://huggingface.co/blog/assets/llama_sagemaker_benchmark/thumbnail.jpg"
  },
  {
    "title": "Non-engineers guide: Train a LLaMA 2 chatbot",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 28 Sep 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/Llama2-for-non-engineers",
    "thumbnail": "https://huggingface.co/blog/assets/78_ml_director_insights/tuto.png"
  },
  {
    "title": "Ethics and Society Newsletter #5: Hugging Face Goes To Washington and Other Summer 2023 Musings",
    "description": "",
    "summary": "",
    "pubDate": "Fri, 29 Sep 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/ethics-soc-5",
    "thumbnail": "https://huggingface.co/blog/assets/164_ethics-soc-5/thumbnail.png"
  },
  {
    "title": "Finetune Stable Diffusion Models with DDPO via TRL",
    "description": "",
    "summary": "",
    "pubDate": "Fri, 29 Sep 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/trl-ddpo",
    "thumbnail": "https://huggingface.co/blog/assets/166_trl_ddpo/thumbnail.png"
  },
  {
    "title": "Deploying the AI Comic Factory using the Inference API",
    "description": "",
    "summary": "",
    "pubDate": "Mon, 02 Oct 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/ai-comic-factory",
    "thumbnail": "https://huggingface.co/blog/assets/165_ai_comic_factory/thumbnail.jpg"
  },
  {
    "title": "Accelerating Stable Diffusion XL Inference with JAX on Cloud TPU v5e",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 03 Oct 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/sdxl_jax",
    "thumbnail": "https://huggingface.co/blog/assets/sdxl-jax/thumbnail.jpg"
  },
  {
    "title": "Chat Templates: An End to the Silent Performance Killer",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 03 Oct 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/chat-templates",
    "thumbnail": "https://huggingface.co/blog/assets/chat-templates/thumbnail.png"
  },
  {
    "title": "DALL·E 3 system card",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 03 Oct 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/dall-e-3-system-card",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Scaling up learning across many different robot types",
    "description": "Robots are great specialists, but poor generalists. Typically, you have to train a model for each task, robot, and environment. Changing a single variable often requires starting from scratch. But what if we could combine the knowledge across robotics and create a way to train a general-purpose robot?",
    "summary": "Robots are great specialists, but poor generalists. Typically, you have to train a model for each task, robot, and environment. Changing a single variable often requires starting from scratch. But what if we could combine the knowledge across robotics and create a way to train a general-purpose robot?",
    "pubDate": "Tue, 03 Oct 2023 15:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/scaling-up-learning-across-many-different-robot-types/",
    "thumbnail": "https://lh3.googleusercontent.com/KiNtKw6sX-3WmNln5pnEZjPMfM7VJLg0qe4VshEj_H_oXCI9hb6iGWl1DPx79WBb4EVds8mq2wUq_n9s2Lk8kkWazPtootwAUYBKxBEp64WTcEmXa6U=w1200-h630-n-nu"
  },
  {
    "title": "Accelerating over 130,000 Hugging Face models with ONNX Runtime",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 04 Oct 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/ort-accelerating-hf-models",
    "thumbnail": "https://huggingface.co/blog/assets/ort_accelerating_hf_models/thumbnail.png"
  },
  {
    "title": "Building AI-powered apps for business",
    "description": "Retool uses GPT-4 to give businesses a fast, secure way to build AI-powered apps.",
    "summary": "Retool uses GPT-4 to give businesses a fast, secure way to build AI-powered apps.",
    "pubDate": "Wed, 11 Oct 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/retool",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Evolving online forms into dynamic data",
    "description": "Typeform evolves online forms into dynamic and conversational data collection experiences with GPT-3.5 and GPT-4.",
    "summary": "Typeform evolves online forms into dynamic and conversational data collection experiences with GPT-3.5 and GPT-4.",
    "pubDate": "Wed, 11 Oct 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/typeform",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "OpenAI’s technology explained",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 11 Oct 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/global-affairs/openai-technology-explained",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Simplifying contract reviews with AI",
    "description": "Ironclad uses GPT-4 to simplify the contract review process.",
    "summary": "Ironclad uses GPT-4 to simplify the contract review process.",
    "pubDate": "Wed, 11 Oct 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/ironclad",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "DALL·E 3 is now available in ChatGPT Plus and Enterprise",
    "description": "We developed a safety mitigation stack to ready DALL·E 3 for wider release and are sharing updates on our provenance research.",
    "summary": "We developed a safety mitigation stack to ready DALL·E 3 for wider release and are sharing updates on our provenance research.",
    "pubDate": "Thu, 19 Oct 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/dall-e-3-is-now-available-in-chatgpt-plus-and-enterprise",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Evaluating social and ethical risks from generative AI",
    "description": "Introducing a context-based framework for comprehensively evaluating the social and ethical risks of AI systems",
    "summary": "Introducing a context-based framework for comprehensively evaluating the social and ethical risks of AI systems",
    "pubDate": "Thu, 19 Oct 2023 15:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/evaluating-social-and-ethical-risks-from-generative-ai/",
    "thumbnail": "https://lh3.googleusercontent.com/LAqM0ZkFzkDefB5oVEEPoq6p--7XcfBWEDPjl6OdcfvwN9q3leY2qWCf30_MquTn5RfpcPswiAoRns2jOKjB5_8u-vl6TqueSwamEM6U-qyJHOiujkI=w1200-h630-n-nu"
  },
  {
    "title": "Gradio-Lite: Serverless Gradio Running Entirely in Your Browser",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 19 Oct 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/gradio-lite",
    "thumbnail": "https://huggingface.co/blog/assets/167_gradio_lite/thumbnail.png"
  },
  {
    "title": "Deploy Embedding Models with Hugging Face Inference Endpoints",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 24 Oct 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/inference-endpoints-embeddings",
    "thumbnail": "https://huggingface.co/blog/assets/168_inference_endpoints_embeddings/thumbnail.jpg"
  },
  {
    "title": "Exploring simple optimizations for SDXL",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 24 Oct 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/simple_sdxl_optimizations",
    "thumbnail": "https://huggingface.co/blog/assets/simple_sdxl_optimizations/thumbnail.png"
  },
  {
    "title": "The N Implementation Details of RLHF with PPO",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 24 Oct 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/the_n_implementation_details_of_rlhf_with_ppo",
    "thumbnail": "https://huggingface.co/blog/assets/167_the_n_implementation_details_of_rlhf_with_ppo/thumbnail.png"
  },
  {
    "title": "Frontier Model Forum updates",
    "description": "Together with Anthropic, Google, and Microsoft, we’re announcing the new Executive Director of the Frontier Model Forum and a new $10 million AI Safety Fund.",
    "summary": "Together with Anthropic, Google, and Microsoft, we’re announcing the new Executive Director of the Frontier Model Forum and a new $10 million AI Safety Fund.",
    "pubDate": "Wed, 25 Oct 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/frontier-model-forum-updates",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Interactively explore your Huggingface dataset with one line of code",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 25 Oct 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/scalable-data-inspection",
    "thumbnail": "https://huggingface.co/blog/assets/scalable-data-inspection/thumbnail.png"
  },
  {
    "title": "Frontier risk and preparedness",
    "description": "To support the safety of highly-capable AI systems, we are developing our approach to catastrophic risk preparedness, including building a Preparedness team and launching a challenge.",
    "summary": "To support the safety of highly-capable AI systems, we are developing our approach to catastrophic risk preparedness, including building a Preparedness team and launching a challenge.",
    "pubDate": "Thu, 26 Oct 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/frontier-risk-and-preparedness",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "OpenAI’s Approach to Frontier Risk",
    "description": "An Update for the UK AI Safety Summit",
    "summary": "An Update for the UK AI Safety Summit",
    "pubDate": "Thu, 26 Oct 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/global-affairs/our-approach-to-frontier-risk",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Personal Copilot: Train Your Own Coding Assistant",
    "description": "",
    "summary": "",
    "pubDate": "Fri, 27 Oct 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/personal-copilot",
    "thumbnail": "https://huggingface.co/blog/assets/170_personal_copilot/thumbnail.png"
  },
  {
    "title": "A glimpse of the next generation of AlphaFold",
    "description": "Progress update: Our latest AlphaFold model shows significantly improved accuracy and expands coverage beyond proteins to other biological molecules, including ligands.",
    "summary": "Progress update: Our latest AlphaFold model shows significantly improved accuracy and expands coverage beyond proteins to other biological molecules, including ligands.",
    "pubDate": "Tue, 31 Oct 2023 13:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/a-glimpse-of-the-next-generation-of-alphafold/",
    "thumbnail": "https://lh3.googleusercontent.com/1xoO5BAUUU8kLns4myMNnKw6RRQyUk1JdlWL1M0aDiagMgaBeDA9O8Y4rYFAo9hfnzmb0cnUMrT_-cStBqnyp_zW59F5Edwbvxcy3EVmfeKS-PNgVw=w1200-h630-n-nu"
  },
  {
    "title": "Introducing Storage Regions on the HF Hub",
    "description": "",
    "summary": "",
    "pubDate": "Fri, 03 Nov 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/regions",
    "thumbnail": "https://huggingface.co/blog/assets/172_regions/thumbnail.png"
  },
  {
    "title": "Introducing GPTs",
    "description": "You can now create custom versions of ChatGPT that combine instructions, extra knowledge, and any combination of skills.",
    "summary": "You can now create custom versions of ChatGPT that combine instructions, extra knowledge, and any combination of skills.",
    "pubDate": "Mon, 06 Nov 2023 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-gpts",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "New models and developer products announced at DevDay",
    "description": "GPT-4 Turbo with 128K context and lower prices, the new Assistants API, GPT-4 Turbo with Vision, DALL·E 3 API, and more.",
    "summary": "GPT-4 Turbo with 128K context and lower prices, the new Assistants API, GPT-4 Turbo with Vision, DALL·E 3 API, and more.",
    "pubDate": "Mon, 06 Nov 2023 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/new-models-and-developer-products-announced-at-devday",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Comparing the Performance of LLMs: A Deep Dive into Roberta, Llama 2, and Mistral for Disaster Tweets Analysis with Lora",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 07 Nov 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/Lora-for-sequence-classification-with-Roberta-Llama-Mistral",
    "thumbnail": "https://huggingface.co/blog/assets/Lora-for-sequence-classification-with-Roberta-Llama-Mistral/Thumbnail.png"
  },
  {
    "title": "Introducing Prodigy-HF: a direct integration with Hugging Face",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 07 Nov 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/prodigy-hf",
    "thumbnail": "https://huggingface.co/blog/assets/171_prodigy_hf/thumbnail.png"
  },
  {
    "title": "Make your llama generation time fly with AWS Inferentia2",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 07 Nov 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/inferentia-llama2",
    "thumbnail": "https://huggingface.co/blog/assets/inferentia-llama2/thumbnail.png"
  },
  {
    "title": "OpenAI Data Partnerships",
    "description": "Working together to create open-source and private datasets for AI training.",
    "summary": "Working together to create open-source and private datasets for AI training.",
    "pubDate": "Thu, 09 Nov 2023 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/data-partnerships",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "SDXL in 4 steps with Latent Consistency LoRAs",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 09 Nov 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/lcm_lora",
    "thumbnail": "https://huggingface.co/blog/assets/lcm_sdxl/lcm_thumbnail.png"
  },
  {
    "title": "GraphCast: AI model for faster and more accurate global weather forecasting",
    "description": "We introduce GraphCast, a state-of-the-art AI model able to make medium-range weather forecasts with unprecedented accuracy",
    "summary": "We introduce GraphCast, a state-of-the-art AI model able to make medium-range weather forecasts with unprecedented accuracy",
    "pubDate": "Tue, 14 Nov 2023 15:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/graphcast-ai-model-for-faster-and-more-accurate-global-weather-forecasting/",
    "thumbnail": "https://lh3.googleusercontent.com/5dL0Cm8RLhoDdfPzVy5MlKB5JDcfYucbgxzNLJVFdtqRe15-bFTvfdOrpqnrM4m5XMEEboWtvyCLQgSCvHEH62QqZZI0V_zuBAz71fghXgU5UNFFwg=w1200-h630-n-nu"
  },
  {
    "title": "Empowering the next generation for an AI-enabled world",
    "description": "Experience AI's course and resources are expanding on a global scale",
    "summary": "Experience AI's course and resources are expanding on a global scale",
    "pubDate": "Wed, 15 Nov 2023 10:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/empowering-the-next-generation-for-an-ai-enabled-world/",
    "thumbnail": "https://lh3.googleusercontent.com/XJ10IR5bv5MmygxoFC0hrepTZtjq_Bwz69bL7d7jBy06fnEFodAa0tbIWKOwV7gW2Im3JY2GGda-xZKtVQhqcaozz6r_vdHXsgVu0CzyIhIz4VGs=w1200-h630-n-nu"
  },
  {
    "title": "Transforming the future of music creation",
    "description": "Announcing our most advanced music generation model and two new AI experiments, designed to open a new playground for creativity",
    "summary": "Announcing our most advanced music generation model and two new AI experiments, designed to open a new playground for creativity",
    "pubDate": "Thu, 16 Nov 2023 07:20:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/transforming-the-future-of-music-creation/",
    "thumbnail": "https://lh3.googleusercontent.com/msr-Fc99rrkeoQkZ6rLTKnof3RTqo5oo9D2_xPyqtpp0mAMqqkn-x3mPy2dD0My1g7w-cysBQzHU_iWF4mlblU4EgQRcMNKoBUgPdmdmEoyekFJEnA=w1200-h630-n-nu"
  },
  {
    "title": "OpenAI announces leadership transition",
    "description": "",
    "summary": "",
    "pubDate": "Fri, 17 Nov 2023 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-announces-leadership-transition",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Millions of new materials discovered with deep learning",
    "description": "We share the discovery of 2.2 million new crystals  –  equivalent to nearly 800 years’ worth of knowledge. We introduce Graph Networks for Materials Exploration (GNoME), our new deep learning tool that dramatically increases the speed and efficiency of discovery by predicting the stability of new materials.",
    "summary": "We share the discovery of 2.2 million new crystals  –  equivalent to nearly 800 years’ worth of knowledge. We introduce Graph Networks for Materials Exploration (GNoME), our new deep learning tool that dramatically increases the speed and efficiency of discovery by predicting the stability of new materials.",
    "pubDate": "Wed, 29 Nov 2023 16:04:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/millions-of-new-materials-discovered-with-deep-learning/",
    "thumbnail": "https://lh3.googleusercontent.com/mq3mFiVHSVuszhJMt-Nz4jckN5qy3cAckEIdNYDPhy8UHjxk4VkGFriqo8sA76teioNQ2fC3qgMH7FJfPc0L5JJPppXiZzHP7Rl3UodlU4IC4TWw=w1200-h630-n-nu"
  },
  {
    "title": "Sam Altman returns as CEO, OpenAI has a new initial board",
    "description": "Mira Murati as CTO, Greg Brockman returns as President. Read messages from CEO Sam Altman and board chair Bret Taylor.",
    "summary": "Mira Murati as CTO, Greg Brockman returns as President. Read messages from CEO Sam Altman and board chair Bret Taylor.",
    "pubDate": "Wed, 29 Nov 2023 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/sam-altman-returns-as-ceo-openai-has-a-new-initial-board",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Open LLM Leaderboard: DROP deep dive",
    "description": "",
    "summary": "",
    "pubDate": "Fri, 01 Dec 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/open-llm-leaderboard-drop",
    "thumbnail": "https://huggingface.co/blog/assets/evaluating-mmlu-leaderboard/thumbnail.png"
  },
  {
    "title": "AMD + 🤗: Large Language Models Out-of-the-Box Acceleration with AMD GPU",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 05 Dec 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/huggingface-and-optimum-amd",
    "thumbnail": "https://huggingface.co/blog/assets/optimum_amd/amd_hf_logo_fixed.png"
  },
  {
    "title": "Goodbye cold boot - how we made LoRA inference 300% faster",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 05 Dec 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/lora-adapters-dynamic-loading",
    "thumbnail": "https://huggingface.co/blog/assets/171_load_lora_adapters/thumbnail3.png"
  },
  {
    "title": "Optimum-NVIDIA - Unlock blazingly fast LLM inference in just 1 line of code",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 05 Dec 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/optimum-nvidia",
    "thumbnail": "https://huggingface.co/blog/assets/optimum_nvidia/hf_nvidia_banner.png"
  },
  {
    "title": "Introducing Gemini: our largest and most capable AI model",
    "description": "Making AI more helpful for everyone",
    "summary": "Making AI more helpful for everyone",
    "pubDate": "Wed, 06 Dec 2023 15:13:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/introducing-gemini-our-largest-and-most-capable-ai-model/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Gemini_SS.width-1300.jpg"
  },
  {
    "title": "SetFitABSA: Few-Shot Aspect Based Sentiment Analysis using SetFit",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 06 Dec 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/setfit-absa",
    "thumbnail": "https://huggingface.co/blog/assets/setfit-absa/intel_hf_logo_2.png"
  },
  {
    "title": "Google DeepMind at NeurIPS 2023",
    "description": "The Neural Information Processing Systems (NeurIPS) is the largest artificial intelligence (AI) conference in the world. NeurIPS 2023 will be taking place December 10-16 in New Orleans, USA.Teams from across Google DeepMind are presenting more than 150 papers at the main conference and workshops.",
    "summary": "The Neural Information Processing Systems (NeurIPS) is the largest artificial intelligence (AI) conference in the world. NeurIPS 2023 will be taking place December 10-16 in New Orleans, USA.Teams from across Google DeepMind are presenting more than 150 papers at the main conference and workshops.",
    "pubDate": "Fri, 08 Dec 2023 15:01:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/google-deepmind-at-neurips-2023/",
    "thumbnail": "https://lh3.googleusercontent.com/MDme_Q62zVqvTUs5uwaI3Ggy2rWIujPt2elkusnUuCA4wEo79V9mabIg66j9cr9zMso-LObOVcj6_ZnrgSMUKn6fl52kxOUEjcigXtDZ2UMuosX3-2s=w1200-h630-n-nu"
  },
  {
    "title": "Mixture of Experts Explained",
    "description": "",
    "summary": "",
    "pubDate": "Mon, 11 Dec 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/moe",
    "thumbnail": "https://huggingface.co/blog/assets/moe/thumbnail.png"
  },
  {
    "title": "Welcome Mixtral - a SOTA Mixture of Experts on Hugging Face",
    "description": "",
    "summary": "",
    "pubDate": "Mon, 11 Dec 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/mixtral",
    "thumbnail": "https://huggingface.co/blog/assets/mixtral/thumbnail.jpg"
  },
  {
    "title": "Partnership with Axel Springer to deepen beneficial use of AI in journalism",
    "description": "Axel Springer is the first publishing house globally to partner with us on a deeper integration of journalism in AI technologies.",
    "summary": "Axel Springer is the first publishing house globally to partner with us on a deeper integration of journalism in AI technologies.",
    "pubDate": "Wed, 13 Dec 2023 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/axel-springer-partnership",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "FunSearch: Making new discoveries in mathematical sciences using Large Language Models",
    "description": "In a paper published in Nature, we introduce FunSearch, a method for searching for “functions” written in computer code, and find new solutions in mathematics and computer science. FunSearch works by pairing a pre-trained LLM, whose goal is to provide creative solutions in the form of computer code, with an automated “evaluator”, which guards against hallucinations and incorrect ideas.",
    "summary": "In a paper published in Nature, we introduce FunSearch, a method for searching for “functions” written in computer code, and find new solutions in mathematics and computer science. FunSearch works by pairing a pre-trained LLM, whose goal is to provide creative solutions in the form of computer code, with an automated “evaluator”, which guards against hallucinations and incorrect ideas.",
    "pubDate": "Thu, 14 Dec 2023 16:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/funsearch-making-new-discoveries-in-mathematical-sciences-using-large-language-models/",
    "thumbnail": "https://lh3.googleusercontent.com/GC6SH0u6DyyCT9C1LH6XXmproSod7o5QGp9-Oe8BsuXyPzBlfcxFHX9pxXg69ZftEVU0Joga7tyo0VwQOSBBrugZ8qfl9_X-pgiH527p71S7DC32Jw=w1200-h630-n-nu"
  },
  {
    "title": "Increasing accuracy of pediatric visit notes",
    "description": "Summer Health reimagines pediatric doctor’s visits with OpenAI.",
    "summary": "Summer Health reimagines pediatric doctor’s visits with OpenAI.",
    "pubDate": "Thu, 14 Dec 2023 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/summer-health",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Practices for Governing Agentic AI Systems",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 14 Dec 2023 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/practices-for-governing-agentic-ai-systems",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Superalignment Fast Grants",
    "description": "We’re launching $10M in grants to support technical research towards the alignment and safety of superhuman AI systems, including weak-to-strong generalization, interpretability, scalable oversight, and more.",
    "summary": "We’re launching $10M in grants to support technical research towards the alignment and safety of superhuman AI systems, including weak-to-strong generalization, interpretability, scalable oversight, and more.",
    "pubDate": "Thu, 14 Dec 2023 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/superalignment-fast-grants",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Weak-to-strong generalization",
    "description": "We present a new research direction for superalignment, together with promising initial results: can we leverage the generalization properties of deep learning to control strong models with weak supervisors?",
    "summary": "We present a new research direction for superalignment, together with promising initial results: can we leverage the generalization properties of deep learning to control strong models with weak supervisors?",
    "pubDate": "Thu, 14 Dec 2023 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/weak-to-strong-generalization",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "2023, year of open LLMs",
    "description": "",
    "summary": "",
    "pubDate": "Mon, 18 Dec 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/2023-in-llms",
    "thumbnail": "https://huggingface.co/blog/assets/cv_state/thumbnail.png"
  },
  {
    "title": "Speculative Decoding for 2x Faster Whisper Inference",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 20 Dec 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/whisper-speculative-decoding",
    "thumbnail": "https://huggingface.co/blog/assets/whisper-speculative-decoding/thumbnail.png"
  },
  {
    "title": "2023: A Year of Groundbreaking Advances in AI and Computing",
    "description": "This has been a year of incredible progress in the field of Artificial Intelligence (AI) research and its practical applications.",
    "summary": "This has been a year of incredible progress in the field of Artificial Intelligence (AI) research and its practical applications.",
    "pubDate": "Fri, 22 Dec 2023 13:30:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/2023-a-year-of-groundbreaking-advances-in-ai-and-computing/",
    "thumbnail": "https://lh3.googleusercontent.com/fkZqqqpfLKvV2E6ebVmYJjR9q9XnczvWtiui5uU-yPkHCQb5mLAB4kBmh3opGqOJLhtaC58td96UtvULI8uGpbB9TmejR82GZ2vWOqTyWZ6HSItIpHg=w1200-h630-n-nu"
  },
  {
    "title": "Images altered to trick machine vision can influence humans too",
    "description": "In a series of experiments published in Nature Communications, we found evidence that human judgments are indeed systematically influenced by adversarial perturbations.",
    "summary": "In a series of experiments published in Nature Communications, we found evidence that human judgments are indeed systematically influenced by adversarial perturbations.",
    "pubDate": "Tue, 02 Jan 2024 16:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/images-altered-to-trick-machine-vision-can-influence-humans-too/",
    "thumbnail": "https://lh3.googleusercontent.com/VEIJiplOab4catyNZs6QjZxwjbqVmrh2fIZF8Gj7Xd7TQRq1q4bqDmbeSuVzHPzDhC8vKYI5nZLft79VWP5Oi7j_ARAzyFVxMdJIMKxDD5VfRpGm=w1200-h630-n-nu"
  },
  {
    "title": "LoRA training scripts of the world, unite!",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 02 Jan 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/sdxl_lora_advanced_script",
    "thumbnail": "https://huggingface.co/blog/assets/dreambooth_lora_sdxl/thumbnail.png"
  },
  {
    "title": "Delivering LLM-powered health solutions",
    "description": "WHOOP delivers personalized fitness and health coaching with GPT-4.",
    "summary": "WHOOP delivers personalized fitness and health coaching with GPT-4.",
    "pubDate": "Thu, 04 Jan 2024 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/whoop",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Shaping the future of advanced robotics",
    "description": "Introducing AutoRT, SARA-RT, and RT-Trajectory",
    "summary": "Introducing AutoRT, SARA-RT, and RT-Trajectory",
    "pubDate": "Thu, 04 Jan 2024 11:39:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/shaping-the-future-of-advanced-robotics/",
    "thumbnail": "https://lh3.googleusercontent.com/qeWlfSbr0jW0OsZ0dvaQK2V7tYM0HtTtwivx-fUJzK4GivdM6kffvNXlSgqOJyjAQWXBCycqF77zT7XDGxIqGvPiCnTqLX_C3VRmXGJIGGW5GAv7YQ=w1200-h630-n-nu"
  },
  {
    "title": "Welcome aMUSEd: Efficient Text-to-Image Generation",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 04 Jan 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/amused",
    "thumbnail": "https://huggingface.co/blog/assets/amused/thumbnail.png"
  },
  {
    "title": "OpenAI and journalism",
    "description": "We support journalism, partner with news organizations, and believe The New York Times lawsuit is without merit.",
    "summary": "We support journalism, partner with news organizations, and believe The New York Times lawsuit is without merit.",
    "pubDate": "Mon, 08 Jan 2024 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-and-journalism",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Faster fine-tuning using TRL & Unsloth",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 10 Jan 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/unsloth-trl",
    "thumbnail": "https://huggingface.co/blog/assets/hf_unsloth/thumbnail.png"
  },
  {
    "title": "Introducing ChatGPT Team",
    "description": "We’re launching a new ChatGPT plan for teams of all sizes, which provides a secure, collaborative workspace to get the most out of ChatGPT at work.",
    "summary": "We’re launching a new ChatGPT plan for teams of all sizes, which provides a secure, collaborative workspace to get the most out of ChatGPT at work.",
    "pubDate": "Wed, 10 Jan 2024 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-chatgpt-team",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Introducing the GPT Store",
    "description": "We’re launching the GPT Store to help you find useful and popular custom versions of ChatGPT.",
    "summary": "We’re launching the GPT Store to help you find useful and popular custom versions of ChatGPT.",
    "pubDate": "Wed, 10 Jan 2024 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-the-gpt-store",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "A guide to setting up your own Hugging Face leaderboard: an end-to-end example with Vectara's hallucination leaderboard",
    "description": "",
    "summary": "",
    "pubDate": "Fri, 12 Jan 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/leaderboard-vectara",
    "thumbnail": "https://huggingface.co/blog/assets/leaderboards-on-the-hub/thumbnail.png"
  },
  {
    "title": "Building agricultural database for farmers",
    "description": "Digital Green uses OpenAI to increase farmer income.",
    "summary": "Digital Green uses OpenAI to increase farmer income.",
    "pubDate": "Fri, 12 Jan 2024 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/digital-green",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Run ComfyUI workflows for free on Spaces",
    "description": "",
    "summary": "",
    "pubDate": "Sun, 14 Jan 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/run-comfyui-workflows-on-spaces",
    "thumbnail": "https://huggingface.co/blog/assets/comfyui-to-gradio/cover.png"
  },
  {
    "title": "Accelerating SD Turbo and SDXL Turbo Inference with ONNX Runtime and Olive",
    "description": "",
    "summary": "",
    "pubDate": "Mon, 15 Jan 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/sdxl_ort_inference",
    "thumbnail": "https://huggingface.co/blog/assets/optimum_onnxruntime-training/thumbnail.png"
  },
  {
    "title": "How OpenAI is approaching 2024 worldwide elections",
    "description": "We’re working to prevent abuse, provide transparency on AI-generated content, and improve access to accurate voting information.",
    "summary": "We’re working to prevent abuse, provide transparency on AI-generated content, and improve access to accurate voting information.",
    "pubDate": "Mon, 15 Jan 2024 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/how-openai-is-approaching-2024-worldwide-elections",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Democratic inputs to AI grant program: lessons learned and implementation plans",
    "description": "We funded 10 teams from around the world to design ideas and tools to collectively govern AI. We summarize the innovations, outline our learnings, and call for researchers and engineers to join us as we continue this work.",
    "summary": "We funded 10 teams from around the world to design ideas and tools to collectively govern AI. We summarize the innovations, outline our learnings, and call for researchers and engineers to join us as we continue this work.",
    "pubDate": "Tue, 16 Jan 2024 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/democratic-inputs-to-ai-grant-program-update",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "AlphaGeometry: An Olympiad-level AI system for geometry",
    "description": "Advancing AI reasoning in mathematics",
    "summary": "Advancing AI reasoning in mathematics",
    "pubDate": "Wed, 17 Jan 2024 16:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/alphageometry-an-olympiad-level-ai-system-for-geometry/",
    "thumbnail": "https://lh3.googleusercontent.com/tVTh_ZCW5Qozy4vOCpMH06B7Ac_eF7fmEULMMTwDellOh6hnOMUtf28toD68N527IHQTlBWfBCHcZykYPMdrS48yvuEcJKMJG8rU3YRM3u5Ojn3JXnc=w1200-h630-n-nu"
  },
  {
    "title": "Preference Tuning LLMs with Direct Preference Optimization Methods",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 18 Jan 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/pref-tuning",
    "thumbnail": "https://huggingface.co/blog/assets/pref-tuning/thumbnail.jpg"
  },
  {
    "title": "Fine-Tune W2V2-Bert for low-resource ASR with 🤗 Transformers",
    "description": "",
    "summary": "",
    "pubDate": "Fri, 19 Jan 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/fine-tune-w2v2-bert",
    "thumbnail": "https://huggingface.co/blog/assets/fine-tune-w2v2-bert/w2v_thumbnail.png"
  },
  {
    "title": "PatchTSMixer in HuggingFace",
    "description": "",
    "summary": "",
    "pubDate": "Fri, 19 Jan 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/patchtsmixer",
    "thumbnail": "https://huggingface.co/blog/assets/patchtsmixer/thumbnail.jpeg"
  },
  {
    "title": "Open-source LLMs as LangChain Agents",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 24 Jan 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/open-source-llms-as-agents",
    "thumbnail": "https://huggingface.co/blog/assets/open-source-llms-as-agents/thumbnail_open_source_agents.png"
  },
  {
    "title": "Hugging Face and Google partner for open AI collaboration",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 25 Jan 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/gcp-partnership",
    "thumbnail": "https://huggingface.co/blog/assets/173_gcp-partnership/thumbnail.jpg"
  },
  {
    "title": "New embedding models and API updates",
    "description": "We are launching a new generation of embedding models, new GPT-4 Turbo and moderation models, new API usage management tools, and soon, lower pricing on GPT-3.5 Turbo.",
    "summary": "We are launching a new generation of embedding models, new GPT-4 Turbo and moderation models, new API usage management tools, and soon, lower pricing on GPT-3.5 Turbo.",
    "pubDate": "Thu, 25 Jan 2024 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/new-embedding-models-and-api-updates",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "An Introduction to AI Secure LLM Safety Leaderboard",
    "description": "",
    "summary": "",
    "pubDate": "Fri, 26 Jan 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/leaderboard-decodingtrust",
    "thumbnail": "https://huggingface.co/blog/assets/leaderboards-on-the-hub/thumbnail_decodingtrust.png"
  },
  {
    "title": "The Hallucinations Leaderboard, an Open Effort to Measure Hallucinations in Large Language Models",
    "description": "",
    "summary": "",
    "pubDate": "Mon, 29 Jan 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/leaderboard-hallucinations",
    "thumbnail": "https://huggingface.co/blog/assets/leaderboards-on-the-hub/thumbnail.png"
  },
  {
    "title": "Accelerate StarCoder with 🤗 Optimum Intel on Xeon: Q8/Q4 and Speculative Decoding",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 30 Jan 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/intel-starcoder-quantization",
    "thumbnail": "https://huggingface.co/blog/assets/optimum_intel/intel_thumbnail.png"
  },
  {
    "title": "Building an early warning system for LLM-aided biological threat creation",
    "description": "We’re developing a blueprint for evaluating the risk that a large language model (LLM) could aid someone in creating a biological threat. In an evaluation involving both biology experts and students, we found that GPT-4 provides at most a mild uplift in biological threat creation accuracy. While this uplift is not large enough to be conclusive, our finding is a starting point for continued research and community deliberation.",
    "summary": "We’re developing a blueprint for evaluating the risk that a large language model (LLM) could aid someone in creating a biological threat. In an evaluation involving both biology experts and students, we found that GPT-4 provides at most a mild uplift in biological threat creation accuracy. While this uplift is not large enough to be conclusive, our finding is a starting point for continued research and community deliberation.",
    "pubDate": "Wed, 31 Jan 2024 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/building-an-early-warning-system-for-llm-aided-biological-threat-creation",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Introducing the Enterprise Scenarios Leaderboard: a Leaderboard for Real World Use Cases",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 31 Jan 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/leaderboard-patronus",
    "thumbnail": "https://huggingface.co/blog/assets/leaderboards-on-the-hub/thumbnail_patronus.png"
  },
  {
    "title": "Constitutional AI with Open LLMs",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 01 Feb 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/constitutional_ai",
    "thumbnail": "https://huggingface.co/blog/assets/175_constitutional_ai/thumbnail.png"
  },
  {
    "title": "Hugging Face Text Generation Inference available for AWS Inferentia2",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 01 Feb 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/text-generation-inference-on-inferentia2",
    "thumbnail": "https://huggingface.co/blog/assets/175_text_generation_inference_on_inferentia2/thumbnail.jpg"
  },
  {
    "title": "Patch Time Series Transformer in Hugging Face",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 01 Feb 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/patchtst",
    "thumbnail": "https://huggingface.co/blog/assets/patchtst/thumbnail.png"
  },
  {
    "title": "NPHardEval Leaderboard: Unveiling the Reasoning Abilities of Large Language Models through Complexity Classes and Dynamic Updates",
    "description": "",
    "summary": "",
    "pubDate": "Fri, 02 Feb 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/leaderboard-nphardeval",
    "thumbnail": "https://huggingface.co/blog/assets/leaderboards-on-the-hub/thumbnail_nphardeval.png"
  },
  {
    "title": "Response to NIST Executive Order on AI",
    "description": "The National Institute of Standards and Technology (NIST) request for information related to its assignments under sections 4.1, 4.5, and 11 of the Executive Order Concerning Artificial Intelligence",
    "summary": "The National Institute of Standards and Technology (NIST) request for information related to its assignments under sections 4.1, 4.5, and 11 of the Executive Order Concerning Artificial Intelligence",
    "pubDate": "Fri, 02 Feb 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/global-affairs/response-to-nist-executive-order-on-ai",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "SegMoE: Segmind Mixture of Diffusion Experts",
    "description": "",
    "summary": "",
    "pubDate": "Sat, 03 Feb 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/segmoe",
    "thumbnail": "https://huggingface.co/blog/assets/segmoe/thumbnail.png"
  },
  {
    "title": "From OpenAI to Open LLMs with Messages API",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 08 Feb 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/tgi-messages-api",
    "thumbnail": "https://huggingface.co/blog/assets/tgi-messages-api/thumbnail.jpg"
  },
  {
    "title": "The next chapter of our Gemini era",
    "description": "We're bringing Gemini to more Google products",
    "summary": "We're bringing Gemini to more Google products",
    "pubDate": "Thu, 08 Feb 2024 13:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/google-gemini-update-sundar-pichai-2024/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Keyword_Social_-_1920x1080.width-1300.png"
  },
  {
    "title": "Memory and new controls for ChatGPT",
    "description": "We’re testing the ability for ChatGPT to remember things you discuss to make future chats more helpful. You’re in control of ChatGPT’s memory.",
    "summary": "We’re testing the ability for ChatGPT to remember things you discuss to make future chats more helpful. You’re in control of ChatGPT’s memory.",
    "pubDate": "Tue, 13 Feb 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/memory-and-new-controls-for-chatgpt",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "AMD Pervasive AI Developer Contest!",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 14 Feb 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/amd_pervasive_developer_ai_contest",
    "thumbnail": "https://huggingface.co/blog/amd_pervasive_developer_ai_contest/assets/amd_pervasive_developer_ai_contest/amd_developer_general_abstract.jpg"
  },
  {
    "title": "Disrupting malicious uses of AI by state-affiliated threat actors",
    "description": "We terminated accounts associated with state-affiliated threat actors. Our findings show our models offer only limited, incremental capabilities for malicious cybersecurity tasks.",
    "summary": "We terminated accounts associated with state-affiliated threat actors. Our findings show our models offer only limited, incremental capabilities for malicious cybersecurity tasks.",
    "pubDate": "Wed, 14 Feb 2024 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/disrupting-malicious-uses-of-ai-by-state-affiliated-threat-actors",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Our next-generation model: Gemini 1.5",
    "description": "The model delivers dramatically enhanced performance, with a breakthrough in long-context understanding across modalities.",
    "summary": "The model delivers dramatically enhanced performance, with a breakthrough in long-context understanding across modalities.",
    "pubDate": "Thu, 15 Feb 2024 15:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/our-next-generation-model-gemini-15/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/final_gemini_1.5_blog_social_share_800x418.width-1300.png"
  },
  {
    "title": "Video generation models as world simulators",
    "description": "We explore large-scale training of generative models on video data. Specifically, we train text-conditional diffusion models jointly on videos and images of variable durations, resolutions and aspect ratios. We leverage a transformer architecture that operates on spacetime patches of video and image latent codes. Our largest model, Sora, is capable of generating a minute of high fidelity video. Our results suggest that scaling video generation models is a promising path towards building general purpose simulators of the physical world.",
    "summary": "We explore large-scale training of generative models on video data. Specifically, we train text-conditional diffusion models jointly on videos and images of variable durations, resolutions and aspect ratios. We leverage a transformer architecture that operates on spacetime patches of video and image latent codes. Our largest model, Sora, is capable of generating a minute of high fidelity video. Our results suggest that scaling video generation models is a promising path towards building general purpose simulators of the physical world.",
    "pubDate": "Thu, 15 Feb 2024 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/video-generation-models-as-world-simulators",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Synthetic data: save money, time and carbon with open source",
    "description": "",
    "summary": "",
    "pubDate": "Fri, 16 Feb 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/synthetic-data-save-costs",
    "thumbnail": "https://huggingface.co/blog/assets/176_synthetic-data-save-costs/thumbnail.png"
  },
  {
    "title": "🤗 PEFT welcomes new merging methods",
    "description": "",
    "summary": "",
    "pubDate": "Mon, 19 Feb 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/peft_merging",
    "thumbnail": "https://huggingface.co/blog/assets/peft_merging/thumbnail.png"
  },
  {
    "title": "Introducing the Open Ko-LLM Leaderboard: Leading the Korean LLM Evaluation Ecosystem",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 20 Feb 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/leaderboard-upstage",
    "thumbnail": "https://huggingface.co/blog/assets/leaderboards-on-the-hub/thumbnail_upstage.png"
  },
  {
    "title": "Gemma: Introducing new state-of-the-art open models",
    "description": "Gemma is built for responsible AI development from the same research and technology used to create Gemini models.",
    "summary": "Gemma is built for responsible AI development from the same research and technology used to create Gemini models.",
    "pubDate": "Wed, 21 Feb 2024 13:06:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/gemma-introducing-new-state-of-the-art-open-models/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Gemma-social-share.width-1300.jpg"
  },
  {
    "title": "Welcome Gemma - Google's new open LLM",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 21 Feb 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/gemma",
    "thumbnail": "https://huggingface.co/blog/assets/gemma/thumbnail.jpg"
  },
  {
    "title": "Fine-Tuning Gemma Models in Hugging Face",
    "description": "",
    "summary": "",
    "pubDate": "Fri, 23 Feb 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/gemma-peft",
    "thumbnail": "https://huggingface.co/blog/assets/gemma-peft/thumbnail.png"
  },
  {
    "title": "Introducing the Red-Teaming Resistance Leaderboard",
    "description": "",
    "summary": "",
    "pubDate": "Fri, 23 Feb 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/leaderboard-haizelab",
    "thumbnail": "https://huggingface.co/blog/assets/leaderboards-on-the-hub/thumbnail_haizelab.png"
  },
  {
    "title": "🪆 Introduction to Matryoshka Embedding Models",
    "description": "",
    "summary": "",
    "pubDate": "Fri, 23 Feb 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/matryoshka",
    "thumbnail": "https://huggingface.co/blog/assets/matryoshka/thumbnail.png"
  },
  {
    "title": "AI Watermarking 101: Tools and Techniques",
    "description": "",
    "summary": "",
    "pubDate": "Mon, 26 Feb 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/watermarking",
    "thumbnail": "https://huggingface.co/blog/assets/watermarking/thumbnail.png"
  },
  {
    "title": "TTS Arena: Benchmarking Text-to-Speech Models in the Wild",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 27 Feb 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/arena-tts",
    "thumbnail": "https://huggingface.co/blog/assets/arenas-on-the-hub/thumbnail.png"
  },
  {
    "title": "StarCoder2 and The Stack v2",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 28 Feb 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/starcoder2",
    "thumbnail": "https://huggingface.co/blog/assets/177_starcoder2/sc2-banner.png"
  },
  {
    "title": "Text-Generation Pipeline on Intel® Gaudi® 2 AI Accelerator",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 29 Feb 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/textgen-pipe-gaudi",
    "thumbnail": "https://huggingface.co/blog/assets/textgen-pipe-gaudi/thumbnail.png"
  },
  {
    "title": "Data is better together",
    "description": "",
    "summary": "",
    "pubDate": "Mon, 04 Mar 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/community-datasets",
    "thumbnail": "https://huggingface.co/blog/assets/community-datasets/thumbnail.png"
  },
  {
    "title": "Introducing ConTextual: How well can your Multimodal model jointly reason over text and image in text-rich scenes?",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 05 Mar 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/leaderboard-contextual",
    "thumbnail": "https://huggingface.co/blog/assets/leaderboards-on-the-hub/thumbnail_contextual.png"
  },
  {
    "title": "OpenAI and Elon Musk",
    "description": "We are dedicated to the OpenAI mission and have pursued it every step of the way.",
    "summary": "We are dedicated to the OpenAI mission and have pursued it every step of the way.",
    "pubDate": "Tue, 05 Mar 2024 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-elon-musk",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Improving health literacy and patient well-being",
    "description": "Lifespan uses GPT-4 to radically improve health literacy and patient outcomes.",
    "summary": "Lifespan uses GPT-4 to radically improve health literacy and patient outcomes.",
    "pubDate": "Wed, 06 Mar 2024 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/lifespan",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Sparking a more productive company with ChatGPT Enterprise",
    "description": "Match Group uses ChatGPT Enterprise to spark creativity and impact.",
    "summary": "Match Group uses ChatGPT Enterprise to spark creativity and impact.",
    "pubDate": "Wed, 06 Mar 2024 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/match-group",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Using AI to improve patient access to clinical trials",
    "description": "Paradigm uses OpenAI’s API to improve patient access to clinical trials.",
    "summary": "Paradigm uses OpenAI’s API to improve patient access to clinical trials.",
    "pubDate": "Wed, 06 Mar 2024 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/paradigm",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "OpenAI announces new members to board of directors",
    "description": "Dr. Sue Desmond-Hellmann, Nicole Seligman, Fidji Simo join; Sam Altman rejoins board",
    "summary": "Dr. Sue Desmond-Hellmann, Nicole Seligman, Fidji Simo join; Sam Altman rejoins board",
    "pubDate": "Fri, 08 Mar 2024 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-announces-new-members-to-board-of-directors",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Review completed & Altman, Brockman to continue to lead OpenAI",
    "description": "New board members named and enhancements to the governance structure introduced",
    "summary": "New board members named and enhancements to the governance structure introduced",
    "pubDate": "Fri, 08 Mar 2024 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/review-completed-altman-brockman-to-continue-to-lead-openai",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "A generalist AI agent for 3D virtual environments",
    "description": "Introducing SIMA, a Scalable Instructable Multiworld Agent",
    "summary": "Introducing SIMA, a Scalable Instructable Multiworld Agent",
    "pubDate": "Wed, 13 Mar 2024 14:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/sima-generalist-ai-agent-for-3d-virtual-environments/",
    "thumbnail": "https://lh3.googleusercontent.com/2GNumOaJCB48RQIFbwJmmZro-AFdBebufxvY_ZkSdUs9RQ-0nSTgBMXuhUdIE5zpPknqevL4ZyP44PLOpJlg0U0ArlOCcJHfoOagzSnZZoXLnq7hdQ=w1200-h630-n-nu"
  },
  {
    "title": "Global news partnerships: Le Monde and Prisa Media",
    "description": "We have partnered with international news organizations Le Monde and Prisa Media to bring French and Spanish news content to ChatGPT.",
    "summary": "We have partnered with international news organizations Le Monde and Prisa Media to bring French and Spanish news content to ChatGPT.",
    "pubDate": "Wed, 13 Mar 2024 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/global-news-partnerships-le-monde-and-prisa-media",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Saving lives with AI health coaching",
    "description": "Healthify collaborates with OpenAI to improve millions of lives with sustainable weight loss.",
    "summary": "Healthify collaborates with OpenAI to improve millions of lives with sustainable weight loss.",
    "pubDate": "Wed, 13 Mar 2024 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/healthify",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "CPU Optimized Embeddings with 🤗 Optimum Intel and fastRAG",
    "description": "",
    "summary": "",
    "pubDate": "Fri, 15 Mar 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/intel-fast-embedding",
    "thumbnail": "https://huggingface.co/blog/assets/optimum_intel/intel_thumbnail.png"
  },
  {
    "title": "Unlocking the conversion of Web Screenshots into HTML Code with the WebSight Dataset",
    "description": "",
    "summary": "",
    "pubDate": "Fri, 15 Mar 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/websight",
    "thumbnail": "https://huggingface.co/blog/assets/websight/thumbnail.png"
  },
  {
    "title": "Building a data-driven, efficient culture with AI",
    "description": "Holiday Extras rolls out ChatGPT Enterprise across every team, boosting productivity by 500 hours weekly.",
    "summary": "Holiday Extras rolls out ChatGPT Enterprise across every team, boosting productivity by 500 hours weekly.",
    "pubDate": "Mon, 18 Mar 2024 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/holiday-extras",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Easily Train Models with H100 GPUs on NVIDIA DGX Cloud",
    "description": "",
    "summary": "",
    "pubDate": "Mon, 18 Mar 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/train-dgx-cloud",
    "thumbnail": "https://huggingface.co/blog/assets/train-dgx-cloud/thumbnail.jpg"
  },
  {
    "title": "Enterprise-ready trust and safety",
    "description": "Salesforce integrates OpenAI’s enterprise-ready LLMs to transform customer applications.",
    "summary": "Salesforce integrates OpenAI’s enterprise-ready LLMs to transform customer applications.",
    "pubDate": "Mon, 18 Mar 2024 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/salesforce",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "quanto: a pytorch quantization toolkit",
    "description": "",
    "summary": "",
    "pubDate": "Mon, 18 Mar 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/quanto-introduction",
    "thumbnail": "https://huggingface.co/blog/assets/169_quanto_intro/thumbnail.png"
  },
  {
    "title": "Reimagining the email experience with AI",
    "description": "Superhuman introduces a new era of email with OpenAI.",
    "summary": "Superhuman introduces a new era of email with OpenAI.",
    "pubDate": "Mon, 18 Mar 2024 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/superhuman",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "TacticAI: an AI assistant for football tactics",
    "description": "As part of our multi-year collaboration with Liverpool FC, we develop a full AI system that can advise coaches on corner kicks",
    "summary": "As part of our multi-year collaboration with Liverpool FC, we develop a full AI system that can advise coaches on corner kicks",
    "pubDate": "Tue, 19 Mar 2024 16:03:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/tacticai-ai-assistant-for-football-tactics/",
    "thumbnail": "https://lh3.googleusercontent.com/pPa45NPPYrOc4QHbcLIsmueJXi9hKNFdB0rbnRMdiRH0Gf3fgIc_g26-UbFxHVzqUT85QA-N3IvPpQaDevlp3OeF3RIiLQjmuONVRVyX1et0WYEKTQ=w1200-h630-n-nu"
  },
  {
    "title": "A Chatbot on your Laptop: Phi-2 on Intel Meteor Lake",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 20 Mar 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/phi2-intel-meteor-lake",
    "thumbnail": "https://huggingface.co/blog/assets/phi2-intel-meteor-lake/02.jpg"
  },
  {
    "title": "Cosmopedia: how to create large-scale synthetic data for pre-training Large Language Models",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 20 Mar 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/cosmopedia",
    "thumbnail": "https://huggingface.co/blog/assets/cosmopedia/thumbnail.png"
  },
  {
    "title": "GaLore: Advancing Large Model Training on Consumer-grade Hardware",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 20 Mar 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/galore",
    "thumbnail": "https://huggingface.co/front/thumbnails/v2-2.png"
  },
  {
    "title": "Embedding AI into developer software",
    "description": "JetBrains uses OpenAI’s API to build its fastest-growing product ever.",
    "summary": "JetBrains uses OpenAI’s API to build its fastest-growing product ever.",
    "pubDate": "Thu, 21 Mar 2024 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/jetbrains",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Introducing the Chatbot Guardrails Arena",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 21 Mar 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/arena-lighthouz",
    "thumbnail": "https://huggingface.co/blog/assets/arenas-on-the-hub/thumbnail_lighthouz.png"
  },
  {
    "title": "Binary and Scalar Embedding Quantization for Significantly Faster & Cheaper Retrieval",
    "description": "",
    "summary": "",
    "pubDate": "Fri, 22 Mar 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/embedding-quantization",
    "thumbnail": "https://huggingface.co/blog/assets/embedding-quantization/thumbnail.png"
  },
  {
    "title": "Total noob’s intro to Hugging Face Transformers",
    "description": "",
    "summary": "",
    "pubDate": "Fri, 22 Mar 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/noob_intro_transformers",
    "thumbnail": "https://huggingface.co/blog/assets/78_ml_director_insights/guide.png"
  },
  {
    "title": "Pollen-Vision: Unified interface for Zero-Shot vision models in robotics",
    "description": "",
    "summary": "",
    "pubDate": "Mon, 25 Mar 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/pollen-vision",
    "thumbnail": "https://huggingface.co/blog/assets/pollen-vision/thumbnail.jpg"
  },
  {
    "title": "Sora first impressions",
    "description": "Since we introduced Sora to the world last month, we’ve been working with artists to learn how Sora might aid in their creative process.",
    "summary": "Since we introduced Sora to the world last month, we’ve been working with artists to learn how Sora might aid in their creative process.",
    "pubDate": "Mon, 25 Mar 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/sora-first-impressions",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "OpenAI’s comment to the NTIA on open model weights",
    "description": "OpenAI’s comment to the NTIA on open model weights This comment was submitted by OpenAI in response to NTIA’s March 2024 Request for Information on Dual-Use Foundation Models with Widely Available Weights.",
    "summary": "OpenAI’s comment to the NTIA on open model weights This comment was submitted by OpenAI in response to NTIA’s March 2024 Request for Information on Dual-Use Foundation Models with Widely Available Weights.",
    "pubDate": "Wed, 27 Mar 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/global-affairs/openai-s-comment-to-the-ntia-on-open-model-weights",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Making education data accessible",
    "description": "Zelma uses GPT-4 to make education data accessible.",
    "summary": "Zelma uses GPT-4 to make education data accessible.",
    "pubDate": "Thu, 28 Mar 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/zelma",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Navigating the challenges and opportunities of synthetic voices",
    "description": "We’re sharing lessons from a small scale preview of Voice Engine, a model for creating custom voices.",
    "summary": "We’re sharing lessons from a small scale preview of Voice Engine, a model for creating custom voices.",
    "pubDate": "Fri, 29 Mar 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/navigating-the-challenges-and-opportunities-of-synthetic-voices",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Reducing health insurance costs and improving care",
    "description": "Oscar brings AI to health insurance, reducing costs and improving patient care.",
    "summary": "Oscar brings AI to health insurance, reducing costs and improving patient care.",
    "pubDate": "Mon, 01 Apr 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/oscar",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Start using ChatGPT instantly",
    "description": "We’re making it easier for people to experience the benefits of AI without needing to sign up",
    "summary": "We’re making it easier for people to experience the benefits of AI without needing to sign up",
    "pubDate": "Mon, 01 Apr 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/start-using-chatgpt-instantly",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Bringing serverless GPU inference to Hugging Face users",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 02 Apr 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/cloudflare-workers-ai",
    "thumbnail": "https://huggingface.co/blog/assets/cloudflare-workers-ai/thumbnail.jpg"
  },
  {
    "title": "Customizing models for legal professionals",
    "description": "Harvey partners with OpenAI to build a custom-trained model for legal professionals.",
    "summary": "Harvey partners with OpenAI to build a custom-trained model for legal professionals.",
    "pubDate": "Tue, 02 Apr 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/harvey",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Blazing Fast SetFit Inference with 🤗 Optimum Intel on Xeon",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 03 Apr 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/setfit-optimum-intel",
    "thumbnail": "https://huggingface.co/blog/assets/optimum_intel/intel_thumbnail.png"
  },
  {
    "title": "Hugging Face partners with Wiz Research to Improve AI Security",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 04 Apr 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/hugging-face-wiz-security-blog",
    "thumbnail": "https://huggingface.co/blog/assets/wiz_security/security.png"
  },
  {
    "title": "Introducing improvements to the fine-tuning API and expanding our custom models program",
    "description": "We’re adding new features to help developers have more control over fine-tuning and announcing new ways to build custom models with OpenAI.",
    "summary": "We’re adding new features to help developers have more control over fine-tuning and announcing new ways to build custom models with OpenAI.",
    "pubDate": "Thu, 04 Apr 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-improvements-to-the-fine-tuning-api-and-expanding-our-custom-models-program",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Text2SQL using Hugging Face Dataset Viewer API and Motherduck DuckDB-NSQL-7B",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 04 Apr 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/duckdb-nsql-7b",
    "thumbnail": "https://huggingface.co/blog/assets/duckdb-nsql-7b/thumbnail.png"
  },
  {
    "title": "Klarna's AI assistant does the work of 700 full-time agents",
    "description": "Klarna is using AI to revolutionize personal shopping, customer service, and employee productivity.",
    "summary": "Klarna is using AI to revolutionize personal shopping, customer service, and employee productivity.",
    "pubDate": "Fri, 05 Apr 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/klarna",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Public Policy at Hugging Face",
    "description": "",
    "summary": "",
    "pubDate": "Mon, 08 Apr 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/policy-blog",
    "thumbnail": "https://huggingface.co/blog/assets/policy_docs/policy_blog_thumbnail.png"
  },
  {
    "title": "CodeGemma - an official Google release for code LLMs",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 09 Apr 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/codegemma",
    "thumbnail": "https://huggingface.co/blog/assets/codegemma/thumbnail_b.png"
  },
  {
    "title": "Making thousands of open LLMs bloom in the Vertex AI Model Garden",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 10 Apr 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/google-cloud-model-garden",
    "thumbnail": "https://huggingface.co/blog/assets/173_gcp-partnership/thumbnail.jpg"
  },
  {
    "title": "Vision Language Models Explained",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 11 Apr 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/vlms",
    "thumbnail": "https://huggingface.co/blog/assets/vlms_explained/thumbnail.png"
  },
  {
    "title": "Introducing OpenAI Japan",
    "description": "We are excited to announce our first office in Asia and we’re releasing a GPT-4 custom model optimized for the Japanese language.",
    "summary": "We are excited to announce our first office in Asia and we’re releasing a GPT-4 custom model optimized for the Japanese language.",
    "pubDate": "Sun, 14 Apr 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-openai-japan",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Introducing Idefics2: A Powerful 8B Vision-Language Model for the community",
    "description": "",
    "summary": "",
    "pubDate": "Mon, 15 Apr 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/idefics2",
    "thumbnail": "https://huggingface.co/blog/assets/idefics/thumbnail.png"
  },
  {
    "title": "AI Apps in a Flash with Gradio's Reload Mode",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 16 Apr 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/gradio-reload",
    "thumbnail": "https://huggingface.co/blog/assets/gradio-reload/thumbnail_compressed.png"
  },
  {
    "title": "Introducing the LiveCodeBench Leaderboard - Holistic and Contamination-Free Evaluation of Code LLMs",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 16 Apr 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/leaderboard-livecodebench",
    "thumbnail": "https://huggingface.co/blog/assets/leaderboards-on-the-hub/thumbnail.png"
  },
  {
    "title": "Running Privacy-Preserving Inference on Hugging Face Endpoints",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 16 Apr 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/fhe-endpoints",
    "thumbnail": "https://huggingface.co/blog/assets/fhe-endpoints/thumbnail.png"
  },
  {
    "title": "Ryght’s Journey to Empower Healthcare and Life Sciences with Expert Support from Hugging Face",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 16 Apr 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/ryght-case-study",
    "thumbnail": "https://huggingface.co/blog/assets/ryght-case-study/thumbnail.png"
  },
  {
    "title": "Welcome Llama 3 - Meta's new open LLM",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 18 Apr 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/llama3",
    "thumbnail": "https://huggingface.co/blog/assets/llama3/thumbnail.jpg"
  },
  {
    "title": "The ethics of advanced AI assistants",
    "description": "Exploring the promise and risks of a future with more capable AI",
    "summary": "Exploring the promise and risks of a future with more capable AI",
    "pubDate": "Fri, 19 Apr 2024 10:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/the-ethics-of-advanced-ai-assistants/",
    "thumbnail": "https://lh3.googleusercontent.com/28MrwSZMny-Gf_FVYJS0z3JbnfLXzRLNAF2BA0YQ7rbcrZWdNNwddfFsWVh_n7C31N8oXBmWexFbyce4jzaX3FSNt3EXG6mSLSlXaSx70Mc7Q0s7FF4=w1200-h630-n-nu"
  },
  {
    "title": "The Instruction Hierarchy: Training LLMs to Prioritize Privileged Instructions",
    "description": "Today's LLMs are susceptible to prompt injections, jailbreaks, and other attacks that allow adversaries to overwrite a model's original instructions with their own malicious prompts.",
    "summary": "Today's LLMs are susceptible to prompt injections, jailbreaks, and other attacks that allow adversaries to overwrite a model's original instructions with their own malicious prompts.",
    "pubDate": "Fri, 19 Apr 2024 19:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/the-instruction-hierarchy",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "The Open Medical-LLM Leaderboard: Benchmarking Large Language Models in Healthcare",
    "description": "",
    "summary": "",
    "pubDate": "Fri, 19 Apr 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/leaderboard-medicalllm",
    "thumbnail": "https://huggingface.co/blog/assets/leaderboards-on-the-hub/thumbnail_medicalllm.png"
  },
  {
    "title": "Jack of All Trades, Master of Some, a Multi-Purpose Transformer Agent",
    "description": "",
    "summary": "",
    "pubDate": "Mon, 22 Apr 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/jat",
    "thumbnail": "https://huggingface.co/blog/assets/jat/thumbnail.png"
  },
  {
    "title": "Introducing more enterprise-grade features for API customers",
    "description": "Increasing enterprise support with more security features and controls, updates to our Assistants API, and tools to better manage costs.",
    "summary": "Increasing enterprise support with more security features and controls, updates to our Assistants API, and tools to better manage costs.",
    "pubDate": "Tue, 23 Apr 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/more-enterprise-grade-features-for-api-customers",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Introducing the Open Chain of Thought Leaderboard",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 23 Apr 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/leaderboard-cot",
    "thumbnail": "https://huggingface.co/blog/assets/leaderboards-on-the-hub/thumbnail_cot.png"
  },
  {
    "title": "OpenAI’s commitment to child safety: adopting safety by design principles",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 23 Apr 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/child-safety-adopting-sbd-principles",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Accelerating the development of life-saving treatments",
    "description": "Accelerating the development of life-saving treatments.",
    "summary": "Accelerating the development of life-saving treatments.",
    "pubDate": "Wed, 24 Apr 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/moderna",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "GPT-4 API general availability and deprecation of older models in the Completions API",
    "description": "GPT-3.5 Turbo, DALL·E and Whisper APIs are also generally available, and we are releasing a deprecation plan for older models of the Completions API, which will retire at the beginning of 2024.",
    "summary": "GPT-3.5 Turbo, DALL·E and Whisper APIs are also generally available, and we are releasing a deprecation plan for older models of the Completions API, which will retire at the beginning of 2024.",
    "pubDate": "Wed, 24 Apr 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/gpt-4-api-general-availability",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Introducing ChatGPT and Whisper APIs",
    "description": "Developers can now integrate ChatGPT and Whisper models into their apps and products through our API.",
    "summary": "Developers can now integrate ChatGPT and Whisper models into their apps and products through our API.",
    "pubDate": "Wed, 24 Apr 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-chatgpt-and-whisper-apis",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "StarCoder2-Instruct: Fully Transparent and Permissive Self-Alignment for Code Generation",
    "description": "",
    "summary": "",
    "pubDate": "Mon, 29 Apr 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/sc2-instruct",
    "thumbnail": "https://huggingface.co/blog/assets/sc2-instruct/sc2-instruct-banner.png"
  },
  {
    "title": "We’re bringing the Financial Times’ world-class journalism to ChatGPT",
    "description": "We will also collaborate on new AI experiences for FT readers.",
    "summary": "We will also collaborate on new AI experiences for FT readers.",
    "pubDate": "Mon, 29 Apr 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/content-partnership-with-financial-times",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Improving Prompt Consistency with Structured Generations",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 30 Apr 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/evaluation-structured-outputs",
    "thumbnail": "https://huggingface.co/blog/assets/evaluating-mmlu-leaderboard/thumbnail.png"
  },
  {
    "title": "Powerful ASR + diarization + speculative decoding with Hugging Face Inference Endpoints",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 01 May 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/asr-diarization",
    "thumbnail": "https://huggingface.co/blog/assets/asr-diarization/thumbnail.png"
  },
  {
    "title": "Bringing the Artificial Analysis LLM Performance Leaderboard to Hugging Face",
    "description": "",
    "summary": "",
    "pubDate": "Fri, 03 May 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/leaderboard-artificial-analysis",
    "thumbnail": "https://huggingface.co/blog/assets/leaderboards-on-the-hub/thumbnail_artificialanalysis.png"
  },
  {
    "title": "Google DeepMind at ICLR 2024",
    "description": "Developing next-gen AI agents, exploring new modalities, and pioneering foundational learning",
    "summary": "Developing next-gen AI agents, exploring new modalities, and pioneering foundational learning",
    "pubDate": "Fri, 03 May 2024 13:39:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/google-deepmind-at-iclr-2024/",
    "thumbnail": "https://lh3.googleusercontent.com/8PzKGooudBtamqh9keU_q7O0ex5XxGgIIK3BKQNAVEV6WDzIkfadsbNPhU0QCg5PurFGnAOSOClrM9dQHIGvOEe9MPluA5uhyFcun3FvNMBfPI63mWk=w1200-h630-n-nu"
  },
  {
    "title": "Reimagining secure infrastructure for advanced AI",
    "description": "Securing advanced AI systems will require an evolution in infrastructure security. We’re calling for research and investment in six security measures that we believe will play key roles in protecting advanced AI. Protecting, exploring, and applying advanced artificial intelligence (AI) is our strategic imperative. OpenAI’s mission is to deliver positive impact of advanced AI to everything from healthcare to science to education – and yes, even to cybersecurity. That work begins with building secure, trustworthy AI systems and protecting the underlying technologies from those who seek to subvert our work to cause harm.",
    "summary": "Securing advanced AI systems will require an evolution in infrastructure security. We’re calling for research and investment in six security measures that we believe will play key roles in protecting advanced AI. Protecting, exploring, and applying advanced artificial intelligence (AI) is our strategic imperative. OpenAI’s mission is to deliver positive impact of advanced AI to everything from healthcare to science to education – and yes, even to cybersecurity. That work begins with building secure, trustworthy AI systems and protecting the underlying technologies from those who seek to subvert our work to cause harm.",
    "pubDate": "Fri, 03 May 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/reimagining-secure-infrastructure-for-advanced-ai",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Introducing the Open Leaderboard for Hebrew LLMs!",
    "description": "",
    "summary": "",
    "pubDate": "Sun, 05 May 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/leaderboard-hebrew",
    "thumbnail": "https://huggingface.co/blog/assets/leaderboards-on-the-hub/thumbnail_hebrew.png"
  },
  {
    "title": "API Partnership with Stack Overflow",
    "description": "API Partnership with Stack Overflow Stack Overflow and OpenAI today announced a new API partnership that will empower developers with the collective strengths of the world’s leading knowledge platform for highly technical content with the world’s most popular LLM models for AI development.",
    "summary": "API Partnership with Stack Overflow Stack Overflow and OpenAI today announced a new API partnership that will empower developers with the collective strengths of the world’s leading knowledge platform for highly technical content with the world’s most popular LLM models for AI development.",
    "pubDate": "Mon, 06 May 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/api-partnership-with-stack-overflow",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Our approach to data and AI",
    "description": "Just over a year after launching ChatGPT, AI is changing how we live, work and learn. It’s also raised important conversations about data in the age of AI. More on our approach, a new Media Manager for creators and content owners, and where we’re headed.",
    "summary": "Just over a year after launching ChatGPT, AI is changing how we live, work and learn. It’s also raised important conversations about data in the age of AI. More on our approach, a new Media Manager for creators and content owners, and where we’re headed.",
    "pubDate": "Tue, 07 May 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/approach-to-data-and-ai",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Understanding the source of what we see and hear online",
    "description": "Today we’re introducing new technology to help researchers identify content created by our tools and joining the Coalition for Content Provenance and Authenticity Steering Committee to promote industry standards.",
    "summary": "Today we’re introducing new technology to help researchers identify content created by our tools and joining the Coalition for Content Provenance and Authenticity Steering Committee to promote industry standards.",
    "pubDate": "Tue, 07 May 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/understanding-the-source-of-what-we-see-and-hear-online",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "AlphaFold 3 predicts the structure and interactions of all of life’s molecules",
    "description": "Introducing a new AI model developed by Google DeepMind and Isomorphic Labs.",
    "summary": "Introducing a new AI model developed by Google DeepMind and Isomorphic Labs.",
    "pubDate": "Wed, 08 May 2024 16:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/alphafold-3-predicts-the-structure-and-interactions-of-all-lifes-molecules/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/AF_social_share.width-1300.jpg"
  },
  {
    "title": "Introducing the Model Spec",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 08 May 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-the-model-spec",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Building Cost-Efficient Enterprise RAG applications with Intel Gaudi 2 and Intel Xeon",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 09 May 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/cost-efficient-rag-applications-with-intel",
    "thumbnail": "https://huggingface.co/blog/assets/cost_efficient_rag_applications_with_intel/main.jpg"
  },
  {
    "title": "Subscribe to Enterprise Hub with your AWS Account",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 09 May 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/enterprise-hub-aws-marketplace",
    "thumbnail": "https://huggingface.co/blog/assets/158_aws_marketplace/thumbnail.jpg"
  },
  {
    "title": "Hello GPT-4o",
    "description": "We’re announcing GPT-4 Omni, our new flagship model which can reason across audio, vision, and text in real time.",
    "summary": "We’re announcing GPT-4 Omni, our new flagship model which can reason across audio, vision, and text in real time.",
    "pubDate": "Mon, 13 May 2024 10:05:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/hello-gpt-4o",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Introducing GPT-4o and more tools to ChatGPT free users",
    "description": "Introducing GPT-4o and more tools to ChatGPT free users We are launching our newest flagship model and making more capabilities available for free in ChatGPT.",
    "summary": "Introducing GPT-4o and more tools to ChatGPT free users We are launching our newest flagship model and making more capabilities available for free in ChatGPT.",
    "pubDate": "Mon, 13 May 2024 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/gpt-4o-and-more-tools-to-chatgpt-free",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "License to Call: Introducing Transformers Agents 2.0",
    "description": "",
    "summary": "",
    "pubDate": "Mon, 13 May 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/agents",
    "thumbnail": "https://huggingface.co/blog/assets/agents/thumbnail.png"
  },
  {
    "title": "Spring Update",
    "description": "Introducing GPT-4o and making more capabilities available for free in ChatGPT.",
    "summary": "Introducing GPT-4o and making more capabilities available for free in ChatGPT.",
    "pubDate": "Mon, 13 May 2024 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/spring-update",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Collaborating with Carlyle to Chart the Future of Private Equity",
    "description": "Collaborating with Carlyle to Chart the Future of Private Equity",
    "summary": "Collaborating with Carlyle to Chart the Future of Private Equity",
    "pubDate": "Tue, 14 May 2024 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/collaborating-with-carlyle-to-chart-the-future-of-private-equity",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Gemini breaks new ground: a faster model, longer context and AI agents",
    "description": "We’re introducing a series of updates across the Gemini family of models, including the new 1.5 Flash, our lightweight model for speed and efficiency, and Project Astra, our vision for the future of AI assistants.",
    "summary": "We’re introducing a series of updates across the Gemini family of models, including the new 1.5 Flash, our lightweight model for speed and efficiency, and Project Astra, our vision for the future of AI assistants.",
    "pubDate": "Tue, 14 May 2024 17:58:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/gemini-breaks-new-ground-a-faster-model-longer-context-and-ai-agents/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Gemini_Blog_Social_Share.width-1300.png"
  },
  {
    "title": "Hugging Face x LangChain : A new partner package in LangChain",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 14 May 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/langchain",
    "thumbnail": "https://huggingface.co/blog/assets/langchain_huggingface/thumbnail.png"
  },
  {
    "title": "Ilya Sutskever to leave OpenAI, Jakub Pachocki announced as Chief Scientist",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 14 May 2024 18:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/jakub-pachocki-announced-as-chief-scientist",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Introducing the Open Arabic LLM Leaderboard",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 14 May 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/leaderboard-arabic",
    "thumbnail": "https://huggingface.co/blog/assets/leaderboards-on-the-hub/thumbnail_arabic.png"
  },
  {
    "title": "New generative media models and tools, built with and for creators",
    "description": "We’re introducing Veo, our most capable model for generating high-definition video, and Imagen 3, our highest quality text-to-image model. We’re also sharing new demo recordings created with our Music AI Sandbox.",
    "summary": "We’re introducing Veo, our most capable model for generating high-definition video, and Imagen 3, our highest quality text-to-image model. We’re also sharing new demo recordings created with our Music AI Sandbox.",
    "pubDate": "Tue, 14 May 2024 17:57:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/new-generative-media-models-and-tools-built-with-and-for-creators/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/IO24_Gen_Media_Header_1.width-1300.png"
  },
  {
    "title": "PaliGemma – Google's Cutting-Edge Open Vision Language Model",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 14 May 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/paligemma",
    "thumbnail": "https://huggingface.co/blog/assets/paligemma/Paligemma.png"
  },
  {
    "title": "Watermarking AI-generated text and video with SynthID",
    "description": "Announcing our novel watermarking method for AI-generated text and video, and how we’re bringing SynthID to key Google products",
    "summary": "Announcing our novel watermarking method for AI-generated text and video, and how we’re bringing SynthID to key Google products",
    "pubDate": "Tue, 14 May 2024 17:56:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/watermarking-ai-generated-text-and-video-with-synthid/",
    "thumbnail": "https://lh3.googleusercontent.com/I6bH75hNf57977cub27rFEsgxhcmkLrcINfCmGUaBCr7Q1bFTIl552R_6kuqlSkUjRtsTh929u6NoQmtHcwIG-GnjvPqMeynVLY0Rc9RRvezPQS0=w1200-h630-n-nu"
  },
  {
    "title": "Creating an AI-powered Magic Studio",
    "description": "Canva is a visual communication platform, enjoyed by more than 175 million people monthly to make presentations, videos, documents, websites, social media graphics and more. A majority of the world’s knowledge workers lack design training, but Canva’s combination of an easy-to-use interface, vast libraries, and time-saving tools allows anyone to create visually compelling content.",
    "summary": "Canva is a visual communication platform, enjoyed by more than 175 million people monthly to make presentations, videos, documents, websites, social media graphics and more. A majority of the world’s knowledge workers lack design training, but Canva’s combination of an easy-to-use interface, vast libraries, and time-saving tools allows anyone to create visually compelling content.",
    "pubDate": "Thu, 16 May 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/canva",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Improvements to data analysis in ChatGPT",
    "description": "Improvements to data analysis in ChatGPT Interact with tables and charts and add files directly from Google Drive and Microsoft OneDrive.",
    "summary": "Improvements to data analysis in ChatGPT Interact with tables and charts and add files directly from Google Drive and Microsoft OneDrive.",
    "pubDate": "Thu, 16 May 2024 15:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/improvements-to-data-analysis-in-chatgpt",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "OpenAI and Reddit Partnership",
    "description": "OpenAI and Reddit Partnership We’re bringing Reddit’s unique content to ChatGPT and our products.",
    "summary": "OpenAI and Reddit Partnership We’re bringing Reddit’s unique content to ChatGPT and our products.",
    "pubDate": "Thu, 16 May 2024 13:30:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-and-reddit-partnership",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Unlocking Longer Generation with Key-Value Cache Quantization",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 16 May 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/kv-cache-quantization",
    "thumbnail": "https://huggingface.co/blog/assets/kv_cache_quantization/thumbnail.png"
  },
  {
    "title": "Introducing the Frontier Safety Framework",
    "description": "Our approach to analyzing and mitigating future risks posed by advanced AI models",
    "summary": "Our approach to analyzing and mitigating future risks posed by advanced AI models",
    "pubDate": "Fri, 17 May 2024 14:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/introducing-the-frontier-safety-framework/",
    "thumbnail": "https://lh3.googleusercontent.com/_NVnftxEp6r9O9gnZT2_jLPpIn_nGjYp9xgl8hFhg_-fX131_koFcj6znzflexf4-MdfkSTtA060-Hh7RcvVkNkY5kQ-QBulRYDCO1Li1R1jK71G=w1200-h630-n-nu"
  },
  {
    "title": "How the voices for ChatGPT were chosen",
    "description": "How the voices for ChatGPT were chosen We worked with industry-leading casting and directing professionals to narrow down over 400 submissions before selecting the 5 voices.",
    "summary": "How the voices for ChatGPT were chosen We worked with industry-leading casting and directing professionals to narrow down over 400 submissions before selecting the 5 voices.",
    "pubDate": "Sun, 19 May 2024 23:30:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/how-the-voices-for-chatgpt-were-chosen",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Looking ahead to the AI Seoul Summit",
    "description": "How summits in Seoul, France and beyond can galvanize international cooperation on frontier AI safety",
    "summary": "How summits in Seoul, France and beyond can galvanize international cooperation on frontier AI safety",
    "pubDate": "Mon, 20 May 2024 07:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/looking-ahead-to-the-ai-seoul-summit/",
    "thumbnail": "https://lh3.googleusercontent.com/LuT46lyRujmyyTlxwixL9_e8LKvzqZOGUyQUAFbTO6POaYlAqWYfEMag39UkZGsZhjs3SmW3V-s0dCjK4_81jpezAzL7c6kXuTY2MhXbv5yR4NDG8Q=w1200-h630-n-nu"
  },
  {
    "title": "Build AI on premise with Dell Enterprise Hub",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 21 May 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/dell-enterprise-hub",
    "thumbnail": "https://huggingface.co/blog/assets/dell-enterprise-hub/thumbnail.jpg"
  },
  {
    "title": "From cloud to developers: Hugging Face and Microsoft Deepen Collaboration",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 21 May 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/microsoft-collaboration",
    "thumbnail": "https://huggingface.co/blog/assets/microsoft-collaboration/thumbnail.jpg"
  },
  {
    "title": "Hugging Face on AMD Instinct MI300 GPU",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 21 May 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/huggingface-amd-mi300",
    "thumbnail": "https://huggingface.co/blog/assets/optimum_amd/amd_hf_logo_fixed.png"
  },
  {
    "title": "Introducing Spaces Dev Mode for a seamless developer experience",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 21 May 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/spaces-dev-mode",
    "thumbnail": "https://huggingface.co/blog/assets/spaces-dev-mode/thumbnail.jpg"
  },
  {
    "title": "OpenAI safety practices",
    "description": "Artificial general intelligence has the potential to benefit nearly every aspect of our lives—so it must be developed and deployed responsibly.",
    "summary": "Artificial general intelligence has the potential to benefit nearly every aspect of our lives—so it must be developed and deployed responsibly.",
    "pubDate": "Tue, 21 May 2024 06:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-safety-update",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "A landmark multi-year global partnership with News Corp",
    "description": "Companies Join Forces to Enrich OpenAI’s Generative AI Products and Platforms with Premium Journalism",
    "summary": "Companies Join Forces to Enrich OpenAI’s Generative AI Products and Platforms with Premium Journalism",
    "pubDate": "Wed, 22 May 2024 13:15:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/news-corp-and-openai-sign-landmark-multi-year-global-partnership",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Deploy models on AWS Inferentia2 from Hugging Face",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 22 May 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/inferentia-inference-endpoints",
    "thumbnail": "https://huggingface.co/blog/assets/inferentia-inference-endpoints/thumbnail.jpg"
  },
  {
    "title": "CyberSecEval 2 - A Comprehensive Evaluation Framework for Cybersecurity Risks and Capabilities of Large Language Models",
    "description": "",
    "summary": "",
    "pubDate": "Fri, 24 May 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/leaderboard-llamaguard",
    "thumbnail": "https://huggingface.co/blog/assets/leaderboards-on-the-hub/thumbnail_llamaguard.png"
  },
  {
    "title": "Falcon 2: An 11B parameter pretrained language model and VLM, trained on over 5000B tokens tokens and 11 languages",
    "description": "",
    "summary": "",
    "pubDate": "Fri, 24 May 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/falcon2-11b",
    "thumbnail": "https://huggingface.co/blog/assets/179_falcon2-11b/thumbnail.jpg"
  },
  {
    "title": "OpenAI Board Forms Safety and Security Committee",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 28 May 2024 03:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-board-forms-safety-and-security-committee",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Training and Finetuning Embedding Models with Sentence Transformers v3",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 28 May 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/train-sentence-transformers",
    "thumbnail": "https://huggingface.co/blog/assets/train-sentence-transformers/st-hf-thumbnail.png"
  },
  {
    "title": "A Content and Product Partnership with Vox Media",
    "description": "In a multi-faceted agreement, Vox Media’s content will enhance the output of OpenAI’s ChatGPT, and the company will build on OpenAI’s technology to develop products to better serve its audiences and advertisers.",
    "summary": "In a multi-faceted agreement, Vox Media’s content will enhance the output of OpenAI’s ChatGPT, and the company will build on OpenAI’s technology to develop products to better serve its audiences and advertisers.",
    "pubDate": "Wed, 29 May 2024 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/a-content-and-product-partnership-with-vox-media",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Automating customer support agents",
    "description": "MavenAGI is a new software company for the AI era. They recently launched an AI customer service agent, built on the flexibility of GPT-4, which a number of companies like Tripadvisor, Clickup and Rho are already using to save time and better serve their customers.",
    "summary": "MavenAGI is a new software company for the AI era. They recently launched an AI customer service agent, built on the flexibility of GPT-4, which a number of companies like Tripadvisor, Clickup and Rho are already using to save time and better serve their customers.",
    "pubDate": "Wed, 29 May 2024 09:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/mavenagi",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Benchmarking Text Generation Inference",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 29 May 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/tgi-benchmarking",
    "thumbnail": "https://huggingface.co/blog/assets/tgi-benchmarking/tgi-benchmarking-thumbnail.png"
  },
  {
    "title": "Enhancing news in ChatGPT with The Atlantic",
    "description": "The Atlantic is announcing a strategic content and product partnership with OpenAI, which positions The Atlantic as a premium news source within OpenAI. The Atlantic’s articles will be discoverable within OpenAI’s products, including ChatGPT, and as a partner, The Atlantic will help to shape how news is surfaced and presented in future real-time discovery products.",
    "summary": "The Atlantic is announcing a strategic content and product partnership with OpenAI, which positions The Atlantic as a premium news source within OpenAI. The Atlantic’s articles will be discoverable within OpenAI’s products, including ChatGPT, and as a partner, The Atlantic will help to shape how news is surfaced and presented in future real-time discovery products.",
    "pubDate": "Wed, 29 May 2024 07:30:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/enhancing-news-in-chatgpt-with-the-atlantic",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "The Newsroom AI Catalyst: a global program with WAN-IFRA",
    "description": "We’re collaborating with WAN-IFRA, the World Association of News Publishers, to launch a global accelerator program that will assist over 100 news publishers to explore and integrate AI in their newsroom.",
    "summary": "We’re collaborating with WAN-IFRA, the World Association of News Publishers, to launch a global accelerator program that will assist over 100 news publishers to explore and integrate AI in their newsroom.",
    "pubDate": "Wed, 29 May 2024 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/newsroom-ai-catalyst-global-program-with-wan-ifra",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Disrupting deceptive uses of AI by covert influence operations",
    "description": "We’ve terminated accounts linked to covert influence operations; no significant audience increase due to our services.",
    "summary": "We’ve terminated accounts linked to covert influence operations; no significant audience increase due to our services.",
    "pubDate": "Thu, 30 May 2024 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/disrupting-deceptive-uses-of-AI-by-covert-influence-operations",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Introducing OpenAI for Nonprofits",
    "description": "We’re launching a new initiative to enhance the accessibility of our tools for nonprofit organizations, including discounted rates for ChatGPT Team and Enterprise.",
    "summary": "We’re launching a new initiative to enhance the accessibility of our tools for nonprofit organizations, including discounted rates for ChatGPT Team and Enterprise.",
    "pubDate": "Thu, 30 May 2024 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-openai-for-nonprofits",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "OpenAI for Education",
    "description": "An affordable offering for universities to responsibly bring AI to campus.",
    "summary": "An affordable offering for universities to responsibly bring AI to campus.",
    "pubDate": "Thu, 30 May 2024 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-chatgpt-edu",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Space secrets security update",
    "description": "",
    "summary": "",
    "pubDate": "Fri, 31 May 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/space-secrets-disclosure",
    "thumbnail": "https://huggingface.co/blog/assets/space-secrets-security-update/space-secrets-security-update.png"
  },
  {
    "title": "Faster assisted generation support for Intel Gaudi",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 04 Jun 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/assisted-generation-support-gaudi",
    "thumbnail": "https://huggingface.co/blog/assets/assisted-generation-support-gaudi/thumbnail.png"
  },
  {
    "title": "Introducing NPC-Playground, a 3D playground to interact with LLM-powered NPCs",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 05 Jun 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/npc-gigax-cubzh",
    "thumbnail": "https://huggingface.co/blog/assets/181_npc-gigax-cubzh/thumbnail.png"
  },
  {
    "title": "Securing Research Infrastructure for Advanced AI",
    "description": "We outline our architecture that supports the secure training of frontier models.",
    "summary": "We outline our architecture that supports the secure training of frontier models.",
    "pubDate": "Wed, 05 Jun 2024 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/securing-research-infrastructure-for-advanced-ai",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Extracting Concepts from GPT-4",
    "description": "Using new techniques for scaling sparse autoencoders, we automatically identified 16 million patterns in GPT-4's computations.",
    "summary": "Using new techniques for scaling sparse autoencoders, we automatically identified 16 million patterns in GPT-4's computations.",
    "pubDate": "Thu, 06 Jun 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/extracting-concepts-from-gpt-4",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Improving India’s critical care infrastructure",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 06 Jun 2024 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/10bedicu",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Launching the Artificial Analysis Text to Image Leaderboard & Arena",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 06 Jun 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/leaderboard-artificial-analysis2",
    "thumbnail": "https://huggingface.co/blog/assets/leaderboards-on-the-hub/thumbnail_artificialanalysis.png"
  },
  {
    "title": "Expanding on how Voice Engine works and our safety research",
    "description": "Exploring the technology behind our text-to-speech model.",
    "summary": "Exploring the technology behind our text-to-speech model.",
    "pubDate": "Fri, 07 Jun 2024 17:45:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/expanding-on-how-voice-engine-works-and-our-safety-research",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Introducing the Hugging Face Embedding Container for Amazon SageMaker",
    "description": "",
    "summary": "",
    "pubDate": "Fri, 07 Jun 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/sagemaker-huggingface-embedding",
    "thumbnail": "https://huggingface.co/blog/assets/sagemaker-huggingface-embedding/thumbnail.jpg"
  },
  {
    "title": "Making sense of this mess",
    "description": "",
    "summary": "",
    "pubDate": "Fri, 07 Jun 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/transformers-docs-redesign",
    "thumbnail": "https://huggingface.co/blog/assets/transformers-docs-redesign/thumbnail.png"
  },
  {
    "title": "OpenAI and Apple announce partnership",
    "description": "OpenAI and Apple announce partnership to integrate ChatGPT into Apple experiences.",
    "summary": "OpenAI and Apple announce partnership to integrate ChatGPT into Apple experiences.",
    "pubDate": "Mon, 10 Jun 2024 11:55:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-and-apple-announce-partnership",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "OpenAI welcomes Sarah Friar (CFO) and Kevin Weil (CPO)",
    "description": "OpenAI welcomes Sarah Friar (CFO) and Kevin Weil (CPO)",
    "summary": "OpenAI welcomes Sarah Friar (CFO) and Kevin Weil (CPO)",
    "pubDate": "Mon, 10 Jun 2024 10:30:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-welcomes-cfo-cpo",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "🧨 Diffusers welcomes Stable Diffusion 3",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 12 Jun 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/sd3",
    "thumbnail": "https://huggingface.co/blog/assets/sd3/thumbnail.png"
  },
  {
    "title": "Putting RL back in RLHF",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 12 Jun 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/putting_rl_back_in_rlhf_with_rloo",
    "thumbnail": "https://huggingface.co/blog/assets/putting_rl_back_in_rlhf_with_rloo/thumbnail.png"
  },
  {
    "title": "From DeepSpeed to FSDP and Back Again with Hugging Face Accelerate",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 13 Jun 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/deepspeed-to-fsdp-and-back",
    "thumbnail": "https://huggingface.co/blog/assets/deepspeed-to-fsdp-and-back/thumbnail.png"
  },
  {
    "title": "OpenAI appoints Retired U.S. Army General Paul M. Nakasone to Board of Directors",
    "description": "Nakasone brings cybersecurity experience to growing Board of Directors; will join the Board’s Safety and Security Committee",
    "summary": "Nakasone brings cybersecurity experience to growing Board of Directors; will join the Board’s Safety and Security Committee",
    "pubDate": "Thu, 13 Jun 2024 14:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-appoints-retired-us-army-general",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Generating audio for video",
    "description": "Video-to-audio research uses video pixels and text prompts to generate rich soundtracks",
    "summary": "Video-to-audio research uses video pixels and text prompts to generate rich soundtracks",
    "pubDate": "Mon, 17 Jun 2024 16:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/generating-audio-for-video/",
    "thumbnail": "https://lh3.googleusercontent.com/Lzihw4F171DQeSgZ9q0MUONzbt1BkbK1sOgnqvLAV3AUIQQ1UJ4niEXOTgWiiyKZrJaCpE4Q6APwV8RRQj7a86_2yDlbIV6WUzD6S_Gu2mjuZDyVWqo=w1200-h630-n-nu"
  },
  {
    "title": "Using GPT-4o reasoning to transform cancer care",
    "description": "Color Health is working with OpenAI to pioneer a new way of accelerating cancer patients’ access to treatment. Their new Cancer Copilot application uses GPT-4o to identify missing diagnostics and create tailored workup plans, enabling healthcare providers to make evidence-based decisions about cancer screening and treatment.",
    "summary": "Color Health is working with OpenAI to pioneer a new way of accelerating cancer patients’ access to treatment. Their new Cancer Copilot application uses GPT-4o to identify missing diagnostics and create tailored workup plans, enabling healthcare providers to make evidence-based decisions about cancer screening and treatment.",
    "pubDate": "Mon, 17 Jun 2024 04:15:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/color-health",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Achieving 10x growth with agentic sales prospecting",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 18 Jun 2024 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/clay",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "BigCodeBench: Benchmarking Large Language Models on Solving Practical and Challenging Programming Tasks",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 18 Jun 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/leaderboard-bigcodebench",
    "thumbnail": "https://huggingface.co/blog/assets/leaderboards-on-the-hub/thumbnail_bigcode.png"
  },
  {
    "title": "Surging developer productivity with custom GPTs",
    "description": "Paf adopted ChatGPT Enterprise across its entire company, with engineers using custom GPTs on a daily basis to speed up routine development tasks. Paf also integrated ChatGPT Enterprise into the grit:lab coding academy (gritlab.ax), training the next generation of software developers using an AI-augmented, systems-architecture mindset from day one. In addition to the wide range of use cases for developers and grit:lab students, 70% of Paf employees actively use ChatGPT Enterprise, spanning business teams like finance, HR, marketing, and customer support.",
    "summary": "Paf adopted ChatGPT Enterprise across its entire company, with engineers using custom GPTs on a daily basis to speed up routine development tasks. Paf also integrated ChatGPT Enterprise into the grit:lab coding academy (gritlab.ax), training the next generation of software developers using an AI-augmented, systems-architecture mindset from day one. In addition to the wide range of use cases for developers and grit:lab students, 70% of Paf employees actively use ChatGPT Enterprise, spanning business teams like finance, HR, marketing, and customer support.",
    "pubDate": "Tue, 18 Jun 2024 08:45:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/paf",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Going multimodal: How Prezi is leveraging the Hub and the Expert Support Program to accelerate their ML roadmap",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 19 Jun 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/prezi-case-study",
    "thumbnail": "https://huggingface.co/blog/assets/70_sempre_health/thumbnailprezi.jpg"
  },
  {
    "title": "A Holistic Approach to Undesired Content Detection in the Real World",
    "description": "We present a holistic approach to building a robust and useful natural language classification system for real-world content moderation.",
    "summary": "We present a holistic approach to building a robust and useful natural language classification system for real-world content moderation.",
    "pubDate": "Thu, 20 Jun 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/a-holistic-approach-to-undesired-content-detection-in-the-real-world",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Consistency Models",
    "description": "Diffusion models have significantly advanced the fields of image, audio, and video generation, but they depend on an iterative sampling process that causes slow generation.",
    "summary": "Diffusion models have significantly advanced the fields of image, audio, and video generation, but they depend on an iterative sampling process that causes slow generation.",
    "pubDate": "Thu, 20 Jun 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/consistency-models",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Data Is Better Together: A Look Back and Forward",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 20 Jun 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/dibt",
    "thumbnail": "https://huggingface.co/blog/assets/dibt/thumbnail.png"
  },
  {
    "title": "Empowering defenders through our Cybersecurity Grant Program",
    "description": "Highlighting innovative research and AI integration in cybersecurity",
    "summary": "Highlighting innovative research and AI integration in cybersecurity",
    "pubDate": "Thu, 20 Jun 2024 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/empowering-defenders-through-our-cybersecurity-grant-program",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Improved Techniques for Training Consistency Models",
    "description": "Consistency models are a nascent family of generative models that can sample high quality data in one step without the need for adversarial training.",
    "summary": "Consistency models are a nascent family of generative models that can sample high quality data in one step without the need for adversarial training.",
    "pubDate": "Thu, 20 Jun 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/improved-techniques-for-training-consistency-models",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "OpenAI acquires Rockset",
    "description": "OpenAI Acquires Rockset",
    "summary": "OpenAI Acquires Rockset",
    "pubDate": "Fri, 21 Jun 2024 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-acquires-rockset",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Ethics and Society Newsletter #6: Building Better AI: The Importance of Data Quality",
    "description": "",
    "summary": "",
    "pubDate": "Mon, 24 Jun 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/ethics-soc-6",
    "thumbnail": "https://huggingface.co/blog/assets/182_ethics-soc-6/thumbnail.png"
  },
  {
    "title": "Fine-tuning Florence-2 - Microsoft's Cutting-edge Vision Language Models",
    "description": "",
    "summary": "",
    "pubDate": "Mon, 24 Jun 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/finetune-florence2",
    "thumbnail": "https://huggingface.co/blog/assets/182_finetune-florence/thumbnail.png"
  },
  {
    "title": "XLSCOUT Unveils ParaEmbed 2.0: a Powerful Embedding Model Tailored for Patents and IP with Expert Support from Hugging Face",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 25 Jun 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/xlscout-case-study",
    "thumbnail": "https://huggingface.co/blog/assets/xlscout-case-study/thumbnail.png"
  },
  {
    "title": "Finding GPT-4’s mistakes with GPT-4",
    "description": "CriticGPT, a model based on GPT-4, writes critiques of ChatGPT responses to help human trainers spot mistakes during RLHF",
    "summary": "CriticGPT, a model based on GPT-4, writes critiques of ChatGPT responses to help human trainers spot mistakes during RLHF",
    "pubDate": "Thu, 27 Jun 2024 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/finding-gpt4s-mistakes-with-gpt-4",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Strategic Content Partnership with TIME",
    "description": "We’re partnering with TIME and its 101 years of archival content to enhance responses and provide links to stories on Time.com",
    "summary": "We’re partnering with TIME and its 101 years of archival content to enhance responses and provide links to stories on Time.com",
    "pubDate": "Thu, 27 Jun 2024 06:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/strategic-content-partnership-with-time",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Welcome Gemma 2 - Google's new open LLM",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 27 Jun 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/gemma2",
    "thumbnail": "https://huggingface.co/blog/assets/gemma2/thumbnail.jpg"
  },
  {
    "title": "Our Transformers Code Agent beats the GAIA benchmark!",
    "description": "",
    "summary": "",
    "pubDate": "Mon, 01 Jul 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/beating-gaia",
    "thumbnail": "https://huggingface.co/blog/assets/beating-gaia/thumbnail.jpeg"
  },
  {
    "title": "Accelerating Protein Language Model ProtST on Intel Gaudi 2",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 03 Jul 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/intel-protein-language-model-protst",
    "thumbnail": "https://huggingface.co/blog/assets/intel-protein-language-model-protst/01.jpeg"
  },
  {
    "title": "Announcing New Dataset Search Features",
    "description": "",
    "summary": "",
    "pubDate": "Mon, 08 Jul 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/datasets-filters",
    "thumbnail": "https://huggingface.co/blog/assets/datasets-filters/thumbnail.png"
  },
  {
    "title": "Banque des Territoires (CDC Group) x Polyconseil x Hugging Face: Enhancing a Major French Environmental Program with a Sovereign Data Solution",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 09 Jul 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/sovereign-data-solution-case-study",
    "thumbnail": "https://huggingface.co/blog/assets/78_ml_director_insights/cdc_poly_hf.png"
  },
  {
    "title": "Google Cloud TPUs made available to Hugging Face users",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 09 Jul 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/tpu-inference-endpoints-spaces",
    "thumbnail": "https://huggingface.co/blog/assets/tpu-inference-endpoints-spaces/thumbnail.png"
  },
  {
    "title": "Announcing New Hugging Face and KerasHub integration",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 10 Jul 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/keras-hub-integration",
    "thumbnail": "https://huggingface.co/blog/assets/keras-hub-integration/thumbnail.png"
  },
  {
    "title": "Experimenting with Automatic PII Detection on the Hub using Presidio",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 10 Jul 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/presidio-pii-detection",
    "thumbnail": "https://huggingface.co/blog/assets/presidio-pii-detection/thumbnail.png"
  },
  {
    "title": "OpenAI and Los Alamos National Laboratory announce research partnership",
    "description": "OpenAI and Los Alamos National Laboratory are working to develop safety evaluations to assess and measure biological capabilities and risks associated with frontier models.",
    "summary": "OpenAI and Los Alamos National Laboratory are working to develop safety evaluations to assess and measure biological capabilities and risks associated with frontier models.",
    "pubDate": "Wed, 10 Jul 2024 06:30:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-and-los-alamos-national-laboratory-work-together",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Preference Optimization for Vision Language Models",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 10 Jul 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/dpo_vlm",
    "thumbnail": "https://huggingface.co/blog/assets/dpo_vlm/thumbnail.png"
  },
  {
    "title": "How NuminaMath Won the 1st AIMO Progress Prize",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 11 Jul 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/winning-aimo-progress-prize",
    "thumbnail": "https://huggingface.co/blog/assets/winning-aimo-progress-prize/thumbnail.png"
  },
  {
    "title": "How we leveraged distilabel to create an Argilla 2.0 Chatbot",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 16 Jul 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/argilla-chatbot",
    "thumbnail": "https://huggingface.co/blog/assets/argilla-chatbot/thumbnail.png"
  },
  {
    "title": "SmolLM - blazingly fast and remarkably powerful",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 16 Jul 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/smollm",
    "thumbnail": "https://huggingface.co/blog/assets/smollm/banner.png"
  },
  {
    "title": "Prover-Verifier Games improve legibility of language model outputs",
    "description": "desc",
    "summary": "desc",
    "pubDate": "Wed, 17 Jul 2024 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/prover-verifier-games-improve-legibility",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Docmatix - a huge dataset for Document Visual Question Answering",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 18 Jul 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/docmatix",
    "thumbnail": "https://huggingface.co/blog/assets/183_docmatix/thumbnail_new.png"
  },
  {
    "title": "GPT-4o mini: advancing cost-efficient intelligence",
    "description": "Introducing the most cost-efficient small model in the market",
    "summary": "Introducing the most cost-efficient small model in the market",
    "pubDate": "Thu, 18 Jul 2024 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/gpt-4o-mini-advancing-cost-efficient-intelligence",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "New compliance and administrative tools for ChatGPT Enterprise",
    "description": "Compliance API integrations, SCIM, and GPT controls to support compliance programs, data security, and user access at scale",
    "summary": "Compliance API integrations, SCIM, and GPT controls to support compliance programs, data security, and user access at scale",
    "pubDate": "Thu, 18 Jul 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/new-tools-for-chatgpt-enterprise",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "TGI Multi-LoRA: Deploy Once, Serve 30 Models",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 18 Jul 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/multi-lora-serving",
    "thumbnail": "https://huggingface.co/blog/assets/multi-lora-serving/thumbnail.png"
  },
  {
    "title": "Google DeepMind at ICML 2024",
    "description": "Exploring AGI, the challenges of scaling and the future of multimodal generative AI",
    "summary": "Exploring AGI, the challenges of scaling and the future of multimodal generative AI",
    "pubDate": "Fri, 19 Jul 2024 10:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/google-deepmind-at-icml-2024/",
    "thumbnail": "https://lh3.googleusercontent.com/_o0MU47bgKrTJi6uOWhc3BjWOOENkBczD2x5-tK5aMLBcljJnV-N8tZuSVN42C3d1pSWawY6NsGuoj6vvl0xMk4tpWOeUjXwlgFNZSMyJkFJ02xTauk=w1200-h630-n-nu"
  },
  {
    "title": "WWDC 24: Running Mistral 7B with Core ML",
    "description": "",
    "summary": "",
    "pubDate": "Mon, 22 Jul 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/mistral-coreml",
    "thumbnail": "https://huggingface.co/blog/assets/mistral-coreml/thumbnail.png"
  },
  {
    "title": "Llama 3.1 - 405B, 70B & 8B with multilinguality and long context",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 23 Jul 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/llama31",
    "thumbnail": "https://huggingface.co/blog/assets/llama31/thumbnail.jpg"
  },
  {
    "title": "Improving Model Safety Behavior with Rule-Based Rewards",
    "description": "We've developed and applied a new method leveraging Rule-Based Rewards (RBRs) that aligns models to behave safely without extensive human data collection.",
    "summary": "We've developed and applied a new method leveraging Rule-Based Rewards (RBRs) that aligns models to behave safely without extensive human data collection.",
    "pubDate": "Wed, 24 Jul 2024 09:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/improving-model-safety-behavior-with-rule-based-rewards",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "AI achieves silver-medal standard solving International Mathematical Olympiad problems",
    "description": "Breakthrough models AlphaProof and AlphaGeometry 2 solve advanced reasoning problems in mathematics",
    "summary": "Breakthrough models AlphaProof and AlphaGeometry 2 solve advanced reasoning problems in mathematics",
    "pubDate": "Thu, 25 Jul 2024 15:29:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/ai-solves-imo-problems-at-silver-medal-level/",
    "thumbnail": "https://lh3.googleusercontent.com/2A21eFt7wdDrmMzzkenrCTuioLWGFdzU5Ao5dPH9yPtAw6QNHxZcDmoQA2_ZriU2gMjX8mzEOtfPbMCRuL5kVzLoz6efLgqT_foBXU3pxKBXTTOXXpc=w1200-h630-n-nu"
  },
  {
    "title": "LAVE: Zero-shot VQA Evaluation on Docmatix with LLMs - Do We Still Need Fine-Tuning?",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 25 Jul 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/zero-shot-vqa-docmatix",
    "thumbnail": "https://huggingface.co/blog/assets/184_zero_shot_docmatix/thumb.001.jpeg"
  },
  {
    "title": "SearchGPT is a prototype of new AI search features",
    "description": "We’re testing SearchGPT, a temporary prototype of new search features that give you fast and timely answers with clear and relevant sources.",
    "summary": "We’re testing SearchGPT, a temporary prototype of new search features that give you fast and timely answers with clear and relevant sources.",
    "pubDate": "Thu, 25 Jul 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/searchgpt-prototype",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Serverless Inference with Hugging Face and NVIDIA NIMs",
    "description": "",
    "summary": "",
    "pubDate": "Mon, 29 Jul 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/inference-dgx-cloud",
    "thumbnail": "https://huggingface.co/blog/assets/train-dgx-cloud/thumbnail.jpg"
  },
  {
    "title": "A Primer on the EU AI Act: What It Means for AI Providers and Deployers",
    "description": "We’re sharing a preliminary overview of the EU AI Act including upcoming deadlines and requirements, with a particular focus on prohibited and high-risk use cases",
    "summary": "We’re sharing a preliminary overview of the EU AI Act including upcoming deadlines and requirements, with a particular focus on prohibited and high-risk use cases",
    "pubDate": "Tue, 30 Jul 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/global-affairs/a-primer-on-the-eu-ai-act",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Memory-efficient Diffusion Transformers with Quanto and Diffusers",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 30 Jul 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/quanto-diffusers",
    "thumbnail": "https://huggingface.co/blog/assets/quanto-diffusers/thumbnail.png"
  },
  {
    "title": "Gemma Scope: helping the safety community shed light on the inner workings of language models",
    "description": "Announcing a comprehensive, open suite of sparse autoencoders for language model interpretability.",
    "summary": "Announcing a comprehensive, open suite of sparse autoencoders for language model interpretability.",
    "pubDate": "Wed, 31 Jul 2024 15:59:19 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/gemma-scope-helping-the-safety-community-shed-light-on-the-inner-workings-of-language-models/",
    "thumbnail": "https://lh3.googleusercontent.com/4amJbS1Q5bh_CoBHPAc4NEn0Q13izqrskMETkJl3h2Jdku08GryCCjW6BM59OKj1-Q7-8ZFCWlgu7tIMzjRBIXImy8wlgTOxYgJ88fQvYJTye07C=w1200-h630-n-nu"
  },
  {
    "title": "Google releases Gemma 2 2B, ShieldGemma and Gemma Scope",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 31 Jul 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/gemma-july-update",
    "thumbnail": "https://huggingface.co/blog/assets/gemma-july-update/thumbnail.jpg"
  },
  {
    "title": "Mapping the misuse of generative AI",
    "description": "New research analyzes the misuse of multimodal generative AI today, in order to help build safer and more responsible technologies.",
    "summary": "New research analyzes the misuse of multimodal generative AI today, in order to help build safer and more responsible technologies.",
    "pubDate": "Fri, 02 Aug 2024 10:50:58 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/mapping-the-misuse-of-generative-ai/",
    "thumbnail": "https://lh3.googleusercontent.com/IzYg4pdM7_tKoEbQHE4-Em9cvFxbx2Aq4_YOQdLr6VK754c8-bJRW9LWMf1_nUraA5BfNcBjAjpIjcfF1M_qQviR8b7qyRnAiUzapq3LKVbTpoJ8Cw=w1200-h630-n-nu"
  },
  {
    "title": "2024 Security Feature Highlights",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 06 Aug 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/2024-security-features",
    "thumbnail": "https://huggingface.co/blog/assets/2024-security-features/thumbnail.png"
  },
  {
    "title": "Introducing Structured Outputs in the API",
    "description": "We are introducing Structured Outputs in the API—model outputs now reliably adhere to developer-supplied JSON Schemas.",
    "summary": "We are introducing Structured Outputs in the API—model outputs now reliably adhere to developer-supplied JSON Schemas.",
    "pubDate": "Tue, 06 Aug 2024 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-structured-outputs-in-the-api",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Introducing TextImage Augmentation for Document Images",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 06 Aug 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/doc_aug_hf_alb",
    "thumbnail": "https://huggingface.co/blog/assets/185_albumentations/thumbnail.png"
  },
  {
    "title": "Pairing data with APIs to unlock customer value",
    "description": "Rakuten Pairs Data with AI to Unlock Customer Insights and Value",
    "summary": "Rakuten Pairs Data with AI to Unlock Customer Insights and Value",
    "pubDate": "Wed, 07 Aug 2024 16:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/rakuten",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Enabling a Data-Driven Workforce",
    "description": "In this video, we share practical examples of how employees can use ChatGPT Enterprise to efficiently analyze data and uncover insights.",
    "summary": "In this video, we share practical examples of how employees can use ChatGPT Enterprise to efficiently analyze data and uncover insights.",
    "pubDate": "Thu, 08 Aug 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/business/enabling-a-data-driven-workforce-webinar",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "GPT-4o System Card External Testers Acknowledgements",
    "description": "GPT-4o system card external testers acknowledgements",
    "summary": "GPT-4o system card external testers acknowledgements",
    "pubDate": "Thu, 08 Aug 2024 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/gpt-4o-system-card/external-testers-acknowledgements",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "GPT-4o System Card",
    "description": "This report outlines the safety work carried out prior to releasing GPT-4o including external red teaming, frontier risk evaluations according to our Preparedness Framework, and an overview of the mitigations we built in to address key risk areas.",
    "summary": "This report outlines the safety work carried out prior to releasing GPT-4o including external red teaming, frontier risk evaluations according to our Preparedness Framework, and an overview of the mitigations we built in to address key risk areas.",
    "pubDate": "Thu, 08 Aug 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/gpt-4o-system-card",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "XetHub is joining Hugging Face!",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 08 Aug 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/xethub-joins-hf",
    "thumbnail": "https://huggingface.co/blog/assets/xethub-joins-hf/thumbnail.png"
  },
  {
    "title": "Zico Kolter Joins OpenAI’s Board of Directors",
    "description": "Zico Kolter Joins OpenAI’s Board of Directors We’re strengthening our governance with expertise in AI safety and alignment. Zico will also join the Safety & Security Committee",
    "summary": "Zico Kolter Joins OpenAI’s Board of Directors We’re strengthening our governance with expertise in AI safety and alignment. Zico will also join the Safety & Security Committee",
    "pubDate": "Thu, 08 Aug 2024 12:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/zico-kolter-joins-openais-board-of-directors",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Tool Use, Unified",
    "description": "",
    "summary": "",
    "pubDate": "Mon, 12 Aug 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/unified-tool-use",
    "thumbnail": "https://huggingface.co/blog/assets/unified-tool-use/thumbnail.png"
  },
  {
    "title": "Welcome FalconMamba: The first strong attention-free 7B model",
    "description": "",
    "summary": "",
    "pubDate": "Mon, 12 Aug 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/falconmamba",
    "thumbnail": "https://huggingface.co/blog/assets/falconmamba/thumbnail.png"
  },
  {
    "title": "Introducing SWE-bench Verified",
    "description": "We’re releasing a human-validated subset of SWE-bench that more reliably evaluates AI models’ ability to solve real-world software issues.",
    "summary": "We’re releasing a human-validated subset of SWE-bench that more reliably evaluates AI models’ ability to solve real-world software issues.",
    "pubDate": "Tue, 13 Aug 2024 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-swe-bench-verified",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Introduction to ggml",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 13 Aug 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/introduction-to-ggml",
    "thumbnail": "https://huggingface.co/blog/assets/introduction-to-ggml/cover.jpg"
  },
  {
    "title": "A failed experiment: Infini-Attention, and why we should keep trying?",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 14 Aug 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/infini-attention",
    "thumbnail": "https://huggingface.co/blog/infini-attention/assets/185_infini_attention/infini_attention_thumbnail.png"
  },
  {
    "title": "Awakening Sleeping Beauties at The Met",
    "description": "AI can enrich lives through beauty and creativity, and its artistic potential shines in 'Sleeping Beauties: Reawakening Fashion,' a collaborative exhibit from The Met's Costume Institute.",
    "summary": "AI can enrich lives through beauty and creativity, and its artistic potential shines in 'Sleeping Beauties: Reawakening Fashion,' a collaborative exhibit from The Met's Costume Institute.",
    "pubDate": "Wed, 14 Aug 2024 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/the-met-museum",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Delivering contextual job matching for millions with OpenAI",
    "description": "Indeed, whose mission is to help people get jobs, is the world’s #1 job site. Over 350 million unique visitors come to Indeed every month to connect with more than 3.5 million employers and over 32 million jobs. But what’s more is that every three seconds someone gets hired on Indeed.",
    "summary": "Indeed, whose mission is to help people get jobs, is the world’s #1 job site. Over 350 million unique visitors come to Indeed every month to connect with more than 3.5 million employers and over 32 million jobs. But what’s more is that every three seconds someone gets hired on Indeed.",
    "pubDate": "Thu, 15 Aug 2024 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/indeed",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Disrupting a covert Iranian influence operation",
    "description": "We banned accounts linked to a covert Iranian influence operation using ChatGPT to generate website and social media content focused on multiple topics, including the U.S. presidential campaign. We have seen no indication that this content reached a meaningful audience.",
    "summary": "We banned accounts linked to a covert Iranian influence operation using ChatGPT to generate website and social media content focused on multiple topics, including the U.S. presidential campaign. We have seen no indication that this content reached a meaningful audience.",
    "pubDate": "Fri, 16 Aug 2024 11:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/disrupting-a-covert-iranian-influence-operation",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Deploy Meta Llama 3.1 405B on Google Cloud Vertex AI",
    "description": "",
    "summary": "",
    "pubDate": "Mon, 19 Aug 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/llama31-on-vertex-ai",
    "thumbnail": "https://huggingface.co/blog/assets/llama31-on-vertex-ai/thumbnail.png"
  },
  {
    "title": "Fine-tuning now available for GPT-4o",
    "description": "Fine-tune custom versions of GPT-4o to increase performance and accuracy for your applications",
    "summary": "Fine-tune custom versions of GPT-4o to increase performance and accuracy for your applications",
    "pubDate": "Tue, 20 Aug 2024 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/gpt-4o-fine-tuning",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "OpenAI partners with Condé Nast",
    "description": "Condé Nast",
    "summary": "Condé Nast",
    "pubDate": "Tue, 20 Aug 2024 11:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/conde-nast",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Putting AI to work at Upwork",
    "description": "Upwork puts AI to work, uniting team members, operations and product development",
    "summary": "Upwork puts AI to work, uniting team members, operations and product development",
    "pubDate": "Tue, 20 Aug 2024 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/upwork",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Improving Hugging Face Training Efficiency Through Packing with Flash Attention",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 21 Aug 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/packing-with-FA2",
    "thumbnail": "https://huggingface.co/blog/assets/packing-with-FA2/thumbnail.png"
  },
  {
    "title": "FermiNet: Quantum physics and chemistry from first principles",
    "description": "Using deep learning to solve fundamental problems in computational quantum chemistry and explore how matter interacts with light",
    "summary": "Using deep learning to solve fundamental problems in computational quantum chemistry and explore how matter interacts with light",
    "pubDate": "Thu, 22 Aug 2024 19:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/ferminet-quantum-physics-and-chemistry-from-first-principles/",
    "thumbnail": "https://lh3.googleusercontent.com/u-LZOO0ynV2UCorbNrUtWS6MJ_sxTfGzObe2YzBt5Grgohx39WcsGiPNOsHwBja8C51lQBclpaovrzUVVQRzj2WpWeM7f7y5eeYt3Dx6l3gxfx9S9g=w1200-h630-n-nu"
  },
  {
    "title": "The 5 Most Under-Rated Tools on Hugging Face",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 22 Aug 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/unsung-heroes",
    "thumbnail": "https://huggingface.co/blog/assets/unsung-heroes/new-thumbnail.png"
  },
  {
    "title": "Fine-Tuning GPT-4o Webinar",
    "description": "Fine-Tuning GPT-4o Webinar",
    "summary": "Fine-Tuning GPT-4o Webinar",
    "pubDate": "Mon, 26 Aug 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/business/fine-tuning-gpt-4o-webinar",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Personalizing education with ChatGPT",
    "description": "Arizona State University embraces ChatGPT campus-wide to personalize learning, advance research, and prepare students for the future",
    "summary": "Arizona State University embraces ChatGPT campus-wide to personalize learning, advance research, and prepare students for the future",
    "pubDate": "Mon, 26 Aug 2024 04:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/asu",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Scaling robotics datasets with video encoding",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 27 Aug 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/video-encoding",
    "thumbnail": "https://huggingface.co/blog/assets/video-encoding/thumbnail.png"
  },
  {
    "title": "Hugging Face partners with TruffleHog to Scan for Secrets",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 04 Sep 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/trufflesecurity-partnership",
    "thumbnail": "https://huggingface.co/blog/assets/trufflesecurity-partnership/thumbnail.png"
  },
  {
    "title": "AlphaProteo generates novel proteins for biology and health research",
    "description": "New AI system designs proteins that successfully bind to target molecules, with potential for advancing drug design, disease understanding and more.",
    "summary": "New AI system designs proteins that successfully bind to target molecules, with potential for advancing drug design, disease understanding and more.",
    "pubDate": "Thu, 05 Sep 2024 15:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/alphaproteo-generates-novel-proteins-for-biology-and-health-research/",
    "thumbnail": "https://lh3.googleusercontent.com/7RKd6r-Wc8JfMau5x9knRq9DrOKGDwS3ye4YxY0jjWGntf74y8WL0lOlktJefxwkJYw33UEf2Ph_BhQ51TIufCxPkmtCPOpakekMpnOUwVI-3R6RzQ=w1200-h630-n-nu"
  },
  {
    "title": "Using GPT-4 to deliver a new customer service standard",
    "description": "Ada uses GPT-4 to deliver a new customer service standard",
    "summary": "Ada uses GPT-4 to deliver a new customer service standard",
    "pubDate": "Thu, 05 Sep 2024 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/ada",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Put AI to Work: Lessons from Hundreds of Successful Deployments",
    "description": "Put AI to Work: Lessons from Hundreds of Successful Deployments",
    "summary": "Put AI to Work: Lessons from Hundreds of Successful Deployments",
    "pubDate": "Tue, 10 Sep 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/business/put-ai-to-work-lessons-from-hundreds-of-successful-deployments",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Answering quantum physics questions with OpenAI o1",
    "description": "Quantum physicist Mario Krenn uses OpenAI o1 to help answer life's biggest questions.",
    "summary": "Quantum physicist Mario Krenn uses OpenAI o1 to help answer life's biggest questions.",
    "pubDate": "Thu, 12 Sep 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/o1-quantum-physics",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Coding with OpenAI o1",
    "description": "Scott Wu, CEO and Co-Founder of Cognition, explains how OpenAI o1 makes coding decisions in a more human-like way.",
    "summary": "Scott Wu, CEO and Co-Founder of Cognition, explains how OpenAI o1 makes coding decisions in a more human-like way.",
    "pubDate": "Thu, 12 Sep 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/o1-coding",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Decoding genetics with OpenAI o1",
    "description": "Geneticist Catherine Brownstein demonstrates how OpenAI o1 can speed up the process of diagnosing rare medical challenges.",
    "summary": "Geneticist Catherine Brownstein demonstrates how OpenAI o1 can speed up the process of diagnosing rare medical challenges.",
    "pubDate": "Thu, 12 Sep 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/o1-genetics",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Economics and reasoning with OpenAI o1",
    "description": "Economist Tyler Cowen explains how OpenAI o1 tackles complex economic questions.",
    "summary": "Economist Tyler Cowen explains how OpenAI o1 tackles complex economic questions.",
    "pubDate": "Thu, 12 Sep 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/o1-economics",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Introducing OpenAI o1",
    "description": "Introducing OpenAI o1",
    "summary": "Introducing OpenAI o1",
    "pubDate": "Thu, 12 Sep 2024 10:03:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-openai-o1-preview",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Learning to reason with LLMs",
    "description": "We are introducing OpenAI o1, a new large language model trained with reinforcement learning to perform complex reasoning. o1 thinks before it answers—it can produce a long internal chain of thought before responding to the user.",
    "summary": "We are introducing OpenAI o1, a new large language model trained with reinforcement learning to perform complex reasoning. o1 thinks before it answers—it can produce a long internal chain of thought before responding to the user.",
    "pubDate": "Thu, 12 Sep 2024 10:02:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/learning-to-reason-with-llms",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "OpenAI o1 Contributions",
    "description": "OpenAI o1 Contributions",
    "summary": "OpenAI o1 Contributions",
    "pubDate": "Thu, 12 Sep 2024 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/openai-o1-contributions",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "OpenAI o1-mini",
    "description": "Advancing cost-efficient reasoning",
    "summary": "Advancing cost-efficient reasoning",
    "pubDate": "Thu, 12 Sep 2024 10:01:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-o1-mini-advancing-cost-efficient-reasoning",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "OpenAI o1 System Card External Testers Acknowledgements",
    "description": "OpenAI o1 system card external testers acknowledgements",
    "summary": "OpenAI o1 system card external testers acknowledgements",
    "pubDate": "Thu, 12 Sep 2024 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-o1-system-card/external-testers-acknowledgements",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Our latest advances in robot dexterity",
    "description": "Two new AI systems, ALOHA Unleashed and DemoStart, help robots learn to perform complex tasks that require dexterous movement",
    "summary": "Two new AI systems, ALOHA Unleashed and DemoStart, help robots learn to perform complex tasks that require dexterous movement",
    "pubDate": "Thu, 12 Sep 2024 14:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/advances-in-robot-dexterity/",
    "thumbnail": "https://lh3.googleusercontent.com/63ROjLq4VNqk3RDA5vl1mYS1i5xvcgU8-augVWQY5OZCtVsm_e4YX8rR4_DLUlQiTmMHT6qx3p9shUtPGUHy_4SA64RDeMghvk0eDKT6Fqh6-P3d4A=w1200-h630-n-nu"
  },
  {
    "title": "Accelerate 1.0.0",
    "description": "",
    "summary": "",
    "pubDate": "Fri, 13 Sep 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/accelerate-v1",
    "thumbnail": "https://huggingface.co/blog/assets/186_accelerate_v1/accelerate_v1_thumbnail.png"
  },
  {
    "title": "An update on our safety & security practices",
    "description": "An update on our safety & security practices",
    "summary": "An update on our safety & security practices",
    "pubDate": "Mon, 16 Sep 2024 13:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/update-on-safety-and-security-practices",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Introducing Community Tools on HuggingChat",
    "description": "",
    "summary": "",
    "pubDate": "Mon, 16 Sep 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/community-tools",
    "thumbnail": "https://huggingface.co/blog/assets/community-tools/thumbnail.png"
  },
  {
    "title": "Introducing the SQL Console on Datasets",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 17 Sep 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/sql-console",
    "thumbnail": "https://huggingface.co/blog/assets/sql_console/thumbnail.png"
  },
  {
    "title": "Using GPT-4 to improve teaching and learning in Brazil",
    "description": "Improving teaching and learning in Brazil",
    "summary": "Improving teaching and learning in Brazil",
    "pubDate": "Tue, 17 Sep 2024 05:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/arco-education",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Empowering YouTube creators with generative AI",
    "description": "New video generation technology in YouTube Shorts will help millions of people realize their creative vision",
    "summary": "New video generation technology in YouTube Shorts will help millions of people realize their creative vision",
    "pubDate": "Wed, 18 Sep 2024 14:30:06 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/empowering-youtube-creators-with-generative-ai/",
    "thumbnail": "https://lh3.googleusercontent.com/Q8qBc1kzbYeksHRjsSuR7HEvezKsw3n1fxYlOqLf2sslqDOqYXJOhxyjznZ4cyq1fwNhpyMTMXW0RRrgHweVg6NaCEPnt3ujcFAIe0bVXK_sHka7cLo=w1200-h630-n-nu"
  },
  {
    "title": "Fine-tuning LLMs to 1.58bit: extreme quantization made easy",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 18 Sep 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/1_58_llm_extreme_quantization",
    "thumbnail": "https://huggingface.co/blog/assets/1_58_llm_extreme_quantization/thumbnail.png"
  },
  {
    "title": "Genmab launches “AI Everywhere”",
    "description": "Genmab embraces ChatGPT Enterprise, supported by OpenAI’s commitment to security and privacy",
    "summary": "Genmab embraces ChatGPT Enterprise, supported by OpenAI’s commitment to security and privacy",
    "pubDate": "Thu, 19 Sep 2024 04:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/genmab",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Optimize and deploy models with Optimum-Intel and OpenVINO GenAI",
    "description": "",
    "summary": "",
    "pubDate": "Fri, 20 Sep 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/deploy-with-openvino",
    "thumbnail": "https://huggingface.co/front/thumbnails/v2-2.png"
  },
  {
    "title": "Exploring the Daily Papers Page on Hugging Face",
    "description": "",
    "summary": "",
    "pubDate": "Mon, 23 Sep 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/daily-papers",
    "thumbnail": "https://huggingface.co/blog/assets/daily-papers/thumbnail.png"
  },
  {
    "title": "FineVideo: behind the scenes",
    "description": "",
    "summary": "",
    "pubDate": "Mon, 23 Sep 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/fine-video",
    "thumbnail": "https://huggingface.co/blog/assets/186_fine_video/thumbnail.png"
  },
  {
    "title": "Introducing the OpenAI Academy",
    "description": "New initiative will fuel innovation by investing in developers and organizations leveraging AI, starting in low- and middle-income countries.",
    "summary": "New initiative will fuel innovation by investing in developers and organizations leveraging AI, starting in low- and middle-income countries.",
    "pubDate": "Mon, 23 Sep 2024 03:30:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/global-affairs/openai-academy",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Introducing Verdi, an AI dev platform powered by GPT-4o",
    "description": "Mercado Libre introduces Verdi, an AI developer platform powered by GPT-4o",
    "summary": "Mercado Libre introduces Verdi, an AI developer platform powered by GPT-4o",
    "pubDate": "Tue, 24 Sep 2024 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/mercado-libre",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Updated production-ready Gemini models, reduced 1.5 Pro pricing, increased rate limits, and more",
    "description": "We’re releasing two updated production-ready Gemini models",
    "summary": "We’re releasing two updated production-ready Gemini models",
    "pubDate": "Tue, 24 Sep 2024 16:03:03 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/updated-production-ready-gemini-models-reduced-15-pro-pricing-increased-rate-limits-and-more/",
    "thumbnail": "https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/Gemini-15-Flash-Social_1.2e16d0ba.fill-1200x600.png"
  },
  {
    "title": "Llama can now see and run on your device - welcome Llama 3.2",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 25 Sep 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/llama32",
    "thumbnail": "https://huggingface.co/blog/assets/llama32/thumbnail.jpg"
  },
  {
    "title": "How AlphaChip transformed computer chip design",
    "description": "Our AI method has accelerated and optimized chip design, and its superhuman chip layouts are used in hardware around the world.",
    "summary": "Our AI method has accelerated and optimized chip design, and its superhuman chip layouts are used in hardware around the world.",
    "pubDate": "Thu, 26 Sep 2024 14:08:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/how-alphachip-transformed-computer-chip-design/",
    "thumbnail": "https://lh3.googleusercontent.com/Y_xdq8eqcQlZXYk-MZ2OWPpppmWG6LAQ8DZ-LZFUh8TV5s2TBb3RK_VkMUe-skRzIop5aP6Ot9xPMWFaWmenz55EwxVFCMszpTg2EzsyOd6ftlllGyE=w1200-h630-n-nu"
  },
  {
    "title": "Minnesota’s Enterprise Translation Office uses ChatGPT to bridge language gaps",
    "description": "Minnesota’s Enterprise Translation Office uses ChatGPT to bridge language gaps",
    "summary": "Minnesota’s Enterprise Translation Office uses ChatGPT to bridge language gaps",
    "pubDate": "Thu, 26 Sep 2024 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/state-of-minnesota",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "OpenAI and GEDI partner for Italian news content",
    "description": "OpenAI and GEDI announce strategic partnership to bring Italian-language news content to ChatGPT.",
    "summary": "OpenAI and GEDI announce strategic partnership to bring Italian-language news content to ChatGPT.",
    "pubDate": "Thu, 26 Sep 2024 04:30:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/gedi",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Upgrading the Moderation API with our new multimodal moderation model",
    "description": "We’re introducing a new model built on GPT-4o that is more accurate at detecting harmful text and images, enabling developers to build more robust moderation systems.",
    "summary": "We’re introducing a new model built on GPT-4o that is more accurate at detecting harmful text and images, enabling developers to build more robust moderation systems.",
    "pubDate": "Thu, 26 Sep 2024 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/upgrading-the-moderation-api-with-our-new-multimodal-moderation-model",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Converting Vertex-Colored Meshes to Textured Meshes",
    "description": "",
    "summary": "",
    "pubDate": "Mon, 30 Sep 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/vertex-colored-to-textured-mesh",
    "thumbnail": "https://huggingface.co/blog/assets/vertex-colored-to-textured-mesh/thumbnail.png"
  },
  {
    "title": "Put AI to work: Automate and Scale Financial Operations",
    "description": "Put AI to work: Automate and Scale Financial Operations",
    "summary": "Put AI to work: Automate and Scale Financial Operations",
    "pubDate": "Mon, 30 Sep 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/business/put-ai-to-work-automate-and-scale-financial-operations",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "🇨🇿 BenCzechMark - Can your LLM Understand Czech?",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 01 Oct 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/benczechmark",
    "thumbnail": "https://huggingface.co/blog/assets/187_benczechmark/thumbnail.png"
  },
  {
    "title": "Creating agent and human collaboration with GPT 4o",
    "description": "Altera uses GPT-4o to build a new area of human collaboration",
    "summary": "Altera uses GPT-4o to build a new area of human collaboration",
    "pubDate": "Tue, 01 Oct 2024 09:59:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/altera",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Introducing the Realtime API",
    "description": "Developers can now build fast speech-to-speech experiences into their applications",
    "summary": "Developers can now build fast speech-to-speech experiences into their applications",
    "pubDate": "Tue, 01 Oct 2024 10:05:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-the-realtime-api",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Introducing vision to the fine-tuning API",
    "description": "Developers can now fine-tune GPT-4o with images and text to improve vision capabilities",
    "summary": "Developers can now fine-tune GPT-4o with images and text to improve vision capabilities",
    "pubDate": "Tue, 01 Oct 2024 10:04:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-vision-to-the-fine-tuning-api",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Model Distillation in the API",
    "description": "Fine-tune a cost-efficient model with the outputs of a large frontier model–all on the OpenAI platform",
    "summary": "Fine-tune a cost-efficient model with the outputs of a large frontier model–all on the OpenAI platform",
    "pubDate": "Tue, 01 Oct 2024 10:02:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/api-model-distillation",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Prompt Caching in the API",
    "description": "Offering automatic discounts on inputs that the model has recently seen",
    "summary": "Offering automatic discounts on inputs that the model has recently seen",
    "pubDate": "Tue, 01 Oct 2024 10:03:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/api-prompt-caching",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "New funding to scale the benefits of AI",
    "description": "We are making progress on our mission to ensure that artificial general intelligence benefits all of humanity.",
    "summary": "We are making progress on our mission to ensure that artificial general intelligence benefits all of humanity.",
    "pubDate": "Wed, 02 Oct 2024 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/scale-the-benefits-of-ai",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "A Short Summary of Chinese AI Global Expansion",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 03 Oct 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/chinese-ai-expansion",
    "thumbnail": "https://huggingface.co/blog/assets/chinese-ai-expansion/thumbnail.png"
  },
  {
    "title": "Introducing canvas, a new way to write and code with ChatGPT.",
    "description": "Introducing canvas",
    "summary": "Introducing canvas",
    "pubDate": "Thu, 03 Oct 2024 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-canvas",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "New Credit Facility Enhances Financial Flexibility",
    "description": "In addition to securing $6.6 billion in new funding from leading investors, we have established a new $4 billion credit facility with leading banks, including JPMorgan Chase, Citi, Goldman Sachs, Morgan Stanley, Santander, Wells Fargo, SMBC, UBS, and HSBC.",
    "summary": "In addition to securing $6.6 billion in new funding from leading investors, we have established a new $4 billion credit facility with leading banks, including JPMorgan Chase, Citi, Goldman Sachs, Morgan Stanley, Santander, Wells Fargo, SMBC, UBS, and HSBC.",
    "pubDate": "Thu, 03 Oct 2024 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/new-credit-facility-enhances-financial-flexibility",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Introducing the Open FinLLM Leaderboard",
    "description": "",
    "summary": "",
    "pubDate": "Fri, 04 Oct 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/leaderboard-finbench",
    "thumbnail": "https://huggingface.co/blog/assets/leaderboards-on-the-hub/thumbnail_finbench.png"
  },
  {
    "title": "OpenAI’s Raising Concerns Policy",
    "description": "We’re publishing our Raising Concerns Policy, which protects employees’ rights to make protected disclosures.",
    "summary": "We’re publishing our Raising Concerns Policy, which protects employees’ rights to make protected disclosures.",
    "pubDate": "Fri, 04 Oct 2024 12:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-raising-concerns-policy",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Improving Parquet Dedupe on Hugging Face Hub",
    "description": "",
    "summary": "",
    "pubDate": "Sat, 05 Oct 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/improve_parquet_dedupe",
    "thumbnail": "https://huggingface.co/blog/assets/improve_parquet_dedupe/thumbnail.png"
  },
  {
    "title": "Faster Assisted Generation with Dynamic Speculation",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 08 Oct 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/dynamic_speculation_lookahead",
    "thumbnail": "https://huggingface.co/blog/assets/optimum_intel/intel_thumbnail.png"
  },
  {
    "title": "OpenAI and Hearst Content Partnership",
    "description": "Hearst’s iconic brands bring curated lifestyle and local news content to OpenAI’s products.",
    "summary": "Hearst’s iconic brands bring curated lifestyle and local news content to OpenAI’s products.",
    "pubDate": "Tue, 08 Oct 2024 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/hearst",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "An update on disrupting deceptive uses of AI",
    "description": "OpenAI’s mission is to ensure that artificial general intelligence benefits all of humanity. We are dedicated to identifying, preventing, and disrupting attempts to abuse our models for harmful ends.",
    "summary": "OpenAI’s mission is to ensure that artificial general intelligence benefits all of humanity. We are dedicated to identifying, preventing, and disrupting attempts to abuse our models for harmful ends.",
    "pubDate": "Wed, 09 Oct 2024 03:30:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/global-affairs/an-update-on-disrupting-deceptive-uses-of-ai",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Demis Hassabis & John Jumper awarded Nobel Prize in Chemistry",
    "description": "The award recognizes their work developing AlphaFold, a groundbreaking AI system that predicts the 3D structure of proteins from their amino acid sequences.",
    "summary": "The award recognizes their work developing AlphaFold, a groundbreaking AI system that predicts the 3D structure of proteins from their amino acid sequences.",
    "pubDate": "Wed, 09 Oct 2024 11:45:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/demis-hassabis-john-jumper-awarded-nobel-prize-in-chemistry/",
    "thumbnail": "https://lh3.googleusercontent.com/7ZdZh5xhoD5NnykRBJHACxkxc3VubCdJLGHty2nYdJ36pBLVxRWO3Keu9C2Tum4OHCyGbJ5K5mB8R_oR94JG700qenuZ2rhq2sKjN4IkjIoU9Chv=w1200-h630-n-nu"
  },
  {
    "title": "Scaling AI-based Data Processing with Hugging Face + Dask",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 09 Oct 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/dask-scaling",
    "thumbnail": "https://huggingface.co/blog/assets/dask-scaling/thumbnail.png"
  },
  {
    "title": "Welcome, Gradio 5",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 09 Oct 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/gradio-5",
    "thumbnail": "https://huggingface.co/blog/assets/gradio-5/thumbnail.png"
  },
  {
    "title": "A Security Review of Gradio 5",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 10 Oct 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/gradio-5-security",
    "thumbnail": "https://huggingface.co/blog/assets/gradio-5-security/thumbnail.png"
  },
  {
    "title": "Introducing the AMD 5th Gen EPYC™ CPU",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 10 Oct 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/huggingface-amd-turin",
    "thumbnail": "https://huggingface.co/blog/assets/optimum_amd/amd_hf_logo_fixed.png"
  },
  {
    "title": "MLE-bench: Evaluating Machine Learning Agents on Machine Learning Engineering",
    "description": "We introduce MLE-bench, a benchmark for measuring how well AI agents perform at machine learning engineering.",
    "summary": "We introduce MLE-bench, a benchmark for measuring how well AI agents perform at machine learning engineering.",
    "pubDate": "Thu, 10 Oct 2024 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/mle-bench",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Evaluating fairness in ChatGPT",
    "description": "We've analyzed how ChatGPT responds to users based on their name, using AI research assistants to protect privacy.",
    "summary": "We've analyzed how ChatGPT responds to users based on their name, using AI research assistants to protect privacy.",
    "pubDate": "Tue, 15 Oct 2024 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/evaluating-fairness-in-chatgpt",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Fixing Gradient Accumulation",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 16 Oct 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/gradient_accumulation",
    "thumbnail": "https://huggingface.co/blog/assets/gradient_accumulation/gradient_accumulation.png"
  },
  {
    "title": "Solving complex problems with OpenAI o1 models",
    "description": "In this video, we share how the o1 reasoning models can help in domains like coding, strategy, and research.",
    "summary": "In this video, we share how the o1 reasoning models can help in domains like coding, strategy, and research.",
    "pubDate": "Thu, 17 Oct 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/business/solving-complex-problems-with-openai-o1-models",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Llama 3.2 in Keras",
    "description": "",
    "summary": "",
    "pubDate": "Mon, 21 Oct 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/keras-llama-32",
    "thumbnail": "https://huggingface.co/blog/assets/keras_llama_32/thumbnail.jpg"
  },
  {
    "title": "Deploying Speech-to-Speech on Hugging Face",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 22 Oct 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/s2s_endpoint",
    "thumbnail": "https://huggingface.co/blog/assets/s2s_endpoint/thumbnail.png"
  },
  {
    "title": "🧨 Diffusers welcomes Stable Diffusion 3.5 Large",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 22 Oct 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/sd3-5",
    "thumbnail": "https://huggingface.co/blog/assets/sd3-5/thumbnail.png"
  },
  {
    "title": "Dr. Ronnie Chatterji named OpenAI’s first Chief Economist",
    "description": "Dr. Ronnie Chatterji named OpenAI’s first Chief Economist",
    "summary": "Dr. Ronnie Chatterji named OpenAI’s first Chief Economist",
    "pubDate": "Tue, 22 Oct 2024 10:05:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/global-affairs/openai-chief-economist-announcement",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Hugging Face Teams Up with Protect AI: Enhancing Model Security for the Community",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 22 Oct 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/protectai",
    "thumbnail": "https://huggingface.co/blog/assets/protectai/thumbnail.png"
  },
  {
    "title": "OpenAI and the Lenfest Institute AI Collaborative and Fellowship program",
    "description": "OpenAI and the Lenfest Institute AI Collaborative and Fellowship program",
    "summary": "OpenAI and the Lenfest Institute AI Collaborative and Fellowship program",
    "pubDate": "Tue, 22 Oct 2024 06:05:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/lenfest-institute",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "OpenAI appoints Scott Schools as Chief Compliance Officer",
    "description": "OpenAI appoints Scott Schools as Chief Compliance Officer",
    "summary": "OpenAI appoints Scott Schools as Chief Compliance Officer",
    "pubDate": "Tue, 22 Oct 2024 10:30:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/global-affairs/openai-chief-compliance-officer-announcement",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Releasing Outlines-core 0.1.0: structured generation in Rust and Python",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 22 Oct 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/outlines-core",
    "thumbnail": "https://huggingface.co/blog/assets/outlines-core/thumbnail.gif"
  },
  {
    "title": "Transformers.js v3: WebGPU support, new models & tasks, and more…",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 22 Oct 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/transformersjs-v3",
    "thumbnail": "https://huggingface.co/blog/assets/transformersjs-v3/thumbnail.png"
  },
  {
    "title": "CinePile 2.0 - making stronger datasets with adversarial refinement",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 23 Oct 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/cinepile2",
    "thumbnail": "https://huggingface.co/blog/assets/188_cinepile2/thumbnail.png"
  },
  {
    "title": "Introducing HUGS - Scale your AI with Open Models",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 23 Oct 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/hugs",
    "thumbnail": "https://huggingface.co/blog/assets/hugs/thumbnail.jpg"
  },
  {
    "title": "Introducing SynthID Text",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 23 Oct 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/synthid-text",
    "thumbnail": "https://huggingface.co/blog/assets/synthid-text/thumbnail.png"
  },
  {
    "title": "New generative AI tools open the doors of music creation",
    "description": "Our latest AI music technologies are now available in MusicFX DJ, Music AI Sandbox and YouTube Shorts",
    "summary": "Our latest AI music technologies are now available in MusicFX DJ, Music AI Sandbox and YouTube Shorts",
    "pubDate": "Wed, 23 Oct 2024 16:53:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/new-generative-ai-tools-open-the-doors-of-music-creation/",
    "thumbnail": "https://lh3.googleusercontent.com/7CWJ9fVeC97FrWgcispxyms9gTL_1PIDMIwBYTQNnU8S56JaxGB2Z4ThqZ-1vBTO-u-UBZg_cYhG8PtZjYP0rPabUbg5x2cCUnNJuiZAZBsE8u7Kvig=w1200-h630-n-nu"
  },
  {
    "title": "Simplifying, stabilizing, and scaling continuous-time consistency models",
    "description": "We’ve simplified, stabilized, and scaled continuous-time consistency models, achieving comparable sample quality to leading diffusion models, while using only two sampling steps.",
    "summary": "We’ve simplified, stabilized, and scaled continuous-time consistency models, achieving comparable sample quality to leading diffusion models, while using only two sampling steps.",
    "pubDate": "Wed, 23 Oct 2024 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/simplifying-stabilizing-and-scaling-continuous-time-consistency-models",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "A Deepdive into Aya Expanse: Advancing the Frontier of Multilinguality",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 24 Oct 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/aya-expanse",
    "thumbnail": "https://huggingface.co/blog/assets/aya-expanse/thumbnail.jpg"
  },
  {
    "title": "OpenAI’s approach to AI and national security",
    "description": "OpenAI’s approach to AI and national security",
    "summary": "OpenAI’s approach to AI and national security",
    "pubDate": "Thu, 24 Oct 2024 14:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/global-affairs/openais-approach-to-ai-and-national-security",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Expert Support case study: Bolstering a RAG app with LLM-as-a-Judge",
    "description": "",
    "summary": "",
    "pubDate": "Mon, 28 Oct 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/digital-green-llm-judge",
    "thumbnail": "https://huggingface.co/blog/assets/digital-gren-llm-judge/thumbnail.png"
  },
  {
    "title": "Delivering high-performance customer support",
    "description": "Decagon and OpenAI deliver high-performance, fully automated customer support at scale",
    "summary": "Decagon and OpenAI deliver high-performance, fully automated customer support at scale",
    "pubDate": "Tue, 29 Oct 2024 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/decagon",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Universal Assisted Generation: Faster Decoding with Any Assistant Model",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 29 Oct 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/universal_assisted_generation",
    "thumbnail": "https://huggingface.co/blog/assets/optimum_intel/intel_thumbnail.png"
  },
  {
    "title": "Introducing SimpleQA",
    "description": "A factuality benchmark called SimpleQA that measures the ability for language models to answer short, fact-seeking questions.",
    "summary": "A factuality benchmark called SimpleQA that measures the ability for language models to answer short, fact-seeking questions.",
    "pubDate": "Wed, 30 Oct 2024 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-simpleqa",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Pushing the frontiers of audio generation",
    "description": "Our pioneering speech generation technologies are helping people around the world interact with more natural, conversational and intuitive digital assistants and AI tools.",
    "summary": "Our pioneering speech generation technologies are helping people around the world interact with more natural, conversational and intuitive digital assistants and AI tools.",
    "pubDate": "Wed, 30 Oct 2024 15:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/pushing-the-frontiers-of-audio-generation/",
    "thumbnail": "https://lh3.googleusercontent.com/wyFc1lo4ByOJsbbSt1NEwBiSi3KpImyqA9ukx-mLxJROIakSxhPwk-kPtlIfFKX9Txm2J_lbpIvnrDhFnegrpN8ihlvYpBTsFNAmOlq0C2rm_gef=w1200-h630-n-nu"
  },
  {
    "title": "Introducing ChatGPT search",
    "description": "Get fast, timely answers with links to relevant web sources",
    "summary": "Get fast, timely answers with links to relevant web sources",
    "pubDate": "Thu, 31 Oct 2024 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-chatgpt-search",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Promega’s top-down adoption of ChatGPT accelerates manufacturing, sales, and marketing",
    "description": "Promega's top-down adoption of ChatGPT accelerates manufacturing, sales, and marketing",
    "summary": "Promega's top-down adoption of ChatGPT accelerates manufacturing, sales, and marketing",
    "pubDate": "Thu, 31 Oct 2024 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/promega",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Put AI to Work for Marketing Teams",
    "description": "Put AI to Work for Marketing Teams",
    "summary": "Put AI to Work for Marketing Teams",
    "pubDate": "Thu, 31 Oct 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/business/put-ai-to-work-for-marketing-teams",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Argilla 2.4: Easily Build Fine-Tuning and Evaluation datasets on the Hub — No Code Required",
    "description": "",
    "summary": "",
    "pubDate": "Mon, 04 Nov 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/argilla-ui-hub",
    "thumbnail": "https://huggingface.co/blog/assets/argilla-ui-hub/thumbnail.png"
  },
  {
    "title": "OpenAI’s comments to the NTIA on data center growth, resilience, and security",
    "description": "This comment was submitted in response to a request for information from the National Telecommunications and Information Administration (NTIA).",
    "summary": "This comment was submitted in response to a request for information from the National Telecommunications and Information Administration (NTIA).",
    "pubDate": "Mon, 04 Nov 2024 12:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/global-affairs/comments-to-the-ntia-on-data-center-growth-resilience-and-security",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Hugging Face + PyCharm",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 05 Nov 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/pycharm-integration",
    "thumbnail": "https://huggingface.co/blog/assets/pycharm-integration/thumbnail.png"
  },
  {
    "title": "Share your open ML datasets on Hugging Face Hub!",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 12 Nov 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/researcher-dataset-sharing",
    "thumbnail": "https://huggingface.co/blog/assets/researcher-dataset-sharing/thumbnail.png"
  },
  {
    "title": "A Student’s Guide to Writing with ChatGPT",
    "description": "A Student’s Guide to Writing with ChatGPT",
    "summary": "A Student’s Guide to Writing with ChatGPT",
    "pubDate": "Wed, 13 Nov 2024 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/chatgpt/use-cases/student-writing-guide",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Data-driven beauty and creativity with ChatGPT",
    "description": "Data-driven beauty: How The Estée Lauder Companies unlocks insights with ChatGPT",
    "summary": "Data-driven beauty: How The Estée Lauder Companies unlocks insights with ChatGPT",
    "pubDate": "Wed, 13 Nov 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/estee-lauder",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "OpenAI en France",
    "description": "Our first office in continental Europe",
    "summary": "Our first office in continental Europe",
    "pubDate": "Fri, 15 Nov 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-en-france",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "The AI for Science Forum: A new era of discovery",
    "description": "The AI Science Forum highlights AI's present and potential role in revolutionizing scientific discovery and solving global challenges, emphasizing collaboration between the scientific community, policymakers, and industry leaders.",
    "summary": "The AI Science Forum highlights AI's present and potential role in revolutionizing scientific discovery and solving global challenges, emphasizing collaboration between the scientific community, policymakers, and industry leaders.",
    "pubDate": "Mon, 18 Nov 2024 19:57:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/the-ai-for-science-forum-a-new-era-of-discovery/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/AIFS_Collection_SS.max-1440x810.jpg"
  },
  {
    "title": "Judge Arena: Benchmarking LLMs as Evaluators",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 19 Nov 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/arena-atla",
    "thumbnail": "https://huggingface.co/blog/assets/arenas-on-the-hub/thumbnail_atla.png"
  },
  {
    "title": "Rox goes “all in” on OpenAI",
    "description": "By combining commercial experience and deep LLM expertise with OpenAI’s models, Rox makes every seller a top 1% seller.",
    "summary": "By combining commercial experience and deep LLM expertise with OpenAI’s models, Rox makes every seller a top 1% seller.",
    "pubDate": "Tue, 19 Nov 2024 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/rox",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "AlphaQubit tackles one of quantum computing’s biggest challenges",
    "description": "Our new AI system accurately identifies errors inside quantum computers, helping to make this new technology more reliable.",
    "summary": "Our new AI system accurately identifies errors inside quantum computers, helping to make this new technology more reliable.",
    "pubDate": "Wed, 20 Nov 2024 18:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/alphaqubit-tackles-one-of-quantum-computings-biggest-challenges/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Social_Share_Image_-_1920_x_1080.width-1300.png"
  },
  {
    "title": "Building smarter maps with GPT-4o vision fine-tuning",
    "description": "Building smarter maps with GPT-4o vision fine-tuning",
    "summary": "Building smarter maps with GPT-4o vision fine-tuning",
    "pubDate": "Wed, 20 Nov 2024 17:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/grab",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Faster Text Generation with Self-Speculative Decoding",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 20 Nov 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/layerskip",
    "thumbnail": "https://huggingface.co/blog/assets/layerskip/thumbnail.png"
  },
  {
    "title": "From Files to Chunks: Improving Hugging Face Storage Efficiency",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 20 Nov 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/from-files-to-chunks",
    "thumbnail": "https://huggingface.co/blog/assets/from-files-to-chunks/thumbnail.png"
  },
  {
    "title": "Introduction to the Open Leaderboard for Japanese LLMs",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 20 Nov 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/leaderboard-japanese",
    "thumbnail": "https://huggingface.co/blog/assets/leaderboards-on-the-hub/thumbnail_japanese.png"
  },
  {
    "title": "Letting Large Models Debate: The First Multilingual LLM Debate Competition",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 20 Nov 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/debate",
    "thumbnail": "https://huggingface.co/front/thumbnails/v2-2.png"
  },
  {
    "title": "Advancing red teaming with people and AI",
    "description": "Advancing red teaming with people and AI",
    "summary": "Advancing red teaming with people and AI",
    "pubDate": "Thu, 21 Nov 2024 10:30:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/advancing-red-teaming-with-people-and-ai",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Empowering a global org with ChatGPT",
    "description": "Empowering a global org with ChatGPT",
    "summary": "Empowering a global org with ChatGPT",
    "pubDate": "Thu, 21 Nov 2024 05:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/bbva",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "You could have designed state of the art positional encoding",
    "description": "",
    "summary": "",
    "pubDate": "Mon, 25 Nov 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/designing-positional-encoding",
    "thumbnail": "https://huggingface.co/blog/assets/designing-positional-encoding/thumbnail_posenc.png"
  },
  {
    "title": "Rearchitecting Hugging Face Uploads and Downloads",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 26 Nov 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/rearchitecting-uploads-and-downloads",
    "thumbnail": "https://huggingface.co/blog/assets/rearchitecting-uploads-and-downloads/thumbnail.png"
  },
  {
    "title": "SmolVLM - small yet mighty Vision Language Model",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 26 Nov 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/smolvlm",
    "thumbnail": "https://huggingface.co/blog/assets/smolvlm/banner.png"
  },
  {
    "title": "Open Source Developers Guide to the EU AI Act",
    "description": "",
    "summary": "",
    "pubDate": "Mon, 02 Dec 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/eu-ai-act-for-oss-developers",
    "thumbnail": "https://huggingface.co/blog/assets/189_eu-ai-act-for-oss-developers/thumbnail.png"
  },
  {
    "title": "Investing in Performance: Fine-tune small models with LLM insights  - a CFM case study",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 03 Dec 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/cfm-case-study",
    "thumbnail": "https://huggingface.co/blog/assets/cfm-case-study/blogpost_cfm.png"
  },
  {
    "title": "GenCast predicts weather and the risks of extreme conditions with state-of-the-art accuracy",
    "description": "New AI model advances the prediction of weather uncertainties and risks, delivering faster, more accurate forecasts up to 15 days ahead",
    "summary": "New AI model advances the prediction of weather uncertainties and risks, delivering faster, more accurate forecasts up to 15 days ahead",
    "pubDate": "Wed, 04 Dec 2024 15:59:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/gencast-predicts-weather-and-the-risks-of-extreme-conditions-with-sota-accuracy/",
    "thumbnail": "https://lh3.googleusercontent.com/4u3n6FBe0eE86yXgppDN_yj_AkiCF5FaSToa8f3Mh5bFWzIH01ewGN737emoYKcGXLxQagYFMxi9j-cAZyAzkdFndCDg2ne9E42w4YZD7HyBChaf=w1200-h630-n-nu"
  },
  {
    "title": "Genie 2: A large-scale foundation world model",
    "description": "Generating unlimited diverse training environments for future general agents",
    "summary": "Generating unlimited diverse training environments for future general agents",
    "pubDate": "Wed, 04 Dec 2024 14:23:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/genie-2-a-large-scale-foundation-world-model/",
    "thumbnail": "https://lh3.googleusercontent.com/wvcJdqh_wddVc-WiMGgcqe7nWp7Ybu0wd-PBDxC_VUQkfxI7HPfQz3fi_HyYTOoRM_XV3Bofp9l1wBZ1CJPZPG6yZMdZxqH8X7_Lb9nhVAquAul1=w1200-h630-n-nu"
  },
  {
    "title": "OpenAI and Future partner on specialist content",
    "description": "OpenAI and Future, the global platform for specialist media, have today announced a strategic partnership to bring content from Future’s 200 plus media brands to OpenAI’s users.",
    "summary": "OpenAI and Future, the global platform for specialist media, have today announced a strategic partnership to bring content from Future’s 200 plus media brands to OpenAI’s users.",
    "pubDate": "Wed, 04 Dec 2024 23:30:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-and-future-partner-on-specialist-content",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Rethinking LLM Evaluation with 3C3H: AraGen Benchmark and Leaderboard",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 04 Dec 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/leaderboard-3c3h-aragen",
    "thumbnail": "https://huggingface.co/blog/assets/leaderboards-on-the-hub/thumbnail_3c3h_aragen.png"
  },
  {
    "title": "Shaping the future of financial services",
    "description": "Morgan Stanley uses AI evals to shape the future of financial services",
    "summary": "Morgan Stanley uses AI evals to shape the future of financial services",
    "pubDate": "Wed, 04 Dec 2024 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/morgan-stanley",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Google DeepMind at NeurIPS 2024",
    "description": "Advancing adaptive AI agents, empowering 3D scene creation, and innovating LLM training for a smarter, safer future",
    "summary": "Advancing adaptive AI agents, empowering 3D scene creation, and innovating LLM training for a smarter, safer future",
    "pubDate": "Thu, 05 Dec 2024 17:45:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/google-deepmind-at-neurips-2024/",
    "thumbnail": "https://lh3.googleusercontent.com/cKpWE16vpsZ21VcH-_SdGF8tQEeEMp2phWFajdBq_A7aMVS2axiXQzd7V8mlHdJm-CXVKh1IaY3yeM_lAwu_zxc6SIBdWahdN6nYoaQqUbC8uU0qoY8=w1200-h630-n-nu"
  },
  {
    "title": "How good are LLMs at fixing their mistakes? A chatbot arena experiment with Keras and TPUs",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 05 Dec 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/keras-chatbot-arena",
    "thumbnail": "https://huggingface.co/blog/assets/keras-chatbot-arena/thumbnail.png"
  },
  {
    "title": "Introducing ChatGPT Pro",
    "description": "Broadening usage of frontier AI",
    "summary": "Broadening usage of frontier AI",
    "pubDate": "Thu, 05 Dec 2024 10:30:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-chatgpt-pro",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "OpenAI o1 System Card",
    "description": "This report outlines the safety work carried out prior to releasing OpenAI o1 and o1-mini, including external red teaming and frontier risk evaluations according to our Preparedness Framework.",
    "summary": "This report outlines the safety work carried out prior to releasing OpenAI o1 and o1-mini, including external red teaming and frontier risk evaluations according to our Preparedness Framework.",
    "pubDate": "Thu, 05 Dec 2024 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-o1-system-card",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Welcome PaliGemma 2 – New vision language models by Google",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 05 Dec 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/paligemma2",
    "thumbnail": "https://huggingface.co/blog/assets/paligemma/Paligemma2.png"
  },
  {
    "title": "Animator Lyndon Barrois creates new worlds with Sora",
    "description": "Filmmaker Lyndon Barrois describes how to use Sora as a storytelling tool.",
    "summary": "Filmmaker Lyndon Barrois describes how to use Sora as a storytelling tool.",
    "pubDate": "Mon, 09 Dec 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/sora-lyndon-barrois",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Hugging Face models in Amazon Bedrock",
    "description": "",
    "summary": "",
    "pubDate": "Mon, 09 Dec 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/bedrock-marketplace",
    "thumbnail": "https://huggingface.co/blog/assets/bedrock-marketplace/thumbnail.png"
  },
  {
    "title": "Minne Atairu & Sora",
    "description": "Interdisciplinary artist Minne Atairu discusses how Sora helps realize her vision.",
    "summary": "Interdisciplinary artist Minne Atairu discusses how Sora helps realize her vision.",
    "pubDate": "Mon, 09 Dec 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/sora-minne-atairu",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Open Preference Dataset for Text-to-Image Generation by the 🤗 Community",
    "description": "",
    "summary": "",
    "pubDate": "Mon, 09 Dec 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/image-preferences",
    "thumbnail": "https://huggingface.co/blog/assets/image_preferences/thumbnail.png"
  },
  {
    "title": "Put AI to work for your product team",
    "description": "Put AI to work for your product team",
    "summary": "Put AI to work for your product team",
    "pubDate": "Mon, 09 Dec 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/put-ai-to-work-for-your-product-team",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Sora is here",
    "description": "Our video generation model, Sora, is now available to use at sora.com. Users can generate videos up to 1080p resolution, up to 20 sec long, and in widescreen, vertical or square aspect ratios. You can bring your own assets to extend, remix, and blend, or generate entirely new content from text.",
    "summary": "Our video generation model, Sora, is now available to use at sora.com. Users can generate videos up to 1080p resolution, up to 20 sec long, and in widescreen, vertical or square aspect ratios. You can bring your own assets to extend, remix, and blend, or generate entirely new content from text.",
    "pubDate": "Mon, 09 Dec 2024 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/sora-is-here",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Sora System Card",
    "description": "Sora is OpenAI’s video generation model, designed to take text, image, and video inputs and generate a new video as an output. Sora builds on learnings from DALL-E and GPT models, and is designed to give people expanded tools for storytelling and creative expression.",
    "summary": "Sora is OpenAI’s video generation model, designed to take text, image, and video inputs and generate a new video as an output. Sora builds on learnings from DALL-E and GPT models, and is designed to give people expanded tools for storytelling and creative expression.",
    "pubDate": "Mon, 09 Dec 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/sora-system-card",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Vallée Duhamel & Sora",
    "description": "Filmmaking duo Vallée Duhamel explains how Sora helps build new worlds.",
    "summary": "Filmmaking duo Vallée Duhamel explains how Sora helps build new worlds.",
    "pubDate": "Mon, 09 Dec 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/sora-vallee-duhamel",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "LeMaterial: an open source initiative to accelerate materials discovery and research",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 10 Dec 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/lematerial",
    "thumbnail": "https://huggingface.co/blog/assets/lematerial/thumbnail_lematerial.png"
  },
  {
    "title": "Boosting the customer retail experience with GPT-4o mini",
    "description": "Zalando boosts the customer experience with its Assistant, powered by GPT-4o mini",
    "summary": "Zalando boosts the customer experience with its Assistant, powered by GPT-4o mini",
    "pubDate": "Wed, 11 Dec 2024 06:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/zalando",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Introducing Gemini 2.0: our new AI model for the agentic era",
    "description": "Today, we’re announcing Gemini 2.0, our most capable multimodal AI model yet.",
    "summary": "Today, we’re announcing Gemini 2.0, our most capable multimodal AI model yet.",
    "pubDate": "Wed, 11 Dec 2024 15:30:40 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/introducing-gemini-20-our-new-ai-model-for-the-agentic-era/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/blog_gemini_hero_thumbnail.width-1300.png"
  },
  {
    "title": "Elon Musk wanted an OpenAI for-profit",
    "description": "Elon Musk’s latest legal filing against OpenAI marks his fourth attempt in less than a year to reframe his claims. However, his own words and actions speak for themselves—in 2017, Elon not only wanted, but actually created, a for-profit as OpenAI’s proposed new structure.",
    "summary": "Elon Musk’s latest legal filing against OpenAI marks his fourth attempt in less than a year to reframe his claims. However, his own words and actions speak for themselves—in 2017, Elon not only wanted, but actually created, a for-profit as OpenAI’s proposed new structure.",
    "pubDate": "Fri, 13 Dec 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/elon-musk-wanted-an-openai-for-profit",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Introducing the Synthetic Data Generator - Build Datasets with Natural Language",
    "description": "",
    "summary": "",
    "pubDate": "Mon, 16 Dec 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/synthetic-data-generator",
    "thumbnail": "https://huggingface.co/blog/assets/synthetic-data-generator/_thumbnail.png"
  },
  {
    "title": "State-of-the-art video and image generation with Veo 2 and Imagen 3",
    "description": "We’re rolling out a new, state-of-the-art video model, Veo 2, and updates to Imagen 3. Plus, check out our new experiment, Whisk.",
    "summary": "We’re rolling out a new, state-of-the-art video model, Veo 2, and updates to Imagen 3. Plus, check out our new experiment, Whisk.",
    "pubDate": "Mon, 16 Dec 2024 17:01:16 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/state-of-the-art-video-and-image-generation-with-veo-2-and-imagen-3/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/12-16-24_GenMedia_16x9.width-1300.png"
  },
  {
    "title": "Benchmarking Language Model Performance on 5th Gen Xeon at GCP",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 17 Dec 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/intel-gcp-c4",
    "thumbnail": "https://huggingface.co/blog/assets/optimum_intel/intel_thumbnail.png"
  },
  {
    "title": "FACTS Grounding: A new benchmark for evaluating the factuality of large language models",
    "description": "Our comprehensive benchmark and online leaderboard offer a much-needed measure of how accurately LLMs ground their responses in provided source material and avoid hallucinations",
    "summary": "Our comprehensive benchmark and online leaderboard offer a much-needed measure of how accurately LLMs ground their responses in provided source material and avoid hallucinations",
    "pubDate": "Tue, 17 Dec 2024 15:29:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/facts-grounding-a-new-benchmark-for-evaluating-the-factuality-of-large-language-models/",
    "thumbnail": "https://lh3.googleusercontent.com/PNlhxhf4LKLRCezIt7Ap358F91-vbK5dLp56Ak1FejpCZh3YTp6jGqIDJm9c0iAtx8Y73MCTu279c1k2GZkM2qXXaqx315NSOaSiU0y0ATMK2c2Hyw=w1200-h630-n-nu"
  },
  {
    "title": "OpenAI o1 and new tools for developers",
    "description": "Introducing OpenAI o1, Realtime API improvements, a new fine-tuning method and more for developers.",
    "summary": "Introducing OpenAI o1, Realtime API improvements, a new fine-tuning method and more for developers.",
    "pubDate": "Tue, 17 Dec 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/o1-and-new-tools-for-developers",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Welcome the Falcon 3 Family of Open Models!",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 17 Dec 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/falcon3",
    "thumbnail": "https://huggingface.co/blog/assets/falcon3/thumbnail.png"
  },
  {
    "title": "Bamba: Inference-Efficient Hybrid Mamba2 Model",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 18 Dec 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/bamba",
    "thumbnail": "https://huggingface.co/blog/assets/bamba/bamba_thumbnail.png"
  },
  {
    "title": "Finally, a Replacement for BERT: Introducing ModernBERT",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 19 Dec 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/modernbert",
    "thumbnail": "https://huggingface.co/blog/assets/modernbert/thumbnail.png"
  },
  {
    "title": "Deliberative alignment: reasoning enables safer language models",
    "description": "Deliberative alignment: reasoning enables safer language models Introducing our new alignment strategy for o1 models, which are directly taught safety specifications and how to reason over them.",
    "summary": "Deliberative alignment: reasoning enables safer language models Introducing our new alignment strategy for o1 models, which are directly taught safety specifications and how to reason over them.",
    "pubDate": "Fri, 20 Dec 2024 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/deliberative-alignment",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Evaluating Audio Reasoning with Big Bench Audio",
    "description": "",
    "summary": "",
    "pubDate": "Fri, 20 Dec 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/big-bench-audio-release",
    "thumbnail": "https://huggingface.co/blog/assets/big_bench_audio_release/big-bench-audio-thumbnail.png"
  },
  {
    "title": "Controlling Language Model Generation with NVIDIA's LogitsProcessorZoo",
    "description": "",
    "summary": "",
    "pubDate": "Mon, 23 Dec 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/logits-processor-zoo",
    "thumbnail": "https://huggingface.co/blog/assets/logits-processor-zoo/thumbnail.png"
  },
  {
    "title": "Visualize and understand GPU memory in PyTorch",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 24 Dec 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/train_memory",
    "thumbnail": "https://huggingface.co/blog/assets/train_memory/thumbnail.png"
  },
  {
    "title": "Why OpenAI’s structure must evolve to advance our mission",
    "description": "A stronger non-profit supported by the for-profit’s success.",
    "summary": "A stronger non-profit supported by the for-profit’s success.",
    "pubDate": "Fri, 27 Dec 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/why-our-structure-must-evolve-to-advance-our-mission",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Introducing smolagents: simple agents that write actions in code.",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 31 Dec 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/smolagents",
    "thumbnail": "https://huggingface.co/blog/assets/smolagents/thumbnail.png"
  },
  {
    "title": "CO₂ Emissions and Models Performance: Insights from the Open LLM Leaderboard",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 09 Jan 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/leaderboard-emissions-analysis",
    "thumbnail": "https://huggingface.co/blog/assets/evaluating-mmlu-leaderboard/thumbnail.png"
  },
  {
    "title": "Visual Document Retrieval Goes Multilingual",
    "description": "",
    "summary": "",
    "pubDate": "Fri, 10 Jan 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/vdr-2b-multilingual",
    "thumbnail": "https://huggingface.co/blog/assets/vdr-2b-multilingual/thumbnail.png"
  },
  {
    "title": "AI Agents Are Here. What Now?",
    "description": "",
    "summary": "",
    "pubDate": "Mon, 13 Jan 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/ethics-soc-7",
    "thumbnail": "https://huggingface.co/blog/assets/190_ethics-soc-7/thumbnail.png"
  },
  {
    "title": "OpenAI’s Economic Blueprint",
    "description": "OpenAI’s Economic Blueprint",
    "summary": "OpenAI’s Economic Blueprint",
    "pubDate": "Mon, 13 Jan 2025 03:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/global-affairs/openais-economic-blueprint",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Adebayo Ogunlesi joins OpenAI’s Board of Directors",
    "description": "Adebayo Ogunlesi Joins OpenAI’s Board of Directors",
    "summary": "Adebayo Ogunlesi Joins OpenAI’s Board of Directors",
    "pubDate": "Tue, 14 Jan 2025 09:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/adebayo-ogunlesi-joins-openais-board-of-directors",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Partnering with Axios expands OpenAI’s work with the news industry",
    "description": "Publishers representing hundreds of newsrooms and content brands are using OpenAI partnerships and grant programs to adopt AI tools and strengthen the news ecosystem, while ChatGPT users gain access to information from leading, reliable publications.",
    "summary": "Publishers representing hundreds of newsrooms and content brands are using OpenAI partnerships and grant programs to adopt AI tools and strengthen the news ecosystem, while ChatGPT users gain access to information from leading, reliable publications.",
    "pubDate": "Wed, 15 Jan 2025 03:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/partnering-with-axios-expands-openai-work-with-the-news-industry",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Train 400x faster Static Embedding Models with Sentence Transformers",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 15 Jan 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/static-embeddings",
    "thumbnail": "https://huggingface.co/blog/assets/train-sentence-transformers/st-hf-thumbnail.png"
  },
  {
    "title": "Introducing multi-backends (TRT-LLM, vLLM) support for Text Generation Inference",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 16 Jan 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/tgi-multi-backend",
    "thumbnail": "https://huggingface.co/blog/assets/tgi-multi-backend/thumbnail.png"
  },
  {
    "title": "Timm ❤️ Transformers: Use any timm model with transformers",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 16 Jan 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/timm-transformers",
    "thumbnail": "https://huggingface.co/blog/assets/timm-transformers/thumbnail.png"
  },
  {
    "title": "The power of personalized AI",
    "description": "The power of personalized AI",
    "summary": "The power of personalized AI",
    "pubDate": "Fri, 17 Jan 2025 13:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/global-affairs/the-power-of-personalized-ai",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Announcing The Stargate Project",
    "description": "Announcing The Stargate Project",
    "summary": "Announcing The Stargate Project",
    "pubDate": "Tue, 21 Jan 2025 13:30:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/announcing-the-stargate-project",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Stargate Infrastructure",
    "description": "OpenAI, and our strategic partners, are thrilled about our shared vision for the Infrastructure of AGI. We are energized by the challenges we face and are excited by the prospect of partnering with firms across the industrial base to deliver against our ambitious mission. Specifically, we want to connect with firms across the built data center infrastructure landscape, from power and land to construction to equipment, and everything in between.",
    "summary": "OpenAI, and our strategic partners, are thrilled about our shared vision for the Infrastructure of AGI. We are energized by the challenges we face and are excited by the prospect of partnering with firms across the industrial base to deliver against our ambitious mission. Specifically, we want to connect with firms across the built data center infrastructure landscape, from power and land to construction to equipment, and everything in between.",
    "pubDate": "Tue, 21 Jan 2025 13:30:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/form/stargate-infrastructure",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Bertelsmann powers creativity and productivity with OpenAI",
    "description": "Bertelsmann, the global media, services, and education company headquartered in Germany, will integrate OpenAI’s technology across multiple brands around the world.",
    "summary": "Bertelsmann, the global media, services, and education company headquartered in Germany, will integrate OpenAI’s technology across multiple brands around the world.",
    "pubDate": "Wed, 22 Jan 2025 17:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/bertelsmann-powers-creativity-and-productivity-with-openai",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Hugging Face and FriendliAI partner to supercharge model deployment on the Hub",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 22 Jan 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/friendliai-partnership",
    "thumbnail": "https://huggingface.co/blog/assets/friendliai-partnership/thumbnail.png"
  },
  {
    "title": "Trading inference-time compute for adversarial robustness",
    "description": "Trading Inference-Time Compute for Adversarial Robustness",
    "summary": "Trading Inference-Time Compute for Adversarial Robustness",
    "pubDate": "Wed, 22 Jan 2025 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/trading-inference-time-compute-for-adversarial-robustness",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Computer-Using Agent",
    "description": "A universal interface for AI to interact with the digital world.",
    "summary": "A universal interface for AI to interact with the digital world.",
    "pubDate": "Thu, 23 Jan 2025 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/computer-using-agent",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Introducing Operator",
    "description": "A research preview of an agent that can use its own browser to perform tasks for you. Available to Pro users in the U.S.",
    "summary": "A research preview of an agent that can use its own browser to perform tasks for you. Available to Pro users in the U.S.",
    "pubDate": "Thu, 23 Jan 2025 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-operator",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Operator System Card",
    "description": "Drawing from OpenAI’s established safety frameworks, this document highlights our multi-layered approach, including model and product mitigations we’ve implemented to protect against prompt engineering and jailbreaks, protect privacy and security, as well as details our external red teaming efforts, safety evaluations, and ongoing work to further refine these safeguards.",
    "summary": "Drawing from OpenAI’s established safety frameworks, this document highlights our multi-layered approach, including model and product mitigations we’ve implemented to protect against prompt engineering and jailbreaks, protect privacy and security, as well as details our external red teaming efforts, safety evaluations, and ongoing work to further refine these safeguards.",
    "pubDate": "Thu, 23 Jan 2025 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/operator-system-card",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "SmolVLM Grows Smaller – Introducing the 250M & 500M Models!",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 23 Jan 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/smolervlm",
    "thumbnail": "https://huggingface.co/blog/assets/smolervlm/banner.png"
  },
  {
    "title": "We now support VLMs in smolagents!",
    "description": "",
    "summary": "",
    "pubDate": "Fri, 24 Jan 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/smolagents-can-see",
    "thumbnail": "https://huggingface.co/blog/assets/smolagents-can-see/thumbnail.png"
  },
  {
    "title": "State of open video generation models in Diffusers",
    "description": "",
    "summary": "",
    "pubDate": "Mon, 27 Jan 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/video_gen",
    "thumbnail": "https://huggingface.co/blog/assets/video_gen/thumbnail.png"
  },
  {
    "title": "Introducing ChatGPT Gov",
    "description": "ChatGPT Gov is designed to streamline government agencies’ access to OpenAI’s frontier models.",
    "summary": "ChatGPT Gov is designed to streamline government agencies’ access to OpenAI’s frontier models.",
    "pubDate": "Tue, 28 Jan 2025 06:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/global-affairs/introducing-chatgpt-gov",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Open-R1: a fully open reproduction of DeepSeek-R1",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 28 Jan 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/open-r1",
    "thumbnail": "https://huggingface.co/blog/assets/open-r1/thumbnails.png"
  },
  {
    "title": "Welcome to Inference Providers on the Hub 🔥",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 28 Jan 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/inference-providers",
    "thumbnail": "https://huggingface.co/blog/assets/inference-providers/thumbnail.png"
  },
  {
    "title": "How to deploy and fine-tune DeepSeek models on AWS",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 30 Jan 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/deepseek-r1-aws",
    "thumbnail": "https://huggingface.co/blog/assets/deepseek-r1-aws/thumbnail.png"
  },
  {
    "title": "Strengthening America’s AI leadership with the U.S. National Laboratories",
    "description": "OpenAI’s latest line of reasoning models will be used by nation’s leading scientists to drive scientific breakthroughs.",
    "summary": "OpenAI’s latest line of reasoning models will be used by nation’s leading scientists to drive scientific breakthroughs.",
    "pubDate": "Thu, 30 Jan 2025 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/strengthening-americas-ai-leadership-with-the-us-national-laboratories",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "OpenAI o3-mini System Card",
    "description": "This report outlines the safety work carried out for the OpenAI o3-mini model, including safety evaluations, external red teaming, and Preparedness Framework evaluations.",
    "summary": "This report outlines the safety work carried out for the OpenAI o3-mini model, including safety evaluations, external red teaming, and Preparedness Framework evaluations.",
    "pubDate": "Fri, 31 Jan 2025 11:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/o3-mini-system-card",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "OpenAI o3-mini",
    "description": "Pushing the frontier of cost-effective reasoning.",
    "summary": "Pushing the frontier of cost-effective reasoning.",
    "pubDate": "Fri, 31 Jan 2025 11:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-o3-mini",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "The AI tools for Art Newsletter - Issue 1",
    "description": "",
    "summary": "",
    "pubDate": "Fri, 31 Jan 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/ai-art-newsletter-jan-25",
    "thumbnail": "https://huggingface.co/blog/assets/ai_art_newsletter_1/thumbnail.png"
  },
  {
    "title": "Introducing deep research",
    "description": "An agent that uses reasoning to synthesize large amounts of online information and complete multi-step research tasks for you. Available to Pro users today, Plus and Team next.",
    "summary": "An agent that uses reasoning to synthesize large amounts of online information and complete multi-step research tasks for you. Available to Pro users today, Plus and Team next.",
    "pubDate": "Sun, 02 Feb 2025 16:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-deep-research",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Understanding complex trends with deep research",
    "description": "How OpenAI deep research helps Bain & Company understand complex industry trends.",
    "summary": "How OpenAI deep research helps Bain & Company understand complex industry trends.",
    "pubDate": "Sun, 02 Feb 2025 16:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/deep-research",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Building a custom math tutor powered by ChatGPT",
    "description": "ChatGPT and personal tutoring",
    "summary": "ChatGPT and personal tutoring",
    "pubDate": "Tue, 04 Feb 2025 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/my-dog-the-math-tutor",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Catching halibut with ChatGPT",
    "description": "Using ChatGPT to catch halibut",
    "summary": "Using ChatGPT to catch halibut",
    "pubDate": "Tue, 04 Feb 2025 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/fishing-for-first-timers",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Creating nail art with ChatGPT",
    "description": "Using ChatGPT to find inspiration for nail art",
    "summary": "Using ChatGPT to find inspiration for nail art",
    "pubDate": "Tue, 04 Feb 2025 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/ten-tiny-canvases",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "DABStep: Data Agent Benchmark for Multi-step Reasoning",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 04 Feb 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/dabstep",
    "thumbnail": "https://huggingface.co/blog/assets/dabstep/thumbnail.png"
  },
  {
    "title": "Open-source DeepResearch – Freeing our search agents",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 04 Feb 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/open-deep-research",
    "thumbnail": "https://huggingface.co/blog/assets/open-deep-research/thumbnail.png"
  },
  {
    "title": "OpenAI and the CSU system bring AI to 500,000 students & faculty",
    "description": "The largest deployment of ChatGPT to date will expand the use of AI in education and help the United States build an AI-ready workforce.",
    "summary": "The largest deployment of ChatGPT to date will expand the use of AI in education and help the United States build an AI-ready workforce.",
    "pubDate": "Tue, 04 Feb 2025 11:30:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-and-the-csu-system",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Updating the Frontier Safety Framework",
    "description": "Our next iteration of the FSF sets out stronger security protocols on the path to AGI",
    "summary": "Our next iteration of the FSF sets out stronger security protocols on the path to AGI",
    "pubDate": "Tue, 04 Feb 2025 16:41:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/updating-the-frontier-safety-framework/",
    "thumbnail": "https://lh3.googleusercontent.com/0fu18H8X3miSAuwcVJ7Zulis_LZAL7F4bIFU7FYFA2dGx3Rm3HHlm5N202B0dtKBuS7iI5SD1QgpFPuU-O3TPzb7iG1Ns-loZzinRB3M3X3W-MAgIQ=w1200-h630-n-nu"
  },
  {
    "title": "π0 and π0-FAST: Vision-Language-Action Models for General Robot Control",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 04 Feb 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/pi0",
    "thumbnail": "https://huggingface.co/blog/assets/192_pi0/new_thumbnail_pi0.001.png"
  },
  {
    "title": "Gemini 2.0 is now available to everyone",
    "description": "We’re announcing new updates to Gemini 2.0 Flash, plus introducing Gemini 2.0 Flash-Lite and Gemini 2.0 Pro Experimental.",
    "summary": "We’re announcing new updates to Gemini 2.0 Flash, plus introducing Gemini 2.0 Flash-Lite and Gemini 2.0 Pro Experimental.",
    "pubDate": "Wed, 05 Feb 2025 16:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/gemini-2-0-is-now-available-to-everyone/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/gemini_28.01.25_keyword_social.width-1300.png"
  },
  {
    "title": "Introducing data residency in Europe",
    "description": "Data residency builds on OpenAI’s enterprise-grade data privacy, security, and compliance programs supporting customers worldwide.",
    "summary": "Data residency builds on OpenAI’s enterprise-grade data privacy, security, and compliance programs supporting customers worldwide.",
    "pubDate": "Wed, 05 Feb 2025 22:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-data-residency-in-europe",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "OpenAI at the Paris AI Action Summit",
    "description": "OpenAI looks forward to engaging with global leaders on AI’s role in shaping innovation and economic prosperity.",
    "summary": "OpenAI looks forward to engaging with global leaders on AI’s role in shaping innovation and economic prosperity.",
    "pubDate": "Fri, 07 Feb 2025 17:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/global-affairs/openai-at-the-paris-ai-action-summit",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Introducing the Intelligence Age",
    "description": "We aired our first-ever television ad during the Super Bowl to pique people’s curiosity and help us all realize how AI can open up new possibilities for us, create more fulfillment in our lives, and make us more productive, just as all the tools that came before AI did for those who came before us.",
    "summary": "We aired our first-ever television ad during the Super Bowl to pique people’s curiosity and help us all realize how AI can open up new possibilities for us, create more fulfillment in our lives, and make us more productive, just as all the tools that came before AI did for those who came before us.",
    "pubDate": "Sun, 09 Feb 2025 22:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/global-affairs/introducing-the-intelligence-age",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "OpenAI partners with Schibsted Media Group",
    "description": "OpenAI and Schibsted Media Group announce content partnership to bring Guardian news and archive content to  ChatGPT.",
    "summary": "OpenAI and Schibsted Media Group announce content partnership to bring Guardian news and archive content to  ChatGPT.",
    "pubDate": "Mon, 10 Feb 2025 06:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-partners-with-schibsted-media-group",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "The Open Arabic LLM Leaderboard 2",
    "description": "",
    "summary": "",
    "pubDate": "Mon, 10 Feb 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/leaderboard-arabic-v2",
    "thumbnail": "https://huggingface.co/blog/assets/leaderboards-on-the-hub/thumbnail_arabic.png"
  },
  {
    "title": "Build awesome datasets for video generation",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 12 Feb 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/vid_ds_scripts",
    "thumbnail": "https://huggingface.co/blog/assets/vid_ds_scripts/thumbnail.png"
  },
  {
    "title": "From Chunks to Blocks: Accelerating Uploads and Downloads on the Hub",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 12 Feb 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/from-chunks-to-blocks",
    "thumbnail": "https://huggingface.co/blog/assets/from-chunks-to-blocks/thumbnail.png"
  },
  {
    "title": "Sharing the latest Model Spec",
    "description": "We’ve made updates to the Model Spec based on external feedback and our continued research in shaping desired model behavior.",
    "summary": "We’ve made updates to the Model Spec based on external feedback and our continued research in shaping desired model behavior.",
    "pubDate": "Wed, 12 Feb 2025 13:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/sharing-the-latest-model-spec",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "1 Billion Classifications",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 13 Feb 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/billion-classifications",
    "thumbnail": "https://huggingface.co/blog/assets/billion-classifications/billion-classifications-thumbnail.png"
  },
  {
    "title": "Fanatics Betting and Gaming uses AI to focus on the big picture",
    "description": "A conversation with Andrea Ellis, Chief Financial Officer of Fanatics Betting and Gaming.",
    "summary": "A conversation with Andrea Ellis, Chief Financial Officer of Fanatics Betting and Gaming.",
    "pubDate": "Thu, 13 Feb 2025 10:01:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/fanatics-betting-gaming-andrea-ellis",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Using OpenAI o1 for financial analysis",
    "description": "Rogo scales AI-driven financial research with OpenAI o1",
    "summary": "Rogo scales AI-driven financial research with OpenAI o1",
    "pubDate": "Thu, 13 Feb 2025 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/rogo",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Wayfair is shaping the future of retail with AI",
    "description": "A conversation with Fiona Tan, Chief Technology Officer of Wayfair.",
    "summary": "A conversation with Fiona Tan, Chief Technology Officer of Wayfair.",
    "pubDate": "Thu, 13 Feb 2025 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/wayfair-fiona-tan",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Fixing Open LLM Leaderboard with Math-Verify",
    "description": "",
    "summary": "",
    "pubDate": "Fri, 14 Feb 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/math_verify_leaderboard",
    "thumbnail": "https://huggingface.co/blog/assets/math_verify_leaderboard/thumbnail.png"
  },
  {
    "title": "OpenAI and Guardian Media Group launch content partnership",
    "description": "OpenAI and Guardian Media Group announce content partnership to bring Guardian news content to ChatGPT.",
    "summary": "OpenAI and Guardian Media Group announce content partnership to bring Guardian news content to ChatGPT.",
    "pubDate": "Fri, 14 Feb 2025 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-and-guardian-media-group-launch-content-partnership",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Welcome Fireworks.ai on the Hub 🎆",
    "description": "",
    "summary": "",
    "pubDate": "Fri, 14 Feb 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/fireworks-ai",
    "thumbnail": "https://huggingface.co/blog/assets/inference-providers/welcome-fireworks.jpg"
  },
  {
    "title": "Introducing the SWE-Lancer benchmark",
    "description": "Can frontier LLMs earn $1 million from real-world freelance software engineering?",
    "summary": "Can frontier LLMs earn $1 million from real-world freelance software engineering?",
    "pubDate": "Tue, 18 Feb 2025 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/swe-lancer",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Introducing Three New Serverless Inference Providers: Hyperbolic, Nebius AI Studio, and Novita 🔥",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 18 Feb 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/inference-providers-nebius-novita-hyperbolic",
    "thumbnail": "https://huggingface.co/blog/assets/inference-providers/second-batch-thumbnail.webp"
  },
  {
    "title": "PaliGemma 2 Mix - New Instruction Vision Language Models by Google",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 19 Feb 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/paligemma2mix",
    "thumbnail": "https://huggingface.co/blog/assets/paligemma2/thumbnail.png"
  },
  {
    "title": "College students and ChatGPT adoption in the US",
    "description": "A look into state-by-state adoption and how gaps might impact workforce readiness.",
    "summary": "A look into state-by-state adoption and how gaps might impact workforce readiness.",
    "pubDate": "Thu, 20 Feb 2025 06:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/global-affairs/college-students-and-chatgpt",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "SmolVLM2: Bringing Video Understanding to Every Device",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 20 Feb 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/smolvlm2",
    "thumbnail": "https://huggingface.co/blog/assets/smolvlm2/banner.png"
  },
  {
    "title": "Uber enables outstanding on-demand experiences with AI",
    "description": "A conversation with Jai Malkani, Head of AI and Product, Customer Obsession at Uber.",
    "summary": "A conversation with Jai Malkani, Head of AI and Product, Customer Obsession at Uber.",
    "pubDate": "Thu, 20 Feb 2025 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/uber-enables-outstanding-experiences",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Disrupting malicious uses of AI",
    "description": "Ensuring AI benefits humanity by advancing democratic AI, preventing misuse, and protecting against authoritarian threats.",
    "summary": "Ensuring AI benefits humanity by advancing democratic AI, preventing misuse, and protecting against authoritarian threats.",
    "pubDate": "Fri, 21 Feb 2025 06:30:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/global-affairs/disrupting-malicious-uses-of-ai",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "SigLIP 2: A better multilingual vision language encoder",
    "description": "",
    "summary": "",
    "pubDate": "Fri, 21 Feb 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/siglip2",
    "thumbnail": "https://huggingface.co/blog/assets/siglip2/thumbnail.png"
  },
  {
    "title": "Remote VAEs for decoding with HF endpoints 🤗",
    "description": "",
    "summary": "",
    "pubDate": "Mon, 24 Feb 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/remote_vae",
    "thumbnail": "https://huggingface.co/blog/assets/remote_vae/thumbnail.png"
  },
  {
    "title": "Deep research System Card",
    "description": "This report outlines the safety work carried out prior to releasing deep research including external red teaming, frontier risk evaluations according to our Preparedness Framework, and an overview of the mitigations we built in to address key risk areas.",
    "summary": "This report outlines the safety work carried out prior to releasing deep research including external red teaming, frontier risk evaluations according to our Preparedness Framework, and an overview of the mitigations we built in to address key risk areas.",
    "pubDate": "Tue, 25 Feb 2025 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/deep-research-system-card",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Estonia and OpenAI to bring ChatGPT to schools nationwide",
    "description": "Estonia and OpenAI to bring ChatGPT to schools nationwide. OpenAI will work with the Estonian Government to provide students and teachers in the secondary school system with access to ChatGPT Edu.",
    "summary": "Estonia and OpenAI to bring ChatGPT to schools nationwide. OpenAI will work with the Estonian Government to provide students and teachers in the secondary school system with access to ChatGPT Edu.",
    "pubDate": "Tue, 25 Feb 2025 04:15:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/estonia-schools-and-chatgpt",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "FastRTC: The Real-Time Communication Library for Python",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 25 Feb 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/fastrtc",
    "thumbnail": "https://huggingface.co/blog/assets/fastrtc/fastrtc_logo.jpg"
  },
  {
    "title": "Start building with Gemini 2.0 Flash and Flash-Lite",
    "description": "Gemini 2.0 Flash-Lite is now generally available in the Gemini API for production use in Google AI Studio and for enterprise customers on Vertex AI",
    "summary": "Gemini 2.0 Flash-Lite is now generally available in the Gemini API for production use in Google AI Studio and for enterprise customers on Vertex AI",
    "pubDate": "Tue, 25 Feb 2025 18:02:12 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/start-building-with-gemini-20-flash-and-flash-lite/",
    "thumbnail": "https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/Flash_Family_meta.2e16d0ba.fill-1200x600.png"
  },
  {
    "title": "Building an autonomous financial analyst with o1 and o3-mini",
    "description": "Endex builds the future of financial analysis, powered by OpenAI’s reasoning models.",
    "summary": "Endex builds the future of financial analysis, powered by OpenAI’s reasoning models.",
    "pubDate": "Thu, 27 Feb 2025 09:30:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/endex",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "HuggingFace, IISc partner to supercharge model building on India's diverse languages",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 27 Feb 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/iisc-huggingface-collab",
    "thumbnail": "https://huggingface.co/blog/assets/iisc-huggingface-collab/thumbnail.png"
  },
  {
    "title": "Introducing GPT-4.5",
    "description": "We’re releasing a research preview of GPT‑4.5—our largest and best model for chat yet. GPT‑4.5 is a step forward in scaling up pre-training and post-training.",
    "summary": "We’re releasing a research preview of GPT‑4.5—our largest and best model for chat yet. GPT‑4.5 is a step forward in scaling up pre-training and post-training.",
    "pubDate": "Thu, 27 Feb 2025 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-gpt-4-5",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "OpenAI GPT-4.5 System Card",
    "description": "We’re releasing a research preview of OpenAI GPT‑4.5, our largest and most knowledgeable model yet.",
    "summary": "We’re releasing a research preview of OpenAI GPT‑4.5, our largest and most knowledgeable model yet.",
    "pubDate": "Thu, 27 Feb 2025 12:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/gpt-4-5-system-card",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Supporting sellers with enhanced product listings",
    "description": "Mercari leverages GPT-4o mini and GPT-4 to streamline selling, enhance product listings, and boost sales, transforming the online marketplace with features like AI Listing Support and Mercari AI Assistant.",
    "summary": "Mercari leverages GPT-4o mini and GPT-4 to streamline selling, enhance product listings, and boost sales, transforming the online marketplace with features like AI Listing Support and Mercari AI Assistant.",
    "pubDate": "Thu, 27 Feb 2025 14:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/mercari",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "1,000 Scientist AI Jam Session",
    "description": "OpenAI and nine national labs bring together leading scientists for first-of-its kind event.",
    "summary": "OpenAI and nine national labs bring together leading scientists for first-of-its kind event.",
    "pubDate": "Fri, 28 Feb 2025 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/global-affairs/1000-scientist-ai-jam-session",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Trace & Evaluate your Agent with Arize Phoenix",
    "description": "",
    "summary": "",
    "pubDate": "Fri, 28 Feb 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/smolagents-phoenix",
    "thumbnail": "https://huggingface.co/blog/assets/smolagents-phoenix/thumbnail.jpg"
  },
  {
    "title": "A Deepdive into Aya Vision: Advancing the Frontier of Multilingual Multimodality",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 04 Mar 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/aya-vision",
    "thumbnail": "https://huggingface.co/blog/assets/aya-vision/thumbnail.png"
  },
  {
    "title": "Hugging Face and JFrog partner to make AI Security more transparent",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 04 Mar 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/jfrog",
    "thumbnail": "https://huggingface.co/blog/assets/jfrog/thumbnail.png"
  },
  {
    "title": "Introducing NextGenAI",
    "description": "OpenAI commits $50M in funding and tools to leading institutions.",
    "summary": "OpenAI commits $50M in funding and tools to leading institutions.",
    "pubDate": "Tue, 04 Mar 2025 06:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-nextgenai",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "LaunchDarkly's approach to AI-powered product management",
    "description": "A conversation with Claire Vo, Chief Product Officer of LaunchDarkly, about the changing role of product managers, her anti-to-do list, and building AI-native teams.",
    "summary": "A conversation with Claire Vo, Chief Product Officer of LaunchDarkly, about the changing role of product managers, her anti-to-do list, and building AI-native teams.",
    "pubDate": "Tue, 04 Mar 2025 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/launchdarkly-claire-vo",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Accelerating engineering cycles 20% with OpenAI",
    "description": "Accelerating engineering cycles 20% with OpenAI.",
    "summary": "Accelerating engineering cycles 20% with OpenAI.",
    "pubDate": "Thu, 06 Mar 2025 09:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/factory",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "LLM Inference on Edge: A Fun and Easy Guide to run LLMs via React Native on your Phone!",
    "description": "",
    "summary": "",
    "pubDate": "Fri, 07 Mar 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/llm-inference-on-edge",
    "thumbnail": "https://huggingface.co/blog/assets/llm_inference_on_edge/thumbnail.png"
  },
  {
    "title": "Nubank elevates customer experiences with OpenAI",
    "description": "Nubank elevates customer experiences with OpenAI",
    "summary": "Nubank elevates customer experiences with OpenAI",
    "pubDate": "Fri, 07 Mar 2025 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/nubank",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Detecting misbehavior in frontier reasoning models",
    "description": "Frontier reasoning models exploit loopholes when given the chance. We show we can detect exploits using an LLM to monitor their chains-of-thought. Penalizing their “bad thoughts” doesn’t stop the majority of misbehavior—it makes them hide their intent.",
    "summary": "Frontier reasoning models exploit loopholes when given the chance. We show we can detect exploits using an LLM to monitor their chains-of-thought. Penalizing their “bad thoughts” doesn’t stop the majority of misbehavior—it makes them hide their intent.",
    "pubDate": "Mon, 10 Mar 2025 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/chain-of-thought-monitoring",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "LeRobot goes to driving school: World’s largest open-source self-driving dataset",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 11 Mar 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/lerobot-goes-to-driving-school",
    "thumbnail": "https://huggingface.co/blog/assets/193_l2d/lerobot-driver.gif"
  },
  {
    "title": "New tools for building agents",
    "description": "We’re evolving our platform to help developers and enterprises build useful and reliable agents.",
    "summary": "We’re evolving our platform to help developers and enterprises build useful and reliable agents.",
    "pubDate": "Tue, 11 Mar 2025 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/new-tools-for-building-agents",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Driving growth and ‘WOW’ moments with OpenAI",
    "description": "LY Corporation: Driving growth and ‘WOW’ moments with OpenAI",
    "summary": "LY Corporation: Driving growth and ‘WOW’ moments with OpenAI",
    "pubDate": "Wed, 12 Mar 2025 18:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/ly-corporation",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Experiment with Gemini 2.0 Flash native image generation",
    "description": "Native image output is available in Gemini 2.0 Flash for developers to experiment with in Google AI Studio and the Gemini API.",
    "summary": "Native image output is available in Gemini 2.0 Flash for developers to experiment with in Google AI Studio and the Gemini API.",
    "pubDate": "Wed, 12 Mar 2025 14:58:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/experiment-with-gemini-20-flash-native-image-generation/",
    "thumbnail": "https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/gemini-image-generation_1.2e16d0ba.fill-1200x600.png"
  },
  {
    "title": "Gemini Robotics brings AI into the physical world",
    "description": "Introducing Gemini Robotics and Gemini Robotics-ER, AI models designed for robots to understand, act and react to the physical world.",
    "summary": "Introducing Gemini Robotics and Gemini Robotics-ER, AI models designed for robots to understand, act and react to the physical world.",
    "pubDate": "Wed, 12 Mar 2025 15:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/gemini-robotics-brings-ai-into-the-physical-world/",
    "thumbnail": "https://lh3.googleusercontent.com/J74rVi68EPPNMBLxhxI76Bli7QggLtYRYfp5Pk2HVPtSt2NIIk2VmLktQbwDZeIlZiW3AHwlpLNcswHuz_ecR-oj4kI-mtF53yYsGJKfvPugAw5ulQ=w1200-h630-n-nu"
  },
  {
    "title": "Introducing Gemma 3",
    "description": "The most capable model you can run on a single GPU or TPU.",
    "summary": "The most capable model you can run on a single GPU or TPU.",
    "pubDate": "Wed, 12 Mar 2025 08:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/introducing-gemma-3/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Gemma3_KeywordBlog_RD3_V01b_SocialShare.width-1300.png"
  },
  {
    "title": "Welcome Gemma 3: Google's all new multimodal, multilingual, long context open LLM",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 12 Mar 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/gemma3",
    "thumbnail": "https://huggingface.co/blog/assets/gemma3/thumbnail.png"
  },
  {
    "title": "OpenAI’s proposals for the U.S. AI Action Plan",
    "description": "Recommendations build on OpenAI’s Economic Blueprint to strengthen America’s AI leadership.",
    "summary": "Recommendations build on OpenAI’s Economic Blueprint to strengthen America’s AI leadership.",
    "pubDate": "Thu, 13 Mar 2025 03:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/global-affairs/openai-proposals-for-the-us-ai-action-plan",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "The court rejects Elon’s latest attempt to slow OpenAI down",
    "description": "We welcome the court’s March 4, 2025, decision rejecting Elon Musk’s latest attempt to slow down OpenAI for his personal benefit.",
    "summary": "We welcome the court’s March 4, 2025, decision rejecting Elon Musk’s latest attempt to slow down OpenAI for his personal benefit.",
    "pubDate": "Fri, 14 Mar 2025 09:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/court-rejects-elon",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "言語処理学会第31回年次大会(NLP2025) 発表報告",
    "description": "<p>1. はじめに こんにちは。AIチームの栗原です。2025年3月10日(月)〜3月14日(金)に出島メッセ長崎にて行われた言語処理学会第31回年次大会で、弊社からポスター発表で3件、口頭発表で1件の発表を行いました。 昨 [&#8230;]</p> <p>投稿 <a href='https://www.ai-shift.co.jp/techblog/5586' rel='nofollow'>言語処理学会第31回年次大会(NLP2025) 発表報告</a> は <a href='https://www.ai-shift.co.jp' rel='nofollow'>株式会社AI Shift</a> に最初に表示されました。</p>",
    "summary": "<p>1. はじめに こんにちは。AIチームの栗原です。2025年3月10日(月)〜3月14日(金)に出島メッセ長崎にて行われた言語処理学会第31回年次大会で、弊社からポスター発表で3件、口頭発表で1件の発表を行いました。 昨 [&#8230;]</p> <p>投稿 <a href='https://www.ai-shift.co.jp/techblog/5586' rel='nofollow'>言語処理学会第31回年次大会(NLP2025) 発表報告</a> は <a href='https://www.ai-shift.co.jp' rel='nofollow'>株式会社AI Shift</a> に最初に表示されました。</p>",
    "pubDate": "Fri, 14 Mar 2025 10:50:19 +0000",
    "source": "AI Shift",
    "url": "https://www.ai-shift.co.jp/techblog/5586",
    "thumbnail": "https://www.ai-shift.co.jp/wp-content/uploads/2025/03/IMG_1253-1-scaled.jpg"
  },
  {
    "title": "LLMで挑むTitanic生存予測: Few-Shot Leaningで表形式データはどこま解ける？",
    "description": "<p>こんにちは、AIチームの戸田です。 KaggleのTitanicデータセットは、機械学習の入門として定番のデータセットです。 多くの機械学習手法が試されてきたこのデータセットに対し、今回は少し異なるアプローチを試みたいと [&#8230;]</p> <p>投稿 <a href='https://www.ai-shift.co.jp/techblog/5560' rel='nofollow'>LLMで挑むTitanic生存予測: Few-Shot Leaningで表形式データはどこま解ける？</a> は <a href='https://www.ai-shift.co.jp' rel='nofollow'>株式会社AI Shift</a> に最初に表示されました。</p>",
    "summary": "<p>こんにちは、AIチームの戸田です。 KaggleのTitanicデータセットは、機械学習の入門として定番のデータセットです。 多くの機械学習手法が試されてきたこのデータセットに対し、今回は少し異なるアプローチを試みたいと [&#8230;]</p> <p>投稿 <a href='https://www.ai-shift.co.jp/techblog/5560' rel='nofollow'>LLMで挑むTitanic生存予測: Few-Shot Leaningで表形式データはどこま解ける？</a> は <a href='https://www.ai-shift.co.jp' rel='nofollow'>株式会社AI Shift</a> に最初に表示されました。</p>",
    "pubDate": "Mon, 17 Mar 2025 21:16:00 +0000",
    "source": "AI Shift",
    "url": "https://www.ai-shift.co.jp/techblog/5560",
    "thumbnail": "https://www.ai-shift.co.jp/wp-content/uploads/2025/03/f81fd2e4c52864042852c112ce927ae2.png"
  },
  {
    "title": "EliseAI improves housing and healthcare efficiency with AI",
    "description": "A conversation with Minna Song, CEO & Co-founder of EliseAI.",
    "summary": "A conversation with Minna Song, CEO & Co-founder of EliseAI.",
    "pubDate": "Tue, 18 Mar 2025 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/eliseai-minna-song",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "New in ChatGPT for Business: March 2025",
    "description": "Join us as we share our latest releases and how ChatGPT is becoming more interactive, customized to the way your teams work, and agentic.",
    "summary": "Join us as we share our latest releases and how ChatGPT is becoming more interactive, customized to the way your teams work, and agentic.",
    "pubDate": "Tue, 18 Mar 2025 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/business/new-in-chatgpt-for-work-march-updates-2025",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "NVIDIA's GTC 2025 Announcement for Physical AI Developers: New Open Models and Datasets",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 18 Mar 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/nvidia-physical-ai",
    "thumbnail": "https://huggingface.co/blog/assets/nvidia-physical-ai/thumbnail.png"
  },
  {
    "title": "Xet is on the Hub",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 18 Mar 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/xet-on-the-hub",
    "thumbnail": "https://huggingface.co/blog/assets/xet-on-the-hub/thumbnail.png"
  },
  {
    "title": "AI Policy: 🤗 Response to the White House AI Action Plan RFI",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 19 Mar 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/ai-action-wh-2025",
    "thumbnail": "https://huggingface.co/blog/assets/151_policy_ntia_rfc/us_policy_thumbnail.png"
  },
  {
    "title": "Introducing next-generation audio models in the API",
    "description": "For the first time, developers can also instruct the text-to-speech model to speak in a specific way—for example, “talk like a sympathetic customer service agent”—unlocking a new level of customization for voice agents.",
    "summary": "For the first time, developers can also instruct the text-to-speech model to speak in a specific way—for example, “talk like a sympathetic customer service agent”—unlocking a new level of customization for voice agents.",
    "pubDate": "Thu, 20 Mar 2025 11:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-our-next-generation-audio-models",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Open R1: How to use OlympicCoder locally for coding?",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 20 Mar 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/olympic-coder-lmstudio",
    "thumbnail": "https://huggingface.co/blog/assets/olympic-coder-lmstudio/banner.png"
  },
  {
    "title": "Personalizing travel at scale with OpenAI",
    "description": "By integrating its data systems with OpenAI’s LLMs, Booking.com delivers smarter search, faster support, and intent-driven travel experiences.",
    "summary": "By integrating its data systems with OpenAI’s LLMs, Booking.com delivers smarter search, faster support, and intent-driven travel experiences.",
    "pubDate": "Thu, 20 Mar 2025 23:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/booking-com",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Early methods for studying affective use and emotional well-being on ChatGPT",
    "description": "An OpenAI and MIT Media Lab Research collaboration.",
    "summary": "An OpenAI and MIT Media Lab Research collaboration.",
    "pubDate": "Fri, 21 Mar 2025 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/affective-use-study",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "The New and Fresh analytics in Inference Endpoints",
    "description": "",
    "summary": "",
    "pubDate": "Fri, 21 Mar 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/endpoint-analytics",
    "thumbnail": "https://huggingface.co/blog/assets/endpoint-analytics/thumbnail.png"
  },
  {
    "title": "Introducing Gradio's new Dataframe!",
    "description": "",
    "summary": "",
    "pubDate": "Mon, 24 Mar 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/gradio-dataframe-upgrade",
    "thumbnail": "https://huggingface.co/blog/assets/gradio-dataframe-upgrade/thumbnail.png"
  },
  {
    "title": "Leadership updates",
    "description": "OpenAI has grown a lot. We remain focused on the same core—pursuing frontier AI research that accelerates human progress–but we now also deliver products used by hundreds of millions of people.",
    "summary": "OpenAI has grown a lot. We remain focused on the same core—pursuing frontier AI research that accelerates human progress–but we now also deliver products used by hundreds of millions of people.",
    "pubDate": "Mon, 24 Mar 2025 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/leadership-updates-march-2025",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Addendum to GPT-4o System Card: 4o image generation",
    "description": "4o image generation is a new, significantly more capable image generation approach than our earlier DALL·E 3 series of models. It can create photorealistic output. It can take images as inputs and transform them.",
    "summary": "4o image generation is a new, significantly more capable image generation approach than our earlier DALL·E 3 series of models. It can create photorealistic output. It can take images as inputs and transform them.",
    "pubDate": "Tue, 25 Mar 2025 11:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/gpt-4o-image-generation-system-card-addendum",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Arize Phoenix で実現する LLM アプリケーションのトレース",
    "description": "<p>こんにちは、AI チームの長澤(@sp_1999N)です。 今回は Arize AI 社が開発・提供する LLM アプリケーション向けの監視ツール Phoenix の紹介および簡単なデモ構築を行いたいと思います。 デモと [&#8230;]</p> <p>投稿 <a href='https://www.ai-shift.co.jp/techblog/5608' rel='nofollow'>Arize Phoenix で実現する LLM アプリケーションのトレース</a> は <a href='https://www.ai-shift.co.jp' rel='nofollow'>株式会社AI Shift</a> に最初に表示されました。</p>",
    "summary": "<p>こんにちは、AI チームの長澤(@sp_1999N)です。 今回は Arize AI 社が開発・提供する LLM アプリケーション向けの監視ツール Phoenix の紹介および簡単なデモ構築を行いたいと思います。 デモと [&#8230;]</p> <p>投稿 <a href='https://www.ai-shift.co.jp/techblog/5608' rel='nofollow'>Arize Phoenix で実現する LLM アプリケーションのトレース</a> は <a href='https://www.ai-shift.co.jp' rel='nofollow'>株式会社AI Shift</a> に最初に表示されました。</p>",
    "pubDate": "Tue, 25 Mar 2025 10:22:46 +0000",
    "source": "AI Shift",
    "url": "https://www.ai-shift.co.jp/techblog/5608",
    "thumbnail": "https://www.ai-shift.co.jp/wp-content/uploads/2025/03/image-4.png"
  },
  {
    "title": "Automating 90% of finance and legal work with agents",
    "description": "Hebbia’s deep research automates 90% of finance and legal work, powered by OpenAI",
    "summary": "Hebbia’s deep research automates 90% of finance and legal work, powered by OpenAI",
    "pubDate": "Tue, 25 Mar 2025 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/hebbia",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Gemini 2.5: Our most intelligent AI model",
    "description": "Gemini 2.5 is our most intelligent AI model, now with thinking built in.",
    "summary": "Gemini 2.5 is our most intelligent AI model, now with thinking built in.",
    "pubDate": "Tue, 25 Mar 2025 17:00:36 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/gemini-2-5-our-most-intelligent-ai-model/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/2.5_keyword_social_share_text.width-1300.png"
  },
  {
    "title": "Introducing 4o Image Generation",
    "description": "At OpenAI, we have long believed image generation should be a primary capability of our language models. That’s why we’ve built our most advanced image generator yet into GPT‑4o. The result—image generation that is not only beautiful, but useful.",
    "summary": "At OpenAI, we have long believed image generation should be a primary capability of our language models. That’s why we’ve built our most advanced image generator yet into GPT‑4o. The result—image generation that is not only beautiful, but useful.",
    "pubDate": "Tue, 25 Mar 2025 11:05:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-4o-image-generation",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Scaling the OpenAI Academy",
    "description": "Online resource hub will support AI literacy and help people from all backgrounds access tools, best practices, and peer insights to use AI.",
    "summary": "Online resource hub will support AI literacy and help people from all backgrounds access tools, best practices, and peer insights to use AI.",
    "pubDate": "Tue, 25 Mar 2025 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/global-affairs/scaling-the-openai-academy",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Security on the path to AGI",
    "description": "At OpenAI, we proactively adapt, including by building comprehensive security measures directly into our infrastructure and models.",
    "summary": "At OpenAI, we proactively adapt, including by building comprehensive security measures directly into our infrastructure and models.",
    "pubDate": "Wed, 26 Mar 2025 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/security-on-the-path-to-agi",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Training and Finetuning Reranker Models with Sentence Transformers v4",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 26 Mar 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/train-reranker",
    "thumbnail": "https://huggingface.co/blog/assets/train-sentence-transformers/st-hf-thumbnail.png"
  },
  {
    "title": "Moving from intent-based bots to proactive AI agents",
    "description": "Moving from intent-based bots to proactive AI agents.",
    "summary": "Moving from intent-based bots to proactive AI agents.",
    "pubDate": "Thu, 27 Mar 2025 09:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/zendesk",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Accelerating LLM Inference with TGI on Intel Gaudi",
    "description": "",
    "summary": "",
    "pubDate": "Fri, 28 Mar 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/intel-gaudi-backend-for-tgi",
    "thumbnail": "https://huggingface.co/blog/assets/intel-gaudi-backend-for-tgi/tgi-gaudi-thumbnail.png"
  },
  {
    "title": "How Hugging Face Scaled Secrets Management for AI Infrastructure",
    "description": "",
    "summary": "",
    "pubDate": "Mon, 31 Mar 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/scaling-secrets-management",
    "thumbnail": "https://huggingface.co/blog/assets/infisical/thumbnail.png"
  },
  {
    "title": "New funding to build towards AGI",
    "description": "Today we’re announcing new funding—$40B at a $300B post-money valuation, which enables us to push the frontiers of AI research even further, scale our compute infrastructure, and deliver increasingly powerful tools for the 500 million people who use ChatGPT every week.",
    "summary": "Today we’re announcing new funding—$40B at a $300B post-money valuation, which enables us to push the frontiers of AI research even further, scale our compute infrastructure, and deliver increasingly powerful tools for the 500 million people who use ChatGPT every week.",
    "pubDate": "Mon, 31 Mar 2025 15:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/march-funding-updates",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Evaluating potential cybersecurity threats of advanced AI",
    "description": "Our framework enables cybersecurity experts to identify which defenses are necessary—and how to prioritize them",
    "summary": "Our framework enables cybersecurity experts to identify which defenses are necessary—and how to prioritize them",
    "pubDate": "Wed, 02 Apr 2025 13:30:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/evaluating-potential-cybersecurity-threats-of-advanced-ai/",
    "thumbnail": "https://lh3.googleusercontent.com/qVftghWK2fcPAfl80FKEGIuxUxYuwlN2guNdIpH5A1nF4KYf5jufujNE7j3zv5uJ3CGPEJ47ec4UaUa1vl8H3rpuEX8jIkdQlXgCEYeGhAAEj3p06IY=w1200-h630-n-nu"
  },
  {
    "title": "New commission to provide insight as OpenAI builds the world’s best-equipped nonprofit",
    "description": "Already a nonprofit, and already using AI to help people solve hard problems, OpenAI aims to build the best-equipped nonprofit the world has ever seen—combining potentially historic financial resources with something even more powerful: technology that can scale human ingenuity itself.",
    "summary": "Already a nonprofit, and already using AI to help people solve hard problems, OpenAI aims to build the best-equipped nonprofit the world has ever seen—combining potentially historic financial resources with something even more powerful: technology that can scale human ingenuity itself.",
    "pubDate": "Wed, 02 Apr 2025 12:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/nonprofit-commission-guidance",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Our response to the UK’s copyright consultation",
    "description": "Recommendations for pro-innovation policies that can help make the UK the AI capital of Europe.",
    "summary": "Recommendations for pro-innovation policies that can help make the UK the AI capital of Europe.",
    "pubDate": "Wed, 02 Apr 2025 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/global-affairs/response-to-uk-copyright-consultation",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "PaperBench: Evaluating AI’s Ability to Replicate AI Research",
    "description": "We introduce PaperBench, a benchmark evaluating the ability of AI agents to replicate state-of-the-art AI research.",
    "summary": "We introduce PaperBench, a benchmark evaluating the ability of AI agents to replicate state-of-the-art AI research.",
    "pubDate": "Wed, 02 Apr 2025 10:15:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/paperbench",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Researchers teach LLMs to solve complex planning challenges",
    "description": "This new framework leverages a model’s reasoning abilities to create a “smart assistant” that finds the optimal solution to multistep problems.",
    "summary": "This new framework leverages a model’s reasoning abilities to create a “smart assistant” that finds the optimal solution to multistep problems.",
    "pubDate": "Wed, 02 Apr 2025 00:00:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/researchers-teach-llms-to-solve-complex-planning-challenges-0402",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202504/MIT-Formalized-Programming-01-press.jpg"
  },
  {
    "title": "Taking a responsible path to AGI",
    "description": "We’re exploring the frontiers of AGI, prioritizing technical safety, proactive risk assessment, and collaboration with the AI community.",
    "summary": "We’re exploring the frontiers of AGI, prioritizing technical safety, proactive risk assessment, and collaboration with the AI community.",
    "pubDate": "Wed, 02 Apr 2025 13:31:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/taking-a-responsible-path-to-agi/",
    "thumbnail": "https://lh3.googleusercontent.com/0sOE0EshCImNhSW7FRZvw-v_eyJJt_WUEh9evgRbhB4tl0o7qY2VAJdAloF5q3Q6CKTCiXdEvv1kUfsyZz8h6rR7Rl9jUhH02ADOyl7A7w-0QDWWr1Y=w1200-h630-n-nu"
  },
  {
    "title": "Bringing intelligence to every workflow",
    "description": "Notion is a connected workspace where teams write, plan, and organize everything from meeting notes to product roadmaps. Today, it’s also a deeply AI-powered platform, used by millions to summarize content, generate writing, and ask questions in natural language across their entire workspace.",
    "summary": "Notion is a connected workspace where teams write, plan, and organize everything from meeting notes to product roadmaps. Today, it’s also a deeply AI-powered platform, used by millions to summarize content, generate writing, and ask questions in natural language across their entire workspace.",
    "pubDate": "Thu, 03 Apr 2025 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/notion",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "The NLP Course is becoming the LLM Course!",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 03 Apr 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/llm-course",
    "thumbnail": "https://huggingface.co/blog/assets/llm-course/llm-course-rename-thumbnail.png"
  },
  {
    "title": "Vana is letting users own a piece of the AI models trained on their data",
    "description": "More than 1 million people are contributing their data to Vana’s decentralized network, which started as an MIT class project.",
    "summary": "More than 1 million people are contributing their data to Vana’s decentralized network, which started as an MIT class project.",
    "pubDate": "Thu, 03 Apr 2025 00:00:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/vana-lets-users-own-piece-ai-models-trained-on-their-data-0403",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202504/MIT-Vana-01.jpg"
  },
  {
    "title": "Journey to 1 Million Gradio Users!",
    "description": "",
    "summary": "",
    "pubDate": "Fri, 04 Apr 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/gradio-1m",
    "thumbnail": "https://huggingface.co/blog/assets/gradio-1m/thumbnail.png"
  },
  {
    "title": "New method assesses and improves the reliability of radiologists’ diagnostic reports",
    "description": "The framework helps clinicians choose phrases that more accurately reflect the likelihood that certain conditions are present in X-rays.",
    "summary": "The framework helps clinicians choose phrases that more accurately reflect the likelihood that certain conditions are present in X-rays.",
    "pubDate": "Fri, 04 Apr 2025 00:00:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/new-method-assesses-and-improves-reliability-radiologists-diagnostic-reports-0404",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202504/MIT-Calibrating-Certainty-01-press_2.jpg"
  },
  {
    "title": "Welcome Llama 4 Maverick & Scout on Hugging Face!",
    "description": "",
    "summary": "",
    "pubDate": "Sat, 05 Apr 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/llama4-release",
    "thumbnail": "https://huggingface.co/blog/assets/llama_4.png"
  },
  {
    "title": "Canva enables creativity with AI",
    "description": "A conversation with Cameron Adams, Chief Product Officer and Co-founder of Canva.",
    "summary": "A conversation with Cameron Adams, Chief Product Officer and Co-founder of Canva.",
    "pubDate": "Mon, 07 Apr 2025 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/canva-cam-adams",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "OpenAI’s EU Economic Blueprint",
    "description": "Today, OpenAI is sharing the EU Economic Blueprint—a set of proposals to help Europe seize the promise of artificial intelligence, drive sustainable economic growth across the region, and ensure that AI is developed and deployed by Europe, in Europe, for Europe.",
    "summary": "Today, OpenAI is sharing the EU Economic Blueprint—a set of proposals to help Europe seize the promise of artificial intelligence, drive sustainable economic growth across the region, and ensure that AI is developed and deployed by Europe, in Europe, for Europe.",
    "pubDate": "Mon, 07 Apr 2025 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/global-affairs/openais-eu-economic-blueprint",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Arabic Leaderboards: Introducing Arabic Instruction Following, Updating AraGen, and More",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 08 Apr 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/leaderboard-3c3h-aragen-ifeval",
    "thumbnail": "https://huggingface.co/blog/assets/leaderboards-on-the-hub/thumbnail_3c3h_aragen.png"
  },
  {
    "title": "Could LLMs help design our next medicines and materials?",
    "description": "A new method lets users ask, in plain language, for a new molecule with certain properties, and receive a detailed description of how to synthesize it.",
    "summary": "A new method lets users ask, in plain language, for a new molecule with certain properties, and receive a detailed description of how to synthesize it.",
    "pubDate": "Wed, 09 Apr 2025 00:00:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/could-llms-help-design-our-next-medicines-and-materials-0409",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202504/MIT-inverse-molecule-01-press.jpg"
  },
  {
    "title": "Hugging Face and Cloudflare Partner to Make Real-Time Speech and Video Seamless with FastRTC",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 09 Apr 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/fastrtc-cloudflare",
    "thumbnail": "https://huggingface.co/blog/assets/fastrtc-cloudflare/fastrtc_cloudflare.png"
  },
  {
    "title": "OpenAI Pioneers Program",
    "description": "Advancing model performance and real world evaluation in applied domains.",
    "summary": "Advancing model performance and real world evaluation in applied domains.",
    "pubDate": "Wed, 09 Apr 2025 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-pioneers-program",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "BrowseComp: a benchmark for browsing agents",
    "description": "BrowseComp: a benchmark for browsing agents.",
    "summary": "BrowseComp: a benchmark for browsing agents.",
    "pubDate": "Thu, 10 Apr 2025 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/browsecomp",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "New method efficiently safeguards sensitive AI training data",
    "description": "The approach maintains an AI model’s accuracy while ensuring attackers can’t extract secret information.",
    "summary": "The approach maintains an AI model’s accuracy while ensuring attackers can’t extract secret information.",
    "pubDate": "Fri, 11 Apr 2025 00:00:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/new-method-efficiently-safeguards-sensitive-ai-training-data-0411",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202504/MIT-Private-Algorithm-01-press.jpg"
  },
  {
    "title": "4M Models Scanned: Protect AI + Hugging Face 6 Months In",
    "description": "",
    "summary": "",
    "pubDate": "Mon, 14 Apr 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/pai-6-month",
    "thumbnail": "https://huggingface.co/blog/assets/pai-6-month/thumbnail.png"
  },
  {
    "title": "DolphinGemma: How Google AI is helping decode dolphin communication",
    "description": "DolphinGemma, a large language model developed by Google, is helping scientists study how dolphins communicate — and hopefully find out what they're saying, too.",
    "summary": "DolphinGemma, a large language model developed by Google, is helping scientists study how dolphins communicate — and hopefully find out what they're saying, too.",
    "pubDate": "Mon, 14 Apr 2025 17:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/dolphingemma-how-google-ai-is-helping-decode-dolphin-communication/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/DolphinGemma_SocialExplainers_16x9_DolphinGem.width-1300.png"
  },
  {
    "title": "Hugging Face to sell open-source robots thanks to Pollen Robotics acquisition 🤖",
    "description": "",
    "summary": "",
    "pubDate": "Mon, 14 Apr 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/hugging-face-pollen-robotics-acquisition",
    "thumbnail": "https://huggingface.co/blog/assets/hugging-face-pollen-robotics-acquisition/hf-pollen.png"
  },
  {
    "title": "Introducing GPT-4.1 in the API",
    "description": "Introducing GPT-4.1 in the API—a new family of models with across-the-board improvements, including major gains in coding, instruction following, and long-context understanding. We’re also releasing our first nano model. Available to developers worldwide starting today.",
    "summary": "Introducing GPT-4.1 in the API—a new family of models with across-the-board improvements, including major gains in coding, instruction following, and long-context understanding. We’re also releasing our first nano model. Available to developers worldwide starting today.",
    "pubDate": "Mon, 14 Apr 2025 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/gpt-4-1",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Generate videos in Gemini and Whisk with Veo 2",
    "description": "Transform text-based prompts into high-resolution eight-second videos in Gemini Advanced and use Whisk Animate to turn images into eight-second animated clips.",
    "summary": "Transform text-based prompts into high-resolution eight-second videos in Gemini Advanced and use Whisk Animate to turn images into eight-second animated clips.",
    "pubDate": "Tue, 15 Apr 2025 17:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/generate-videos-in-gemini-and-whisk-with-veo-2/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/GenerateVideos_Static1_1920x1080.width-1300.png"
  },
  {
    "title": "ICASSP2025 発表報告 @Hyderabad, India",
    "description": "<p>はじめに こんにちは、AIチームの大竹です。 2025年4月6日(日)〜4月11日(金)にインド・ハイデラバード、Hyderabad International Convention Centreにて開催された、音響・音 [&#8230;]</p> <p>投稿 <a href='https://www.ai-shift.co.jp/techblog/5728' rel='nofollow'>ICASSP2025 発表報告 @Hyderabad, India</a> は <a href='https://www.ai-shift.co.jp' rel='nofollow'>株式会社AI Shift</a> に最初に表示されました。</p>",
    "summary": "<p>はじめに こんにちは、AIチームの大竹です。 2025年4月6日(日)〜4月11日(金)にインド・ハイデラバード、Hyderabad International Convention Centreにて開催された、音響・音 [&#8230;]</p> <p>投稿 <a href='https://www.ai-shift.co.jp/techblog/5728' rel='nofollow'>ICASSP2025 発表報告 @Hyderabad, India</a> は <a href='https://www.ai-shift.co.jp' rel='nofollow'>株式会社AI Shift</a> に最初に表示されました。</p>",
    "pubDate": "Tue, 15 Apr 2025 01:50:49 +0000",
    "source": "AI Shift",
    "url": "https://www.ai-shift.co.jp/techblog/5728",
    "thumbnail": "https://www.ai-shift.co.jp/wp-content/uploads/2025/04/IMG_20250406_091623-1.jpg"
  },
  {
    "title": "OpenAI announces nonprofit commission advisors",
    "description": "OpenAI is appointing four new advisors to help inform OpenAI’s philanthropic efforts.",
    "summary": "OpenAI is appointing four new advisors to help inform OpenAI’s philanthropic efforts.",
    "pubDate": "Tue, 15 Apr 2025 13:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/nonprofit-commission-advisors",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Our updated Preparedness Framework",
    "description": "Sharing our updated framework for measuring and protecting against severe harm from frontier AI capabilities.",
    "summary": "Sharing our updated framework for measuring and protecting against severe harm from frontier AI capabilities.",
    "pubDate": "Tue, 15 Apr 2025 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/updating-our-preparedness-framework",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "17 Reasons Why Gradio Isn't Just Another UI Library",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 16 Apr 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/why-gradio-stands-out",
    "thumbnail": "https://huggingface.co/blog/assets/why-gradio-stands-out/thumbnail.png"
  },
  {
    "title": "A faster way to solve complex planning problems",
    "description": "By eliminating redundant computations, a new data-driven method can streamline processes like scheduling trains, routing delivery drivers, or assigning airline crews.",
    "summary": "By eliminating redundant computations, a new data-driven method can streamline processes like scheduling trains, routing delivery drivers, or assigning airline crews.",
    "pubDate": "Wed, 16 Apr 2025 00:00:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/faster-way-solve-complex-planning-problems-0416",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202504/MIT_Long-Horizon-01.jpg"
  },
  {
    "title": "Cohere on Hugging Face Inference Providers 🔥",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 16 Apr 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/inference-providers-cohere",
    "thumbnail": "https://huggingface.co/blog/assets/inference-providers-cohere/thumbnail.png"
  },
  {
    "title": "FastRTCを使って爆速でVoicebotを構築する",
    "description": "<p>こんにちは、 AIチームの戸田です 今回はPythonでリアルタイムなAIアプリケーションを作る際に役立つライブラリ、FastRTCを使って簡単なVoicebotを構築してみたいと思います。 FastRTC FastRT [&#8230;]</p> <p>投稿 <a href='https://www.ai-shift.co.jp/techblog/5680' rel='nofollow'>FastRTCを使って爆速でVoicebotを構築する</a> は <a href='https://www.ai-shift.co.jp' rel='nofollow'>株式会社AI Shift</a> に最初に表示されました。</p>",
    "summary": "<p>こんにちは、 AIチームの戸田です 今回はPythonでリアルタイムなAIアプリケーションを作る際に役立つライブラリ、FastRTCを使って簡単なVoicebotを構築してみたいと思います。 FastRTC FastRT [&#8230;]</p> <p>投稿 <a href='https://www.ai-shift.co.jp/techblog/5680' rel='nofollow'>FastRTCを使って爆速でVoicebotを構築する</a> は <a href='https://www.ai-shift.co.jp' rel='nofollow'>株式会社AI Shift</a> に最初に表示されました。</p>",
    "pubDate": "Wed, 16 Apr 2025 00:41:50 +0000",
    "source": "AI Shift",
    "url": "https://www.ai-shift.co.jp/techblog/5680",
    "thumbnail": "https://www.ai-shift.co.jp/wp-content/uploads/2025/04/f81fd2e4c52864042852c112ce927ae2.png"
  },
  {
    "title": "Introducing HELMET",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 16 Apr 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/helmet",
    "thumbnail": "https://huggingface.co/blog/assets/helmet/thumbnail.png"
  },
  {
    "title": "Introducing OpenAI o3 and o4-mini",
    "description": "Our smartest and most capable models to date with full tool access",
    "summary": "Our smartest and most capable models to date with full tool access",
    "pubDate": "Wed, 16 Apr 2025 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-o3-and-o4-mini",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "OpenAI o3 and o4-mini System Card",
    "description": "OpenAI o3 and OpenAI o4-mini combine state-of-the-art reasoning with full tool capabilities—web browsing, Python, image and file analysis, image generation, canvas, automations, file search, and memory.",
    "summary": "OpenAI o3 and OpenAI o4-mini combine state-of-the-art reasoning with full tool capabilities—web browsing, Python, image and file analysis, image generation, canvas, automations, file search, and memory.",
    "pubDate": "Wed, 16 Apr 2025 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/o3-o4-mini-system-card",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Thinking with images",
    "description": "OpenAI o3 and o4-mini represent a significant breakthrough in visual perception by reasoning with images in their chain of thought.",
    "summary": "OpenAI o3 and o4-mini represent a significant breakthrough in visual perception by reasoning with images in their chain of thought.",
    "pubDate": "Wed, 16 Apr 2025 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/thinking-with-images",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Introducing Gemini 2.5 Flash",
    "description": "Gemini 2.5 Flash is our first fully hybrid reasoning model, giving developers the ability to turn thinking on or off.",
    "summary": "Gemini 2.5 Flash is our first fully hybrid reasoning model, giving developers the ability to turn thinking on or off.",
    "pubDate": "Thu, 17 Apr 2025 19:02:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/introducing-gemini-2-5-flash/",
    "thumbnail": "https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/Gemini-2-5-Flash-ai.dev.2e16d0ba.fill-1200x600.png"
  },
  {
    "title": "LangGraph CodeActをE2Bの安全な仮想環境で動かす",
    "description": "<p>こんにちは、 AIチームの戸田です 今回は先日LangChainから発表されたLangGraph CodeActをE2Bの仮想環境で動かしてみようと思います。CodeActは最近注目を集めているAI AgentのTool [&#8230;]</p> <p>投稿 <a href='https://www.ai-shift.co.jp/techblog/5652' rel='nofollow'>LangGraph CodeActをE2Bの安全な仮想環境で動かす</a> は <a href='https://www.ai-shift.co.jp' rel='nofollow'>株式会社AI Shift</a> に最初に表示されました。</p>",
    "summary": "<p>こんにちは、 AIチームの戸田です 今回は先日LangChainから発表されたLangGraph CodeActをE2Bの仮想環境で動かしてみようと思います。CodeActは最近注目を集めているAI AgentのTool [&#8230;]</p> <p>投稿 <a href='https://www.ai-shift.co.jp/techblog/5652' rel='nofollow'>LangGraph CodeActをE2Bの安全な仮想環境で動かす</a> は <a href='https://www.ai-shift.co.jp' rel='nofollow'>株式会社AI Shift</a> に最初に表示されました。</p>",
    "pubDate": "Thu, 17 Apr 2025 01:11:36 +0000",
    "source": "AI Shift",
    "url": "https://www.ai-shift.co.jp/techblog/5652",
    "thumbnail": "https://www.ai-shift.co.jp/wp-content/uploads/2025/03/f81fd2e4c52864042852c112ce927ae2-1.png"
  },
  {
    "title": "Making AI-generated code more accurate in any language",
    "description": "A new technique automatically guides an LLM toward outputs that adhere to the rules of whatever programming language or other format is being used.",
    "summary": "A new technique automatically guides an LLM toward outputs that adhere to the rules of whatever programming language or other format is being used.",
    "pubDate": "Fri, 18 Apr 2025 00:00:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/making-ai-generated-code-more-accurate-0418",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202504/MIT-Probalistic-Control-compressed.gif"
  },
  {
    "title": "MIT’s McGovern Institute is shaping brain science and improving human lives on a global scale",
    "description": "A quarter century after its founding, the McGovern Institute reflects on its discoveries in the areas of neuroscience, neurotechnology, artificial intelligence, brain-body connections, and therapeutics.",
    "summary": "A quarter century after its founding, the McGovern Institute reflects on its discoveries in the areas of neuroscience, neurotechnology, artificial intelligence, brain-body connections, and therapeutics.",
    "pubDate": "Fri, 18 Apr 2025 10:40:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/mit-mcgovern-institute-shaping-brain-science-improving-human-lives-0418",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202504/mit-mcgovern-madonna-fmri-600x900.jpg"
  },
  {
    "title": "3D modeling you can feel",
    "description": "TactStyle, a system developed by CSAIL researchers, uses image prompts to replicate both the visual appearance and tactile properties of 3D models.",
    "summary": "TactStyle, a system developed by CSAIL researchers, uses image prompts to replicate both the visual appearance and tactile properties of 3D models.",
    "pubDate": "Tue, 22 Apr 2025 15:00:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/3d-modeling-you-can-feel-0422",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202504/MIT-TactStyle-00.jpg"
  },
  {
    "title": "Norma Kamali is transforming the future of fashion with AI",
    "description": "The renowned designer embraces generative AI to preserve and propel her legacy.",
    "summary": "The renowned designer embraces generative AI to preserve and propel her legacy.",
    "pubDate": "Tue, 22 Apr 2025 14:00:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/norma-kamali-transforming-future-fashion-ai-0422",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202504/Norma-Kamali.jpg"
  },
  {
    "title": "Speak is personalizing language learning with AI",
    "description": "A conversation with Connor Zwick, CEO & Co-founder of Speak.",
    "summary": "A conversation with Connor Zwick, CEO & Co-founder of Speak.",
    "pubDate": "Tue, 22 Apr 2025 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/speak-connor-zwick",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "The Washington Post partners with OpenAI on search content",
    "description": "The Washington Post is partnering with with OpenAI to integrate news into ChatGPT, providing users with summaries, quotes, and direct links to original reporting.",
    "summary": "The Washington Post is partnering with with OpenAI to integrate news into ChatGPT, providing users with summaries, quotes, and direct links to original reporting.",
    "pubDate": "Tue, 22 Apr 2025 06:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/global-affairs/the-washington-post-partners-with-openai",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Introducing our latest image generation model in the API",
    "description": "Our latest image generation model is now available in the API via ‘gpt-image-1’—enabling developers and businesses to build professional-grade, customizable visuals directly into their own tools and platforms.",
    "summary": "Our latest image generation model is now available in the API via ‘gpt-image-1’—enabling developers and businesses to build professional-grade, customizable visuals directly into their own tools and platforms.",
    "pubDate": "Wed, 23 Apr 2025 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/image-generation-api",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "New model predicts a chemical reaction’s point of no return",
    "description": "Chemists could use this quick computational method to design more efficient reactions that yield useful compounds, from fuels to pharmaceuticals.",
    "summary": "Chemists could use this quick computational method to design more efficient reactions that yield useful compounds, from fuels to pharmaceuticals.",
    "pubDate": "Wed, 23 Apr 2025 11:00:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/new-model-predicts-chemical-reactions-no-return-point-0423",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202504/BetterPredict-01-press.jpg"
  },
  {
    "title": "“Periodic table of machine learning” could fuel AI discovery",
    "description": "Researchers have created a unifying framework that can help scientists combine existing ideas to improve AI models or create new ones.",
    "summary": "Researchers have created a unifying framework that can help scientists combine existing ideas to improve AI models or create new ones.",
    "pubDate": "Wed, 23 Apr 2025 00:00:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/machine-learning-periodic-table-could-fuel-ai-discovery-0423",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202504/MIT_Periodic-Algorithm-01-PRESS.jpg"
  },
  {
    "title": "Designing a new way to optimize complex coordinated systems",
    "description": "Using diagrams to represent interactions in multipart systems can provide a faster way to design software improvements.",
    "summary": "Using diagrams to represent interactions in multipart systems can provide a faster way to design software improvements.",
    "pubDate": "Thu, 24 Apr 2025 15:00:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/designing-new-way-optimize-complex-coordinated-systems-0424",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202504/deep-learning-diagram.jpg"
  },
  {
    "title": "Music AI Sandbox, now with new features and broader access",
    "description": "Helping music professionals explore the potential of generative AI",
    "summary": "Helping music professionals explore the potential of generative AI",
    "pubDate": "Thu, 24 Apr 2025 15:01:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/music-ai-sandbox-now-with-new-features-and-broader-access/",
    "thumbnail": "https://lh3.googleusercontent.com/t_n_87B373tBNlvzgBy7RuJXb5hoPdLtBBgWjzfJnVuauI0JFwiYAyGM_LMl-yeJ3zNWO782VBE8m6ByaxDJoIvIbWoQ_DQPMdxszprk5Tbh2xQx5Q=w1200-h630-n-nu"
  },
  {
    "title": "New in ChatGPT for Business: April 2025",
    "description": "Watch hands-on demos of the lastest in ChatGPT for Business: o3, image generation, enhanced memory, and internal knowledge.",
    "summary": "Watch hands-on demos of the lastest in ChatGPT for Business: o3, image generation, enhanced memory, and internal knowledge.",
    "pubDate": "Thu, 24 Apr 2025 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/business/new-in-chatgpt-for-business-april-updates-2025",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Artificial intelligence enhances air mobility planning",
    "description": "Lincoln Laboratory is transitioning tools to the 618th Air Operations Center to streamline global transport logistics.",
    "summary": "Lincoln Laboratory is transitioning tools to the 618th Air Operations Center to streamline global transport logistics.",
    "pubDate": "Fri, 25 Apr 2025 12:00:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/artificial-intelligence-enhances-air-mobility-planning-0425",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202504/mit-lincoln-lab-us-air-mobility-00.jpg"
  },
  {
    "title": "Novel method detects microbial contamination in cell cultures",
    "description": "Ultraviolet light “fingerprints” on cell cultures and machine learning can provide a definitive yes/no contamination assessment within 30 minutes.",
    "summary": "Ultraviolet light “fingerprints” on cell cultures and machine learning can provide a definitive yes/no contamination assessment within 30 minutes.",
    "pubDate": "Fri, 25 Apr 2025 22:00:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/novel-method-detects-microbial-contamination-smart-0425",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202504/SMART-CAMP-Senior-Research-Engineer.jpg"
  },
  {
    "title": "Tiny Agents: a MCP-powered agent in 50 lines of code",
    "description": "",
    "summary": "",
    "pubDate": "Fri, 25 Apr 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/tiny-agents",
    "thumbnail": "https://huggingface.co/blog/assets/tiny-agents/thumbnail.jpg"
  },
  {
    "title": "Merging design and computer science in creative ways",
    "description": "MAD Fellow Alexander Htet Kyaw connects humans, machines, and the physical world using AI and augmented reality.",
    "summary": "MAD Fellow Alexander Htet Kyaw connects humans, machines, and the physical world using AI and augmented reality.",
    "pubDate": "Mon, 28 Apr 2025 16:55:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/alexander-htet-kyaw-merging-design-computer-science-in-creative-ways-0428",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202504/mit-mad-Alexander-htet-kyaw_0.jpg"
  },
  {
    "title": "Introducing AutoRound: Intel’s Advanced Quantization for LLMs and VLMs",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 29 Apr 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/autoround",
    "thumbnail": "https://huggingface.co/blog/assets/autoround/thumbnail.png"
  },
  {
    "title": "Sycophancy in GPT-4o: what happened and what we’re doing about it",
    "description": "We have rolled back last week’s GPT‑4o update in ChatGPT so people are now using an earlier version with more balanced behavior. The update we removed was overly flattering or agreeable—often described as sycophantic.",
    "summary": "We have rolled back last week’s GPT‑4o update in ChatGPT so people are now using an earlier version with more balanced behavior. The update we removed was overly flattering or agreeable—often described as sycophantic.",
    "pubDate": "Tue, 29 Apr 2025 18:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/sycophancy-in-gpt-4o",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Welcoming Llama Guard 4 on Hugging Face Hub",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 29 Apr 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/llama-guard-4",
    "thumbnail": "https://huggingface.co/blog/assets/llama-guard-4/thumbnail.png"
  },
  {
    "title": "How to Build an MCP Server with Gradio",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 30 Apr 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/gradio-mcp",
    "thumbnail": "https://huggingface.co/blog/assets/gradio-mcp/thumbnail.png"
  },
  {
    "title": "The 4 Things Qwen-3's Chat Template Teaches Us",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 30 Apr 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/qwen-3-chat-template-deep-dive",
    "thumbnail": "https://huggingface.co/blog/assets/qwen-3-chat-template-deep-dive/thumbnail.png"
  },
  {
    "title": "The MIT-Portugal Program enters Phase 4",
    "description": "New phase will support continued exploration of ideas and solutions in fields ranging from AI to nanotech to climate — with emphasis on educational exchanges and entrepreneurship.",
    "summary": "New phase will support continued exploration of ideas and solutions in fields ranging from AI to nanotech to climate — with emphasis on educational exchanges and entrepreneurship.",
    "pubDate": "Wed, 30 Apr 2025 16:20:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/mit-portugal-program-enters-phase-4-0430",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202504/mit-portugal-2024-Conference.jpg"
  },
  {
    "title": "Inception Labsの拡散言語モデルを試してみた",
    "description": "<p>こんにちは、 AIチームの戸田です。 本記事ではInception LabsのMercury APIのベータ版が使えるようになったので、簡単に試してみました。 ドキュメントはこちらで確認できます。 拡散言語モデル 現在の [&#8230;]</p> <p>投稿 <a href='https://www.ai-shift.co.jp/techblog/5738' rel='nofollow'>Inception Labsの拡散言語モデルを試してみた</a> は <a href='https://www.ai-shift.co.jp' rel='nofollow'>株式会社AI Shift</a> に最初に表示されました。</p>",
    "summary": "<p>こんにちは、 AIチームの戸田です。 本記事ではInception LabsのMercury APIのベータ版が使えるようになったので、簡単に試してみました。 ドキュメントはこちらで確認できます。 拡散言語モデル 現在の [&#8230;]</p> <p>投稿 <a href='https://www.ai-shift.co.jp/techblog/5738' rel='nofollow'>Inception Labsの拡散言語モデルを試してみた</a> は <a href='https://www.ai-shift.co.jp' rel='nofollow'>株式会社AI Shift</a> に最初に表示されました。</p>",
    "pubDate": "Thu, 01 May 2025 03:02:11 +0000",
    "source": "AI Shift",
    "url": "https://www.ai-shift.co.jp/techblog/5738",
    "thumbnail": "https://www.ai-shift.co.jp/wp-content/uploads/2025/04/f81fd2e4c52864042852c112ce927ae2-1.png"
  },
  {
    "title": "Making AI models more trustworthy for high-stakes settings",
    "description": "A new method helps convey uncertainty more precisely, which could give researchers and medical clinicians better information to make decisions.",
    "summary": "A new method helps convey uncertainty more precisely, which could give researchers and medical clinicians better information to make decisions.",
    "pubDate": "Thu, 01 May 2025 00:00:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/making-ai-models-more-trustworthy-high-stakes-settings-0501",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202504/MIT_Conformal-Prediction-01.jpg"
  },
  {
    "title": "Expanding on what we missed with sycophancy",
    "description": "A deeper dive on our findings, what went wrong, and future changes we’re making.",
    "summary": "A deeper dive on our findings, what went wrong, and future changes we’re making.",
    "pubDate": "Fri, 02 May 2025 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/expanding-on-sycophancy",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Novel AI model inspired by neural dynamics from the brain",
    "description": "New type of “state-space model” leverages principles of harmonic oscillators.",
    "summary": "New type of “state-space model” leverages principles of harmonic oscillators.",
    "pubDate": "Fri, 02 May 2025 15:30:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/novel-ai-model-inspired-neural-dynamics-from-brain-0502",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202504/MIT-LinOSS.jpg"
  },
  {
    "title": "Evolving OpenAI’s structure",
    "description": "An update from the OpenAI board on transitioning its for-profit entity to a Public Benefit Corporation, reinforcing its mission-driven structure under nonprofit oversight while enabling greater impact and long-term alignment with the public good.",
    "summary": "An update from the OpenAI board on transitioning its for-profit entity to a Public Benefit Corporation, reinforcing its mission-driven structure under nonprofit oversight while enabling greater impact and long-term alignment with the public good.",
    "pubDate": "Mon, 05 May 2025 11:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/evolving-our-structure",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Lowe’s leverages AI to power home improvement retail",
    "description": "A conversation with Chandhu Nair, Senior Vice President of Data, AI, and Innovation.",
    "summary": "A conversation with Chandhu Nair, Senior Vice President of Data, AI, and Innovation.",
    "pubDate": "Mon, 05 May 2025 05:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/lowes-chandhu-nair",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "New tool evaluates progress in reinforcement learning",
    "description": "“IntersectionZoo,” a benchmarking tool, uses a real-world traffic problem to test progress in deep reinforcement learning algorithms.",
    "summary": "“IntersectionZoo,” a benchmarking tool, uses a real-world traffic problem to test progress in deep reinforcement learning algorithms.",
    "pubDate": "Mon, 05 May 2025 16:00:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/new-tool-evaluate-progress-reinforcement-learning-0505",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202504/Intersection-Zoo.jpg"
  },
  {
    "title": "Q&A: A roadmap for revolutionizing health care through data-driven innovation",
    "description": "A new book coauthored by MIT’s Dimitris Bertsimas explores how analytics is driving decisions and outcomes in health care.",
    "summary": "A new book coauthored by MIT’s Dimitris Bertsimas explores how analytics is driving decisions and outcomes in health care.",
    "pubDate": "Mon, 05 May 2025 16:15:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/qa-roadmap-revolutionizing-health-care-through-data-driven-innovation-0505",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202505/Analytics-Edge-in-Healthcare-Dimitris-Bertsimas-00.png"
  },
  {
    "title": "AI helps John Deere transform agriculture",
    "description": "John Deere’s Justin Rose talks about transforming agriculture with AI and shares how the company is scaling innovation to help farmers work smarter, more efficiently, and sustainably.",
    "summary": "John Deere’s Justin Rose talks about transforming agriculture with AI and shares how the company is scaling innovation to help farmers work smarter, more efficiently, and sustainably.",
    "pubDate": "Tue, 06 May 2025 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/john-deere-justin-rose",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Build rich, interactive web apps with an updated Gemini 2.5 Pro",
    "description": "Our updated version of Gemini 2.5 Pro Preview has improved capabilities for coding.",
    "summary": "Our updated version of Gemini 2.5 Pro Preview has improved capabilities for coding.",
    "pubDate": "Tue, 06 May 2025 15:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/build-rich-interactive-web-apps-with-an-updated-gemini-25-pro/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/gemini25prohero.width-1300.png"
  },
  {
    "title": "Gemini 2.5 Pro Preview: even better coding performance",
    "description": "We’ve seen developers doing amazing things with Gemini 2.5 Pro, so we decided to release an updated version a couple of weeks early to get into developers hands sooner.",
    "summary": "We’ve seen developers doing amazing things with Gemini 2.5 Pro, so we decided to release an updated version a couple of weeks early to get into developers hands sooner.",
    "pubDate": "Tue, 06 May 2025 15:06:55 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/gemini-25-pro-preview-even-better-coding-performance/",
    "thumbnail": "https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/gemini_2-5_pro_claybrook__dev_her.2e16d0ba.fill-1200x600.jpg"
  },
  {
    "title": "Hybrid AI model crafts smooth, high-quality videos in seconds",
    "description": "The CausVid generative AI tool uses a diffusion model to teach an autoregressive (frame-by-frame) system to rapidly produce stable, high-resolution videos.",
    "summary": "The CausVid generative AI tool uses a diffusion model to teach an autoregressive (frame-by-frame) system to rapidly produce stable, high-resolution videos.",
    "pubDate": "Tue, 06 May 2025 12:15:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/causevid-hybrid-ai-model-crafts-smooth-high-quality-videos-in-seconds-0506",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202504/MIT-CausVid.jpg"
  },
  {
    "title": "Introducing AI stories: daily benefits shine a light on bigger opportunities",
    "description": "Sam Altman has written that we are entering the Intelligence Age, a time when AI will help people become dramatically more capable. The biggest problems of today—across science, medicine, education, national defense—will no longer seem intractable, but will in fact be solvable. New horizons of possibility and prosperity will open up.",
    "summary": "Sam Altman has written that we are entering the Intelligence Age, a time when AI will help people become dramatically more capable. The biggest problems of today—across science, medicine, education, national defense—will no longer seem intractable, but will in fact be solvable. New horizons of possibility and prosperity will open up.",
    "pubDate": "Tue, 06 May 2025 10:30:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/global-affairs/ai-stories-daily-benefits-bigger-opportunities",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Introducing data residency in Asia",
    "description": "Data residency builds on OpenAI’s enterprise-grade data privacy, security, and compliance programs supporting customers worldwide.",
    "summary": "Data residency builds on OpenAI’s enterprise-grade data privacy, security, and compliance programs supporting customers worldwide.",
    "pubDate": "Wed, 07 May 2025 18:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-data-residency-in-asia",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Introducing OpenAI for Countries",
    "description": "A new initiative to support countries around the world that want to build on democratic AI rails.",
    "summary": "A new initiative to support countries around the world that want to build on democratic AI rails.",
    "pubDate": "Wed, 07 May 2025 03:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/global-affairs/openai-for-countries",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Lowe’s puts project expertise into every hand",
    "description": "Lowe’s partnered with OpenAI to build Mylow and Mylow Companion, AI-powered tools that bring expert help to both customers and store associates—making complex home improvement projects easier to plan, navigate, and complete.",
    "summary": "Lowe’s partnered with OpenAI to build Mylow and Mylow Companion, AI-powered tools that bring expert help to both customers and store associates—making complex home improvement projects easier to plan, navigate, and complete.",
    "pubDate": "Wed, 07 May 2025 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/lowes",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "OpenAI Expands Leadership with Fidji Simo",
    "description": "Read the message Sam shared with the company earlier today.",
    "summary": "Read the message Sam shared with the company earlier today.",
    "pubDate": "Wed, 07 May 2025 21:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/leadership-expansion-with-fidji-simo",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "OpenAI’s response to the Department of Energy on AI infrastructure",
    "description": "Why infrastructure is destiny and how the US can seize it.",
    "summary": "Why infrastructure is destiny and how the US can seize it.",
    "pubDate": "Wed, 07 May 2025 18:30:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/global-affairs/response-to-department-of-energy",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "The San Antonio Spurs use ChatGPT to scale impact on and off the court",
    "description": "Discover how the San Antonio Spurs are using custom GPTs to enhance fan engagement, streamline operations, and drive innovation across teams.",
    "summary": "Discover how the San Antonio Spurs are using custom GPTs to enhance fan engagement, streamline operations, and drive innovation across teams.",
    "pubDate": "Wed, 07 May 2025 09:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/san-antonio-spurs",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "LeRobot Community Datasets: The “ImageNet” of Robotics — When and How?",
    "description": "",
    "summary": "",
    "pubDate": "Sun, 11 May 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/lerobot-datasets",
    "thumbnail": "https://huggingface.co/blog/assets/195_lerobot_datasets/1.png"
  },
  {
    "title": "Introducing HealthBench",
    "description": "HealthBench is a new evaluation benchmark for AI in healthcare which evaluates models in realistic scenarios. Built with input from 250+ physicians, it aims to provide a shared standard for model performance and safety in health.",
    "summary": "HealthBench is a new evaluation benchmark for AI in healthcare which evaluates models in realistic scenarios. Built with input from 250+ physicians, it aims to provide a shared standard for model performance and safety in health.",
    "pubDate": "Mon, 12 May 2025 10:30:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/healthbench",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Vision Language Models (Better, Faster, Stronger)",
    "description": "",
    "summary": "",
    "pubDate": "Mon, 12 May 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/vlms-2025",
    "thumbnail": "https://huggingface.co/blog/assets/vlms2/vlms2.png"
  },
  {
    "title": "Blazingly fast whisper transcriptions with Inference Endpoints",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 13 May 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/fast-whisper-endpoints",
    "thumbnail": "https://huggingface.co/blog/assets/fast-whisper-endpoints/thumbnail.png"
  },
  {
    "title": "MIT Department of Economics to launch James M. and Cathleen D. Stone Center on Inequality and Shaping the Future of Work",
    "description": "With support from the Stone Foundation, the center will advance cutting-edge research and inform policy.",
    "summary": "With support from the Stone Foundation, the center will advance cutting-edge research and inform policy.",
    "pubDate": "Tue, 13 May 2025 16:35:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/mit-economics-department-launches-james-cathleen-stone-center-inequality-shaping-future-work-0513",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202505/mit-campus.jpg"
  },
  {
    "title": "AI powers Expedia’s marketing evolution",
    "description": "A conversation with Jochen Koedijk, Chief Marketing Officer of Expedia Group.",
    "summary": "A conversation with Jochen Koedijk, Chief Marketing Officer of Expedia Group.",
    "pubDate": "Wed, 14 May 2025 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/expedia-jochen-koedijk",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "AlphaEvolve: A Gemini-powered coding agent for designing advanced algorithms",
    "description": "New AI agent evolves algorithms for math and practical applications in computing by combining the creativity of large language models with automated evaluators",
    "summary": "New AI agent evolves algorithms for math and practical applications in computing by combining the creativity of large language models with automated evaluators",
    "pubDate": "Wed, 14 May 2025 14:59:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/alphaevolve-a-gemini-powered-coding-agent-for-designing-advanced-algorithms/",
    "thumbnail": "https://lh3.googleusercontent.com/tG6-MqdlvhQ-z7ENzGxR-kpGPPdPHbJ8UZtbTP66Rxi0UftTFU1yAvaBCVuigYuKvESMeEFf4jqNBVENFcZXEUnj8SSqj8zsop8UHAl0eD9A-hUCvQ=w1200-h630-n-nu"
  },
  {
    "title": "Improving Hugging Face Model Access for Kaggle Users",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 14 May 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/kaggle-integration",
    "thumbnail": "https://huggingface.co/blog/assets/kaggle-integration/thumbnail.png"
  },
  {
    "title": "Study shows vision-language models can’t handle queries with negation words",
    "description": "Words like “no” and “not” can cause this popular class of AI models to fail unexpectedly in high-stakes settings, such as medical diagnosis.",
    "summary": "Words like “no” and “not” can cause this popular class of AI models to fail unexpectedly in high-stakes settings, such as medical diagnosis.",
    "pubDate": "Wed, 14 May 2025 00:00:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/study-shows-vision-language-models-cant-handle-negation-words-queries-0514",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202505/MIT-LMNegation-01-press.jpg"
  },
  {
    "title": "The Transformers Library: standardizing model definitions",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 15 May 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/transformers-model-definition",
    "thumbnail": "https://huggingface.co/blog/assets/transformers-model-definition/transformers-thumbnail.png"
  },
  {
    "title": "With AI, researchers predict the location of virtually any protein within a human cell",
    "description": "Trained with a joint understanding of protein and cell behavior, the model could help with diagnosing disease and developing new drugs.",
    "summary": "Trained with a joint understanding of protein and cell behavior, the model could help with diagnosing disease and developing new drugs.",
    "pubDate": "Thu, 15 May 2025 10:30:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/researchers-predict-protein-location-within-human-cell-using-ai-0515",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202505/MIT-ProteinLocalization-01-press.jpg"
  },
  {
    "title": "Addendum to o3 and o4-mini system card: Codex",
    "description": "Codex is a cloud-based coding agent. Codex is powered by codex-1, a version of OpenAI o3 optimized for software engineering. codex-1 was trained using reinforcement learning on real-world coding tasks in a variety of environments to generate code that closely mirrors human style and PR preferences, adheres precisely to instructions, and iteratively runs tests until passing results are achieved.",
    "summary": "Codex is a cloud-based coding agent. Codex is powered by codex-1, a version of OpenAI o3 optimized for software engineering. codex-1 was trained using reinforcement learning on real-world coding tasks in a variety of environments to generate code that closely mirrors human style and PR preferences, adheres precisely to instructions, and iteratively runs tests until passing results are achieved.",
    "pubDate": "Fri, 16 May 2025 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/o3-o4-mini-codex-system-card-addendum",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Introducing Codex",
    "description": "Introducing Codex: a cloud-based software engineering agent that can work on many tasks in parallel, powered by codex-1. With Codex, developers can simultaneously deploy multiple agents to independently handle coding tasks such as writing features, answering questions about your codebase, fixing bugs, and proposing pull requests for review.",
    "summary": "Introducing Codex: a cloud-based software engineering agent that can work on many tasks in parallel, powered by codex-1. With Codex, developers can simultaneously deploy multiple agents to independently handle coding tasks such as writing features, answering questions about your codebase, fixing bugs, and proposing pull requests for review.",
    "pubDate": "Fri, 16 May 2025 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-codex",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "LLMの推論における “aha moment” について調べてみた",
    "description": "<p>こんにちは AIチームの戸田です 先日、LLMの 'aha moment' に関して興味を持ち、関連論文やWeb上の記事を読んでみたところ、賛否両論の様々な見解があり興味深かったので、今回はその内容を共有したいと思います [&#8230;]</p> <p>投稿 <a href='https://www.ai-shift.co.jp/techblog/5766' rel='nofollow'>LLMの推論における &#8220;aha moment&#8221; について調べてみた</a> は <a href='https://www.ai-shift.co.jp' rel='nofollow'>株式会社AI Shift</a> に最初に表示されました。</p>",
    "summary": "<p>こんにちは AIチームの戸田です 先日、LLMの 'aha moment' に関して興味を持ち、関連論文やWeb上の記事を読んでみたところ、賛否両論の様々な見解があり興味深かったので、今回はその内容を共有したいと思います [&#8230;]</p> <p>投稿 <a href='https://www.ai-shift.co.jp/techblog/5766' rel='nofollow'>LLMの推論における &#8220;aha moment&#8221; について調べてみた</a> は <a href='https://www.ai-shift.co.jp' rel='nofollow'>株式会社AI Shift</a> に最初に表示されました。</p>",
    "pubDate": "Fri, 16 May 2025 04:41:37 +0000",
    "source": "AI Shift",
    "url": "https://www.ai-shift.co.jp/techblog/5766",
    "thumbnail": "https://www.ai-shift.co.jp/wp-content/uploads/2025/05/d099d886ed65ef765625779e628d2c5f.png"
  },
  {
    "title": "Microsoft and Hugging Face expand collaboration",
    "description": "",
    "summary": "",
    "pubDate": "Mon, 19 May 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/azure-ai-foundry",
    "thumbnail": "https://huggingface.co/blog/assets/azure-ai-foundry/satya-hf-build-compressed.png"
  },
  {
    "title": "The sweet taste of a new idea",
    "description": "Sendhil Mullainathan brings a lifetime of unique perspectives to research in behavioral economics and machine learning.",
    "summary": "Sendhil Mullainathan brings a lifetime of unique perspectives to research in behavioral economics and machine learning.",
    "pubDate": "Mon, 19 May 2025 16:30:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/sweet-taste-new-idea-sendhil-mullainathan-0519",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202505/mit-sendhil-Mullainathan.jpg"
  },
  {
    "title": "Advancing Gemini's security safeguards",
    "description": "We’ve made Gemini 2.5 our most secure model family to date.",
    "summary": "We’ve made Gemini 2.5 our most secure model family to date.",
    "pubDate": "Tue, 20 May 2025 09:45:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/advancing-geminis-security-safeguards/",
    "thumbnail": "https://lh3.googleusercontent.com/Uh_O6Nx1GWznAfODatYYz2sxiDekdb6HWnnSsy-cfmTxfjdUEEleh9w4cBdwUfBnyQBS-t1xW4UZXrMmC-rI6bz31hCrm5nHLt6Cp1FJAT7X9Upv5g=w1200-h630-n-nu"
  },
  {
    "title": "Announcing Gemma 3n preview: Powerful, efficient, mobile-first AI",
    "description": "Gemma 3n is a cutting-edge open model designed for fast, multimodal AI on devices, featuring optimized performance, unique flexibility with a 2-in-1 model, and expanded multimodal understanding with audio, empowering developers to build live, interactive applications and sophisticated audio-centric experiences.",
    "summary": "Gemma 3n is a cutting-edge open model designed for fast, multimodal AI on devices, featuring optimized performance, unique flexibility with a 2-in-1 model, and expanded multimodal understanding with audio, empowering developers to build live, interactive applications and sophisticated audio-centric experiences.",
    "pubDate": "Tue, 20 May 2025 09:45:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/announcing-gemma-3n-preview-powerful-efficient-mobile-first-ai/",
    "thumbnail": "https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/Gemma3n_Metadatal_RD2-V01.2e16d0ba.fill-1200x600.jpg"
  },
  {
    "title": "Collaborators: Healthcare Innovation to Impact",
    "description": "<p>In this discussion, Matthew Lungren, Jonathan Carlson, Smitha Saligrama, Will Guyman, and Cameron Runde explore how teams across Microsoft are working together to generate advanced AI capabilities and solutions for developers and clinicians around the globe. </p> <p>The post <a href='https://www.microsoft.com/en-us/research/podcast/collaborators-healthcare-innovation-to-impact/'>Collaborators: Healthcare Innovation to Impact</a> appeared first on <a href='https://www.microsoft.com/en-us/research'>Microsoft Research</a>.</p>",
    "summary": "<p>In this discussion, Matthew Lungren, Jonathan Carlson, Smitha Saligrama, Will Guyman, and Cameron Runde explore how teams across Microsoft are working together to generate advanced AI capabilities and solutions for developers and clinicians around the globe. </p> <p>The post <a href='https://www.microsoft.com/en-us/research/podcast/collaborators-healthcare-innovation-to-impact/'>Collaborators: Healthcare Innovation to Impact</a> appeared first on <a href='https://www.microsoft.com/en-us/research'>Microsoft Research</a>.</p>",
    "pubDate": "Tue, 20 May 2025 20:39:01 +0000",
    "source": "Microsoft Research Blog",
    "url": "https://www.microsoft.com/en-us/research/podcast/collaborators-healthcare-innovation-to-impact/",
    "thumbnail": "https://img-prod-cms-rt-microsoft-com.akamaized.net/cms/api/am/imageFileData/RE1Mu3b?ver=5c31&h=30"
  },
  {
    "title": "Fuel your creativity with new generative media models and tools",
    "description": "Introducing Veo 3 and Imagen 4, and a new tool for filmmaking called Flow.",
    "summary": "Introducing Veo 3 and Imagen 4, and a new tool for filmmaking called Flow.",
    "pubDate": "Tue, 20 May 2025 09:45:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/fuel-your-creativity-with-new-generative-media-models-and-tools/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/5.20v2_SS_1920x1080.width-1300.png"
  },
  {
    "title": "Gemini 2.5: Our most intelligent models are getting even better",
    "description": "Gemini 2.5 Pro continues to be loved by developers as the best model for coding, and 2.5 Flash is getting even better with a new update. We’re bringing new capabilities to our models, including Deep Think, an experimental enhanced reasoning mode for 2.5 Pro.",
    "summary": "Gemini 2.5 Pro continues to be loved by developers as the best model for coding, and 2.5 Flash is getting even better with a new update. We’re bringing new capabilities to our models, including Deep Think, an experimental enhanced reasoning mode for 2.5 Pro.",
    "pubDate": "Tue, 20 May 2025 09:45:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/gemini-25-our-world-leading-model-is-getting-even-better/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/deep-think__key-art_16-9.width-1300.jpg"
  },
  {
    "title": "Our vision for building a universal AI assistant",
    "description": "We’re extending Gemini to become a world model that can make plans and imagine new experiences by simulating aspects of the world.",
    "summary": "We’re extending Gemini to become a world model that can make plans and imagine new experiences by simulating aspects of the world.",
    "pubDate": "Tue, 20 May 2025 09:45:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/our-vision-for-building-a-universal-ai-assistant/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/IO25_GeminiVision_SocialShare.width-1300.png"
  },
  {
    "title": "SynthID Detector — a new portal to help identify AI-generated content",
    "description": "Learn about the new SynthID Detector portal we announced at I/O to help people understand how the content they see online was generated.",
    "summary": "Learn about the new SynthID Detector portal we announced at I/O to help people understand how the content they see online was generated.",
    "pubDate": "Tue, 20 May 2025 09:45:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/synthid-detector--a-new-portal-to-help-identify-ai-generated-content/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/IO25_Gemini_MOD_HEADER.width-1300.jpg"
  },
  {
    "title": "Abstracts: Aurora with Megan Stanley and Wessel Bruinsma",
    "description": "<p>A new Nature paper explores Aurora, an AI model that redefines weather prediction with application to other environmental domains such as tropical cyclones. Hear from senior researchers Megan Stanley and Wessel Bruinsma as they share their groundbreaking work.</p> <p>The post <a href='https://www.microsoft.com/en-us/research/podcast/abstracts-aurora-with-megan-stanley-and-wessel-bruinsma/'>Abstracts: Aurora with Megan Stanley and Wessel Bruinsma</a> appeared first on <a href='https://www.microsoft.com/en-us/research'>Microsoft Research</a>.</p>",
    "summary": "<p>A new Nature paper explores Aurora, an AI model that redefines weather prediction with application to other environmental domains such as tropical cyclones. Hear from senior researchers Megan Stanley and Wessel Bruinsma as they share their groundbreaking work.</p> <p>The post <a href='https://www.microsoft.com/en-us/research/podcast/abstracts-aurora-with-megan-stanley-and-wessel-bruinsma/'>Abstracts: Aurora with Megan Stanley and Wessel Bruinsma</a> appeared first on <a href='https://www.microsoft.com/en-us/research'>Microsoft Research</a>.</p>",
    "pubDate": "Wed, 21 May 2025 15:22:51 +0000",
    "source": "Microsoft Research Blog",
    "url": "https://www.microsoft.com/en-us/research/podcast/abstracts-aurora-with-megan-stanley-and-wessel-bruinsma/",
    "thumbnail": "https://img-prod-cms-rt-microsoft-com.akamaized.net/cms/api/am/imageFileData/RE1Mu3b?ver=5c31&h=30"
  },
  {
    "title": "Exploring Quantization Backends in Diffusers",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 21 May 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/diffusers-quantization",
    "thumbnail": "https://huggingface.co/blog/assets/diffusers-quantization/thumbnail.png"
  },
  {
    "title": "Learning how to predict rare kinds of failures",
    "description": "Researchers are developing algorithms to predict failures when automation meets the real world in areas like air traffic scheduling or autonomous vehicles.",
    "summary": "Researchers are developing algorithms to predict failures when automation meets the real world in areas like air traffic scheduling or autonomous vehicles.",
    "pubDate": "Wed, 21 May 2025 16:35:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/learning-how-predict-rare-kinds-failures-0521",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202505/mit-rare-event-modeling.jpg"
  },
  {
    "title": "nanoVLM: The simplest repository to train your VLM in pure PyTorch",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 21 May 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/nanovlm",
    "thumbnail": "https://huggingface.co/blog/assets/nanovlm/thumbnail.png"
  },
  {
    "title": "New tools and features in the Responses API",
    "description": "New features in the Responses API: Remote MCP, image gen, Code Interpreter, and more. Powering faster, smarter agents with GPT-4o & o-series models, plus new features for reliability and efficiency.",
    "summary": "New features in the Responses API: Remote MCP, image gen, Code Interpreter, and more. Powering faster, smarter agents with GPT-4o & o-series models, plus new features for reliability and efficiency.",
    "pubDate": "Wed, 21 May 2025 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/new-tools-and-features-in-the-responses-api",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Sam & Jony",
    "description": "Sam & Jony",
    "summary": "Sam & Jony",
    "pubDate": "Wed, 21 May 2025 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/sam-and-jony",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Abstracts: Zero-shot models in single-cell biology with Alex Lu",
    "description": "<p>The emergence of foundation models has sparked interest in applications to single-cell biology, but when tested in zero-shot settings, they underperform compared to simpler methods. Alex Lu shares insights on why more research on AI models is needed in biological applications.</p> <p>The post <a href='https://www.microsoft.com/en-us/research/podcast/abstracts-zero-shot-models-in-single-cell-biology-with-alex-lu/'>Abstracts: Zero-shot models in single-cell biology with Alex Lu</a> appeared first on <a href='https://www.microsoft.com/en-us/research'>Microsoft Research</a>.</p>",
    "summary": "<p>The emergence of foundation models has sparked interest in applications to single-cell biology, but when tested in zero-shot settings, they underperform compared to simpler methods. Alex Lu shares insights on why more research on AI models is needed in biological applications.</p> <p>The post <a href='https://www.microsoft.com/en-us/research/podcast/abstracts-zero-shot-models-in-single-cell-biology-with-alex-lu/'>Abstracts: Zero-shot models in single-cell biology with Alex Lu</a> appeared first on <a href='https://www.microsoft.com/en-us/research'>Microsoft Research</a>.</p>",
    "pubDate": "Thu, 22 May 2025 15:58:00 +0000",
    "source": "Microsoft Research Blog",
    "url": "https://www.microsoft.com/en-us/research/podcast/abstracts-zero-shot-models-in-single-cell-biology-with-alex-lu/",
    "thumbnail": "https://img-prod-cms-rt-microsoft-com.akamaized.net/cms/api/am/imageFileData/RE1Mu3b?ver=5c31&h=30"
  },
  {
    "title": "AI learns how vision and sound are connected, without human intervention",
    "description": "This new machine-learning model can match corresponding audio and visual data, which could someday help robots interact in the real world.",
    "summary": "This new machine-learning model can match corresponding audio and visual data, which could someday help robots interact in the real world.",
    "pubDate": "Thu, 22 May 2025 00:00:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/ai-learns-how-vision-and-sound-are-connected-without-human-intervention-0522",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202505/MIT-AV-Learning-01-press.jpg"
  },
  {
    "title": "Introducing Stargate UAE",
    "description": "We’re launching Stargate UAE – the first international deployment of Stargate, OpenAI’s AI infrastructure platform.",
    "summary": "We’re launching Stargate UAE – the first international deployment of Stargate, OpenAI’s AI infrastructure platform.",
    "pubDate": "Thu, 22 May 2025 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-stargate-uae",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "OpenAI Deutschland",
    "description": "OpenAI announces the opening of its first office in Germany, based in Munich.",
    "summary": "OpenAI announces the opening of its first office in Germany, based in Munich.",
    "pubDate": "Thu, 22 May 2025 23:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-deutschland",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Shipping code faster with o3, o4-mini, and GPT-4.1",
    "description": "CodeRabbit uses OpenAI models to revolutionize code reviews—boosting accuracy, accelerating PR merges, and helping developers ship faster with fewer bugs and higher ROI.",
    "summary": "CodeRabbit uses OpenAI models to revolutionize code reviews—boosting accuracy, accelerating PR merges, and helping developers ship faster with fewer bugs and higher ROI.",
    "pubDate": "Thu, 22 May 2025 10:25:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/coderabbit",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Addendum to OpenAI o3 and o4-mini system card: OpenAI o3 Operator",
    "description": "We are replacing the existing GPT-4o-based model for Operator with a version based on OpenAI o3. The API version will remain based on 4o.",
    "summary": "We are replacing the existing GPT-4o-based model for Operator with a version based on OpenAI o3. The API version will remain based on 4o.",
    "pubDate": "Fri, 23 May 2025 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/o3-o4-mini-system-card-addendum-operator-o3",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Dell Enterprise Hub is all you need to build AI on premises",
    "description": "",
    "summary": "",
    "pubDate": "Fri, 23 May 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/dell-ai-applications",
    "thumbnail": "https://huggingface.co/blog/assets/dell-ai-applications/dell-post-thumbnail.png"
  },
  {
    "title": "Tiny Agents in Python: a MCP-powered agent in ~70 lines of code",
    "description": "",
    "summary": "",
    "pubDate": "Fri, 23 May 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/python-tiny-agents",
    "thumbnail": "https://huggingface.co/blog/assets/python-tiny-agents/thumbnail.png"
  },
  {
    "title": "🐯 Liger GRPO meets TRL",
    "description": "",
    "summary": "",
    "pubDate": "Sun, 25 May 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/liger-grpo",
    "thumbnail": "https://huggingface.co/blog/assets/liger-grpo/thumbnail.png"
  },
  {
    "title": "Building networks of data science talent",
    "description": "Through collaborations with organizations like BREIT in Peru, the MIT Institute for Data, Systems, and Society is upskilling hundreds of learners around the world in data science and machine learning.",
    "summary": "Through collaborations with organizations like BREIT in Peru, the MIT Institute for Data, Systems, and Society is upskilling hundreds of learners around the world in data science and machine learning.",
    "pubDate": "Tue, 27 May 2025 16:11:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/building-networks-data-science-talent-0527",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202504/mit-breit-idss-killian.jpg"
  },
  {
    "title": "FrodoKEM: A conservative quantum-safe cryptographic algorithm",
    "description": "<p>The recent advances in quantum computing offer many advantages—but also challenge current cryptographic strategies. Learn how FrodoKEM could help strengthen security, even in a future with powerful quantum computers.</p> <p>The post <a href='https://www.microsoft.com/en-us/research/blog/frodokem-a-conservative-quantum-safe-cryptographic-algorithm/'>FrodoKEM: A conservative quantum-safe cryptographic algorithm</a> appeared first on <a href='https://www.microsoft.com/en-us/research'>Microsoft Research</a>.</p>",
    "summary": "<p>The recent advances in quantum computing offer many advantages—but also challenge current cryptographic strategies. Learn how FrodoKEM could help strengthen security, even in a future with powerful quantum computers.</p> <p>The post <a href='https://www.microsoft.com/en-us/research/blog/frodokem-a-conservative-quantum-safe-cryptographic-algorithm/'>FrodoKEM: A conservative quantum-safe cryptographic algorithm</a> appeared first on <a href='https://www.microsoft.com/en-us/research'>Microsoft Research</a>.</p>",
    "pubDate": "Tue, 27 May 2025 16:00:00 +0000",
    "source": "Microsoft Research Blog",
    "url": "https://www.microsoft.com/en-us/research/blog/frodokem-a-conservative-quantum-safe-cryptographic-algorithm/",
    "thumbnail": "https://img-prod-cms-rt-microsoft-com.akamaized.net/cms/api/am/imageFileData/RE1Mu3b?ver=5c31&h=30"
  },
  {
    "title": "MIT announces the Initiative for New Manufacturing",
    "description": "The Institute-wide effort aims to bolster industry and create jobs by driving innovation across vital manufacturing sectors.",
    "summary": "The Institute-wide effort aims to bolster industry and create jobs by driving innovation across vital manufacturing sectors.",
    "pubDate": "Tue, 27 May 2025 10:00:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/mit-announces-initiative-for-new-manufacturing-0527",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202505/MIT-ManufacturingAnn-01-press.jpg"
  },
  {
    "title": "10 tips for 10 years of Google Photos",
    "description": "Google Photos logo with the number ten and colorful confetti shapes.",
    "summary": "Google Photos logo with the number ten and colorful confetti shapes.",
    "pubDate": "Wed, 28 May 2025 17:00:00 +0000",
    "source": "Google AI Blog",
    "url": "https://blog.google/products/photos/google-photos-10-years-tips-tricks/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/GooglePhotos-10year-Blog-header.width-1300.png"
  },
  {
    "title": "An anomaly detection framework anyone can use",
    "description": "PhD student Sarah Alnegheimish wants to make machine learning systems accessible.",
    "summary": "PhD student Sarah Alnegheimish wants to make machine learning systems accessible.",
    "pubDate": "Wed, 28 May 2025 16:00:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/anomaly-detection-framework-anyone-can-use-sarah-alnegheimish-0528",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202505/mit-Sarah-Abdulaziz-Alnegheimish.JPG"
  },
  {
    "title": "CodeAgents + Structure: A Better Way to Execute Actions",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 28 May 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/structured-codeagent",
    "thumbnail": "https://huggingface.co/blog/assets/structured-codeagent/thumbnail-codeagent.png"
  },
  {
    "title": "Rationale engineering generates a compact new tool for gene therapy",
    "description": "Researchers redesign a compact RNA-guided enzyme from bacteria, making it an efficient editor of human DNA.",
    "summary": "Researchers redesign a compact RNA-guided enzyme from bacteria, making it an efficient editor of human DNA.",
    "pubDate": "Wed, 28 May 2025 16:15:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/rationale-engineering-generates-compact-new-tool-gene-therapy-0528",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202505/phylogenetic-tree.jpg"
  },
  {
    "title": "Creating websites in minutes with AI Website Builder",
    "description": "Wix’s AI Website Builder, powered by OpenAI, lets anyone create a full website in minutes—just by describing their idea in a conversation.",
    "summary": "Wix’s AI Website Builder, powered by OpenAI, lets anyone create a full website in minutes—just by describing their idea in a conversation.",
    "pubDate": "Thu, 29 May 2025 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/wix",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "What AI’s impact on individuals means for the health workforce and industry",
    "description": "<p>Ethan Mollick and Azeem Azhar, thought leaders at the forefront of AI’s influence on work, education, and society, discuss the impact of AI at the individual level and what that means for the healthcare workforce and the organizations and systems in medicine.</p> <p>The post <a href='https://www.microsoft.com/en-us/research/podcast/what-ais-impact-on-individuals-means-for-the-health-workforce-and-industry/'>What AI&#8217;s impact on individuals means for the health workforce and industry</a> appeared first on <a href='https://www.microsoft.com/en-us/research'>Microsoft Research</a>.</p>",
    "summary": "<p>Ethan Mollick and Azeem Azhar, thought leaders at the forefront of AI’s influence on work, education, and society, discuss the impact of AI at the individual level and what that means for the healthcare workforce and the organizations and systems in medicine.</p> <p>The post <a href='https://www.microsoft.com/en-us/research/podcast/what-ais-impact-on-individuals-means-for-the-health-workforce-and-industry/'>What AI&#8217;s impact on individuals means for the health workforce and industry</a> appeared first on <a href='https://www.microsoft.com/en-us/research'>Microsoft Research</a>.</p>",
    "pubDate": "Thu, 29 May 2025 15:13:48 +0000",
    "source": "Microsoft Research Blog",
    "url": "https://www.microsoft.com/en-us/research/podcast/what-ais-impact-on-individuals-means-for-the-health-workforce-and-industry/",
    "thumbnail": "https://img-prod-cms-rt-microsoft-com.akamaized.net/cms/api/am/imageFileData/RE1Mu3b?ver=5c31&h=30"
  },
  {
    "title": "E2E音声対話API・構築プラットフォーム最新動向の調査と自律型音声対話システムの展望",
    "description": "<p>はじめに こんにちは、AIチームの大竹です。 近年、音声対話アプリケーションの進化が目覚ましく、顧客対応の自動化や業務効率化への期待が高まっています。弊社のAI Messenger Voicebotも例外ではなく、最先端 [&#8230;]</p> <p>投稿 <a href='https://www.ai-shift.co.jp/techblog/5852' rel='nofollow'>E2E音声対話API・構築プラットフォーム最新動向の調査と自律型音声対話システムの展望</a> は <a href='https://www.ai-shift.co.jp' rel='nofollow'>株式会社AI Shift</a> に最初に表示されました。</p>",
    "summary": "<p>はじめに こんにちは、AIチームの大竹です。 近年、音声対話アプリケーションの進化が目覚ましく、顧客対応の自動化や業務効率化への期待が高まっています。弊社のAI Messenger Voicebotも例外ではなく、最先端 [&#8230;]</p> <p>投稿 <a href='https://www.ai-shift.co.jp/techblog/5852' rel='nofollow'>E2E音声対話API・構築プラットフォーム最新動向の調査と自律型音声対話システムの展望</a> は <a href='https://www.ai-shift.co.jp' rel='nofollow'>株式会社AI Shift</a> に最初に表示されました。</p>",
    "pubDate": "Fri, 30 May 2025 01:38:01 +0000",
    "source": "AI Shift",
    "url": "https://www.ai-shift.co.jp/techblog/5852",
    "thumbnail": "https://www.ai-shift.co.jp/wp-content/uploads/2025/05/icon.png"
  },
  {
    "title": "How Google is driving a new era of American innovation in Iowa.",
    "description": "A group of six people, five women and one man, stand smiling on a white platform. They are positioned outdoors with a large data center featuring a Google logo and an American flag hanging from it in the background. Construction equipment, including a yellow crane, is visible next to the building.",
    "summary": "A group of six people, five women and one man, stand smiling on a white platform. They are positioned outdoors with a large data center featuring a Google logo and an American flag hanging from it in the background. Construction equipment, including a yellow crane, is visible next to the building.",
    "pubDate": "Fri, 30 May 2025 19:08:00 +0000",
    "source": "Google AI Blog",
    "url": "https://blog.google/feed/new-7-billion-investment-iowa/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Iowa_SS.max-1440x810.png"
  },
  {
    "title": "3 Questions: How to help students recognize potential bias in their AI datasets",
    "description": "Courses on developing AI models for health care need to focus more on identifying and addressing bias, says Leo Anthony Celi.",
    "summary": "Courses on developing AI models for health care need to focus more on identifying and addressing bias, says Leo Anthony Celi.",
    "pubDate": "Mon, 02 Jun 2025 10:30:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/3-questions-recognizing-potential-bias-in-ai-datasets-0602",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202506/MIT_AI-Health-Data-01.jpg"
  },
  {
    "title": "AI stirs up the recipe for concrete in MIT study",
    "description": "With demand for cement alternatives rising, an MIT team uses machine learning to hunt for new ingredients across the scientific literature.",
    "summary": "With demand for cement alternatives rising, an MIT team uses machine learning to hunt for new ingredients across the scientific literature.",
    "pubDate": "Mon, 02 Jun 2025 15:45:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/ai-stirs-recipe-for-concrete-0602",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202505/mit-Soroush-Mahjoubi.jpg"
  },
  {
    "title": "Teaching AI models the broad strokes to sketch more like humans do",
    "description": "SketchAgent, a drawing system developed by MIT CSAIL researchers, sketches up concepts stroke-by-stroke, teaching language models to visually express concepts on their own and collaborate with humans.",
    "summary": "SketchAgent, a drawing system developed by MIT CSAIL researchers, sketches up concepts stroke-by-stroke, teaching language models to visually express concepts on their own and collaborate with humans.",
    "pubDate": "Mon, 02 Jun 2025 14:50:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/teaching-ai-models-to-sketch-more-like-humans-0602",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202505/MIT-SketchAgent.jpg"
  },
  {
    "title": "拡散言語モデルの推論過程を眺めてみる",
    "description": "<p>こんにちはAIチームの戸田です。今回はGemini Diffusionの登場をきっかけに最近話題になった拡散言語モデルの推論過程に興味を持ち、その一例として拡散言語モデルのLLaDAの推論を実際に手元で確認してみた結果を [&#8230;]</p> <p>投稿 <a href='https://www.ai-shift.co.jp/techblog/5850' rel='nofollow'>拡散言語モデルの推論過程を眺めてみる</a> は <a href='https://www.ai-shift.co.jp' rel='nofollow'>株式会社AI Shift</a> に最初に表示されました。</p>",
    "summary": "<p>こんにちはAIチームの戸田です。今回はGemini Diffusionの登場をきっかけに最近話題になった拡散言語モデルの推論過程に興味を持ち、その一例として拡散言語モデルのLLaDAの推論を実際に手元で確認してみた結果を [&#8230;]</p> <p>投稿 <a href='https://www.ai-shift.co.jp/techblog/5850' rel='nofollow'>拡散言語モデルの推論過程を眺めてみる</a> は <a href='https://www.ai-shift.co.jp' rel='nofollow'>株式会社AI Shift</a> に最初に表示されました。</p>",
    "pubDate": "Mon, 02 Jun 2025 00:13:43 +0000",
    "source": "AI Shift",
    "url": "https://www.ai-shift.co.jp/techblog/5850",
    "thumbnail": "https://www.ai-shift.co.jp/wp-content/uploads/2025/05/f81fd2e4c52864042852c112ce927ae2-1.png"
  },
  {
    "title": "Advanced audio dialog and generation with Gemini 2.5",
    "description": "Gemini 2.5 has new capabilities in AI-powered audio dialog and generation.",
    "summary": "Gemini 2.5 has new capabilities in AI-powered audio dialog and generation.",
    "pubDate": "Tue, 03 Jun 2025 17:15:47 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/advanced-audio-dialog-and-generation-with-gemini-25/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/capability__native-audio_16-9_121.width-1300.jpg"
  },
  {
    "title": "No GPU left behind: Unlocking Efficiency with Co-located vLLM in TRL",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 03 Jun 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/vllm-colocate",
    "thumbnail": "https://huggingface.co/blog/assets/liger-grpo/thumbnail.png"
  },
  {
    "title": "NotebookLM is adding a new way to share your own notebooks publicly.",
    "description": "<img src='https://storage.googleapis.com/gweb-uniblog-publish-prod/images/NotebookLMSharing_SS.max-600x600.format-webp.webp' />Many people who use NotebookLM already share their notebooks with classmates, coworkers, students and friends. Today, we're making sharing and curation easier — with pub…",
    "summary": "<img src='https://storage.googleapis.com/gweb-uniblog-publish-prod/images/NotebookLMSharing_SS.max-600x600.format-webp.webp' />Many people who use NotebookLM already share their notebooks with classmates, coworkers, students and friends. Today, we're making sharing and curation easier — with pub…",
    "pubDate": "Tue, 03 Jun 2025 16:00:00 +0000",
    "source": "Google AI Blog",
    "url": "https://blog.google/technology/google-labs/notebooklm-public-notebooks/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/NotebookLMSharing_SS.max-1440x810.png"
  },
  {
    "title": "SmolVLA: Efficient Vision-Language-Action Model trained on Lerobot Community Data",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 03 Jun 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/smolvla",
    "thumbnail": "https://huggingface.co/blog/assets/smolvla/SmolVLA_thumbnail.png"
  },
  {
    "title": "Teaching AI models what they don’t know",
    "description": "A team of MIT researchers founded Themis AI to quantify AI model uncertainty and address knowledge gaps.",
    "summary": "A team of MIT researchers founded Themis AI to quantify AI model uncertainty and address knowledge gaps.",
    "pubDate": "Tue, 03 Jun 2025 00:00:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/themis-ai-teaches-ai-models-what-they-dont-know-0603",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202506/MIT-ThemisAI-01-Press.jpg"
  },
  {
    "title": "AI breakthroughs are bringing hope to cancer research and treatment",
    "description": "A presentation slide displays 'Why not?' in multiple languages, representing global communication. Smaller images show Ruth Porat on stage, medical professionals, and 3D virus models, connecting technology with healthcare.",
    "summary": "A presentation slide displays 'Why not?' in multiple languages, representing global communication. Smaller images show Ruth Porat on stage, medical professionals, and 3D virus models, connecting technology with healthcare.",
    "pubDate": "Wed, 04 Jun 2025 18:00:00 +0000",
    "source": "Google AI Blog",
    "url": "https://blog.google/technology/health/ruth-porat-remarks-asco/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/RuthAsco_Hero_2097x1182.width-1300.png"
  },
  {
    "title": "KV Cache from scratch in nanoVLM",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 04 Jun 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/kv-cache",
    "thumbnail": "https://huggingface.co/blog/assets/kv-cache/thumbnail.png"
  },
  {
    "title": "A closer look inside AI Mode",
    "description": "Two smartphones showing AI Mode. The left phone shows an AI Mode prompt being entered: ‘things to do in nashville this weekend with friends, we’re big foodies who like music but also more chill vibes and exploring off the beaten path’. The right phone sho",
    "summary": "Two smartphones showing AI Mode. The left phone shows an AI Mode prompt being entered: ‘things to do in nashville this weekend with friends, we’re big foodies who like music but also more chill vibes and exploring off the beaten path’. The right phone sho",
    "pubDate": "Thu, 05 Jun 2025 18:30:00 +0000",
    "source": "Google AI Blog",
    "url": "https://blog.google/products/search/ai-mode-development/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Meet_AI_mode_ss.width-1300.png"
  },
  {
    "title": "BenchmarkQED: Automated benchmarking of RAG systems",
    "description": "<p>BenchmarkQED is an open-source toolkit for benchmarking RAG systems using automated query generation, evaluation, and dataset prep. It shows that LazyGraphRAG outperforms standard methods, especially on complex, global queries.</p> <p>The post <a href='https://www.microsoft.com/en-us/research/blog/benchmarkqed-automated-benchmarking-of-rag-systems/'>BenchmarkQED: Automated benchmarking of RAG systems</a> appeared first on <a href='https://www.microsoft.com/en-us/research'>Microsoft Research</a>.</p>",
    "summary": "<p>BenchmarkQED is an open-source toolkit for benchmarking RAG systems using automated query generation, evaluation, and dataset prep. It shows that LazyGraphRAG outperforms standard methods, especially on complex, global queries.</p> <p>The post <a href='https://www.microsoft.com/en-us/research/blog/benchmarkqed-automated-benchmarking-of-rag-systems/'>BenchmarkQED: Automated benchmarking of RAG systems</a> appeared first on <a href='https://www.microsoft.com/en-us/research'>Microsoft Research</a>.</p>",
    "pubDate": "Thu, 05 Jun 2025 16:00:00 +0000",
    "source": "Microsoft Research Blog",
    "url": "https://www.microsoft.com/en-us/research/blog/benchmarkqed-automated-benchmarking-of-rag-systems/",
    "thumbnail": "https://img-prod-cms-rt-microsoft-com.akamaized.net/cms/api/am/imageFileData/RE1Mu3b?ver=5c31&h=30"
  },
  {
    "title": "Disrupting malicious uses of AI: June 2025",
    "description": "In our June 2025 update, we outline how we’re disrupting malicious uses of AI—through safety tools that detect and counter abuse, support democratic values, and promote responsible AI deployment for the benefit of all.",
    "summary": "In our June 2025 update, we outline how we’re disrupting malicious uses of AI—through safety tools that detect and counter abuse, support democratic values, and promote responsible AI deployment for the benefit of all.",
    "pubDate": "Thu, 05 Jun 2025 02:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/global-affairs/disrupting-malicious-uses-of-ai-june-2025",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "How we’re responding to The New York Times’ data demands in order to protect user privacy",
    "description": "OpenAI is fighting a court order at the demands of The New York Times and plaintiffs, which involves retention of consumer ChatGPT and API user data indefinitely. Learn how we’re working to uphold user privacy, address legal requirements, and stay true to our data protection commitments.",
    "summary": "OpenAI is fighting a court order at the demands of The New York Times and plaintiffs, which involves retention of consumer ChatGPT and API user data indefinitely. Learn how we’re working to uphold user privacy, address legal requirements, and stay true to our data protection commitments.",
    "pubDate": "Thu, 05 Jun 2025 16:30:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/response-to-nyt-data-demands",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Portraits: personalized AI coaching built alongside real experts",
    "description": "Kim Scott Portrait chat example",
    "summary": "Kim Scott Portrait chat example",
    "pubDate": "Thu, 05 Jun 2025 18:00:00 +0000",
    "source": "Google AI Blog",
    "url": "https://blog.google/technology/google-labs/portraits/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/portraits-hero.width-1300.png"
  },
  {
    "title": "The latest AI news we announced in May",
    "description": "an mp4 showing a carousel of images including a collage of people, an illustrated graph with codes and the characters 'I/O'",
    "summary": "an mp4 showing a carousel of images including a collage of people, an illustrated graph with codes and the characters 'I/O'",
    "pubDate": "Thu, 05 Jun 2025 18:30:00 +0000",
    "source": "Google AI Blog",
    "url": "https://blog.google/technology/ai/google-ai-updates-may-2025/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/May_AI_roundup_ss.width-1300.png"
  },
  {
    "title": "Try new data visualizations and graphs for finance queries in AI Mode.",
    "description": "<img src='https://storage.googleapis.com/gweb-uniblog-publish-prod/images/BlueChip_1920x1080.max-600x600.format-webp.webp' />Today, we’re starting to roll out interactive chart visualizations in AI Mode in Labs to help bring financial data to life for questions on stocks and mutual funds.Now, …",
    "summary": "<img src='https://storage.googleapis.com/gweb-uniblog-publish-prod/images/BlueChip_1920x1080.max-600x600.format-webp.webp' />Today, we’re starting to roll out interactive chart visualizations in AI Mode in Labs to help bring financial data to life for questions on stocks and mutual funds.Now, …",
    "pubDate": "Thu, 05 Jun 2025 19:00:00 +0000",
    "source": "Google AI Blog",
    "url": "https://blog.google/products/search/ai-mode-data-visualization/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/BlueChip_1920x1080.max-1440x810.png"
  },
  {
    "title": "Try the latest Gemini 2.5 Pro before general availability.",
    "description": "<img src='https://storage.googleapis.com/gweb-uniblog-publish-prod/images/2.5_pro_preview_snippet_social_.max-600x600.format-webp.webp' />We’re introducing an upgraded preview of Gemini 2.5 Pro, our most intelligent model yet. Building on the version we released in May and showed at I/O, this model will be…",
    "summary": "<img src='https://storage.googleapis.com/gweb-uniblog-publish-prod/images/2.5_pro_preview_snippet_social_.max-600x600.format-webp.webp' />We’re introducing an upgraded preview of Gemini 2.5 Pro, our most intelligent model yet. Building on the version we released in May and showed at I/O, this model will be…",
    "pubDate": "Thu, 05 Jun 2025 16:00:00 +0000",
    "source": "Google AI Blog",
    "url": "https://blog.google/products/gemini/gemini-2-5-pro-latest-preview/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/2.5_pro_preview_snippet_social_share.max-1440x810.jpg"
  },
  {
    "title": "ScreenSuite - The most comprehensive evaluation suite for GUI Agents!",
    "description": "",
    "summary": "",
    "pubDate": "Fri, 06 Jun 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/screensuite",
    "thumbnail": "https://huggingface.co/blog/assets/screensuite/thumbnail.png"
  },
  {
    "title": "AI-enabled control system helps autonomous drones stay on target in uncertain environments",
    "description": "The system automatically learns to adapt to unknown disturbances such as gusting winds.",
    "summary": "The system automatically learns to adapt to unknown disturbances such as gusting winds.",
    "pubDate": "Mon, 09 Jun 2025 16:40:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/ai-enabled-control-system-helps-autonomous-drones-uncertain-environments-0609",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202506/MIT_MetaLearning-01.jpg"
  },
  {
    "title": "Envisioning a future where health care tech leaves some behind",
    "description": "The winning essay of the Envisioning the Future of Computing Prize puts health care disparities at the forefront.",
    "summary": "The winning essay of the Envisioning the Future of Computing Prize puts health care disparities at the forefront.",
    "pubDate": "Mon, 09 Jun 2025 16:10:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/envisioning-future-where-health-care-tech-leaves-some-behind-0609",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202506/Annaliese%20statue%20crop_v2.jpg"
  },
  {
    "title": "Helping machines understand visual content with AI",
    "description": "Coactive, founded by two MIT alumni, has built an AI-powered platform to unlock new insights from content of all types.",
    "summary": "Coactive, founded by two MIT alumni, has built an AI-powered platform to unlock new insights from content of all types.",
    "pubDate": "Mon, 09 Jun 2025 15:45:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/coactive-helps-machines-understand-visual-content-ai-0609",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202506/MIT-Coactive-AI-01-press.jpg"
  },
  {
    "title": "Here’s the next cohort of the Google.org Accelerator: Generative AI",
    "description": "A collage of photos showing people using technology around the world, on a white background",
    "summary": "A collage of photos showing people using technology around the world, on a white background",
    "pubDate": "Mon, 09 Jun 2025 14:00:00 +0000",
    "source": "Google AI Blog",
    "url": "https://blog.google/outreach-initiatives/google-org/generative-ai-accelerator-cohort-2025/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Gen_AI_Accelerator_ss.width-1300.png"
  },
  {
    "title": "How we built one of the most ambitious datasets in brain activity research",
    "description": "Four small, translucent zebrafish swim against a dark background",
    "summary": "Four small, translucent zebrafish swim against a dark background",
    "pubDate": "Mon, 09 Jun 2025 16:00:00 +0000",
    "source": "Google AI Blog",
    "url": "https://blog.google/technology/research/zapbench-zebrafish-brain-mapping/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/SS_How-we-built-one-of-the-most-ambitious-dat.width-1300.png"
  },
  {
    "title": "Outbound coordinated vulnerability disclosure policy",
    "description": "Outbound coordinated vulnerability disclosure policy",
    "summary": "Outbound coordinated vulnerability disclosure policy",
    "pubDate": "Mon, 09 Jun 2025 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/policies/outbound-coordinated-disclosure-policy",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Scaling security with responsible disclosure",
    "description": "OpenAI introduces its Outbound Coordinated Disclosure Policy to guide how it responsibly reports vulnerabilities in third-party software—emphasizing integrity, collaboration, and proactive security at scale.",
    "summary": "OpenAI introduces its Outbound Coordinated Disclosure Policy to guide how it responsibly reports vulnerabilities in third-party software—emphasizing integrity, collaboration, and proactive security at scale.",
    "pubDate": "Mon, 09 Jun 2025 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/scaling-coordinated-vulnerability-disclosure",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "UK government harnesses Gemini to support faster planning decisions",
    "description": "A summary of how Extract works",
    "summary": "A summary of how Extract works",
    "pubDate": "Mon, 09 Jun 2025 11:00:00 +0000",
    "source": "Google AI Blog",
    "url": "https://blog.google/around-the-globe/google-europe/united-kingdom/uk-government-harnesses-gemini-to-support-faster-planning-decisions/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/overview.width-1300.png"
  },
  {
    "title": "How we really judge AI",
    "description": "Forget optimists vs. Luddites. Most people evaluate AI based on its perceived capability and their need for personalization.",
    "summary": "Forget optimists vs. Luddites. Most people evaluate AI based on its perceived capability and their need for personalization.",
    "pubDate": "Tue, 10 Jun 2025 11:30:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/how-we-really-judge-ai-0610",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202506/MIT-AI-Aversion-Appreciation-01.jpg"
  },
  {
    "title": "How we used generative media at I/O 2025",
    "description": "Video showing the I/O opening film.",
    "summary": "Video showing the I/O opening film.",
    "pubDate": "Tue, 10 Jun 2025 17:00:00 +0000",
    "source": "Google AI Blog",
    "url": "https://blog.google/technology/ai/generative-ai-io-keynote-2025/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/thumbnail_opener_hero.width-1300.png"
  },
  {
    "title": "Inroads to personalized AI trip planning",
    "description": "A new framework from the MIT-IBM Watson AI Lab supercharges language models, so they can reason over, interactively develop, and verify valid, complex travel agendas.",
    "summary": "A new framework from the MIT-IBM Watson AI Lab supercharges language models, so they can reason over, interactively develop, and verify valid, complex travel agendas.",
    "pubDate": "Tue, 10 Jun 2025 15:00:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/inroads-personalized-ai-trip-planning-0610",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202505/mit-watson-travel-planning.jpg"
  },
  {
    "title": "Melding data, systems, and society",
    "description": "A new book from Professor Munther Dahleh details the creation of a unique kind of transdisciplinary center, uniting many specialties through a common need for data science.",
    "summary": "A new book from Professor Munther Dahleh details the creation of a unique kind of transdisciplinary center, uniting many specialties through a common need for data science.",
    "pubDate": "Tue, 10 Jun 2025 14:25:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/data-systems-and-society-0610",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202505/mit-Data-Systems-Dahleh-book.jpg"
  },
  {
    "title": "Rewriting SymCrypt in Rust to modernize Microsoft’s cryptographic library",
    "description": "<p>We're rewriting parts of Microsoft's SymCrypt cryptographic library in Rust to improve memory safety and defend against side-channel attacks, enabling formal verification while maintaining backward compatibility via a Rust-to-C compiler.</p> <p>The post <a href='https://www.microsoft.com/en-us/research/blog/rewriting-symcrypt-in-rust-to-modernize-microsofts-cryptographic-library/'>Rewriting SymCrypt in Rust to modernize Microsoft’s cryptographic library </a> appeared first on <a href='https://www.microsoft.com/en-us/research'>Microsoft Research</a>.</p>",
    "summary": "<p>We're rewriting parts of Microsoft's SymCrypt cryptographic library in Rust to improve memory safety and defend against side-channel attacks, enabling formal verification while maintaining backward compatibility via a Rust-to-C compiler.</p> <p>The post <a href='https://www.microsoft.com/en-us/research/blog/rewriting-symcrypt-in-rust-to-modernize-microsofts-cryptographic-library/'>Rewriting SymCrypt in Rust to modernize Microsoft’s cryptographic library </a> appeared first on <a href='https://www.microsoft.com/en-us/research'>Microsoft Research</a>.</p>",
    "pubDate": "Tue, 10 Jun 2025 16:00:00 +0000",
    "source": "Microsoft Research Blog",
    "url": "https://www.microsoft.com/en-us/research/blog/rewriting-symcrypt-in-rust-to-modernize-microsofts-cryptographic-library/",
    "thumbnail": "https://img-prod-cms-rt-microsoft-com.akamaized.net/cms/api/am/imageFileData/RE1Mu3b?ver=5c31&h=30"
  },
  {
    "title": "Allganize、ノーコードで自社専用AIエージェントを構築できる「Agent Builder」を提供開始",
    "description": "<p>Allganizeは、企業が高度なセキュリティ環境下でAIエージェントをノーコードで簡単に構築できる「Agent Builder」の提供を開始しました。 このニュースのポイント Allganizeが、企業が高度なセキュリ [&#8230;]</p> <p>The post <a href='https://aismiley.co.jp/ai_news/allganize_agent_builder/'>Allganize、ノーコードで自社専用AIエージェントを構築できる「Agent Builder」を提供開始</a> first appeared on <a href='https://aismiley.co.jp'>AIポータルメディアAIsmiley</a>.</p>",
    "summary": "<p>Allganizeは、企業が高度なセキュリティ環境下でAIエージェントをノーコードで簡単に構築できる「Agent Builder」の提供を開始しました。 このニュースのポイント Allganizeが、企業が高度なセキュリ [&#8230;]</p> <p>The post <a href='https://aismiley.co.jp/ai_news/allganize_agent_builder/'>Allganize、ノーコードで自社専用AIエージェントを構築できる「Agent Builder」を提供開始</a> first appeared on <a href='https://aismiley.co.jp'>AIポータルメディアAIsmiley</a>.</p>",
    "pubDate": "Wed, 11 Jun 2025 09:00:24 +0000",
    "source": "AI Smily",
    "url": "https://aismiley.co.jp/ai_news/allganize_agent_builder/",
    "thumbnail": "https://aismiley.co.jp/wp-content/uploads/2025/06/main-agentbuilder.png"
  },
  {
    "title": "Bringing meaning into technology deployment",
    "description": "The MIT Ethics of Computing Research Symposium showcases projects at the intersection of technology, ethics, and social responsibility.",
    "summary": "The MIT Ethics of Computing Research Symposium showcases projects at the intersection of technology, ethics, and social responsibility.",
    "pubDate": "Wed, 11 Jun 2025 16:15:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/bringing-meaning-technology-deployment-0611",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202505/mit-SERC-Symposium.jpg"
  },
  {
    "title": "Google for Nonprofits will expand to 100+ new countries and launch 10+ new no-cost AI features",
    "description": "Collage on a white background showing people in multiple different situations including two people in suits sitting on the back of an ambulance, and an adult and child using a laptop together",
    "summary": "Collage on a white background showing people in multiple different situations including two people in suits sitting on the back of an ambulance, and an adult and child using a laptop together",
    "pubDate": "Wed, 11 Jun 2025 16:00:00 +0000",
    "source": "Google AI Blog",
    "url": "https://blog.google/outreach-initiatives/google-org/google-nonprofits-updates-june-2025/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/GoogleforNonProfit_SS.width-1300.png"
  },
  {
    "title": "Have a damaged painting? Restore it in just hours with an AI-generated “mask”",
    "description": "A new method can physically restore original paintings using digitally constructed films, which can be removed if desired.",
    "summary": "A new method can physically restore original paintings using digitally constructed films, which can be removed if desired.",
    "pubDate": "Wed, 11 Jun 2025 11:00:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/restoring-damaged-paintings-using-ai-generated-mask-0611",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202506/MIT-Restoring-Paintings-01-press.jpg"
  },
  {
    "title": "Introducing Training Cluster as a Service - a new collaboration with NVIDIA",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 11 Jun 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/nvidia-training-cluster",
    "thumbnail": "https://huggingface.co/blog/assets/nvidia-training-cluster/nvidia-training-cluster-thumbnail-compressed.png"
  },
  {
    "title": "Photonic processor could streamline 6G wireless signal processing",
    "description": "By performing deep learning at the speed of light, this chip could give edge devices new capabilities for real-time data analysis.",
    "summary": "By performing deep learning at the speed of light, this chip could give edge devices new capabilities for real-time data analysis.",
    "pubDate": "Wed, 11 Jun 2025 14:00:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/photonic-processor-could-streamline-6g-wireless-signal-processing-0611",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202506/MIT-Photonic-Process-01-press.jpg"
  },
  {
    "title": "tsuzumi活用、医療文書作成支援AIで医療サービス向上を目指す。NTT東日本と新潟大学が共同研究",
    "description": "<p>NTT東日本と新潟大学は、医師不足の解消と医療サービスの質向上を目的に、NTTが開発した大規模言語モデル「tsuzumi」を活用した医療文書作成支援AIモデルの実証事業を開始しました。 このニュースのポイント NTT東日 [&#8230;]</p> <p>The post <a href='https://aismiley.co.jp/ai_news/ntt-east-niigata-university-ai/'>tsuzumi活用、医療文書作成支援AIで医療サービス向上を目指す。NTT東日本と新潟大学が共同研究</a> first appeared on <a href='https://aismiley.co.jp'>AIポータルメディアAIsmiley</a>.</p>",
    "summary": "<p>NTT東日本と新潟大学は、医師不足の解消と医療サービスの質向上を目的に、NTTが開発した大規模言語モデル「tsuzumi」を活用した医療文書作成支援AIモデルの実証事業を開始しました。 このニュースのポイント NTT東日 [&#8230;]</p> <p>The post <a href='https://aismiley.co.jp/ai_news/ntt-east-niigata-university-ai/'>tsuzumi活用、医療文書作成支援AIで医療サービス向上を目指す。NTT東日本と新潟大学が共同研究</a> first appeared on <a href='https://aismiley.co.jp'>AIポータルメディアAIsmiley</a>.</p>",
    "pubDate": "Wed, 11 Jun 2025 00:55:41 +0000",
    "source": "AI Smily",
    "url": "https://aismiley.co.jp/ai_news/ntt-east-niigata-university-ai/",
    "thumbnail": "https://aismiley.co.jp/wp-content/uploads/2025/05/ntt-east-niigata-university-ai.png"
  },
  {
    "title": "生成AI社会実装に向けた最新成果とは―GENIAC第2期成果報告会レポート",
    "description": "<p>日本の生成AI開発力を底上げする取り組みとして注目されている「GENIAC（Generative AI Accelerator Challenge）」の第2期成果報告会が開催されました。 GENIACは、経済産業省とNE [&#8230;]</p> <p>The post <a href='https://aismiley.co.jp/ai_news/report-geniac-second-results-presentation/'>生成AI社会実装に向けた最新成果とは―GENIAC第2期成果報告会レポート</a> first appeared on <a href='https://aismiley.co.jp'>AIポータルメディアAIsmiley</a>.</p>",
    "summary": "<p>日本の生成AI開発力を底上げする取り組みとして注目されている「GENIAC（Generative AI Accelerator Challenge）」の第2期成果報告会が開催されました。 GENIACは、経済産業省とNE [&#8230;]</p> <p>The post <a href='https://aismiley.co.jp/ai_news/report-geniac-second-results-presentation/'>生成AI社会実装に向けた最新成果とは―GENIAC第2期成果報告会レポート</a> first appeared on <a href='https://aismiley.co.jp'>AIポータルメディアAIsmiley</a>.</p>",
    "pubDate": "Wed, 11 Jun 2025 07:45:26 +0000",
    "source": "AI Smily",
    "url": "https://aismiley.co.jp/ai_news/report-geniac-second-results-presentation/",
    "thumbnail": "https://aismiley.co.jp/wp-content/uploads/2025/06/geniac-main.png"
  },
  {
    "title": "5 things from I/O to try right now",
    "description": "Collage on a dark background showing AI-generated media including humpback whales jumping from the water and the very detailed face of a chameleon",
    "summary": "Collage on a dark background showing AI-generated media including humpback whales jumping from the water and the very detailed face of a chameleon",
    "pubDate": "Thu, 12 Jun 2025 16:00:00 +0000",
    "source": "Google AI Blog",
    "url": "https://blog.google/technology/ai/io-2025-tools-to-try-globally/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/5_I_O_tools_ss.width-1300.png"
  },
  {
    "title": "Bringing the Magic of AI to Mattel’s Iconic Brands",
    "description": "OpenAI and Mattel are partnering to integrate AI into iconic brands such as Barbie and Hot Wheels, aiming to enhance creative development, streamline workflows, and create new ways for fans to engage.",
    "summary": "OpenAI and Mattel are partnering to integrate AI into iconic brands such as Barbie and Hot Wheels, aiming to enhance creative development, streamline workflows, and create new ways for fans to engage.",
    "pubDate": "Thu, 12 Jun 2025 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/mattels-iconic-brands",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Enhance Your Models in 5 Minutes with the Hugging Face Kernel Hub",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 12 Jun 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/hello-hf-kernels",
    "thumbnail": "https://huggingface.co/blog/assets/hello-hf-kernels/kernel-hub-five-mins-short.png"
  },
  {
    "title": "EQUES、製薬特化LLM「JPharmatron-7B」を開発。薬文書作成など、製薬業務における活用を目指す",
    "description": "<p>EQUESは、経済産業省/NEDOによる生成AI研究支援プログラム「GENIAC」の一環として、製薬業界向けの新しいLLM「JPharmatron-7B」を発表しました。 このニュースのポイント 製薬業界向けLLM「JP [&#8230;]</p> <p>The post <a href='https://aismiley.co.jp/ai_news/eques-develops-pharmaceutical-specific-llm/'>EQUES、製薬特化LLM「JPharmatron-7B」を開発。薬文書作成など、製薬業務における活用を目指す</a> first appeared on <a href='https://aismiley.co.jp'>AIポータルメディアAIsmiley</a>.</p>",
    "summary": "<p>EQUESは、経済産業省/NEDOによる生成AI研究支援プログラム「GENIAC」の一環として、製薬業界向けの新しいLLM「JPharmatron-7B」を発表しました。 このニュースのポイント 製薬業界向けLLM「JP [&#8230;]</p> <p>The post <a href='https://aismiley.co.jp/ai_news/eques-develops-pharmaceutical-specific-llm/'>EQUES、製薬特化LLM「JPharmatron-7B」を開発。薬文書作成など、製薬業務における活用を目指す</a> first appeared on <a href='https://aismiley.co.jp'>AIポータルメディアAIsmiley</a>.</p>",
    "pubDate": "Thu, 12 Jun 2025 09:25:20 +0000",
    "source": "AI Smily",
    "url": "https://aismiley.co.jp/ai_news/eques-develops-pharmaceutical-specific-llm/",
    "thumbnail": "https://aismiley.co.jp/wp-content/uploads/2025/06/eques-develops-pharmaceutical-specific-llm1.png"
  },
  {
    "title": "Featherless AI on Hugging Face Inference Providers 🔥",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 12 Jun 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/inference-providers-featherless",
    "thumbnail": "https://huggingface.co/blog/assets/inference-providers/welcome-featherless.jpg"
  },
  {
    "title": "How AI is reshaping the future of healthcare and medical research",
    "description": "<p>Technologists Bill Gates and Sébastien Bubeck discuss the state of generative AI in medicine, how access to “medical intelligence” might help empower people across healthcare, and how AI’s accelerating improvements are likely to affect both delivery and discovery.</p> <p>The post <a href='https://www.microsoft.com/en-us/research/podcast/how-ai-is-reshaping-the-future-of-healthcare-and-medical-research/'>How AI is reshaping the future of healthcare and medical research</a> appeared first on <a href='https://www.microsoft.com/en-us/research'>Microsoft Research</a>.</p>",
    "summary": "<p>Technologists Bill Gates and Sébastien Bubeck discuss the state of generative AI in medicine, how access to “medical intelligence” might help empower people across healthcare, and how AI’s accelerating improvements are likely to affect both delivery and discovery.</p> <p>The post <a href='https://www.microsoft.com/en-us/research/podcast/how-ai-is-reshaping-the-future-of-healthcare-and-medical-research/'>How AI is reshaping the future of healthcare and medical research</a> appeared first on <a href='https://www.microsoft.com/en-us/research'>Microsoft Research</a>.</p>",
    "pubDate": "Thu, 12 Jun 2025 16:17:04 +0000",
    "source": "Microsoft Research Blog",
    "url": "https://www.microsoft.com/en-us/research/podcast/how-ai-is-reshaping-the-future-of-healthcare-and-medical-research/",
    "thumbnail": "https://img-prod-cms-rt-microsoft-com.akamaized.net/cms/api/am/imageFileData/RE1Mu3b?ver=5c31&h=30"
  },
  {
    "title": "How we're supporting better tropical cyclone prediction with AI",
    "description": "We’re launching Weather Lab, featuring our experimental cyclone predictions, and we’re partnering with the U.S. National Hurricane Center to support their forecasts and warnings this cyclone season.",
    "summary": "We’re launching Weather Lab, featuring our experimental cyclone predictions, and we’re partnering with the U.S. National Hurricane Center to support their forecasts and warnings this cyclone season.",
    "pubDate": "Thu, 12 Jun 2025 15:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/weather-lab-cyclone-predictions-with-ai/",
    "thumbnail": "https://lh3.googleusercontent.com/4emGMNrEdaydebppYDiyQMNhXtgUFr8VvrKhVItMHENrxeWmWO9yqhteSj2fe25lxkiZAu7vOZZcsXPDLg0O-LPSvk6CS1I8E2-GdjtoN_2ViJOY=w1200-h630-n-nu"
  },
  {
    "title": "OpenAI o3-proとは？最新AIモデルの実力を徹底解説",
    "description": "<p>2025年6月に、OpenAIの最新モデル「o3-pro」がリリースされました。主に科学や数学など深い推論を得意として、自然言語処理、画像理解、音声認識といったマルチモーダル対応が特徴となっています。 本記事では、o3- [&#8230;]</p> <p>The post <a href='https://aismiley.co.jp/ai_news/o3-pro/'>OpenAI o3-proとは？最新AIモデルの実力を徹底解説</a> first appeared on <a href='https://aismiley.co.jp'>AIポータルメディアAIsmiley</a>.</p>",
    "summary": "<p>2025年6月に、OpenAIの最新モデル「o3-pro」がリリースされました。主に科学や数学など深い推論を得意として、自然言語処理、画像理解、音声認識といったマルチモーダル対応が特徴となっています。 本記事では、o3- [&#8230;]</p> <p>The post <a href='https://aismiley.co.jp/ai_news/o3-pro/'>OpenAI o3-proとは？最新AIモデルの実力を徹底解説</a> first appeared on <a href='https://aismiley.co.jp'>AIポータルメディアAIsmiley</a>.</p>",
    "pubDate": "Thu, 12 Jun 2025 06:31:40 +0000",
    "source": "AI Smily",
    "url": "https://aismiley.co.jp/ai_news/o3-pro/",
    "thumbnail": "https://aismiley.co.jp/wp-content/uploads/2025/06/o3-pro.png"
  },
  {
    "title": "Behind “ANCESTRA”: combining Veo with live-action filmmaking",
    "description": "We partnered with Darren Aronofsky, Eliza McNitt and a team of more than 200 people to make a film using Veo and live-action filmmaking.",
    "summary": "We partnered with Darren Aronofsky, Eliza McNitt and a team of more than 200 people to make a film using Veo and live-action filmmaking.",
    "pubDate": "Fri, 13 Jun 2025 13:30:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/behind-ancestra-combining-veo-with-live-action-filmmaking/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Ancestra-YTThumbnail.width-1300.png"
  },
  {
    "title": "Get an audio overview of Search results in Labs, then click through to learn more.",
    "description": "A phone screen showing Google search results with a section titled 'Search Labs | Audio Overviews' and an audio player.",
    "summary": "A phone screen showing Google search results with a section titled 'Search Labs | Audio Overviews' and an audio player.",
    "pubDate": "Fri, 13 Jun 2025 15:30:00 +0000",
    "source": "Google AI Blog",
    "url": "https://blog.google/products/search/audio-overviews-search-labs/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/AudioOverview_SS.max-1440x810.png"
  },
  {
    "title": "KMS、業務効率化サービス「DAIVERSE」にGPT-4.1とWeb情報登録機能を実装",
    "description": "<p>KMSは、業務効率化サービス「DAIVERSE」に、Azure OpenAI ServiceのGPT-4.1モデルとWebサイト情報登録機能を実装しました。 このニュースのポイント 「DAIVERSE」にGPT-4.1モ [&#8230;]</p> <p>The post <a href='https://aismiley.co.jp/ai_news/kms-azure-openai-service/'>KMS、業務効率化サービス「DAIVERSE」にGPT-4.1とWeb情報登録機能を実装</a> first appeared on <a href='https://aismiley.co.jp'>AIポータルメディアAIsmiley</a>.</p>",
    "summary": "<p>KMSは、業務効率化サービス「DAIVERSE」に、Azure OpenAI ServiceのGPT-4.1モデルとWebサイト情報登録機能を実装しました。 このニュースのポイント 「DAIVERSE」にGPT-4.1モ [&#8230;]</p> <p>The post <a href='https://aismiley.co.jp/ai_news/kms-azure-openai-service/'>KMS、業務効率化サービス「DAIVERSE」にGPT-4.1とWeb情報登録機能を実装</a> first appeared on <a href='https://aismiley.co.jp'>AIポータルメディアAIsmiley</a>.</p>",
    "pubDate": "Fri, 13 Jun 2025 02:00:38 +0000",
    "source": "AI Smily",
    "url": "https://aismiley.co.jp/ai_news/kms-azure-openai-service/",
    "thumbnail": "https://aismiley.co.jp/wp-content/uploads/2025/06/kms-azure-openai-service1.png"
  },
  {
    "title": "7/9開催【生成AI品質改善ウェビナー】 本番品質の生成AIをどう作る？LLMOps×高精度データで実現する改善プロセス",
    "description": "<p>AIポータルメディア「AIsmiley」は、2025年7月9日（水）12時から生成AI活用をテーマにウェビナーを開催します。 本ウェビナーでは、生成AI活用のポイントについてご紹介。生成AIを本番品質へ改善するポイントか [&#8230;]</p> <p>The post <a href='https://aismiley.co.jp/ai_news/20250709webinar/'>7/9開催【生成AI品質改善ウェビナー】 本番品質の生成AIをどう作る？LLMOps×高精度データで実現する改善プロセス</a> first appeared on <a href='https://aismiley.co.jp'>AIポータルメディアAIsmiley</a>.</p>",
    "summary": "<p>AIポータルメディア「AIsmiley」は、2025年7月9日（水）12時から生成AI活用をテーマにウェビナーを開催します。 本ウェビナーでは、生成AI活用のポイントについてご紹介。生成AIを本番品質へ改善するポイントか [&#8230;]</p> <p>The post <a href='https://aismiley.co.jp/ai_news/20250709webinar/'>7/9開催【生成AI品質改善ウェビナー】 本番品質の生成AIをどう作る？LLMOps×高精度データで実現する改善プロセス</a> first appeared on <a href='https://aismiley.co.jp'>AIポータルメディアAIsmiley</a>.</p>",
    "pubDate": "Mon, 16 Jun 2025 01:37:40 +0000",
    "source": "AI Smily",
    "url": "https://aismiley.co.jp/ai_news/20250709webinar/",
    "thumbnail": "https://aismiley.co.jp/wp-content/uploads/2025/06/699_1200x628_2.jpg"
  },
  {
    "title": "Celebrating an academic-industry collaboration to advance vehicle technology",
    "description": "MIT Advanced Vehicle Technology Consortium marks a decade of developing data that improve understanding of how drivers use and respond to increasingly sophisticated automotive features.",
    "summary": "MIT Advanced Vehicle Technology Consortium marks a decade of developing data that improve understanding of how drivers use and respond to increasingly sophisticated automotive features.",
    "pubDate": "Mon, 16 Jun 2025 14:45:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/celebrating-academic-industry-collaboration-advance-vehicle-technology-0616",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202505/MIT-AVT-conference.jpg"
  },
  {
    "title": "Groq on Hugging Face Inference Providers 🔥",
    "description": "",
    "summary": "",
    "pubDate": "Mon, 16 Jun 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/inference-providers-groq",
    "thumbnail": "https://huggingface.co/blog/assets/inference-providers/welcome-groq.jpg"
  },
  {
    "title": "Introducing OpenAI for Government",
    "description": "We’re launching OpenAI for Government, a new initiative focused on bringing our most advanced AI tools to public servants across the United States. We're supporting the U.S. government's efforts in adopting best-in-class technology and deploying these tools in service of the public good.",
    "summary": "We’re launching OpenAI for Government, a new initiative focused on bringing our most advanced AI tools to public servants across the United States. We're supporting the U.S. government's efforts in adopting best-in-class technology and deploying these tools in service of the public good.",
    "pubDate": "Mon, 16 Jun 2025 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/global-affairs/introducing-openai-for-government",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "A sounding board for strengthening the student experience",
    "description": "Composed of “computing bilinguals,” the Undergraduate Advisory Group provides vital input to help advance the mission of the MIT Schwarzman College of Computing.",
    "summary": "Composed of “computing bilinguals,” the Undergraduate Advisory Group provides vital input to help advance the mission of the MIT Schwarzman College of Computing.",
    "pubDate": "Tue, 17 Jun 2025 16:00:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/sounding-board-for-strengthening-student-experience-0617",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202505/mit-SCC-UAG.jpg"
  },
  {
    "title": "Combining technology, education, and human connection to improve online learning",
    "description": "Caitlin Morris, a PhD student and 2024 MAD Fellow affiliated with the MIT Media Lab, designs digital learning platforms that make room for the “social magic” that influences curiosity and motivation.",
    "summary": "Caitlin Morris, a PhD student and 2024 MAD Fellow affiliated with the MIT Media Lab, designs digital learning platforms that make room for the “social magic” that influences curiosity and motivation.",
    "pubDate": "Tue, 17 Jun 2025 16:25:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/caitlin-morris-combines-tech-education-human-connection-improve-online-learning-0617",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202506/mit-Caitlin-Morris.jpg"
  },
  {
    "title": "Gemini 2.5: Updates to our family of thinking models",
    "description": "Explore the latest Gemini 2.5 model updates with enhanced performance and accuracy: Gemini 2.5 Pro now stable, Flash generally available, and the new Flash-Lite in preview.",
    "summary": "Explore the latest Gemini 2.5 model updates with enhanced performance and accuracy: Gemini 2.5 Pro now stable, Flash generally available, and the new Flash-Lite in preview.",
    "pubDate": "Tue, 17 Jun 2025 16:03:39 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/gemini-25-updates-to-our-family-of-thinking-models/",
    "thumbnail": "https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/gemini-2-5-pro-meta_1.2e16d0ba.fill-1200x600.png"
  },
  {
    "title": "New methods boost reasoning in small and large language models",
    "description": "<p>New techniques are reimagining how LLMs reason. By combining symbolic logic, mathematical rigor, and adaptive planning, these methods enable models to tackle complex, real-world problems across a variety of fields.</p> <p>The post <a href='https://www.microsoft.com/en-us/research/blog/new-methods-boost-reasoning-in-small-and-large-language-models/'>New methods boost reasoning in small and large language models</a> appeared first on <a href='https://www.microsoft.com/en-us/research'>Microsoft Research</a>.</p>",
    "summary": "<p>New techniques are reimagining how LLMs reason. By combining symbolic logic, mathematical rigor, and adaptive planning, these methods enable models to tackle complex, real-world problems across a variety of fields.</p> <p>The post <a href='https://www.microsoft.com/en-us/research/blog/new-methods-boost-reasoning-in-small-and-large-language-models/'>New methods boost reasoning in small and large language models</a> appeared first on <a href='https://www.microsoft.com/en-us/research'>Microsoft Research</a>.</p>",
    "pubDate": "Tue, 17 Jun 2025 16:00:00 +0000",
    "source": "Microsoft Research Blog",
    "url": "https://www.microsoft.com/en-us/research/blog/new-methods-boost-reasoning-in-small-and-large-language-models/",
    "thumbnail": "https://img-prod-cms-rt-microsoft-com.akamaized.net/cms/api/am/imageFileData/RE1Mu3b?ver=5c31&h=30"
  },
  {
    "title": "Unpacking the bias of large language models",
    "description": "In a new study, researchers discover the root cause of a type of bias in LLMs, paving the way for more accurate and reliable AI systems.",
    "summary": "In a new study, researchers discover the root cause of a type of bias in LLMs, paving the way for more accurate and reliable AI systems.",
    "pubDate": "Tue, 17 Jun 2025 16:00:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/unpacking-large-language-model-bias-0617",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202506/MIT-transform-bias-01-press.jpg"
  },
  {
    "title": "We’re expanding our Gemini 2.5 family of models",
    "description": "Gemini 2.5 Flash and Pro are now generally available, and we’re introducing 2.5 Flash-Lite, our most cost-efficient and fastest 2.5 model yet.",
    "summary": "Gemini 2.5 Flash and Pro are now generally available, and we’re introducing 2.5 Flash-Lite, our most cost-efficient and fastest 2.5 model yet.",
    "pubDate": "Tue, 17 Jun 2025 16:01:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/were-expanding-our-gemini-25-family-of-models/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/2.5_bundle_keyword_social-share_1920-1080.width-1300.png"
  },
  {
    "title": "【7/16開催ウェビナー】LLM開発におけるGPUクラウドとオンプレの徹底比較！  ~独自LLMの開発秘話からGPUコストを削減するための具体的なポイントまで一挙大公開~",
    "description": "<p>AIポータルメディア「AIsmiley」は、2025年7月16日（水）12時からLLM開発に関するウェビナーを開催します。 本ウェビナーでは、他社のGPUクラウドサービスやオンプレミス環境との比較を通じて、GPUコストを [&#8230;]</p> <p>The post <a href='https://aismiley.co.jp/ai_news/20250716webinar/'>【7/16開催ウェビナー】LLM開発におけるGPUクラウドとオンプレの徹底比較！  ~独自LLMの開発秘話からGPUコストを削減するための具体的なポイントまで一挙大公開~</a> first appeared on <a href='https://aismiley.co.jp'>AIポータルメディアAIsmiley</a>.</p>",
    "summary": "<p>AIポータルメディア「AIsmiley」は、2025年7月16日（水）12時からLLM開発に関するウェビナーを開催します。 本ウェビナーでは、他社のGPUクラウドサービスやオンプレミス環境との比較を通じて、GPUコストを [&#8230;]</p> <p>The post <a href='https://aismiley.co.jp/ai_news/20250716webinar/'>【7/16開催ウェビナー】LLM開発におけるGPUクラウドとオンプレの徹底比較！  ~独自LLMの開発秘話からGPUコストを削減するための具体的なポイントまで一挙大公開~</a> first appeared on <a href='https://aismiley.co.jp'>AIポータルメディアAIsmiley</a>.</p>",
    "pubDate": "Wed, 18 Jun 2025 01:00:37 +0000",
    "source": "AI Smily",
    "url": "https://aismiley.co.jp/ai_news/20250716webinar/",
    "thumbnail": "https://aismiley.co.jp/wp-content/uploads/2025/06/700_1200x628_2.jpg"
  },
  {
    "title": "Archaic、日本語特化型RAGシステムAIを開発。製造業分野でトップクラスの正答率",
    "description": "<p>Archaicは日本語業務文書に特化したRAGシステムAIを開発。公開ベンチマークの評価データセットで製造業カテゴリと全体平均でトップクラスの正答率を記録しました。 このニュースのポイント 日本語業務文書に特化したRAG [&#8230;]</p> <p>The post <a href='https://aismiley.co.jp/ai_news/archaic-develops-japanese-specific-rag/'>Archaic、日本語特化型RAGシステムAIを開発。製造業分野でトップクラスの正答率</a> first appeared on <a href='https://aismiley.co.jp'>AIポータルメディアAIsmiley</a>.</p>",
    "summary": "<p>Archaicは日本語業務文書に特化したRAGシステムAIを開発。公開ベンチマークの評価データセットで製造業カテゴリと全体平均でトップクラスの正答率を記録しました。 このニュースのポイント 日本語業務文書に特化したRAG [&#8230;]</p> <p>The post <a href='https://aismiley.co.jp/ai_news/archaic-develops-japanese-specific-rag/'>Archaic、日本語特化型RAGシステムAIを開発。製造業分野でトップクラスの正答率</a> first appeared on <a href='https://aismiley.co.jp'>AIポータルメディアAIsmiley</a>.</p>",
    "pubDate": "Wed, 18 Jun 2025 05:51:09 +0000",
    "source": "AI Smily",
    "url": "https://aismiley.co.jp/ai_news/archaic-develops-japanese-specific-rag/",
    "thumbnail": "https://aismiley.co.jp/wp-content/uploads/2025/06/Archaic-develops-Japanese-specific-RAG1.png"
  },
  {
    "title": "Breaking bonds, breaking ground: Advancing the accuracy of computational chemistry with deep learning",
    "description": "<p>Microsoft researchers achieved a breakthrough in the accuracy of DFT, a method for predicting the properties of molecules and materials, by using deep learning. This work can lead to better batteries, green fertilizers, precision drug discovery, and more.</p> <p>The post <a href='https://www.microsoft.com/en-us/research/blog/breaking-bonds-breaking-ground-advancing-the-accuracy-of-computational-chemistry-with-deep-learning/'>Breaking bonds, breaking ground: Advancing the accuracy of computational chemistry with deep learning</a> appeared first on <a href='https://www.microsoft.com/en-us/research'>Microsoft Research</a>.</p>",
    "summary": "<p>Microsoft researchers achieved a breakthrough in the accuracy of DFT, a method for predicting the properties of molecules and materials, by using deep learning. This work can lead to better batteries, green fertilizers, precision drug discovery, and more.</p> <p>The post <a href='https://www.microsoft.com/en-us/research/blog/breaking-bonds-breaking-ground-advancing-the-accuracy-of-computational-chemistry-with-deep-learning/'>Breaking bonds, breaking ground: Advancing the accuracy of computational chemistry with deep learning</a> appeared first on <a href='https://www.microsoft.com/en-us/research'>Microsoft Research</a>.</p>",
    "pubDate": "Wed, 18 Jun 2025 10:01:47 +0000",
    "source": "Microsoft Research Blog",
    "url": "https://www.microsoft.com/en-us/research/blog/breaking-bonds-breaking-ground-advancing-the-accuracy-of-computational-chemistry-with-deep-learning/",
    "thumbnail": "https://img-prod-cms-rt-microsoft-com.akamaized.net/cms/api/am/imageFileData/RE1Mu3b?ver=5c31&h=30"
  },
  {
    "title": "Hear a podcast discussion about Gemini’s coding capabilities.",
    "description": "<img src='https://storage.googleapis.com/gweb-uniblog-publish-prod/images/ep8_thumbnail.max-600x600.format-webp.webp' />The latest episode of the Google AI: Release Notes podcast focuses on how the Gemini team built one of the world’s leading AI coding models.Host Logan Kilpatrick chats w…",
    "summary": "<img src='https://storage.googleapis.com/gweb-uniblog-publish-prod/images/ep8_thumbnail.max-600x600.format-webp.webp' />The latest episode of the Google AI: Release Notes podcast focuses on how the Gemini team built one of the world’s leading AI coding models.Host Logan Kilpatrick chats w…",
    "pubDate": "Wed, 18 Jun 2025 10:28:00 +0000",
    "source": "Google AI Blog",
    "url": "https://blog.google/products/gemini/gemini-coding-podcast/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/ep8_thumbnail.max-1440x810.png"
  },
  {
    "title": "Preparing for future AI risks in biology",
    "description": "Advanced AI can transform biology and medicine—but also raises biosecurity risks. We’re proactively assessing capabilities and implementing safeguards to prevent misuse.",
    "summary": "Advanced AI can transform biology and medicine—but also raises biosecurity risks. We’re proactively assessing capabilities and implementing safeguards to prevent misuse.",
    "pubDate": "Wed, 18 Jun 2025 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/preparing-for-future-ai-capabilities-in-biology",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Search Live: Talk, listen and explore in real time with AI Mode",
    "description": "Logos for AI Mode in Search and Search Live in front of a black background",
    "summary": "Logos for AI Mode in Search and Search Live in front of a black background",
    "pubDate": "Wed, 18 Jun 2025 16:00:00 +0000",
    "source": "Google AI Blog",
    "url": "https://blog.google/products/search/search-live-ai-mode/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/SearchLive_SS.width-1300.png"
  },
  {
    "title": "Toward understanding and preventing misalignment generalization",
    "description": "We study how training on incorrect responses can cause broader misalignment in language models and identify an internal feature driving this behavior—one that can be reversed with minimal fine-tuning.",
    "summary": "We study how training on incorrect responses can cause broader misalignment in language models and identify an internal feature driving this behavior—one that can be reversed with minimal fine-tuning.",
    "pubDate": "Wed, 18 Jun 2025 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/emergent-misalignment",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "(LoRA) Fine-Tuning FLUX.1-dev on Consumer Hardware",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 19 Jun 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/flux-qlora",
    "thumbnail": "https://huggingface.co/blog/assets/flux-qlora/thumbnail.png"
  },
  {
    "title": "Microsoft、また“AIレイオフ”か　営業職中心に数千人を削減　Bloomberg報道",
    "description": "米Microsoftが、営業部門を中心に数千人規模の人員削減を計画していると、米Bloombergが報じた。AIに関する支出増に伴う施策という。",
    "summary": "米Microsoftが、営業部門を中心に数千人規模の人員削減を計画していると、米Bloombergが報じた。AIに関する支出増に伴う施策という。",
    "pubDate": "Thu, 19 Jun 2025 12:40:00 +0900",
    "source": "ITmedia AI",
    "url": "https://www.itmedia.co.jp/news/articles/2506/19/news077.html",
    "thumbnail": "https://image.itmedia.co.jp/news/articles/2506/19/cover_news077.jpg"
  },
  {
    "title": "Napkin AI（ナプキンAI）とは？使い方からかかる料金まで詳しく解説",
    "description": "<p>仕事で使う文章やアイデアをまとめてわかりやすい形で整理したいので、何か良いツールはないか探しているけれど、なかなか見つからず困っている人はいませんか？ 仕事で周囲の人に物事をわかりやすく説明するためには、文章だけではなく [&#8230;]</p> <p>The post <a href='https://aismiley.co.jp/ai_news/what-is-napkinai/'>Napkin AI（ナプキンAI）とは？使い方からかかる料金まで詳しく解説</a> first appeared on <a href='https://aismiley.co.jp'>AIポータルメディアAIsmiley</a>.</p>",
    "summary": "<p>仕事で使う文章やアイデアをまとめてわかりやすい形で整理したいので、何か良いツールはないか探しているけれど、なかなか見つからず困っている人はいませんか？ 仕事で周囲の人に物事をわかりやすく説明するためには、文章だけではなく [&#8230;]</p> <p>The post <a href='https://aismiley.co.jp/ai_news/what-is-napkinai/'>Napkin AI（ナプキンAI）とは？使い方からかかる料金まで詳しく解説</a> first appeared on <a href='https://aismiley.co.jp'>AIポータルメディアAIsmiley</a>.</p>",
    "pubDate": "Thu, 19 Jun 2025 05:40:52 +0000",
    "source": "AI Smily",
    "url": "https://aismiley.co.jp/ai_news/what-is-napkinai/",
    "thumbnail": "https://aismiley.co.jp/wp-content/uploads/2025/02/what-is-dify.jpg"
  },
  {
    "title": "YouTubeショートに動画生成AI「Veo 3」統合へ　今夏",
    "description": "米YouTubeが、YouTube Shortsに米Googleの動画生成AI「Veo 3」を統合すると発表した。",
    "summary": "米YouTubeが、YouTube Shortsに米Googleの動画生成AI「Veo 3」を統合すると発表した。",
    "pubDate": "Thu, 19 Jun 2025 13:53:00 +0900",
    "source": "ITmedia AI",
    "url": "https://www.itmedia.co.jp/news/articles/2506/19/news085.html",
    "thumbnail": "https://image.itmedia.co.jp/news/articles/2506/19/cover_news085.jpg"
  },
  {
    "title": "サイバーエージェント、AIエージェントに年4億円投資　開発エンジニアに月200ドル支援　業務外でも試せる",
    "description": "サイバーエージェントは、エンジニア約1200人に1人当たり月200ドル、開発AIエージェント導入費用をサポートする。",
    "summary": "サイバーエージェントは、エンジニア約1200人に1人当たり月200ドル、開発AIエージェント導入費用をサポートする。",
    "pubDate": "Thu, 19 Jun 2025 15:59:00 +0900",
    "source": "ITmedia AI",
    "url": "https://www.itmedia.co.jp/aiplus/articles/2506/19/news100.html",
    "thumbnail": "https://image.itmedia.co.jp/aiplus/articles/2506/19/cover_news100.jpg"
  },
  {
    "title": "ディズニーらと係争中のMidjourney、動画生成AI「V1」発表　月10ドルから　どんな動画が作れる？",
    "description": "画像生成AIサービス「Midjourney」を提供する米Midjourney社は、同社初の動画生成AI「V1」を発表した。画像を入力すると、5秒の動画を生成する。まずは有料ユーザー向けに、MidjourneyのWeb版で提供を始める。",
    "summary": "画像生成AIサービス「Midjourney」を提供する米Midjourney社は、同社初の動画生成AI「V1」を発表した。画像を入力すると、5秒の動画を生成する。まずは有料ユーザー向けに、MidjourneyのWeb版で提供を始める。",
    "pubDate": "Thu, 19 Jun 2025 15:38:00 +0900",
    "source": "ITmedia AI",
    "url": "https://www.itmedia.co.jp/aiplus/articles/2506/19/news073.html",
    "thumbnail": "https://image.itmedia.co.jp/aiplus/articles/2506/19/cover_news073.jpg"
  },
  {
    "title": "映画「岸辺露伴は動かない」劇伴制作元、AIの利用について声明　“1万6000文字超”で訴えた、AIを使う理由は？",
    "description": "作曲家・菊地成孔さんが率いる楽曲制作グループ「新音楽制作工房」は、生成AIの利用に関する声明を出した。同グループを巡っては、映画「岸辺露伴は動かない 懺悔室」の劇伴をAIを活用して制作。Xで賛否を巻き起こしていた。",
    "summary": "作曲家・菊地成孔さんが率いる楽曲制作グループ「新音楽制作工房」は、生成AIの利用に関する声明を出した。同グループを巡っては、映画「岸辺露伴は動かない 懺悔室」の劇伴をAIを活用して制作。Xで賛否を巻き起こしていた。",
    "pubDate": "Thu, 19 Jun 2025 09:00:00 +0900",
    "source": "ITmedia AI",
    "url": "https://www.itmedia.co.jp/aiplus/articles/2506/17/news107.html",
    "thumbnail": "https://image.itmedia.co.jp/aiplus/articles/2506/17/cover_news107.jpg"
  },
  {
    "title": "銅線泥棒を許さない　KDDI系企業がAWSで一計案じる",
    "description": "KDDIスマートドローンは「Amazon SageMaker」と連携したAI解析ドローンシステムを開発し、太陽光発電施設の夜間警備に実装した。遠隔運航とリアルタイム解析を組み合わせ、人的負担を軽減しつつ盗難対策を強化している。",
    "summary": "KDDIスマートドローンは「Amazon SageMaker」と連携したAI解析ドローンシステムを開発し、太陽光発電施設の夜間警備に実装した。遠隔運航とリアルタイム解析を組み合わせ、人的負担を軽減しつつ盗難対策を強化している。",
    "pubDate": "Thu, 19 Jun 2025 10:00:00 +0900",
    "source": "ITmedia AI",
    "url": "https://kn.itmedia.co.jp/kn/articles/2506/19/news033.html",
    "thumbnail": "https://image.itmedia.co.jp/kn/articles/2506/19/cover_news033.png"
  },
  {
    "title": "MIXIの会話ロボ、ASD・ADHD当事者向けの新モデル発売　会話を通じ、自身の特性理解するサポート",
    "description": "MIXIは、自閉スペクトラム症（ASD）と注意欠如・多動症（ADHD）当事者の社会人向けに、AI会話ロボット「Romi」の新モデル「ライフスキルトレーニングモデル」を発売した。Romiとの会話を通じて、ASD・ADHD当事者が自身の特性を理解する手助けをするという。",
    "summary": "MIXIは、自閉スペクトラム症（ASD）と注意欠如・多動症（ADHD）当事者の社会人向けに、AI会話ロボット「Romi」の新モデル「ライフスキルトレーニングモデル」を発売した。Romiとの会話を通じて、ASD・ADHD当事者が自身の特性を理解する手助けをするという。",
    "pubDate": "Fri, 20 Jun 2025 18:36:00 +0900",
    "source": "ITmedia AI",
    "url": "https://www.itmedia.co.jp/aiplus/articles/2506/20/news099.html",
    "thumbnail": "https://image.itmedia.co.jp/aiplus/articles/2506/20/cover_news099.jpg"
  },
  {
    "title": "OpenAI、AIによる生物兵器開発リスクに警鐘",
    "description": "OpenAIは、AIが悪用され生物兵器開発につながる深刻なリスクがあると警告した。同社の将来のAIモデルは専門知識のない人物による生物学的脅威の作成を可能にする恐れがあるという。有害リクエストの拒否や専門家との連携、疑わしい行為の監視などの多角的な対策を講じ、社会全体の防御力向上も提唱している。",
    "summary": "OpenAIは、AIが悪用され生物兵器開発につながる深刻なリスクがあると警告した。同社の将来のAIモデルは専門知識のない人物による生物学的脅威の作成を可能にする恐れがあるという。有害リクエストの拒否や専門家との連携、疑わしい行為の監視などの多角的な対策を講じ、社会全体の防御力向上も提唱している。",
    "pubDate": "Fri, 20 Jun 2025 07:04:00 +0900",
    "source": "ITmedia AI",
    "url": "https://www.itmedia.co.jp/aiplus/articles/2506/20/news054.html",
    "thumbnail": "https://image.itmedia.co.jp/aiplus/articles/2506/20/cover_news054.jpg"
  },
  {
    "title": "OpenAI、AIモデルに潜む“悪ガキペルソナ”の更生について説明",
    "description": "OpenAIは、AIモデルが意図せず「悪ガキペルソナ」のような望ましくない振る舞いをする「誤アラインメント」に関する論文を公開した。不適切な学習が特定のペルソナを増幅させることが原因だという。対策として高品質なデータの使用が重要で、発生後も少量の良質なデータで再調整すれば修復可能としている。",
    "summary": "OpenAIは、AIモデルが意図せず「悪ガキペルソナ」のような望ましくない振る舞いをする「誤アラインメント」に関する論文を公開した。不適切な学習が特定のペルソナを増幅させることが原因だという。対策として高品質なデータの使用が重要で、発生後も少量の良質なデータで再調整すれば修復可能としている。",
    "pubDate": "Fri, 20 Jun 2025 10:58:00 +0900",
    "source": "ITmedia AI",
    "url": "https://www.itmedia.co.jp/aiplus/articles/2506/20/news062.html",
    "thumbnail": "https://image.itmedia.co.jp/aiplus/articles/2506/20/cover_news062.jpg"
  },
  {
    "title": "Researchers present bold ideas for AI at MIT Generative AI Impact Consortium kickoff event",
    "description": "Presentations targeted high-impact intersections of AI and other areas, such as health care, business, and education.",
    "summary": "Presentations targeted high-impact intersections of AI and other areas, such as health care, business, and education.",
    "pubDate": "Fri, 20 Jun 2025 16:45:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/researchers-present-bold-ideas-ai-mit-generative-ai-impact-consortium-event-0620",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202506/mit-Anantha.jpg"
  },
  {
    "title": "アングラAI「WormGPT」の亜種が登場　Grokなどのモデルを改造か",
    "description": "Cato Networksは、地下フォーラムで流通するWormGPT派生2モデルの存在を報告した。GrokとMixtralを悪用したkeanu-WormGPTとxzin0vich-WormGPTが検閲回避で犯罪支援に利用されている実態が明らかになっている。",
    "summary": "Cato Networksは、地下フォーラムで流通するWormGPT派生2モデルの存在を報告した。GrokとMixtralを悪用したkeanu-WormGPTとxzin0vich-WormGPTが検閲回避で犯罪支援に利用されている実態が明らかになっている。",
    "pubDate": "Fri, 20 Jun 2025 07:00:00 +0900",
    "source": "ITmedia AI",
    "url": "https://www.itmedia.co.jp/enterprise/articles/2506/20/news022.html",
    "thumbnail": "https://image.itmedia.co.jp/enterprise/articles/2506/20/cover_news022.jpg"
  },
  {
    "title": "プロジェクトマネジャーが生成AI導入のために“今すぐできる”3つのこと　Googleがブログで紹介",
    "description": "プロジェクトマネジャー（PM）が組織に生成AIを導入するため“今すぐできる”3つのこと――米Googleが公式ブログで、こんなチェックリストを公開している。",
    "summary": "プロジェクトマネジャー（PM）が組織に生成AIを導入するため“今すぐできる”3つのこと――米Googleが公式ブログで、こんなチェックリストを公開している。",
    "pubDate": "Fri, 20 Jun 2025 07:00:00 +0900",
    "source": "ITmedia AI",
    "url": "https://www.itmedia.co.jp/aiplus/articles/2506/19/news110.html",
    "thumbnail": "https://image.itmedia.co.jp/aiplus/articles/2506/19/cover_news110.jpg"
  },
  {
    "title": "A Brain-to-Population Graph Learning Framework for Diagnosing Brain Disorders",
    "description": "arXiv:2506.16096v1 Announce Type: cross Abstract: Recent developed graph-based methods for diagnosing brain disorders using functional connectivity highly rely on predefined brain atlases, but overlook the rich information embedded within atlases and the confounding effects of site and phenotype variability. To address these challenges, we propose a two-stage Brain-to-Population Graph Learning (B2P-GL) framework that integrates the semantic similarity of brain regions and condition-based population graph modeling. In the first stage, termed brain representation learning, we leverage brain atlas knowledge from GPT-4 to enrich the graph representation and refine the brain graph through an adaptive node reassignment graph attention network. In the second stage, termed population disorder diagnosis, phenotypic data is incorporated into population graph construction and feature fusion to mitigate confounding effects and enhance diagnosis performance. Experiments on the ABIDE I, ADHD-200, and Rest-meta-MDD datasets show that B2P-GL outperforms state-of-the-art methods in prediction accuracy while enhancing interpretability. Overall, our proposed framework offers a reliable and personalized approach to brain disorder diagnosis, advancing clinical applicability.",
    "summary": "arXiv:2506.16096v1 Announce Type: cross Abstract: Recent developed graph-based methods for diagnosing brain disorders using functional connectivity highly rely on predefined brain atlases, but overlook the rich information embedded within atlases and the confounding effects of site and phenotype variability. To address these challenges, we propose a two-stage Brain-to-Population Graph Learning (B2P-GL) framework that integrates the semantic similarity of brain regions and condition-based population graph modeling. In the first stage, termed brain representation learning, we leverage brain atlas knowledge from GPT-4 to enrich the graph representation and refine the brain graph through an adaptive node reassignment graph attention network. In the second stage, termed population disorder diagnosis, phenotypic data is incorporated into population graph construction and feature fusion to mitigate confounding effects and enhance diagnosis performance. Experiments on the ABIDE I, ADHD-200, and Rest-meta-MDD datasets show that B2P-GL outperforms state-of-the-art methods in prediction accuracy while enhancing interpretability. Overall, our proposed framework offers a reliable and personalized approach to brain disorder diagnosis, advancing clinical applicability.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16096",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "A Community-driven vision for a new Knowledge Resource for AI",
    "description": "arXiv:2506.16596v1 Announce Type: new Abstract: The long-standing goal of creating a comprehensive, multi-purpose knowledge resource, reminiscent of the 1984 Cyc project, still persists in AI. Despite the success of knowledge resources like WordNet, ConceptNet, Wolfram|Alpha and other commercial knowledge graphs, verifiable, general-purpose widely available sources of knowledge remain a critical deficiency in AI infrastructure. Large language models struggle due to knowledge gaps; robotic planning lacks necessary world knowledge; and the detection of factually false information relies heavily on human expertise. What kind of knowledge resource is most needed in AI today? How can modern technology shape its development and evaluation? A recent AAAI workshop gathered over 50 researchers to explore these questions. This paper synthesizes our findings and outlines a community-driven vision for a new knowledge infrastructure. In addition to leveraging contemporary advances in knowledge representation and reasoning, one promising idea is to build an open engineering framework to exploit knowledge modules effectively within the context of practical applications. Such a framework should include sets of conventions and social structures that are adopted by contributors.",
    "summary": "arXiv:2506.16596v1 Announce Type: new Abstract: The long-standing goal of creating a comprehensive, multi-purpose knowledge resource, reminiscent of the 1984 Cyc project, still persists in AI. Despite the success of knowledge resources like WordNet, ConceptNet, Wolfram|Alpha and other commercial knowledge graphs, verifiable, general-purpose widely available sources of knowledge remain a critical deficiency in AI infrastructure. Large language models struggle due to knowledge gaps; robotic planning lacks necessary world knowledge; and the detection of factually false information relies heavily on human expertise. What kind of knowledge resource is most needed in AI today? How can modern technology shape its development and evaluation? A recent AAAI workshop gathered over 50 researchers to explore these questions. This paper synthesizes our findings and outlines a community-driven vision for a new knowledge infrastructure. In addition to leveraging contemporary advances in knowledge representation and reasoning, one promising idea is to build an open engineering framework to exploit knowledge modules effectively within the context of practical applications. Such a framework should include sets of conventions and social structures that are adopted by contributors.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16596",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "A deep learning and machine learning approach to predict neonatal death in the context of S~ao Paulo",
    "description": "arXiv:2506.16929v1 Announce Type: cross Abstract: Neonatal death is still a concerning reality for underdeveloped and even some developed countries. Worldwide data indicate that 26.693 babies out of 1,000 births die, according to Macro Trades. To reduce this number, early prediction of endangered babies is crucial. Such prediction enables the opportunity to take ample care of the child and mother so that early child death can be avoided. In this context, machine learning was used to determine whether a newborn baby is at risk. To train the predictive model, historical data of 1.4 million newborns was used. Machine learning and deep learning techniques such as logical regression, K-nearest neighbor, random forest classifier, extreme gradient boosting (XGBoost), convolutional neural network, and long short-term memory (LSTM) were implemented using the dataset to identify the most accurate model for predicting neonatal mortality. Among the machine learning algorithms, XGBoost and random forest classifier achieved the best accuracy with 94%, while among the deep learning models, LSTM delivered the highest accuracy with 99%. Therefore, using LSTM appears to be the most suitable approach to predict whether precautionary measures for a child are necessary.",
    "summary": "arXiv:2506.16929v1 Announce Type: cross Abstract: Neonatal death is still a concerning reality for underdeveloped and even some developed countries. Worldwide data indicate that 26.693 babies out of 1,000 births die, according to Macro Trades. To reduce this number, early prediction of endangered babies is crucial. Such prediction enables the opportunity to take ample care of the child and mother so that early child death can be avoided. In this context, machine learning was used to determine whether a newborn baby is at risk. To train the predictive model, historical data of 1.4 million newborns was used. Machine learning and deep learning techniques such as logical regression, K-nearest neighbor, random forest classifier, extreme gradient boosting (XGBoost), convolutional neural network, and long short-term memory (LSTM) were implemented using the dataset to identify the most accurate model for predicting neonatal mortality. Among the machine learning algorithms, XGBoost and random forest classifier achieved the best accuracy with 94%, while among the deep learning models, LSTM delivered the highest accuracy with 99%. Therefore, using LSTM appears to be the most suitable approach to predict whether precautionary measures for a child are necessary.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16929",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "A Hybrid DeBERTa and Gated Broad Learning System for Cyberbullying Detection in English Text",
    "description": "arXiv:2506.16052v1 Announce Type: cross Abstract: The proliferation of online communication platforms has created unprecedented opportunities for global connectivity while simultaneously enabling harmful behaviors such as cyberbullying, which affects approximately 54.4% of teenagers according to recent research. This paper presents a hybrid architecture that combines the contextual understanding capabilities of transformer-based models with the pattern recognition strengths of broad learning systems for effective cyberbullying detection. This approach integrates a modified DeBERTa model augmented with Squeeze-and-Excitation blocks and sentiment analysis capabilities with a Gated Broad Learning System (GBLS) classifier, creating a synergistic framework that outperforms existing approaches across multiple benchmark datasets. The proposed ModifiedDeBERTa + GBLS model achieved good performance on four English datasets: 79.3% accuracy on HateXplain, 95.41% accuracy on SOSNet, 91.37% accuracy on Mendeley-I, and 94.67% accuracy on Mendeley-II. Beyond performance gains, the framework incorporates comprehensive explainability mechanisms including token-level attribution analysis, LIME-based local interpretations, and confidence calibration, addressing critical transparency requirements in automated content moderation. Ablation studies confirm the meaningful contribution of each architectural component, while failure case analysis reveals specific challenges in detecting implicit bias and sarcastic content, providing valuable insights for future improvements in cyberbullying detection systems.",
    "summary": "arXiv:2506.16052v1 Announce Type: cross Abstract: The proliferation of online communication platforms has created unprecedented opportunities for global connectivity while simultaneously enabling harmful behaviors such as cyberbullying, which affects approximately 54.4% of teenagers according to recent research. This paper presents a hybrid architecture that combines the contextual understanding capabilities of transformer-based models with the pattern recognition strengths of broad learning systems for effective cyberbullying detection. This approach integrates a modified DeBERTa model augmented with Squeeze-and-Excitation blocks and sentiment analysis capabilities with a Gated Broad Learning System (GBLS) classifier, creating a synergistic framework that outperforms existing approaches across multiple benchmark datasets. The proposed ModifiedDeBERTa + GBLS model achieved good performance on four English datasets: 79.3% accuracy on HateXplain, 95.41% accuracy on SOSNet, 91.37% accuracy on Mendeley-I, and 94.67% accuracy on Mendeley-II. Beyond performance gains, the framework incorporates comprehensive explainability mechanisms including token-level attribution analysis, LIME-based local interpretations, and confidence calibration, addressing critical transparency requirements in automated content moderation. Ablation studies confirm the meaningful contribution of each architectural component, while failure case analysis reveals specific challenges in detecting implicit bias and sarcastic content, providing valuable insights for future improvements in cyberbullying detection systems.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16052",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "A Implies B: Circuit Analysis in LLMs for Propositional Logical Reasoning",
    "description": "arXiv:2411.04105v4 Announce Type: replace-cross Abstract: Due to the size and complexity of modern large language models (LLMs), it has proven challenging to uncover the underlying mechanisms that models use to solve reasoning problems. For instance, is their reasoning for a specific problem localized to certain parts of the network? Do they break down the reasoning problem into modular components that are then executed as sequential steps as we go deeper in the model? To better understand the reasoning capability of LLMs, we study a minimal propositional logic problem that requires combining multiple facts to arrive at a solution. By studying this problem on Mistral and Gemma models, up to 27B parameters, we illuminate the core components the models use to solve such logic problems. From a mechanistic interpretability point of view, we use causal mediation analysis to uncover the pathways and components of the LLMs' reasoning processes. Then, we offer fine-grained insights into the functions of attention heads in different layers. We not only find a sparse circuit that computes the answer, but we decompose it into sub-circuits that have four distinct and modular uses. Finally, we reveal that three distinct models -- Mistral-7B, Gemma-2-9B and Gemma-2-27B -- contain analogous but not identical mechanisms.",
    "summary": "arXiv:2411.04105v4 Announce Type: replace-cross Abstract: Due to the size and complexity of modern large language models (LLMs), it has proven challenging to uncover the underlying mechanisms that models use to solve reasoning problems. For instance, is their reasoning for a specific problem localized to certain parts of the network? Do they break down the reasoning problem into modular components that are then executed as sequential steps as we go deeper in the model? To better understand the reasoning capability of LLMs, we study a minimal propositional logic problem that requires combining multiple facts to arrive at a solution. By studying this problem on Mistral and Gemma models, up to 27B parameters, we illuminate the core components the models use to solve such logic problems. From a mechanistic interpretability point of view, we use causal mediation analysis to uncover the pathways and components of the LLMs' reasoning processes. Then, we offer fine-grained insights into the functions of attention heads in different layers. We not only find a sparse circuit that computes the answer, but we decompose it into sub-circuits that have four distinct and modular uses. Finally, we reveal that three distinct models -- Mistral-7B, Gemma-2-9B and Gemma-2-27B -- contain analogous but not identical mechanisms.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2411.04105",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "A Minimalist Method for Fine-tuning Text-to-Image Diffusion Models",
    "description": "arXiv:2506.12036v2 Announce Type: replace-cross Abstract: Recent work uses reinforcement learning (RL) to fine-tune text-to-image diffusion models, improving text-image alignment and sample quality. However, existing approaches introduce unnecessary complexity: they cache the full sampling trajectory, depend on differentiable reward models or large preference datasets, or require specialized guidance techniques. Motivated by the 'golden noise' hypothesis -- that certain initial noise samples can consistently yield superior alignment -- we introduce Noise PPO, a minimalist RL algorithm that leaves the pre-trained diffusion model entirely frozen and learns a prompt-conditioned initial noise generator. Our approach requires no trajectory storage, reward backpropagation, or complex guidance tricks. Extensive experiments show that optimizing the initial noise distribution consistently improves alignment and sample quality over the original model, with the most significant gains at low inference steps. As the number of inference steps increases, the benefit of noise optimization diminishes but remains present. These findings clarify the scope and limitations of the golden noise hypothesis and reinforce the practical value of minimalist RL fine-tuning for diffusion models.",
    "summary": "arXiv:2506.12036v2 Announce Type: replace-cross Abstract: Recent work uses reinforcement learning (RL) to fine-tune text-to-image diffusion models, improving text-image alignment and sample quality. However, existing approaches introduce unnecessary complexity: they cache the full sampling trajectory, depend on differentiable reward models or large preference datasets, or require specialized guidance techniques. Motivated by the 'golden noise' hypothesis -- that certain initial noise samples can consistently yield superior alignment -- we introduce Noise PPO, a minimalist RL algorithm that leaves the pre-trained diffusion model entirely frozen and learns a prompt-conditioned initial noise generator. Our approach requires no trajectory storage, reward backpropagation, or complex guidance tricks. Extensive experiments show that optimizing the initial noise distribution consistently improves alignment and sample quality over the original model, with the most significant gains at low inference steps. As the number of inference steps increases, the benefit of noise optimization diminishes but remains present. These findings clarify the scope and limitations of the golden noise hypothesis and reinforce the practical value of minimalist RL fine-tuning for diffusion models.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.12036",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "A Minimalist Optimizer Design for LLM Pretraining",
    "description": "arXiv:2506.16659v1 Announce Type: cross Abstract: Training large language models (LLMs) typically relies on adaptive optimizers such as Adam, which require significant memory to maintain first- and second-moment matrices, known as optimizer states. While recent works such as GaLore, Fira, and APOLLO have proposed state-compressed variants to reduce memory consumption, a fundamental question remains: What is the minimal amount of optimizer state that is truly necessary to retain state-of-the-art performance in LLM pretraining? In this work, we systematically investigate this question using a bottom-up approach. We find that two memory- and compute-efficient optimization techniques are particularly effective: (1) column-wise gradient normalization significantly boosts the performance of plain SGD without requiring momentum; and (2) adding first-order momentum only to the output layer - where gradient variance is highest - yields performance competitive with fully adaptive methods such as Muon. Based on these insights, we propose SCALE (Stochastic Column-normalized Last-layer Momentum), a new optimizer that combines column-normalized SGD with last-layer momentum, where column normalization refers to normalizing the gradient along the output dimension. Across multiple LLaMA models (60M-1B), SCALE matches or exceeds the performance of Adam while using only 35-45% of the total memory. It also consistently outperforms memory-efficient optimizers such as GaLore, Fira, and APOLLO, making it a strong candidate for large-scale pretraining under memory constraints. For the LLaMA 7B model, SCALE outperforms the state-of-the-art method APOLLO in terms of both perplexity and memory consumption. In addition, our method serves as a minimalist baseline for more sophisticated optimizer design.",
    "summary": "arXiv:2506.16659v1 Announce Type: cross Abstract: Training large language models (LLMs) typically relies on adaptive optimizers such as Adam, which require significant memory to maintain first- and second-moment matrices, known as optimizer states. While recent works such as GaLore, Fira, and APOLLO have proposed state-compressed variants to reduce memory consumption, a fundamental question remains: What is the minimal amount of optimizer state that is truly necessary to retain state-of-the-art performance in LLM pretraining? In this work, we systematically investigate this question using a bottom-up approach. We find that two memory- and compute-efficient optimization techniques are particularly effective: (1) column-wise gradient normalization significantly boosts the performance of plain SGD without requiring momentum; and (2) adding first-order momentum only to the output layer - where gradient variance is highest - yields performance competitive with fully adaptive methods such as Muon. Based on these insights, we propose SCALE (Stochastic Column-normalized Last-layer Momentum), a new optimizer that combines column-normalized SGD with last-layer momentum, where column normalization refers to normalizing the gradient along the output dimension. Across multiple LLaMA models (60M-1B), SCALE matches or exceeds the performance of Adam while using only 35-45% of the total memory. It also consistently outperforms memory-efficient optimizers such as GaLore, Fira, and APOLLO, making it a strong candidate for large-scale pretraining under memory constraints. For the LLaMA 7B model, SCALE outperforms the state-of-the-art method APOLLO in terms of both perplexity and memory consumption. In addition, our method serves as a minimalist baseline for more sophisticated optimizer design.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16659",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "A Quantile Regression Approach for Remaining Useful Life Estimation with State Space Models",
    "description": "arXiv:2506.17018v1 Announce Type: new Abstract: Predictive Maintenance (PdM) is pivotal in Industry 4.0 and 5.0, proactively enhancing efficiency through accurate equipment Remaining Useful Life (RUL) prediction, thus optimizing maintenance scheduling and reducing unexpected failures and premature interventions. This paper introduces a novel RUL estimation approach leveraging State Space Models (SSM) for efficient long-term sequence modeling. To handle model uncertainty, Simoultaneous Quantile Regression (SQR) is integrated into the SSM, enabling multiple quantile estimations. The proposed method is benchmarked against traditional sequence modelling techniques (LSTM, Transformer, Informer) using the C-MAPSS dataset. Results demonstrate superior accuracy and computational efficiency of SSM models, underscoring their potential for high-stakes industrial applications.",
    "summary": "arXiv:2506.17018v1 Announce Type: new Abstract: Predictive Maintenance (PdM) is pivotal in Industry 4.0 and 5.0, proactively enhancing efficiency through accurate equipment Remaining Useful Life (RUL) prediction, thus optimizing maintenance scheduling and reducing unexpected failures and premature interventions. This paper introduces a novel RUL estimation approach leveraging State Space Models (SSM) for efficient long-term sequence modeling. To handle model uncertainty, Simoultaneous Quantile Regression (SQR) is integrated into the SSM, enabling multiple quantile estimations. The proposed method is benchmarked against traditional sequence modelling techniques (LSTM, Transformer, Informer) using the C-MAPSS dataset. Results demonstrate superior accuracy and computational efficiency of SSM models, underscoring their potential for high-stakes industrial applications.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.17018",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "A Simple Contrastive Framework Of Item Tokenization For Generative Recommendation",
    "description": "arXiv:2506.16683v1 Announce Type: cross Abstract: Generative retrieval-based recommendation has emerged as a promising paradigm aiming at directly generating the identifiers of the target candidates. However, in large-scale recommendation systems, this approach becomes increasingly cumbersome due to the redundancy and sheer scale of the token space. To overcome these limitations, recent research has explored the use of semantic tokens as an alternative to ID tokens, which typically leveraged reconstruction-based strategies, like RQ-VAE, to quantize content embeddings and significantly reduce the embedding size. However, reconstructive quantization aims for the precise reconstruction of each item embedding independently, which conflicts with the goal of generative retrieval tasks focusing more on differentiating among items. Moreover, multi-modal side information of items, such as descriptive text and images, geographical knowledge in location-based recommendation services, has been shown to be effective in improving recommendations by providing richer contexts for interactions. Nevertheless, effectively integrating such complementary knowledge into existing generative recommendation frameworks remains challenging. To overcome these challenges, we propose a novel unsupervised deep quantization exclusively based on contrastive learning, named SimCIT (a Simple Contrastive Item Tokenization framework). Specifically, different from existing reconstruction-based strategies, SimCIT propose to use a learnable residual quantization module to align with the signals from different modalities of the items, which combines multi-modal knowledge alignment and semantic tokenization in a mutually beneficial contrastive learning framework. Extensive experiments across public datasets and a large-scale industrial dataset from various domains demonstrate SimCIT's effectiveness in LLM-based generative recommendation.",
    "summary": "arXiv:2506.16683v1 Announce Type: cross Abstract: Generative retrieval-based recommendation has emerged as a promising paradigm aiming at directly generating the identifiers of the target candidates. However, in large-scale recommendation systems, this approach becomes increasingly cumbersome due to the redundancy and sheer scale of the token space. To overcome these limitations, recent research has explored the use of semantic tokens as an alternative to ID tokens, which typically leveraged reconstruction-based strategies, like RQ-VAE, to quantize content embeddings and significantly reduce the embedding size. However, reconstructive quantization aims for the precise reconstruction of each item embedding independently, which conflicts with the goal of generative retrieval tasks focusing more on differentiating among items. Moreover, multi-modal side information of items, such as descriptive text and images, geographical knowledge in location-based recommendation services, has been shown to be effective in improving recommendations by providing richer contexts for interactions. Nevertheless, effectively integrating such complementary knowledge into existing generative recommendation frameworks remains challenging. To overcome these challenges, we propose a novel unsupervised deep quantization exclusively based on contrastive learning, named SimCIT (a Simple Contrastive Item Tokenization framework). Specifically, different from existing reconstruction-based strategies, SimCIT propose to use a learnable residual quantization module to align with the signals from different modalities of the items, which combines multi-modal knowledge alignment and semantic tokenization in a mutually beneficial contrastive learning framework. Extensive experiments across public datasets and a large-scale industrial dataset from various domains demonstrate SimCIT's effectiveness in LLM-based generative recommendation.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16683",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "A Study of Hybrid and Evolutionary Metaheuristics for Single Hidden Layer Feedforward Neural Network Architecture",
    "description": "arXiv:2506.15737v1 Announce Type: cross Abstract: Training Artificial Neural Networks (ANNs) with Stochastic Gradient Descent (SGD) frequently encounters difficulties, including substantial computing expense and the risk of converging to local optima, attributable to its dependence on partial weight gradients. Therefore, this work investigates Particle Swarm Optimization (PSO) and Genetic Algorithms (GAs) - two population-based Metaheuristic Optimizers (MHOs) - as alternatives to SGD to mitigate these constraints. A hybrid PSO-SGD strategy is developed to improve local search efficiency. The findings indicate that the hybrid PSO-SGD technique decreases the median training MSE by 90 to 95 percent relative to conventional GA and PSO across various network sizes (e.g., from around 0.02 to approximately 0.001 in the Sphere function). RMHC attains substantial enhancements, reducing MSE by roughly 85 to 90 percent compared to GA. Simultaneously, RS consistently exhibits errors exceeding 0.3, signifying subpar performance. These findings underscore that hybrid and evolutionary procedures significantly improve training efficiency and accuracy compared to conventional optimization methods and imply that the Building Block Hypothesis (BBH) may still be valid, indicating that advantageous weight structures are retained during evolutionary search.",
    "summary": "arXiv:2506.15737v1 Announce Type: cross Abstract: Training Artificial Neural Networks (ANNs) with Stochastic Gradient Descent (SGD) frequently encounters difficulties, including substantial computing expense and the risk of converging to local optima, attributable to its dependence on partial weight gradients. Therefore, this work investigates Particle Swarm Optimization (PSO) and Genetic Algorithms (GAs) - two population-based Metaheuristic Optimizers (MHOs) - as alternatives to SGD to mitigate these constraints. A hybrid PSO-SGD strategy is developed to improve local search efficiency. The findings indicate that the hybrid PSO-SGD technique decreases the median training MSE by 90 to 95 percent relative to conventional GA and PSO across various network sizes (e.g., from around 0.02 to approximately 0.001 in the Sphere function). RMHC attains substantial enhancements, reducing MSE by roughly 85 to 90 percent compared to GA. Simultaneously, RS consistently exhibits errors exceeding 0.3, signifying subpar performance. These findings underscore that hybrid and evolutionary procedures significantly improve training efficiency and accuracy compared to conventional optimization methods and imply that the Building Block Hypothesis (BBH) may still be valid, indicating that advantageous weight structures are retained during evolutionary search.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.15737",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "A Survey of Automatic Hallucination Evaluation on Natural Language Generation",
    "description": "arXiv:2404.12041v3 Announce Type: replace-cross Abstract: The proliferation of Large Language Models (LLMs) has introduced a critical challenge: accurate hallucination evaluation that ensures model reliability. While Automatic Hallucination Evaluation (AHE) has emerged as essential, the field suffers from methodological fragmentation, hindering both theoretical understanding and practical advancement. This survey addresses this critical gap through a comprehensive analysis of 74 evaluation methods, revealing that 74% specifically target LLMs, a paradigm shift that demands new evaluation frameworks. We formulate a unified evaluation pipeline encompassing datasets and benchmarks, evidence collection strategies, and comparison mechanisms, systematically documenting the evolution from pre-LLM to post-LLM methodologies. Beyond taxonomical organization, we identify fundamental limitations in current approaches and their implications for real-world deployment. To guide future research, we delineate key challenges and propose strategic directions, including enhanced interpretability mechanisms and integration of application-specific evaluation criteria, ultimately providing a roadmap for developing more robust and practical hallucination evaluation systems.",
    "summary": "arXiv:2404.12041v3 Announce Type: replace-cross Abstract: The proliferation of Large Language Models (LLMs) has introduced a critical challenge: accurate hallucination evaluation that ensures model reliability. While Automatic Hallucination Evaluation (AHE) has emerged as essential, the field suffers from methodological fragmentation, hindering both theoretical understanding and practical advancement. This survey addresses this critical gap through a comprehensive analysis of 74 evaluation methods, revealing that 74% specifically target LLMs, a paradigm shift that demands new evaluation frameworks. We formulate a unified evaluation pipeline encompassing datasets and benchmarks, evidence collection strategies, and comparison mechanisms, systematically documenting the evolution from pre-LLM to post-LLM methodologies. Beyond taxonomical organization, we identify fundamental limitations in current approaches and their implications for real-world deployment. To guide future research, we delineate key challenges and propose strategic directions, including enhanced interpretability mechanisms and integration of application-specific evaluation criteria, ultimately providing a roadmap for developing more robust and practical hallucination evaluation systems.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2404.12041",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "A Technical Study into 0.5B Reasoning Language Models",
    "description": "arXiv:2506.13404v2 Announce Type: replace Abstract: The ongoing evolution of language models has led to the development of large-scale architectures that demonstrate exceptional performance across a wide range of tasks. However, these models come with significant computational and energy demands, as well as potential privacy implications. In this context, Small Reasoning Language Models (SRLMs) with approximately 0.5 billion parameters present a compelling alternative due to their remarkable computational efficiency and cost effectiveness, particularly in resource-constrained environments. Despite these advantages, the limited capacity of 0.5 billion parameter models poses challenges in handling complex tasks such as mathematical reasoning and code generation. This research investigates various training strategies, including supervised fine-tuning (SFT), knowledge distillation (KD), and reinforcement learning (RL), as well as their hybrid implementations, to enhance the performance of 0.5B SRLMs. We analyze effective methodologies to bridge the performance gap between SRLMS and larger models and present insights into optimal training pipelines tailored for these smaller architectures. Through extensive experimental validation and analysis, our work aims to provide actionable recommendations for maximizing the reasoning capabilities of 0.5B models.",
    "summary": "arXiv:2506.13404v2 Announce Type: replace Abstract: The ongoing evolution of language models has led to the development of large-scale architectures that demonstrate exceptional performance across a wide range of tasks. However, these models come with significant computational and energy demands, as well as potential privacy implications. In this context, Small Reasoning Language Models (SRLMs) with approximately 0.5 billion parameters present a compelling alternative due to their remarkable computational efficiency and cost effectiveness, particularly in resource-constrained environments. Despite these advantages, the limited capacity of 0.5 billion parameter models poses challenges in handling complex tasks such as mathematical reasoning and code generation. This research investigates various training strategies, including supervised fine-tuning (SFT), knowledge distillation (KD), and reinforcement learning (RL), as well as their hybrid implementations, to enhance the performance of 0.5B SRLMs. We analyze effective methodologies to bridge the performance gap between SRLMS and larger models and present insights into optimal training pipelines tailored for these smaller architectures. Through extensive experimental validation and analysis, our work aims to provide actionable recommendations for maximizing the reasoning capabilities of 0.5B models.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.13404",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "A Vietnamese Dataset for Text Segmentation and Multiple Choices Reading Comprehension",
    "description": "arXiv:2506.15978v1 Announce Type: cross Abstract: Vietnamese, the 20th most spoken language with over 102 million native speakers, lacks robust resources for key natural language processing tasks such as text segmentation and machine reading comprehension (MRC). To address this gap, we present VSMRC, the Vietnamese Text Segmentation and Multiple-Choice Reading Comprehension Dataset. Sourced from Vietnamese Wikipedia, our dataset includes 15,942 documents for text segmentation and 16,347 synthetic multiple-choice question-answer pairs generated with human quality assurance, ensuring a reliable and diverse resource. Experiments show that mBERT consistently outperforms monolingual models on both tasks, achieving an accuracy of 88.01% on MRC test set and an F1 score of 63.15% on text segmentation test set. Our analysis reveals that multilingual models excel in NLP tasks for Vietnamese, suggesting potential applications to other under-resourced languages. VSMRC is available at HuggingFace",
    "summary": "arXiv:2506.15978v1 Announce Type: cross Abstract: Vietnamese, the 20th most spoken language with over 102 million native speakers, lacks robust resources for key natural language processing tasks such as text segmentation and machine reading comprehension (MRC). To address this gap, we present VSMRC, the Vietnamese Text Segmentation and Multiple-Choice Reading Comprehension Dataset. Sourced from Vietnamese Wikipedia, our dataset includes 15,942 documents for text segmentation and 16,347 synthetic multiple-choice question-answer pairs generated with human quality assurance, ensuring a reliable and diverse resource. Experiments show that mBERT consistently outperforms monolingual models on both tasks, achieving an accuracy of 88.01% on MRC test set and an F1 score of 63.15% on text segmentation test set. Our analysis reveals that multilingual models excel in NLP tasks for Vietnamese, suggesting potential applications to other under-resourced languages. VSMRC is available at HuggingFace",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.15978",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Adapting While Learning: Grounding LLMs for Scientific Problems with Intelligent Tool Usage Adaptation",
    "description": "arXiv:2411.00412v4 Announce Type: replace-cross Abstract: Large Language Models (LLMs) demonstrate promising capabilities in solving scientific problems but often suffer from the issue of hallucination. While integrating LLMs with tools can mitigate this issue, models fine-tuned on tool usage become overreliant on them and incur unnecessary costs. Inspired by how human experts assess problem complexity before selecting solutions, we propose a novel two-component fine-tuning method, Adapting While Learning (AWL). In the first component, World Knowledge Learning (WKL), LLMs internalize scientific knowledge by learning from tool-generated solutions. In the second component, Tool Usage Adaptation (TUA), we categorize problems as easy or hard based on the model's accuracy, and train it to maintain direct reasoning for easy problems while switching to tools for hard ones. We validate our method on six scientific benchmark datasets across climate science, epidemiology, physics, and other domains. Compared to the original instruct model (8B), models post-trained with AWL achieve 29.11% higher answer accuracy and 12.72% better tool usage accuracy, even surpassing state-of-the-art models including GPT-4o and Claude-3.5 on four custom-created datasets. Our code is open-source at https://github.com/Rose-STL-Lab/Adapting-While-Learning.",
    "summary": "arXiv:2411.00412v4 Announce Type: replace-cross Abstract: Large Language Models (LLMs) demonstrate promising capabilities in solving scientific problems but often suffer from the issue of hallucination. While integrating LLMs with tools can mitigate this issue, models fine-tuned on tool usage become overreliant on them and incur unnecessary costs. Inspired by how human experts assess problem complexity before selecting solutions, we propose a novel two-component fine-tuning method, Adapting While Learning (AWL). In the first component, World Knowledge Learning (WKL), LLMs internalize scientific knowledge by learning from tool-generated solutions. In the second component, Tool Usage Adaptation (TUA), we categorize problems as easy or hard based on the model's accuracy, and train it to maintain direct reasoning for easy problems while switching to tools for hard ones. We validate our method on six scientific benchmark datasets across climate science, epidemiology, physics, and other domains. Compared to the original instruct model (8B), models post-trained with AWL achieve 29.11% higher answer accuracy and 12.72% better tool usage accuracy, even surpassing state-of-the-art models including GPT-4o and Claude-3.5 on four custom-created datasets. Our code is open-source at https://github.com/Rose-STL-Lab/Adapting-While-Learning.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2411.00412",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Adaptive Experimental Design for Policy Learning",
    "description": "arXiv:2401.03756v4 Announce Type: replace-cross Abstract: This study investigates the contextual best arm identification (BAI) problem, aiming to design an adaptive experiment to identify the best treatment arm conditioned on contextual information (covariates). We consider a decision-maker who assigns treatment arms to experimental units during an experiment and recommends the estimated best treatment arm based on the contexts at the end of the experiment. The decision-maker uses a policy for recommendations, which is a function that provides the estimated best treatment arm given the contexts. In our evaluation, we focus on the worst-case expected regret, a relative measure between the expected outcomes of an optimal policy and our proposed policy. We derive a lower bound for the expected simple regret and then propose a strategy called Adaptive Sampling-Policy Learning (PLAS). We prove that this strategy is minimax rate-optimal in the sense that its leading factor in the regret upper bound matches the lower bound as the number of experimental units increases.",
    "summary": "arXiv:2401.03756v4 Announce Type: replace-cross Abstract: This study investigates the contextual best arm identification (BAI) problem, aiming to design an adaptive experiment to identify the best treatment arm conditioned on contextual information (covariates). We consider a decision-maker who assigns treatment arms to experimental units during an experiment and recommends the estimated best treatment arm based on the contexts at the end of the experiment. The decision-maker uses a policy for recommendations, which is a function that provides the estimated best treatment arm given the contexts. In our evaluation, we focus on the worst-case expected regret, a relative measure between the expected outcomes of an optimal policy and our proposed policy. We derive a lower bound for the expected simple regret and then propose a strategy called Adaptive Sampling-Policy Learning (PLAS). We prove that this strategy is minimax rate-optimal in the sense that its leading factor in the regret upper bound matches the lower bound as the number of experimental units increases.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2401.03756",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Adaptive Guidance Accelerates Reinforcement Learning of Reasoning Models",
    "description": "arXiv:2506.13923v2 Announce Type: replace-cross Abstract: We study the process through which reasoning models trained with reinforcement learning on verifiable rewards (RLVR) can learn to solve new problems. We find that RLVR drives performance in two main ways: (1) by compressing pass@$k$ into pass@1 and (2) via 'capability gain' in which models learn to solve new problems that they previously could not solve even at high $k$. We find that while capability gain exists across model scales, learning to solve new problems is primarily driven through self-distillation. We demonstrate these findings across model scales ranging from 0.5B to 72B parameters on >500,000 reasoning problems with prompts and verifiable final answers across math, science, and code domains. We further show that we can significantly improve pass@$k$ rates by leveraging natural language guidance for the model to consider within context while still requiring the model to derive a solution chain from scratch. Based of these insights, we derive $text{Guide}$ -- a new class of online training algorithms. $text{Guide}$ adaptively incorporates hints into the model's context on problems for which all rollouts were initially incorrect and adjusts the importance sampling ratio for the 'off-policy' trajectories in order to optimize the policy for contexts in which the hints are no longer present. We describe variants of $text{Guide}$ for GRPO and PPO and empirically show that Guide-GRPO on 7B and 32B parameter models improves generalization over its vanilla counterpart with up to 4$%$ macro-average improvement across math benchmarks. We include careful ablations to analyze $text{Guide}$'s components and theoretically analyze Guide's learning efficiency.",
    "summary": "arXiv:2506.13923v2 Announce Type: replace-cross Abstract: We study the process through which reasoning models trained with reinforcement learning on verifiable rewards (RLVR) can learn to solve new problems. We find that RLVR drives performance in two main ways: (1) by compressing pass@$k$ into pass@1 and (2) via 'capability gain' in which models learn to solve new problems that they previously could not solve even at high $k$. We find that while capability gain exists across model scales, learning to solve new problems is primarily driven through self-distillation. We demonstrate these findings across model scales ranging from 0.5B to 72B parameters on >500,000 reasoning problems with prompts and verifiable final answers across math, science, and code domains. We further show that we can significantly improve pass@$k$ rates by leveraging natural language guidance for the model to consider within context while still requiring the model to derive a solution chain from scratch. Based of these insights, we derive $text{Guide}$ -- a new class of online training algorithms. $text{Guide}$ adaptively incorporates hints into the model's context on problems for which all rollouts were initially incorrect and adjusts the importance sampling ratio for the 'off-policy' trajectories in order to optimize the policy for contexts in which the hints are no longer present. We describe variants of $text{Guide}$ for GRPO and PPO and empirically show that Guide-GRPO on 7B and 32B parameter models improves generalization over its vanilla counterpart with up to 4$%$ macro-average improvement across math benchmarks. We include careful ablations to analyze $text{Guide}$'s components and theoretically analyze Guide's learning efficiency.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.13923",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Advanced Sign Language Video Generation with Compressed and Quantized Multi-Condition Tokenization",
    "description": "arXiv:2506.15980v1 Announce Type: cross Abstract: Sign Language Video Generation (SLVG) seeks to generate identity-preserving sign language videos from spoken language texts. Existing methods primarily rely on the single coarse condition (eg, skeleton sequences) as the intermediary to bridge the translation model and the video generation model, which limits both the naturalness and expressiveness of the generated videos. To overcome these limitations, we propose SignViP, a novel SLVG framework that incorporates multiple fine-grained conditions for improved generation fidelity. Rather than directly translating error-prone high-dimensional conditions, SignViP adopts a discrete tokenization paradigm to integrate and represent fine-grained conditions (ie, fine-grained poses and 3D hands). SignViP contains three core components. (1) Sign Video Diffusion Model is jointly trained with a multi-condition encoder to learn continuous embeddings that encapsulate fine-grained motion and appearance. (2) Finite Scalar Quantization (FSQ) Autoencoder is further trained to compress and quantize these embeddings into discrete tokens for compact representation of the conditions. (3) Multi-Condition Token Translator is trained to translate spoken language text to discrete multi-condition tokens. During inference, Multi-Condition Token Translator first translates the spoken language text into discrete multi-condition tokens. These tokens are then decoded to continuous embeddings by FSQ Autoencoder, which are subsequently injected into Sign Video Diffusion Model to guide video generation. Experimental results show that SignViP achieves state-of-the-art performance across metrics, including video quality, temporal coherence, and semantic fidelity. The code is available at https://github.com/umnooob/signvip/.",
    "summary": "arXiv:2506.15980v1 Announce Type: cross Abstract: Sign Language Video Generation (SLVG) seeks to generate identity-preserving sign language videos from spoken language texts. Existing methods primarily rely on the single coarse condition (eg, skeleton sequences) as the intermediary to bridge the translation model and the video generation model, which limits both the naturalness and expressiveness of the generated videos. To overcome these limitations, we propose SignViP, a novel SLVG framework that incorporates multiple fine-grained conditions for improved generation fidelity. Rather than directly translating error-prone high-dimensional conditions, SignViP adopts a discrete tokenization paradigm to integrate and represent fine-grained conditions (ie, fine-grained poses and 3D hands). SignViP contains three core components. (1) Sign Video Diffusion Model is jointly trained with a multi-condition encoder to learn continuous embeddings that encapsulate fine-grained motion and appearance. (2) Finite Scalar Quantization (FSQ) Autoencoder is further trained to compress and quantize these embeddings into discrete tokens for compact representation of the conditions. (3) Multi-Condition Token Translator is trained to translate spoken language text to discrete multi-condition tokens. During inference, Multi-Condition Token Translator first translates the spoken language text into discrete multi-condition tokens. These tokens are then decoded to continuous embeddings by FSQ Autoencoder, which are subsequently injected into Sign Video Diffusion Model to guide video generation. Experimental results show that SignViP achieves state-of-the-art performance across metrics, including video quality, temporal coherence, and semantic fidelity. The code is available at https://github.com/umnooob/signvip/.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.15980",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Advancing Embodied Agent Security: From Safety Benchmarks to Input Moderation",
    "description": "arXiv:2504.15699v3 Announce Type: replace Abstract: Embodied agents exhibit immense potential across a multitude of domains, making the assurance of their behavioral safety a fundamental prerequisite for their widespread deployment. However, existing research predominantly concentrates on the security of general large language models, lacking specialized methodologies for establishing safety benchmarks and input moderation tailored to embodied agents. To bridge this gap, this paper introduces a novel input moderation framework, meticulously designed to safeguard embodied agents. This framework encompasses the entire pipeline, including taxonomy definition, dataset curation, moderator architecture, model training, and rigorous evaluation. Notably, we introduce EAsafetyBench, a meticulously crafted safety benchmark engineered to facilitate both the training and stringent assessment of moderators specifically designed for embodied agents. Furthermore, we propose Pinpoint, an innovative prompt-decoupled input moderation scheme that harnesses a masked attention mechanism to effectively isolate and mitigate the influence of functional prompts on moderation tasks. Extensive experiments conducted on diverse benchmark datasets and models validate the feasibility and efficacy of the proposed approach. The results demonstrate that our methodologies achieve an impressive average detection accuracy of 94.58%, surpassing the performance of existing state-of-the-art techniques, alongside an exceptional moderation processing time of merely 0.002 seconds per instance.",
    "summary": "arXiv:2504.15699v3 Announce Type: replace Abstract: Embodied agents exhibit immense potential across a multitude of domains, making the assurance of their behavioral safety a fundamental prerequisite for their widespread deployment. However, existing research predominantly concentrates on the security of general large language models, lacking specialized methodologies for establishing safety benchmarks and input moderation tailored to embodied agents. To bridge this gap, this paper introduces a novel input moderation framework, meticulously designed to safeguard embodied agents. This framework encompasses the entire pipeline, including taxonomy definition, dataset curation, moderator architecture, model training, and rigorous evaluation. Notably, we introduce EAsafetyBench, a meticulously crafted safety benchmark engineered to facilitate both the training and stringent assessment of moderators specifically designed for embodied agents. Furthermore, we propose Pinpoint, an innovative prompt-decoupled input moderation scheme that harnesses a masked attention mechanism to effectively isolate and mitigate the influence of functional prompts on moderation tasks. Extensive experiments conducted on diverse benchmark datasets and models validate the feasibility and efficacy of the proposed approach. The results demonstrate that our methodologies achieve an impressive average detection accuracy of 94.58%, surpassing the performance of existing state-of-the-art techniques, alongside an exceptional moderation processing time of merely 0.002 seconds per instance.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2504.15699",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Advancing Harmful Content Detection in Organizational Research: Integrating Large Language Models with Elo Rating System",
    "description": "arXiv:2506.16575v1 Announce Type: new Abstract: Large language models (LLMs) offer promising opportunities for organizational research. However, their built-in moderation systems can create problems when researchers try to analyze harmful content, often refusing to follow certain instructions or producing overly cautious responses that undermine validity of the results. This is particularly problematic when analyzing organizational conflicts such as microaggressions or hate speech. This paper introduces an Elo rating-based method that significantly improves LLM performance for harmful content analysis In two datasets, one focused on microaggression detection and the other on hate speech, we find that our method outperforms traditional LLM prompting techniques and conventional machine learning models on key measures such as accuracy, precision, and F1 scores. Advantages include better reliability when analyzing harmful content, fewer false positives, and greater scalability for large-scale datasets. This approach supports organizational applications, including detecting workplace harassment, assessing toxic communication, and fostering safer and more inclusive work environments.",
    "summary": "arXiv:2506.16575v1 Announce Type: new Abstract: Large language models (LLMs) offer promising opportunities for organizational research. However, their built-in moderation systems can create problems when researchers try to analyze harmful content, often refusing to follow certain instructions or producing overly cautious responses that undermine validity of the results. This is particularly problematic when analyzing organizational conflicts such as microaggressions or hate speech. This paper introduces an Elo rating-based method that significantly improves LLM performance for harmful content analysis In two datasets, one focused on microaggression detection and the other on hate speech, we find that our method outperforms traditional LLM prompting techniques and conventional machine learning models on key measures such as accuracy, precision, and F1 scores. Advantages include better reliability when analyzing harmful content, fewer false positives, and greater scalability for large-scale datasets. This approach supports organizational applications, including detecting workplace harassment, assessing toxic communication, and fostering safer and more inclusive work environments.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16575",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Advancing Stochastic 3-SAT Solvers by Dissipating Oversatisfied Constraints",
    "description": "arXiv:2506.15774v1 Announce Type: new Abstract: We introduce and benchmark a stochastic local search heuristic for the NP-complete satisfiability problem 3-SAT that drastically outperforms existing solvers in the notoriously difficult realm of critically hard instances. Our construction is based on the crucial observation that well established previous approaches such as WalkSAT are prone to get stuck in local minima that are distinguished from true solutions by a larger number of oversatisfied combinatorial constraints. To address this issue, the proposed algorithm, coined DOCSAT, dissipates oversatisfied constraints (DOC), i.e. reduces their unfavorable abundance so as to render them critical. We analyze and benchmark our algorithm on a randomly generated sample of hard but satisfiable 3-SAT instances with varying problem sizes up to N=15000. Quite remarkably, we find that DOCSAT outperforms both WalkSAT and other well known algorithms including the complete solver Kissat, even when comparing its ability to solve the hardest quintile of the sample to the average performance of its competitors. The essence of DOCSAT may be seen as a way of harnessing statistical structure beyond the primary cost function of a combinatorial problem to avoid or escape local minima traps in stochastic local search, which opens avenues for generalization to other optimization problems.",
    "summary": "arXiv:2506.15774v1 Announce Type: new Abstract: We introduce and benchmark a stochastic local search heuristic for the NP-complete satisfiability problem 3-SAT that drastically outperforms existing solvers in the notoriously difficult realm of critically hard instances. Our construction is based on the crucial observation that well established previous approaches such as WalkSAT are prone to get stuck in local minima that are distinguished from true solutions by a larger number of oversatisfied combinatorial constraints. To address this issue, the proposed algorithm, coined DOCSAT, dissipates oversatisfied constraints (DOC), i.e. reduces their unfavorable abundance so as to render them critical. We analyze and benchmark our algorithm on a randomly generated sample of hard but satisfiable 3-SAT instances with varying problem sizes up to N=15000. Quite remarkably, we find that DOCSAT outperforms both WalkSAT and other well known algorithms including the complete solver Kissat, even when comparing its ability to solve the hardest quintile of the sample to the average performance of its competitors. The essence of DOCSAT may be seen as a way of harnessing statistical structure beyond the primary cost function of a combinatorial problem to avoid or escape local minima traps in stochastic local search, which opens avenues for generalization to other optimization problems.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.15774",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "AerialVG: A Challenging Benchmark for Aerial Visual Grounding by Exploring Positional Relations",
    "description": "arXiv:2504.07836v3 Announce Type: replace-cross Abstract: Visual grounding (VG) aims to localize target objects in an image based on natural language descriptions. In this paper, we propose AerialVG, a new task focusing on visual grounding from aerial views. Compared to traditional VG, AerialVG poses new challenges, emph{e.g.}, appearance-based grounding is insufficient to distinguish among multiple visually similar objects, and positional relations should be emphasized. Besides, existing VG models struggle when applied to aerial imagery, where high-resolution images cause significant difficulties. To address these challenges, we introduce the first AerialVG dataset, consisting of 5K real-world aerial images, 50K manually annotated descriptions, and 103K objects. Particularly, each annotation in AerialVG dataset contains multiple target objects annotated with relative spatial relations, requiring models to perform comprehensive spatial reasoning. Furthermore, we propose an innovative model especially for the AerialVG task, where a Hierarchical Cross-Attention is devised to focus on target regions, and a Relation-Aware Grounding module is designed to infer positional relations. Experimental results validate the effectiveness of our dataset and method, highlighting the importance of spatial reasoning in aerial visual grounding. The code and dataset will be released.",
    "summary": "arXiv:2504.07836v3 Announce Type: replace-cross Abstract: Visual grounding (VG) aims to localize target objects in an image based on natural language descriptions. In this paper, we propose AerialVG, a new task focusing on visual grounding from aerial views. Compared to traditional VG, AerialVG poses new challenges, emph{e.g.}, appearance-based grounding is insufficient to distinguish among multiple visually similar objects, and positional relations should be emphasized. Besides, existing VG models struggle when applied to aerial imagery, where high-resolution images cause significant difficulties. To address these challenges, we introduce the first AerialVG dataset, consisting of 5K real-world aerial images, 50K manually annotated descriptions, and 103K objects. Particularly, each annotation in AerialVG dataset contains multiple target objects annotated with relative spatial relations, requiring models to perform comprehensive spatial reasoning. Furthermore, we propose an innovative model especially for the AerialVG task, where a Hierarchical Cross-Attention is devised to focus on target regions, and a Relation-Aware Grounding module is designed to infer positional relations. Experimental results validate the effectiveness of our dataset and method, highlighting the importance of spatial reasoning in aerial visual grounding. The code and dataset will be released.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2504.07836",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Agentic Personalisation of Cross-Channel Marketing Experiences",
    "description": "arXiv:2506.16429v1 Announce Type: new Abstract: Consumer applications provide ample opportunities to surface and communicate various forms of content to users. From promotional campaigns for new features or subscriptions, to evergreen nudges for engagement, or personalised recommendations; across e-mails, push notifications, and in-app surfaces. The conventional approach to orchestration for communication relies heavily on labour-intensive manual marketer work, and inhibits effective personalisation of content, timing, frequency, and copy-writing. We formulate this task under a sequential decision-making framework, where we aim to optimise a modular decision-making policy that maximises incremental engagement for any funnel event. Our approach leverages a Difference-in-Differences design for Individual Treatment Effect estimation, and Thompson sampling to balance the explore-exploit trade-off. We present results from a multi-service application, where our methodology has resulted in significant increases to a variety of goal events across several product features, and is currently deployed across 150 million users.",
    "summary": "arXiv:2506.16429v1 Announce Type: new Abstract: Consumer applications provide ample opportunities to surface and communicate various forms of content to users. From promotional campaigns for new features or subscriptions, to evergreen nudges for engagement, or personalised recommendations; across e-mails, push notifications, and in-app surfaces. The conventional approach to orchestration for communication relies heavily on labour-intensive manual marketer work, and inhibits effective personalisation of content, timing, frequency, and copy-writing. We formulate this task under a sequential decision-making framework, where we aim to optimise a modular decision-making policy that maximises incremental engagement for any funnel event. Our approach leverages a Difference-in-Differences design for Individual Treatment Effect estimation, and Thompson sampling to balance the explore-exploit trade-off. We present results from a multi-service application, where our methodology has resulted in significant increases to a variety of goal events across several product features, and is currently deployed across 150 million users.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16429",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "AGI-Driven Generative Semantic Communications: Principles and Practices",
    "description": "arXiv:2504.14947v2 Announce Type: replace Abstract: Semantic communications leverage artificial intelligence (AI) technologies to extract semantic information for efficient data delivery, thereby significantly reducing communication cost. With the evolution towards artificial general intelligence (AGI), the increasing demands for AGI services pose new challenges to semantic communications. In this context, an AGI application is typically defined on a general-sense task, covering a broad, even unforeseen, set of objectives, as well as driven by the need for a human-friendly interface in forms (e.g., videos, images, or text) easily understood by human users.In response, we introduce an AGI-driven communication paradigm for supporting AGI applications, called generative semantic communication (GSC). We first describe the basic concept of GSC and its difference from existing semantic communications, and then introduce a general framework of GSC based on advanced AI technologies including foundation models and generative models. Two case studies are presented to verify the advantages of GSC. Finally, open challenges and new research directions are discussed to stimulate this line of research and pave the way for practical applications.",
    "summary": "arXiv:2504.14947v2 Announce Type: replace Abstract: Semantic communications leverage artificial intelligence (AI) technologies to extract semantic information for efficient data delivery, thereby significantly reducing communication cost. With the evolution towards artificial general intelligence (AGI), the increasing demands for AGI services pose new challenges to semantic communications. In this context, an AGI application is typically defined on a general-sense task, covering a broad, even unforeseen, set of objectives, as well as driven by the need for a human-friendly interface in forms (e.g., videos, images, or text) easily understood by human users.In response, we introduce an AGI-driven communication paradigm for supporting AGI applications, called generative semantic communication (GSC). We first describe the basic concept of GSC and its difference from existing semantic communications, and then introduce a general framework of GSC based on advanced AI technologies including foundation models and generative models. Two case studies are presented to verify the advantages of GSC. Finally, open challenges and new research directions are discussed to stimulate this line of research and pave the way for practical applications.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2504.14947",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "AI-Driven Tools in Modern Software Quality Assurance: An Assessment of Benefits, Challenges, and Future Directions",
    "description": "arXiv:2506.16586v1 Announce Type: cross Abstract: Traditional quality assurance (QA) methods face significant challenges in addressing the complexity, scale, and rapid iteration cycles of modern software systems and are strained by limited resources available, leading to substantial costs associated with poor quality. The object of this research is the Quality Assurance processes for modern distributed software applications. The subject of the research is the assessment of the benefits, challenges, and prospects of integrating modern AI-oriented tools into quality assurance processes. We performed comprehensive analysis of implications on both verification and validation processes covering exploratory test analyses, equivalence partitioning and boundary analyses, metamorphic testing, finding inconsistencies in acceptance criteria (AC), static analyses, test case generation, unit test generation, test suit optimization and assessment, end to end scenario execution. End to end regression of sample enterprise application utilizing AI-agents over generated test scenarios was implemented as a proof of concept highlighting practical use of the study. The results, with only 8.3% flaky executions of generated test cases, indicate significant potential for the proposed approaches. However, the study also identified substantial challenges for practical adoption concerning generation of semantically identical coverage, 'black box' nature and lack of explainability from state-of-the-art Large Language Models (LLMs), the tendency to correct mutated test cases to match expected results, underscoring the necessity for thorough verification of both generated artifacts and test execution results. The research demonstrates AI's transformative potential for QA but highlights the importance of a strategic approach to implementing these technologies, considering the identified limitations and the need for developing appropriate verification methodologies.",
    "summary": "arXiv:2506.16586v1 Announce Type: cross Abstract: Traditional quality assurance (QA) methods face significant challenges in addressing the complexity, scale, and rapid iteration cycles of modern software systems and are strained by limited resources available, leading to substantial costs associated with poor quality. The object of this research is the Quality Assurance processes for modern distributed software applications. The subject of the research is the assessment of the benefits, challenges, and prospects of integrating modern AI-oriented tools into quality assurance processes. We performed comprehensive analysis of implications on both verification and validation processes covering exploratory test analyses, equivalence partitioning and boundary analyses, metamorphic testing, finding inconsistencies in acceptance criteria (AC), static analyses, test case generation, unit test generation, test suit optimization and assessment, end to end scenario execution. End to end regression of sample enterprise application utilizing AI-agents over generated test scenarios was implemented as a proof of concept highlighting practical use of the study. The results, with only 8.3% flaky executions of generated test cases, indicate significant potential for the proposed approaches. However, the study also identified substantial challenges for practical adoption concerning generation of semantically identical coverage, 'black box' nature and lack of explainability from state-of-the-art Large Language Models (LLMs), the tendency to correct mutated test cases to match expected results, underscoring the necessity for thorough verification of both generated artifacts and test execution results. The research demonstrates AI's transformative potential for QA but highlights the importance of a strategic approach to implementing these technologies, considering the identified limitations and the need for developing appropriate verification methodologies.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16586",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "AI Testing and Evaluation: Learnings from Science and Industry",
    "description": "<p>In the introductory episode of this new series, host Kathleen Sullivan and Senior Director Amanda Craig Deckard explore Microsoft’s efforts to draw on the experience of other domains to help advance the role of AI testing and evaluation as a governance tool.</p> <p>The post <a href='https://www.microsoft.com/en-us/research/podcast/ai-testing-and-evaluation-learnings-from-science-and-industry/'>AI Testing and Evaluation: Learnings from Science and Industry</a> appeared first on <a href='https://www.microsoft.com/en-us/research'>Microsoft Research</a>.</p>",
    "summary": "<p>In the introductory episode of this new series, host Kathleen Sullivan and Senior Director Amanda Craig Deckard explore Microsoft’s efforts to draw on the experience of other domains to help advance the role of AI testing and evaluation as a governance tool.</p> <p>The post <a href='https://www.microsoft.com/en-us/research/podcast/ai-testing-and-evaluation-learnings-from-science-and-industry/'>AI Testing and Evaluation: Learnings from Science and Industry</a> appeared first on <a href='https://www.microsoft.com/en-us/research'>Microsoft Research</a>.</p>",
    "pubDate": "Mon, 23 Jun 2025 16:38:09 +0000",
    "source": "Microsoft Research Blog",
    "url": "https://www.microsoft.com/en-us/research/podcast/ai-testing-and-evaluation-learnings-from-science-and-industry/",
    "thumbnail": "https://img-prod-cms-rt-microsoft-com.akamaized.net/cms/api/am/imageFileData/RE1Mu3b?ver=5c31&h=30"
  },
  {
    "title": "AI's Blind Spots: Geographic Knowledge and Diversity Deficit in Generated Urban Scenario",
    "description": "arXiv:2506.16898v1 Announce Type: new Abstract: Image generation models are revolutionizing many domains, and urban analysis and design is no exception. While such models are widely adopted, there is a limited literature exploring their geographic knowledge, along with the biases they embed. In this work, we generated 150 synthetic images for each state in the USA and related capitals using FLUX 1 and Stable Diffusion 3.5, two state-of-the-art models for image generation. We embed each image using DINO-v2 ViT-S/14 and the Fr'echet Inception Distances to measure the similarity between the generated images. We found that while these models have implicitly learned aspects of USA geography, if we prompt the models to generate an image for 'United States' instead of specific cities or states, the models exhibit a strong representative bias toward metropolis-like areas, excluding rural states and smaller cities. {color{black} In addition, we found that models systematically exhibit some entity-disambiguation issues with European-sounding names like Frankfort or Devon.",
    "summary": "arXiv:2506.16898v1 Announce Type: new Abstract: Image generation models are revolutionizing many domains, and urban analysis and design is no exception. While such models are widely adopted, there is a limited literature exploring their geographic knowledge, along with the biases they embed. In this work, we generated 150 synthetic images for each state in the USA and related capitals using FLUX 1 and Stable Diffusion 3.5, two state-of-the-art models for image generation. We embed each image using DINO-v2 ViT-S/14 and the Fr'echet Inception Distances to measure the similarity between the generated images. We found that while these models have implicitly learned aspects of USA geography, if we prompt the models to generate an image for 'United States' instead of specific cities or states, the models exhibit a strong representative bias toward metropolis-like areas, excluding rural states and smaller cities. {color{black} In addition, we found that models systematically exhibit some entity-disambiguation issues with European-sounding names like Frankfort or Devon.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16898",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "AIによる生産要件の自動判定機能が好評な3Dプラットフォーム",
    "description": "LIGHTzは、製造業の設計開発における開発速度や生産性の向上を支援する3Dプラットフォーム「blooplinter」の導入が製造業で進んでいると発表した。特に「AI要件チェック機能」が活用されているという。",
    "summary": "LIGHTzは、製造業の設計開発における開発速度や生産性の向上を支援する3Dプラットフォーム「blooplinter」の導入が製造業で進んでいると発表した。特に「AI要件チェック機能」が活用されているという。",
    "pubDate": "Mon, 23 Jun 2025 09:00:00 +0900",
    "source": "ITmedia AI",
    "url": "https://monoist.itmedia.co.jp/mn/articles/2506/23/news006.html",
    "thumbnail": "https://image.itmedia.co.jp/mn/articles/2506/23/cover_news006.jpg"
  },
  {
    "title": "AIイラストに“ファンアートタグ”使わないで──VTuber「ぶいすぽっ！」運営が声明　「#AIイラスト」の利用を必須化",
    "description": "AIイラストには“ファンアートタグ”は使わないで──VTuberプロジェクト「ぶいすぽっ！」を運営するバーチャルエンターテイメントは、公式Xアカウント（＠Vspo77）でそんな声明を発表した。",
    "summary": "AIイラストには“ファンアートタグ”は使わないで──VTuberプロジェクト「ぶいすぽっ！」を運営するバーチャルエンターテイメントは、公式Xアカウント（＠Vspo77）でそんな声明を発表した。",
    "pubDate": "Mon, 23 Jun 2025 19:11:00 +0900",
    "source": "ITmedia AI",
    "url": "https://www.itmedia.co.jp/aiplus/articles/2506/23/news098.html",
    "thumbnail": "https://image.itmedia.co.jp/aiplus/articles/2506/23/cover_news098.jpg"
  },
  {
    "title": "AI作成の偽サイトをAI用いて捜査、フィッシングサイト作成の男2人を逮捕　大阪府警",
    "description": "ECサイトになりすましたフィッシングサイトを作成し、インターネットに公開したなどとして、大阪府警サイバー犯罪捜査課は不正アクセス禁止法違反の疑いで2人を逮捕したと発表した。",
    "summary": "ECサイトになりすましたフィッシングサイトを作成し、インターネットに公開したなどとして、大阪府警サイバー犯罪捜査課は不正アクセス禁止法違反の疑いで2人を逮捕したと発表した。",
    "pubDate": "Mon, 23 Jun 2025 17:27:00 +0900",
    "source": "ITmedia AI",
    "url": "https://www.itmedia.co.jp/news/articles/2506/23/news093.html",
    "thumbnail": "https://image.itmedia.co.jp/news/articles/2506/23/cover_news093.jpg"
  },
  {
    "title": "AlignDistil: Token-Level Language Model Alignment as Adaptive Policy Distillation",
    "description": "arXiv:2503.02832v2 Announce Type: replace-cross Abstract: In modern large language models (LLMs), LLM alignment is of crucial importance and is typically achieved through methods such as reinforcement learning from human feedback (RLHF) and direct preference optimization (DPO). However, in most existing methods for LLM alignment, all tokens in the response are optimized using a sparse, response-level reward or preference annotation. The ignorance of token-level rewards may erroneously punish high-quality tokens or encourage low-quality tokens, resulting in suboptimal performance and slow convergence speed. To address this issue, we propose AlignDistil, an RLHF-equivalent distillation method for token-level reward optimization. Specifically, we introduce the reward learned by DPO into the RLHF objective and theoretically prove the equivalence between this objective and a token-level distillation process, where the teacher distribution linearly combines the logits from the DPO model and a reference model. On this basis, we further bridge the accuracy gap between the reward from the DPO model and the pure reward model, by building a contrastive DPO reward with a normal and a reverse DPO model. Moreover, to avoid under- and over-optimization on different tokens, we design a token adaptive logit extrapolation mechanism to construct an appropriate teacher distribution for each token. Experimental results demonstrate the superiority of our AlignDistil over existing methods and showcase fast convergence due to its token-level distributional reward optimization.",
    "summary": "arXiv:2503.02832v2 Announce Type: replace-cross Abstract: In modern large language models (LLMs), LLM alignment is of crucial importance and is typically achieved through methods such as reinforcement learning from human feedback (RLHF) and direct preference optimization (DPO). However, in most existing methods for LLM alignment, all tokens in the response are optimized using a sparse, response-level reward or preference annotation. The ignorance of token-level rewards may erroneously punish high-quality tokens or encourage low-quality tokens, resulting in suboptimal performance and slow convergence speed. To address this issue, we propose AlignDistil, an RLHF-equivalent distillation method for token-level reward optimization. Specifically, we introduce the reward learned by DPO into the RLHF objective and theoretically prove the equivalence between this objective and a token-level distillation process, where the teacher distribution linearly combines the logits from the DPO model and a reference model. On this basis, we further bridge the accuracy gap between the reward from the DPO model and the pure reward model, by building a contrastive DPO reward with a normal and a reverse DPO model. Moreover, to avoid under- and over-optimization on different tokens, we design a token adaptive logit extrapolation mechanism to construct an appropriate teacher distribution for each token. Experimental results demonstrate the superiority of our AlignDistil over existing methods and showcase fast convergence due to its token-level distributional reward optimization.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2503.02832",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "ALTA: Compiler-Based Analysis of Transformers",
    "description": "arXiv:2410.18077v2 Announce Type: replace-cross Abstract: We propose a new programming language called ALTA and a compiler that can map ALTA programs to Transformer weights. ALTA is inspired by RASP, a language proposed by Weiss et al. (2021), and Tracr (Lindner et al., 2023), a compiler from RASP programs to Transformer weights. ALTA complements and extends this prior work, offering the ability to express loops and to compile programs to Universal Transformers, among other advantages. ALTA allows us to constructively show how Transformers can represent length-invariant algorithms for computing parity and addition, as well as a solution to the SCAN benchmark of compositional generalization tasks, without requiring intermediate scratchpad decoding steps. We also propose tools to analyze cases where the expressibility of an algorithm is established, but end-to-end training on a given training set fails to induce behavior consistent with the desired algorithm. To this end, we explore training from ALTA execution traces as a more fine-grained supervision signal. This enables additional experiments and theoretical analyses relating the learnability of various algorithms to data availability and modeling decisions, such as positional encodings. We make the ALTA framework -- language specification, symbolic interpreter, and weight compiler -- available to the community to enable further applications and insights.",
    "summary": "arXiv:2410.18077v2 Announce Type: replace-cross Abstract: We propose a new programming language called ALTA and a compiler that can map ALTA programs to Transformer weights. ALTA is inspired by RASP, a language proposed by Weiss et al. (2021), and Tracr (Lindner et al., 2023), a compiler from RASP programs to Transformer weights. ALTA complements and extends this prior work, offering the ability to express loops and to compile programs to Universal Transformers, among other advantages. ALTA allows us to constructively show how Transformers can represent length-invariant algorithms for computing parity and addition, as well as a solution to the SCAN benchmark of compositional generalization tasks, without requiring intermediate scratchpad decoding steps. We also propose tools to analyze cases where the expressibility of an algorithm is established, but end-to-end training on a given training set fails to induce behavior consistent with the desired algorithm. To this end, we explore training from ALTA execution traces as a more fine-grained supervision signal. This enables additional experiments and theoretical analyses relating the learnability of various algorithms to data availability and modeling decisions, such as positional encodings. We make the ALTA framework -- language specification, symbolic interpreter, and weight compiler -- available to the community to enable further applications and insights.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2410.18077",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Alternates, Assemble! Selecting Optimal Alternates for Citizens' Assemblies",
    "description": "arXiv:2506.15716v1 Announce Type: cross Abstract: An increasingly influential form of deliberative democracy centers on citizens' assemblies, where randomly selected people discuss policy questions. The legitimacy of these panels hinges on their representation of the broader population, but panelists often drop out, leading to an unbalanced composition. Although participant attrition is mitigated in practice by alternates, their selection is not taken into account by existing methods. To address this gap, we introduce an optimization framework for alternate selection. Our algorithmic approach, which leverages learning-theoretic machinery, estimates dropout probabilities using historical data and selects alternates to minimize expected misrepresentation. We establish theoretical guarantees for our approach, including worst-case bounds on sample complexity (with implications for computational efficiency) and on loss when panelists' probabilities of dropping out are mis-estimated. Empirical evaluation using real-world data demonstrates that, compared to the status quo, our method significantly improves representation while requiring fewer alternates.",
    "summary": "arXiv:2506.15716v1 Announce Type: cross Abstract: An increasingly influential form of deliberative democracy centers on citizens' assemblies, where randomly selected people discuss policy questions. The legitimacy of these panels hinges on their representation of the broader population, but panelists often drop out, leading to an unbalanced composition. Although participant attrition is mitigated in practice by alternates, their selection is not taken into account by existing methods. To address this gap, we introduce an optimization framework for alternate selection. Our algorithmic approach, which leverages learning-theoretic machinery, estimates dropout probabilities using historical data and selects alternates to minimize expected misrepresentation. We establish theoretical guarantees for our approach, including worst-case bounds on sample complexity (with implications for computational efficiency) and on loss when panelists' probabilities of dropping out are mis-estimated. Empirical evaluation using real-world data demonstrates that, compared to the status quo, our method significantly improves representation while requiring fewer alternates.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.15716",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Alto: Orchestrating Distributed Compound AI Systems with Nested Ancestry",
    "description": "arXiv:2403.04311v2 Announce Type: replace Abstract: Compound AI applications chain together subcomponents such as generative language models, document retrievers, and embedding models. Applying traditional systems optimizations such as parallelism and pipelining in compound AI systems is difficult because each component has different constraints in terms of the granularity and type of data that it ingests. New data is often generated during intermediate computations, and text streams may be split into smaller, independent fragments (such as documents to sentences) which may then be re-aggregated at later parts of the computation. Due to this complexity, existing systems to serve compound AI queries do not fully take advantage of parallelism and pipelining opportunities. We present Alto, a framework that automatically optimizes execution of compound AI queries through streaming and parallelism. Bento introduces a new abstraction called nested ancestry, a metadata hierarchy that allows the system to correctly track partial outputs and aggregate data across the heterogeneous constraints of the components of compound AI applications. This metadata is automatically inferred from the programming model, allowing developers to express complex dataflow patterns without needing to reason manually about the details of routing and aggregation. Implementations of four applications in Alto outperform or match implementations in LangGraph, a popular existing AI programming framework. Alto implementations match or improve latency by between 10-30%.",
    "summary": "arXiv:2403.04311v2 Announce Type: replace Abstract: Compound AI applications chain together subcomponents such as generative language models, document retrievers, and embedding models. Applying traditional systems optimizations such as parallelism and pipelining in compound AI systems is difficult because each component has different constraints in terms of the granularity and type of data that it ingests. New data is often generated during intermediate computations, and text streams may be split into smaller, independent fragments (such as documents to sentences) which may then be re-aggregated at later parts of the computation. Due to this complexity, existing systems to serve compound AI queries do not fully take advantage of parallelism and pipelining opportunities. We present Alto, a framework that automatically optimizes execution of compound AI queries through streaming and parallelism. Bento introduces a new abstraction called nested ancestry, a metadata hierarchy that allows the system to correctly track partial outputs and aggregate data across the heterogeneous constraints of the components of compound AI applications. This metadata is automatically inferred from the programming model, allowing developers to express complex dataflow patterns without needing to reason manually about the details of routing and aggregation. Implementations of four applications in Alto outperform or match implementations in LangGraph, a popular existing AI programming framework. Alto implementations match or improve latency by between 10-30%.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2403.04311",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Analyzing the Influence of Knowledge Graph Information on Relation Extraction",
    "description": "arXiv:2506.16343v1 Announce Type: cross Abstract: We examine the impact of incorporating knowledge graph information on the performance of relation extraction models across a range of datasets. Our hypothesis is that the positions of entities within a knowledge graph provide important insights for relation extraction tasks. We conduct experiments on multiple datasets, each varying in the number of relations, training examples, and underlying knowledge graphs. Our results demonstrate that integrating knowledge graph information significantly enhances performance, especially when dealing with an imbalance in the number of training examples for each relation. We evaluate the contribution of knowledge graph-based features by combining established relation extraction methods with graph-aware Neural Bellman-Ford networks. These features are tested in both supervised and zero-shot settings, demonstrating consistent performance improvements across various datasets.",
    "summary": "arXiv:2506.16343v1 Announce Type: cross Abstract: We examine the impact of incorporating knowledge graph information on the performance of relation extraction models across a range of datasets. Our hypothesis is that the positions of entities within a knowledge graph provide important insights for relation extraction tasks. We conduct experiments on multiple datasets, each varying in the number of relations, training examples, and underlying knowledge graphs. Our results demonstrate that integrating knowledge graph information significantly enhances performance, especially when dealing with an imbalance in the number of training examples for each relation. We evaluate the contribution of knowledge graph-based features by combining established relation extraction methods with graph-aware Neural Bellman-Ford networks. These features are tested in both supervised and zero-shot settings, demonstrating consistent performance improvements across various datasets.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16343",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "AnyTraverse: An off-road traversability framework with VLM and human operator in the loop",
    "description": "arXiv:2506.16826v1 Announce Type: cross Abstract: Off-road traversability segmentation enables autonomous navigation with applications in search-and-rescue, military operations, wildlife exploration, and agriculture. Current frameworks struggle due to significant variations in unstructured environments and uncertain scene changes, and are not adaptive to be used for different robot types. We present AnyTraverse, a framework combining natural language-based prompts with human-operator assistance to determine navigable regions for diverse robotic vehicles. The system segments scenes for a given set of prompts and calls the operator only when encountering previously unexplored scenery or unknown class not part of the prompt in its region-of-interest, thus reducing active supervision load while adapting to varying outdoor scenes. Our zero-shot learning approach eliminates the need for extensive data collection or retraining. Our experimental validation includes testing on RELLIS-3D, Freiburg Forest, and RUGD datasets and demonstrate real-world deployment on multiple robot platforms. The results show that AnyTraverse performs better than GA-NAV and Off-seg while offering a vehicle-agnostic approach to off-road traversability that balances automation with targeted human supervision.",
    "summary": "arXiv:2506.16826v1 Announce Type: cross Abstract: Off-road traversability segmentation enables autonomous navigation with applications in search-and-rescue, military operations, wildlife exploration, and agriculture. Current frameworks struggle due to significant variations in unstructured environments and uncertain scene changes, and are not adaptive to be used for different robot types. We present AnyTraverse, a framework combining natural language-based prompts with human-operator assistance to determine navigable regions for diverse robotic vehicles. The system segments scenes for a given set of prompts and calls the operator only when encountering previously unexplored scenery or unknown class not part of the prompt in its region-of-interest, thus reducing active supervision load while adapting to varying outdoor scenes. Our zero-shot learning approach eliminates the need for extensive data collection or retraining. Our experimental validation includes testing on RELLIS-3D, Freiburg Forest, and RUGD datasets and demonstrate real-world deployment on multiple robot platforms. The results show that AnyTraverse performs better than GA-NAV and Off-seg while offering a vehicle-agnostic approach to off-road traversability that balances automation with targeted human supervision.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16826",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Approximation Fixpoint Theory with Refined Approximation Spaces",
    "description": "arXiv:2506.16294v1 Announce Type: new Abstract: Approximation Fixpoint Theory (AFT) is a powerful theory covering various semantics of non-monotonic reasoning formalisms in knowledge representation such as Logic Programming and Answer Set Programming. Many semantics of such non-monotonic formalisms can be characterized as suitable fixpoints of a non-monotonic operator on a suitable lattice. Instead of working on the original lattice, AFT operates on intervals in such lattice to approximate or construct the fixpoints of interest. While AFT has been applied successfully across a broad range of non-monotonic reasoning formalisms, it is confronted by its limitations in other, relatively simple, examples. In this paper, we overcome those limitations by extending consistent AFT to deal with approximations that are more refined than intervals. Therefore, we introduce a more general notion of approximation spaces, showcase the improved expressiveness and investigate relations between different approximation spaces.",
    "summary": "arXiv:2506.16294v1 Announce Type: new Abstract: Approximation Fixpoint Theory (AFT) is a powerful theory covering various semantics of non-monotonic reasoning formalisms in knowledge representation such as Logic Programming and Answer Set Programming. Many semantics of such non-monotonic formalisms can be characterized as suitable fixpoints of a non-monotonic operator on a suitable lattice. Instead of working on the original lattice, AFT operates on intervals in such lattice to approximate or construct the fixpoints of interest. While AFT has been applied successfully across a broad range of non-monotonic reasoning formalisms, it is confronted by its limitations in other, relatively simple, examples. In this paper, we overcome those limitations by extending consistent AFT to deal with approximations that are more refined than intervals. Therefore, we introduce a more general notion of approximation spaces, showcase the improved expressiveness and investigate relations between different approximation spaces.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16294",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "AQA-Bench: An Interactive Benchmark for Evaluating LLMs' Sequential Reasoning Ability",
    "description": "arXiv:2402.09404v2 Announce Type: replace-cross Abstract: This paper introduces AQA-Bench, a novel benchmark to assess the sequential reasoning capabilities of large language models (LLMs) in algorithmic contexts, such as depth-first search (DFS). The key feature of our evaluation benchmark lies in its interactive evaluation protocol - for example, in DFS, the availability of each node's connected edge is contingent upon the model's traversal to that node, thereby necessitating the LLM's ability to effectively remember visited nodes and strategize subsequent moves considering the possible environmental feedback in the future steps. We comprehensively build AQA-Bench with three different algorithms, namely binary search, depth-first search, and breadth-first search, and to evaluate the sequential reasoning ability of 14 different LLMs. Our investigations reveal several interesting findings: (1) Closed-source models like GPT-4 and Gemini generally show much stronger sequential reasoning ability, significantly outperforming open-source LLMs. (2) Naively providing in-context examples may inadvertently hurt few-shot performance in an interactive environment due to over-fitting to examples. (3) Instead of using optimal steps from another test case as the in-context example, a very limited number of predecessor steps in the current test case following the optimal policy can substantially boost small models' performance. (4) The performance gap between weak models and strong models is greatly due to the incapability of weak models to start well. (5) The scaling correlation between performance and model size is not always significant, sometimes even showcasing an inverse trend. We hope our study can catalyze future work on advancing the understanding and enhancement of LLMs' capabilities in sequential reasoning. The code is available at https://github.com/UCSC-VLAA/AQA-Bench.",
    "summary": "arXiv:2402.09404v2 Announce Type: replace-cross Abstract: This paper introduces AQA-Bench, a novel benchmark to assess the sequential reasoning capabilities of large language models (LLMs) in algorithmic contexts, such as depth-first search (DFS). The key feature of our evaluation benchmark lies in its interactive evaluation protocol - for example, in DFS, the availability of each node's connected edge is contingent upon the model's traversal to that node, thereby necessitating the LLM's ability to effectively remember visited nodes and strategize subsequent moves considering the possible environmental feedback in the future steps. We comprehensively build AQA-Bench with three different algorithms, namely binary search, depth-first search, and breadth-first search, and to evaluate the sequential reasoning ability of 14 different LLMs. Our investigations reveal several interesting findings: (1) Closed-source models like GPT-4 and Gemini generally show much stronger sequential reasoning ability, significantly outperforming open-source LLMs. (2) Naively providing in-context examples may inadvertently hurt few-shot performance in an interactive environment due to over-fitting to examples. (3) Instead of using optimal steps from another test case as the in-context example, a very limited number of predecessor steps in the current test case following the optimal policy can substantially boost small models' performance. (4) The performance gap between weak models and strong models is greatly due to the incapability of weak models to start well. (5) The scaling correlation between performance and model size is not always significant, sometimes even showcasing an inverse trend. We hope our study can catalyze future work on advancing the understanding and enhancement of LLMs' capabilities in sequential reasoning. The code is available at https://github.com/UCSC-VLAA/AQA-Bench.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2402.09404",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Are Bias Evaluation Methods Biased ?",
    "description": "arXiv:2506.17111v1 Announce Type: new Abstract: The creation of benchmarks to evaluate the safety of Large Language Models is one of the key activities within the trusted AI community. These benchmarks allow models to be compared for different aspects of safety such as toxicity, bias, harmful behavior etc. Independent benchmarks adopt different approaches with distinct data sets and evaluation methods. We investigate how robust such benchmarks are by using different approaches to rank a set of representative models for bias and compare how similar are the overall rankings. We show that different but widely used bias evaluations methods result in disparate model rankings. We conclude with recommendations for the community in the usage of such benchmarks.",
    "summary": "arXiv:2506.17111v1 Announce Type: new Abstract: The creation of benchmarks to evaluate the safety of Large Language Models is one of the key activities within the trusted AI community. These benchmarks allow models to be compared for different aspects of safety such as toxicity, bias, harmful behavior etc. Independent benchmarks adopt different approaches with distinct data sets and evaluation methods. We investigate how robust such benchmarks are by using different approaches to rank a set of representative models for bias and compare how similar are the overall rankings. We show that different but widely used bias evaluations methods result in disparate model rankings. We conclude with recommendations for the community in the usage of such benchmarks.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.17111",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Artificial Intelligence for Atmospheric Sciences: A Research Roadmap",
    "description": "arXiv:2506.16281v1 Announce Type: cross Abstract: Atmospheric sciences are crucial for understanding environmental phenomena ranging from air quality to extreme weather events, and climate change. Recent breakthroughs in sensing, communication, computing, and Artificial Intelligence (AI) have significantly advanced atmospheric sciences, enabling the generation of vast amounts of data through long-term Earth observations and providing powerful tools for analyzing atmospheric phenomena and predicting natural disasters. This paper contributes a critical interdisciplinary overview that bridges the fields of atmospheric science and computer science, highlighting the transformative potential of AI in atmospheric research. We identify key challenges associated with integrating AI into atmospheric research, including issues related to big data and infrastructure, and provide a detailed research roadmap that addresses both current and emerging challenges.",
    "summary": "arXiv:2506.16281v1 Announce Type: cross Abstract: Atmospheric sciences are crucial for understanding environmental phenomena ranging from air quality to extreme weather events, and climate change. Recent breakthroughs in sensing, communication, computing, and Artificial Intelligence (AI) have significantly advanced atmospheric sciences, enabling the generation of vast amounts of data through long-term Earth observations and providing powerful tools for analyzing atmospheric phenomena and predicting natural disasters. This paper contributes a critical interdisciplinary overview that bridges the fields of atmospheric science and computer science, highlighting the transformative potential of AI in atmospheric research. We identify key challenges associated with integrating AI into atmospheric research, including issues related to big data and infrastructure, and provide a detailed research roadmap that addresses both current and emerging challenges.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16281",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Ask a Techspert: What is inference?",
    "description": "Illustration of a computer chip surrounded by elements representing AI and data, including a cat's head, a wireframe cat, puzzle pieces, a bar graph, gears, and text bubbles.",
    "summary": "Illustration of a computer chip surrounded by elements representing AI and data, including a cat's head, a wireframe cat, puzzle pieces, a bar graph, gears, and text bubbles.",
    "pubDate": "Mon, 23 Jun 2025 17:30:00 +0000",
    "source": "Google AI Blog",
    "url": "https://blog.google/technology/ai/ask-a-techspert-what-is-inference/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/InferenceHero_v3.width-1300.png"
  },
  {
    "title": "Assessing Tenstorrent's RISC-V MatMul Acceleration Capabilities",
    "description": "arXiv:2505.06085v3 Announce Type: replace-cross Abstract: The increasing demand for generative AI as Large Language Models (LLMs) services has driven the need for specialized hardware architectures that optimize computational efficiency and energy consumption. This paper evaluates the performance of the Tenstorrent Grayskull e75 RISC-V accelerator for basic linear algebra kernels at reduced numerical precision, a fundamental operation in LLM computations. We present a detailed characterization of Grayskull's execution model, gridsize, matrix dimensions, data formats, and numerical precision impact computational efficiency. Furthermore, we compare Grayskull's performance against state-of-the-art architectures with tensor acceleration, including Intel Sapphire Rapids processors and two NVIDIA GPUs (V100 and A100). Whilst NVIDIA GPUs dominate raw performance, Grayskull demonstrates a competitive trade-off between power consumption and computational throughput, reaching a peak of 1.55 TFLOPs/Watt with BF16.",
    "summary": "arXiv:2505.06085v3 Announce Type: replace-cross Abstract: The increasing demand for generative AI as Large Language Models (LLMs) services has driven the need for specialized hardware architectures that optimize computational efficiency and energy consumption. This paper evaluates the performance of the Tenstorrent Grayskull e75 RISC-V accelerator for basic linear algebra kernels at reduced numerical precision, a fundamental operation in LLM computations. We present a detailed characterization of Grayskull's execution model, gridsize, matrix dimensions, data formats, and numerical precision impact computational efficiency. Furthermore, we compare Grayskull's performance against state-of-the-art architectures with tensor acceleration, including Intel Sapphire Rapids processors and two NVIDIA GPUs (V100 and A100). Whilst NVIDIA GPUs dominate raw performance, Grayskull demonstrates a competitive trade-off between power consumption and computational throughput, reaching a peak of 1.55 TFLOPs/Watt with BF16.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2505.06085",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "AssistantX: An LLM-Powered Proactive Assistant in Collaborative Human-Populated Environment",
    "description": "arXiv:2409.17655v3 Announce Type: replace-cross Abstract: Current service robots suffer from limited natural language communication abilities, heavy reliance on predefined commands, ongoing human intervention, and, most notably, a lack of proactive collaboration awareness in human-populated environments. This results in narrow applicability and low utility. In this paper, we introduce AssistantX, an LLM-powered proactive assistant designed for autonomous operation in realworld scenarios with high accuracy. AssistantX employs a multi-agent framework consisting of 4 specialized LLM agents, each dedicated to perception, planning, decision-making, and reflective review, facilitating advanced inference capabilities and comprehensive collaboration awareness, much like a human assistant by your side. We built a dataset of 210 real-world tasks to validate AssistantX, which includes instruction content and status information on whether relevant personnel are available. Extensive experiments were conducted in both text-based simulations and a real office environment over the course of a month and a half. Our experiments demonstrate the effectiveness of the proposed framework, showing that AssistantX can reactively respond to user instructions, actively adjust strategies to adapt to contingencies, and proactively seek assistance from humans to ensure successful task completion. More details and videos can be found at https://assistantx-agent.github.io/AssistantX/.",
    "summary": "arXiv:2409.17655v3 Announce Type: replace-cross Abstract: Current service robots suffer from limited natural language communication abilities, heavy reliance on predefined commands, ongoing human intervention, and, most notably, a lack of proactive collaboration awareness in human-populated environments. This results in narrow applicability and low utility. In this paper, we introduce AssistantX, an LLM-powered proactive assistant designed for autonomous operation in realworld scenarios with high accuracy. AssistantX employs a multi-agent framework consisting of 4 specialized LLM agents, each dedicated to perception, planning, decision-making, and reflective review, facilitating advanced inference capabilities and comprehensive collaboration awareness, much like a human assistant by your side. We built a dataset of 210 real-world tasks to validate AssistantX, which includes instruction content and status information on whether relevant personnel are available. Extensive experiments were conducted in both text-based simulations and a real office environment over the course of a month and a half. Our experiments demonstrate the effectiveness of the proposed framework, showing that AssistantX can reactively respond to user instructions, actively adjust strategies to adapt to contingencies, and proactively seek assistance from humans to ensure successful task completion. More details and videos can be found at https://assistantx-agent.github.io/AssistantX/.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2409.17655",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "AutoHFormer: Efficient Hierarchical Autoregressive Transformer for Time Series Prediction",
    "description": "arXiv:2506.16001v1 Announce Type: cross Abstract: Time series forecasting requires architectures that simultaneously achieve three competing objectives: (1) strict temporal causality for reliable predictions, (2) sub-quadratic complexity for practical scalability, and (3) multi-scale pattern recognition for accurate long-horizon forecasting. We introduce AutoHFormer, a hierarchical autoregressive transformer that addresses these challenges through three key innovations: 1) Hierarchical Temporal Modeling: Our architecture decomposes predictions into segment-level blocks processed in parallel, followed by intra-segment sequential refinement. This dual-scale approach maintains temporal coherence while enabling efficient computation. 2) Dynamic Windowed Attention: The attention mechanism employs learnable causal windows with exponential decay, reducing complexity while preserving precise temporal relationships. This design avoids both the anti-causal violations of standard transformers and the sequential bottlenecks of RNN hybrids. 3) Adaptive Temporal Encoding: a novel position encoding system is adopted to capture time patterns at multiple scales. It combines fixed oscillating patterns for short-term variations with learnable decay rates for long-term trends. Comprehensive experiments demonstrate that AutoHFormer 10.76X faster training and 6.06X memory reduction compared to PatchTST on PEMS08, while maintaining consistent accuracy across 96-720 step horizons in most of cases. These breakthroughs establish new benchmarks for efficient and precise time series modeling. Implementations of our method and all baselines in hierarchical autoregressive mechanism are available at https://github.com/lizzyhku/Autotime.",
    "summary": "arXiv:2506.16001v1 Announce Type: cross Abstract: Time series forecasting requires architectures that simultaneously achieve three competing objectives: (1) strict temporal causality for reliable predictions, (2) sub-quadratic complexity for practical scalability, and (3) multi-scale pattern recognition for accurate long-horizon forecasting. We introduce AutoHFormer, a hierarchical autoregressive transformer that addresses these challenges through three key innovations: 1) Hierarchical Temporal Modeling: Our architecture decomposes predictions into segment-level blocks processed in parallel, followed by intra-segment sequential refinement. This dual-scale approach maintains temporal coherence while enabling efficient computation. 2) Dynamic Windowed Attention: The attention mechanism employs learnable causal windows with exponential decay, reducing complexity while preserving precise temporal relationships. This design avoids both the anti-causal violations of standard transformers and the sequential bottlenecks of RNN hybrids. 3) Adaptive Temporal Encoding: a novel position encoding system is adopted to capture time patterns at multiple scales. It combines fixed oscillating patterns for short-term variations with learnable decay rates for long-term trends. Comprehensive experiments demonstrate that AutoHFormer 10.76X faster training and 6.06X memory reduction compared to PatchTST on PEMS08, while maintaining consistent accuracy across 96-720 step horizons in most of cases. These breakthroughs establish new benchmarks for efficient and precise time series modeling. Implementations of our method and all baselines in hierarchical autoregressive mechanism are available at https://github.com/lizzyhku/Autotime.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16001",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Automated Skill Discovery for Language Agents through Exploration and Iterative Feedback",
    "description": "arXiv:2506.04287v2 Announce Type: replace Abstract: Training large language model (LLM) agents to acquire necessary skills and perform diverse tasks within an environment is gaining interest as a means to enable open-endedness. However, creating the training dataset for their skill acquisition faces several challenges. Manual trajectory collection requires significant human effort. Another approach, where LLMs directly propose tasks to learn, is often invalid, as the LLMs lack knowledge of which tasks are actually feasible. Moreover, the generated data may not provide a meaningful learning signal, as agents often already perform well on the proposed tasks. To address this, we propose a novel automatic skill discovery framework EXIF for LLM-powered agents, designed to improve the feasibility of generated target behaviors while accounting for the agents' capabilities. Our method adopts an exploration-first strategy by employing an exploration agent (Alice) to train the target agent (Bob) to learn essential skills in the environment. Specifically, Alice first interacts with the environment to retrospectively generate a feasible, environment-grounded skill dataset, which is then used to train Bob. Crucially, we incorporate an iterative feedback loop, where Alice evaluates Bob's performance to identify areas for improvement. This feedback then guides Alice's next round of exploration, forming a closed-loop data generation process. Experiments on Webshop and Crafter demonstrate EXIF's ability to effectively discover meaningful skills and iteratively expand the capabilities of the trained agent without any human intervention, achieving substantial performance improvements. Interestingly, we observe that setting Alice to the same model as Bob also notably improves performance, demonstrating EXIF's potential for building a self-evolving system.",
    "summary": "arXiv:2506.04287v2 Announce Type: replace Abstract: Training large language model (LLM) agents to acquire necessary skills and perform diverse tasks within an environment is gaining interest as a means to enable open-endedness. However, creating the training dataset for their skill acquisition faces several challenges. Manual trajectory collection requires significant human effort. Another approach, where LLMs directly propose tasks to learn, is often invalid, as the LLMs lack knowledge of which tasks are actually feasible. Moreover, the generated data may not provide a meaningful learning signal, as agents often already perform well on the proposed tasks. To address this, we propose a novel automatic skill discovery framework EXIF for LLM-powered agents, designed to improve the feasibility of generated target behaviors while accounting for the agents' capabilities. Our method adopts an exploration-first strategy by employing an exploration agent (Alice) to train the target agent (Bob) to learn essential skills in the environment. Specifically, Alice first interacts with the environment to retrospectively generate a feasible, environment-grounded skill dataset, which is then used to train Bob. Crucially, we incorporate an iterative feedback loop, where Alice evaluates Bob's performance to identify areas for improvement. This feedback then guides Alice's next round of exploration, forming a closed-loop data generation process. Experiments on Webshop and Crafter demonstrate EXIF's ability to effectively discover meaningful skills and iteratively expand the capabilities of the trained agent without any human intervention, achieving substantial performance improvements. Interestingly, we observe that setting Alice to the same model as Bob also notably improves performance, demonstrating EXIF's potential for building a self-evolving system.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.04287",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Automatic dataset shift identification to support safe deployment of medical imaging AI",
    "description": "arXiv:2411.07940v3 Announce Type: replace Abstract: Shifts in data distribution can substantially harm the performance of clinical AI models and lead to misdiagnosis. Hence, various methods have been developed to detect the presence of such shifts at deployment time. However, the root causes of dataset shifts are diverse, and the choice of shift mitigation strategies is highly dependent on the precise type of shift encountered at test time. As such, detecting test-time dataset shift is not sufficient: precisely identifying which type of shift has occurred is critical. In this work, we propose the first unsupervised dataset shift identification framework for imaging datasets, effectively distinguishing between prevalence shift (caused by a change in the label distribution), covariate shift (caused by a change in input characteristics) and mixed shifts (simultaneous prevalence and covariate shifts). We discuss the importance of self-supervised encoders for detecting subtle covariate shifts and propose a novel shift detector leveraging both self-supervised encoders and task model outputs for improved shift detection. We show the effectiveness of the proposed shift identification framework across three different imaging modalities (chest radiography, digital mammography, and retinal fundus images) on five types of real-world dataset shifts using five large publicly available datasets.",
    "summary": "arXiv:2411.07940v3 Announce Type: replace Abstract: Shifts in data distribution can substantially harm the performance of clinical AI models and lead to misdiagnosis. Hence, various methods have been developed to detect the presence of such shifts at deployment time. However, the root causes of dataset shifts are diverse, and the choice of shift mitigation strategies is highly dependent on the precise type of shift encountered at test time. As such, detecting test-time dataset shift is not sufficient: precisely identifying which type of shift has occurred is critical. In this work, we propose the first unsupervised dataset shift identification framework for imaging datasets, effectively distinguishing between prevalence shift (caused by a change in the label distribution), covariate shift (caused by a change in input characteristics) and mixed shifts (simultaneous prevalence and covariate shifts). We discuss the importance of self-supervised encoders for detecting subtle covariate shifts and propose a novel shift detector leveraging both self-supervised encoders and task model outputs for improved shift detection. We show the effectiveness of the proposed shift identification framework across three different imaging modalities (chest radiography, digital mammography, and retinal fundus images) on five types of real-world dataset shifts using five large publicly available datasets.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2411.07940",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Autonomous Computer Vision Development with Agentic AI",
    "description": "arXiv:2506.11140v3 Announce Type: replace-cross Abstract: Agentic Artificial Intelligence (AI) systems leveraging Large Language Models (LLMs) exhibit significant potential for complex reasoning, planning, and tool utilization. We demonstrate that a specialized computer vision system can be built autonomously from a natural language prompt using Agentic AI methods. This involved extending SimpleMind (SM), an open-source Cognitive AI environment with configurable tools for medical image analysis, with an LLM-based agent, implemented using OpenManus, to automate the planning (tool configuration) for a particular computer vision task. We provide a proof-of-concept demonstration that an agentic system can interpret a computer vision task prompt, plan a corresponding SimpleMind workflow by decomposing the task and configuring appropriate tools. From the user input prompt, 'provide sm (SimpleMind) config for lungs, heart, and ribs segmentation for cxr (chest x-ray)'), the agent LLM was able to generate the plan (tool configuration file in YAML format), and execute SM-Learn (training) and SM-Think (inference) scripts autonomously. The computer vision agent automatically configured, trained, and tested itself on 50 chest x-ray images, achieving mean dice scores of 0.96, 0.82, 0.83, for lungs, heart, and ribs, respectively. This work shows the potential for autonomous planning and tool configuration that has traditionally been performed by a data scientist in the development of computer vision applications.",
    "summary": "arXiv:2506.11140v3 Announce Type: replace-cross Abstract: Agentic Artificial Intelligence (AI) systems leveraging Large Language Models (LLMs) exhibit significant potential for complex reasoning, planning, and tool utilization. We demonstrate that a specialized computer vision system can be built autonomously from a natural language prompt using Agentic AI methods. This involved extending SimpleMind (SM), an open-source Cognitive AI environment with configurable tools for medical image analysis, with an LLM-based agent, implemented using OpenManus, to automate the planning (tool configuration) for a particular computer vision task. We provide a proof-of-concept demonstration that an agentic system can interpret a computer vision task prompt, plan a corresponding SimpleMind workflow by decomposing the task and configuring appropriate tools. From the user input prompt, 'provide sm (SimpleMind) config for lungs, heart, and ribs segmentation for cxr (chest x-ray)'), the agent LLM was able to generate the plan (tool configuration file in YAML format), and execute SM-Learn (training) and SM-Think (inference) scripts autonomously. The computer vision agent automatically configured, trained, and tested itself on 50 chest x-ray images, achieving mean dice scores of 0.96, 0.82, 0.83, for lungs, heart, and ribs, respectively. This work shows the potential for autonomous planning and tool configuration that has traditionally been performed by a data scientist in the development of computer vision applications.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.11140",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "AutoSculpt: A Pattern-based Model Auto-pruning Framework Using Reinforcement Learning and Graph Learning",
    "description": "arXiv:2412.18091v2 Announce Type: replace Abstract: As deep neural networks (DNNs) are increasingly deployed on edge devices, optimizing models for constrained computational resources is critical. Existing auto-pruning methods face challenges due to the diversity of DNN models, various operators (e.g., filters), and the difficulty in balancing pruning granularity with model accuracy. To address these limitations, we introduce AutoSculpt, a pattern-based automated pruning framework designed to enhance efficiency and accuracy by leveraging graph learning and deep reinforcement learning (DRL). AutoSculpt automatically identifies and prunes regular patterns within DNN architectures that can be recognized by existing inference engines, enabling runtime acceleration. Three key steps in AutoSculpt include: (1) Constructing DNNs as graphs to encode their topology and parameter dependencies, (2) embedding computationally efficient pruning patterns, and (3) utilizing DRL to iteratively refine auto-pruning strategies until the optimal balance between compression and accuracy is achieved. Experimental results demonstrate the effectiveness of AutoSculpt across various architectures, including ResNet, MobileNet, VGG, and Vision Transformer, achieving pruning rates of up to 90% and nearly 18% improvement in FLOPs reduction, outperforming all baselines. The codes can be available at https://anonymous.4open.science/r/AutoSculpt-DDA0",
    "summary": "arXiv:2412.18091v2 Announce Type: replace Abstract: As deep neural networks (DNNs) are increasingly deployed on edge devices, optimizing models for constrained computational resources is critical. Existing auto-pruning methods face challenges due to the diversity of DNN models, various operators (e.g., filters), and the difficulty in balancing pruning granularity with model accuracy. To address these limitations, we introduce AutoSculpt, a pattern-based automated pruning framework designed to enhance efficiency and accuracy by leveraging graph learning and deep reinforcement learning (DRL). AutoSculpt automatically identifies and prunes regular patterns within DNN architectures that can be recognized by existing inference engines, enabling runtime acceleration. Three key steps in AutoSculpt include: (1) Constructing DNNs as graphs to encode their topology and parameter dependencies, (2) embedding computationally efficient pruning patterns, and (3) utilizing DRL to iteratively refine auto-pruning strategies until the optimal balance between compression and accuracy is achieved. Experimental results demonstrate the effectiveness of AutoSculpt across various architectures, including ResNet, MobileNet, VGG, and Vision Transformer, achieving pruning rates of up to 90% and nearly 18% improvement in FLOPs reduction, outperforming all baselines. The codes can be available at https://anonymous.4open.science/r/AutoSculpt-DDA0",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2412.18091",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Bandwidth Selectors on Semiparametric Bayesian Networks",
    "description": "arXiv:2506.16844v1 Announce Type: cross Abstract: Semiparametric Bayesian networks (SPBNs) integrate parametric and non-parametric probabilistic models, offering flexibility in learning complex data distributions from samples. In particular, kernel density estimators (KDEs) are employed for the non-parametric component. Under the assumption of data normality, the normal rule is used to learn the bandwidth matrix for the KDEs in SPBNs. This matrix is the key hyperparameter that controls the trade-off between bias and variance. However, real-world data often deviates from normality, potentially leading to suboptimal density estimation and reduced predictive performance. This paper first establishes the theoretical framework for the application of state-of-the-art bandwidth selectors and subsequently evaluates their impact on SPBN performance. We explore the approaches of cross-validation and plug-in selectors, assessing their effectiveness in enhancing the learning capability and applicability of SPBNs. To support this investigation, we have extended the open-source package PyBNesian for SPBNs with the additional bandwidth selection techniques and conducted extensive experimental analyses. Our results demonstrate that the proposed bandwidth selectors leverage increasing information more effectively than the normal rule, which, despite its robustness, stagnates with more data. In particular, unbiased cross-validation generally outperforms the normal rule, highlighting its advantage in high sample size scenarios.",
    "summary": "arXiv:2506.16844v1 Announce Type: cross Abstract: Semiparametric Bayesian networks (SPBNs) integrate parametric and non-parametric probabilistic models, offering flexibility in learning complex data distributions from samples. In particular, kernel density estimators (KDEs) are employed for the non-parametric component. Under the assumption of data normality, the normal rule is used to learn the bandwidth matrix for the KDEs in SPBNs. This matrix is the key hyperparameter that controls the trade-off between bias and variance. However, real-world data often deviates from normality, potentially leading to suboptimal density estimation and reduced predictive performance. This paper first establishes the theoretical framework for the application of state-of-the-art bandwidth selectors and subsequently evaluates their impact on SPBN performance. We explore the approaches of cross-validation and plug-in selectors, assessing their effectiveness in enhancing the learning capability and applicability of SPBNs. To support this investigation, we have extended the open-source package PyBNesian for SPBNs with the additional bandwidth selection techniques and conducted extensive experimental analyses. Our results demonstrate that the proposed bandwidth selectors leverage increasing information more effectively than the normal rule, which, despite its robustness, stagnates with more data. In particular, unbiased cross-validation generally outperforms the normal rule, highlighting its advantage in high sample size scenarios.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16844",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "BASE-Q: Bias and Asymmetric Scaling Enhanced Rotational Quantization for Large Language Models",
    "description": "arXiv:2506.15689v1 Announce Type: cross Abstract: Rotations have become essential to state-of-the-art quantization pipelines for large language models (LLMs) by effectively smoothing outliers in weights and activations. However, further optimizing the rotation parameters offers only limited performance gains and introduces significant training overhead: due to rotation parameter sharing, full-model must be loaded simultaneously to enable backpropagation, resulting in substantial memory consumption and limited practical utility. In this work, we identify two fundamental limitations of current rotational quantization methods: (i) rotation fails to align channel means, resulting in wider quantization bounds and increased rounding errors; and (ii) rotation makes the activation distribution more Gaussian-like, increasing energy loss caused by clipping errors. To address these issues, we introduce textbf{BASE-Q}, a simple yet powerful approach that combines bias correction and asymmetric scaling to effectively reduce rounding and clipping errors. Furthermore, BASE-Q enables blockwise optimization, eliminating the need for memory-intensive full-model backpropagation. Extensive experiments on various LLMs and benchmarks demonstrate the effectiveness of BASE-Q, narrowing the accuracy gap to full-precision models by 50.5%, 42.9%, and 29.2% compared to QuaRot, SpinQuant, and OSTQuant, respectively. The code will be released soon.",
    "summary": "arXiv:2506.15689v1 Announce Type: cross Abstract: Rotations have become essential to state-of-the-art quantization pipelines for large language models (LLMs) by effectively smoothing outliers in weights and activations. However, further optimizing the rotation parameters offers only limited performance gains and introduces significant training overhead: due to rotation parameter sharing, full-model must be loaded simultaneously to enable backpropagation, resulting in substantial memory consumption and limited practical utility. In this work, we identify two fundamental limitations of current rotational quantization methods: (i) rotation fails to align channel means, resulting in wider quantization bounds and increased rounding errors; and (ii) rotation makes the activation distribution more Gaussian-like, increasing energy loss caused by clipping errors. To address these issues, we introduce textbf{BASE-Q}, a simple yet powerful approach that combines bias correction and asymmetric scaling to effectively reduce rounding and clipping errors. Furthermore, BASE-Q enables blockwise optimization, eliminating the need for memory-intensive full-model backpropagation. Extensive experiments on various LLMs and benchmarks demonstrate the effectiveness of BASE-Q, narrowing the accuracy gap to full-precision models by 50.5%, 42.9%, and 29.2% compared to QuaRot, SpinQuant, and OSTQuant, respectively. The code will be released soon.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.15689",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Batayan: A Filipino NLP benchmark for evaluating Large Language Models",
    "description": "arXiv:2502.14911v2 Announce Type: replace-cross Abstract: Recent advances in large language models (LLMs) have demonstrated remarkable capabilities on widely benchmarked high-resource languages. However, linguistic nuances of under-resourced languages remain unexplored. We introduce Batayan, a holistic Filipino benchmark that systematically evaluates LLMs across three key natural language processing (NLP) competencies: understanding, reasoning, and generation. Batayan consolidates eight tasks, three of which have not existed prior for Filipino corpora, covering both Tagalog and code-switched Taglish utterances. Our rigorous, native-speaker-driven adaptation and validation processes ensures fluency and authenticity to the complex morphological and syntactic structures of Filipino, alleviating the pervasive translationese bias in existing Filipino corpora. We report empirical results on a variety of open-source and commercial LLMs, highlighting significant performance gaps that signal the under-representation of Filipino in pre-training corpora, the unique hurdles in modeling Filipino's rich morphology and construction, and the importance of explicit Filipino language support. Moreover, we discuss the practical challenges encountered in dataset construction and propose principled solutions for building culturally and linguistically-faithful resources in under-represented languages. We also provide a public evaluation suite as a clear foundation for iterative, community-driven progress in Filipino NLP.",
    "summary": "arXiv:2502.14911v2 Announce Type: replace-cross Abstract: Recent advances in large language models (LLMs) have demonstrated remarkable capabilities on widely benchmarked high-resource languages. However, linguistic nuances of under-resourced languages remain unexplored. We introduce Batayan, a holistic Filipino benchmark that systematically evaluates LLMs across three key natural language processing (NLP) competencies: understanding, reasoning, and generation. Batayan consolidates eight tasks, three of which have not existed prior for Filipino corpora, covering both Tagalog and code-switched Taglish utterances. Our rigorous, native-speaker-driven adaptation and validation processes ensures fluency and authenticity to the complex morphological and syntactic structures of Filipino, alleviating the pervasive translationese bias in existing Filipino corpora. We report empirical results on a variety of open-source and commercial LLMs, highlighting significant performance gaps that signal the under-representation of Filipino in pre-training corpora, the unique hurdles in modeling Filipino's rich morphology and construction, and the importance of explicit Filipino language support. Moreover, we discuss the practical challenges encountered in dataset construction and propose principled solutions for building culturally and linguistically-faithful resources in under-represented languages. We also provide a public evaluation suite as a clear foundation for iterative, community-driven progress in Filipino NLP.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2502.14911",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "BatteryBERT for Realistic Battery Fault Detection Using Point-Masked Signal Modeling",
    "description": "arXiv:2506.15712v1 Announce Type: cross Abstract: Accurate fault detection in lithium-ion batteries is essential for the safe and reliable operation of electric vehicles and energy storage systems. However, existing methods often struggle to capture complex temporal dependencies and cannot fully leverage abundant unlabeled data. Although large language models (LLMs) exhibit strong representation capabilities, their architectures are not directly suited to the numerical time-series data common in industrial settings. To address these challenges, we propose a novel framework that adapts BERT-style pretraining for battery fault detection by extending the standard BERT architecture with a customized time-series-to-token representation module and a point-level Masked Signal Modeling (point-MSM) pretraining task tailored to battery applications. This approach enables self-supervised learning on sequential current, voltage, and other charge-discharge cycle data, yielding distributionally robust, context-aware temporal embeddings. We then concatenate these embeddings with battery metadata and feed them into a downstream classifier for accurate fault classification. Experimental results on a large-scale real-world dataset show that models initialized with our pretrained parameters significantly improve both representation quality and classification accuracy, achieving an AUROC of 0.945 and substantially outperforming existing approaches. These findings validate the effectiveness of BERT-style pretraining for time-series fault detection.",
    "summary": "arXiv:2506.15712v1 Announce Type: cross Abstract: Accurate fault detection in lithium-ion batteries is essential for the safe and reliable operation of electric vehicles and energy storage systems. However, existing methods often struggle to capture complex temporal dependencies and cannot fully leverage abundant unlabeled data. Although large language models (LLMs) exhibit strong representation capabilities, their architectures are not directly suited to the numerical time-series data common in industrial settings. To address these challenges, we propose a novel framework that adapts BERT-style pretraining for battery fault detection by extending the standard BERT architecture with a customized time-series-to-token representation module and a point-level Masked Signal Modeling (point-MSM) pretraining task tailored to battery applications. This approach enables self-supervised learning on sequential current, voltage, and other charge-discharge cycle data, yielding distributionally robust, context-aware temporal embeddings. We then concatenate these embeddings with battery metadata and feed them into a downstream classifier for accurate fault classification. Experimental results on a large-scale real-world dataset show that models initialized with our pretrained parameters significantly improve both representation quality and classification accuracy, achieving an AUROC of 0.945 and substantially outperforming existing approaches. These findings validate the effectiveness of BERT-style pretraining for time-series fault detection.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.15712",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Bayesian Epistemology with Weighted Authority: A Formal Architecture for Truth-Promoting Autonomous Scientific Reasoning",
    "description": "arXiv:2506.16015v1 Announce Type: new Abstract: The exponential expansion of scientific literature has surpassed the epistemic processing capabilities of both human experts and current artificial intelligence systems. This paper introduces Bayesian Epistemology with Weighted Authority (BEWA), a formally structured architecture that operationalises belief as a dynamic, probabilistically coherent function over structured scientific claims. Each claim is contextualised, author-attributed, and evaluated through a system of replication scores, citation weighting, and temporal decay. Belief updates are performed via evidence-conditioned Bayesian inference, contradiction processing, and epistemic decay mechanisms. The architecture supports graph-based claim propagation, authorial credibility modelling, cryptographic anchoring, and zero-knowledge audit verification. By formalising scientific reasoning into a computationally verifiable epistemic network, BEWA advances the foundation for machine reasoning systems that promote truth utility, rational belief convergence, and audit-resilient integrity across dynamic scientific domains.",
    "summary": "arXiv:2506.16015v1 Announce Type: new Abstract: The exponential expansion of scientific literature has surpassed the epistemic processing capabilities of both human experts and current artificial intelligence systems. This paper introduces Bayesian Epistemology with Weighted Authority (BEWA), a formally structured architecture that operationalises belief as a dynamic, probabilistically coherent function over structured scientific claims. Each claim is contextualised, author-attributed, and evaluated through a system of replication scores, citation weighting, and temporal decay. Belief updates are performed via evidence-conditioned Bayesian inference, contradiction processing, and epistemic decay mechanisms. The architecture supports graph-based claim propagation, authorial credibility modelling, cryptographic anchoring, and zero-knowledge audit verification. By formalising scientific reasoning into a computationally verifiable epistemic network, BEWA advances the foundation for machine reasoning systems that promote truth utility, rational belief convergence, and audit-resilient integrity across dynamic scientific domains.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16015",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "BEADs: Bias Evaluation Across Domains",
    "description": "arXiv:2406.04220v5 Announce Type: replace-cross Abstract: Recent advancements in large language models (LLMs) have significantly improved natural language processing (NLP) applications. However, these models often inherit biases from their training data. While several datasets exist for bias detection, most are limited to one or two NLP tasks, typically classification or evaluation, and lack comprehensive coverage across a broader range of tasks. To address this gap, we introduce the Bias Evaluations Across Domains (BEADs) dataset, designed to support a wide range of NLP tasks, including text classification, token classification, bias quantification, and benign language generation. A key contribution of this work is the gold-standard annotation provided by GPT-4 for scalability, with expert verification to ensure high reliability. BEADs can be used for both fine-tuning models (for classification and generation tasks) and evaluating LLM behavior. Our findings show that BEADs effectively surfaces various biases during model fine-tuning and helps reduce biases in language generation tasks while maintaining output quality. The dataset also highlights prevalent demographic biases in LLMs during evaluation. We release BEADs as a practical resource for detecting and mitigating bias across domains, supporting the development of responsible AI systems. Project: https://vectorinstitute.github.io/BEAD/ Data: https://huggingface.co/datasets/shainar/BEAD",
    "summary": "arXiv:2406.04220v5 Announce Type: replace-cross Abstract: Recent advancements in large language models (LLMs) have significantly improved natural language processing (NLP) applications. However, these models often inherit biases from their training data. While several datasets exist for bias detection, most are limited to one or two NLP tasks, typically classification or evaluation, and lack comprehensive coverage across a broader range of tasks. To address this gap, we introduce the Bias Evaluations Across Domains (BEADs) dataset, designed to support a wide range of NLP tasks, including text classification, token classification, bias quantification, and benign language generation. A key contribution of this work is the gold-standard annotation provided by GPT-4 for scalability, with expert verification to ensure high reliability. BEADs can be used for both fine-tuning models (for classification and generation tasks) and evaluating LLM behavior. Our findings show that BEADs effectively surfaces various biases during model fine-tuning and helps reduce biases in language generation tasks while maintaining output quality. The dataset also highlights prevalent demographic biases in LLMs during evaluation. We release BEADs as a practical resource for detecting and mitigating bias across domains, supporting the development of responsible AI systems. Project: https://vectorinstitute.github.io/BEAD/ Data: https://huggingface.co/datasets/shainar/BEAD",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2406.04220",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Behaviour Planning: A Toolkit for Diverse Planning",
    "description": "arXiv:2405.04300v3 Announce Type: replace Abstract: Diverse planning approaches are utilised in real-world applications like risk management, automated streamed data analysis, and malware detection. The current diverse planning formulations encode the diversity model as a distance function, which is computational inexpensive when comparing two plans. However, such modelling approach limits what can be encoded as measure of diversity, as well as the ability to explain why two plans are different. This paper introduces a novel approach to the diverse planning problem, allowing for more expressive modelling of diversity using a n-dimensional grid representation, where each dimension corresponds to a user-defined feature. Furthermore, we present a novel toolkit that generates diverse plans based on such customisable diversity models, called emph{Behaviour Planning}. We provide an implementation for behaviour planning using planning-as-satisfiability. An empirical evaluation of our implementation shows that behaviour planning significantly outperforms the current diverse planning method in generating diverse plans measured on our new customisable diversity models. Our implementation is the first diverse planning approach to support planning categories beyond classical planning, such as over-subscription and numerical planning.",
    "summary": "arXiv:2405.04300v3 Announce Type: replace Abstract: Diverse planning approaches are utilised in real-world applications like risk management, automated streamed data analysis, and malware detection. The current diverse planning formulations encode the diversity model as a distance function, which is computational inexpensive when comparing two plans. However, such modelling approach limits what can be encoded as measure of diversity, as well as the ability to explain why two plans are different. This paper introduces a novel approach to the diverse planning problem, allowing for more expressive modelling of diversity using a n-dimensional grid representation, where each dimension corresponds to a user-defined feature. Furthermore, we present a novel toolkit that generates diverse plans based on such customisable diversity models, called emph{Behaviour Planning}. We provide an implementation for behaviour planning using planning-as-satisfiability. An empirical evaluation of our implementation shows that behaviour planning significantly outperforms the current diverse planning method in generating diverse plans measured on our new customisable diversity models. Our implementation is the first diverse planning approach to support planning categories beyond classical planning, such as over-subscription and numerical planning.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2405.04300",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Beyond Audio and Pose: A General-Purpose Framework for Video Synchronization",
    "description": "arXiv:2506.15937v1 Announce Type: cross Abstract: Video synchronization-aligning multiple video streams capturing the same event from different angles-is crucial for applications such as reality TV show production, sports analysis, surveillance, and autonomous systems. Prior work has heavily relied on audio cues or specific visual events, limiting applicability in diverse settings where such signals may be unreliable or absent. Additionally, existing benchmarks for video synchronization lack generality and reproducibility, restricting progress in the field. In this work, we introduce VideoSync, a video synchronization framework that operates independently of specific feature extraction methods, such as human pose estimation, enabling broader applicability across different content types. We evaluate our system on newly composed datasets covering single-human, multi-human, and non-human scenarios, providing both the methodology and code for dataset creation to establish reproducible benchmarks. Our analysis reveals biases in prior SOTA work, particularly in SeSyn-Net's preprocessing pipeline, leading to inflated performance claims. We correct these biases and propose a more rigorous evaluation framework, demonstrating that VideoSync outperforms existing approaches, including SeSyn-Net, under fair experimental conditions. Additionally, we explore various synchronization offset prediction methods, identifying a convolutional neural network (CNN)-based model as the most effective. Our findings advance video synchronization beyond domain-specific constraints, making it more generalizable and robust for real-world applications.",
    "summary": "arXiv:2506.15937v1 Announce Type: cross Abstract: Video synchronization-aligning multiple video streams capturing the same event from different angles-is crucial for applications such as reality TV show production, sports analysis, surveillance, and autonomous systems. Prior work has heavily relied on audio cues or specific visual events, limiting applicability in diverse settings where such signals may be unreliable or absent. Additionally, existing benchmarks for video synchronization lack generality and reproducibility, restricting progress in the field. In this work, we introduce VideoSync, a video synchronization framework that operates independently of specific feature extraction methods, such as human pose estimation, enabling broader applicability across different content types. We evaluate our system on newly composed datasets covering single-human, multi-human, and non-human scenarios, providing both the methodology and code for dataset creation to establish reproducible benchmarks. Our analysis reveals biases in prior SOTA work, particularly in SeSyn-Net's preprocessing pipeline, leading to inflated performance claims. We correct these biases and propose a more rigorous evaluation framework, demonstrating that VideoSync outperforms existing approaches, including SeSyn-Net, under fair experimental conditions. Additionally, we explore various synchronization offset prediction methods, identifying a convolutional neural network (CNN)-based model as the most effective. Our findings advance video synchronization beyond domain-specific constraints, making it more generalizable and robust for real-world applications.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.15937",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "BIDA: A Bi-level Interaction Decision-making Algorithm for Autonomous Vehicles in Dynamic Traffic Scenarios",
    "description": "arXiv:2506.16546v1 Announce Type: cross Abstract: In complex real-world traffic environments, autonomous vehicles (AVs) need to interact with other traffic participants while making real-time and safety-critical decisions accordingly. The unpredictability of human behaviors poses significant challenges, particularly in dynamic scenarios, such as multi-lane highways and unsignalized T-intersections. To address this gap, we design a bi-level interaction decision-making algorithm (BIDA) that integrates interactive Monte Carlo tree search (MCTS) with deep reinforcement learning (DRL), aiming to enhance interaction rationality, efficiency and safety of AVs in dynamic key traffic scenarios. Specifically, we adopt three types of DRL algorithms to construct a reliable value network and policy network, which guide the online deduction process of interactive MCTS by assisting in value update and node selection. Then, a dynamic trajectory planner and a trajectory tracking controller are designed and implemented in CARLA to ensure smooth execution of planned maneuvers. Experimental evaluations demonstrate that our BIDA not only enhances interactive deduction and reduces computational costs, but also outperforms other latest benchmarks, which exhibits superior safety, efficiency and interaction rationality under varying traffic conditions.",
    "summary": "arXiv:2506.16546v1 Announce Type: cross Abstract: In complex real-world traffic environments, autonomous vehicles (AVs) need to interact with other traffic participants while making real-time and safety-critical decisions accordingly. The unpredictability of human behaviors poses significant challenges, particularly in dynamic scenarios, such as multi-lane highways and unsignalized T-intersections. To address this gap, we design a bi-level interaction decision-making algorithm (BIDA) that integrates interactive Monte Carlo tree search (MCTS) with deep reinforcement learning (DRL), aiming to enhance interaction rationality, efficiency and safety of AVs in dynamic key traffic scenarios. Specifically, we adopt three types of DRL algorithms to construct a reliable value network and policy network, which guide the online deduction process of interactive MCTS by assisting in value update and node selection. Then, a dynamic trajectory planner and a trajectory tracking controller are designed and implemented in CARLA to ensure smooth execution of planned maneuvers. Experimental evaluations demonstrate that our BIDA not only enhances interactive deduction and reduces computational costs, but also outperforms other latest benchmarks, which exhibits superior safety, efficiency and interaction rationality under varying traffic conditions.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16546",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "BLUR: A Benchmark for LLM Unlearning Robust to Forget-Retain Overlap",
    "description": "arXiv:2506.15699v1 Announce Type: cross Abstract: Machine unlearning has the potential to improve the safety of large language models (LLMs) by removing sensitive or harmful information post hoc. A key challenge in unlearning involves balancing between forget quality (effectively unlearning undesirable information) and retain quality (maintaining good performance on other, general tasks). Unfortunately, as we show, current LLM unlearning benchmarks contain highly disparate forget and retain sets -- painting a false picture of the effectiveness of LLM unlearning methods. This can be particularly problematic because it opens the door for benign perturbations, such as relearning attacks, to easily reveal supposedly unlearned knowledge once models are deployed. To address this, we present $texttt{BLUR}$: a benchmark for LLM unlearning that provides more realistic scenarios of forget-retain overlap. $texttt{BLUR}$ significantly expands on existing unlearning benchmarks by providing extended evaluation tasks, combined forget/retain queries, and relearning datasets of varying degrees of difficulty. Despite the benign nature of the queries considered, we find that the performance of existing methods drops significantly when evaluated on $texttt{BLUR}$, with simple approaches performing better on average than more recent methods. These results highlight the importance of robust evaluation and suggest several important directions of future study. Our benchmark is publicly available at: https://huggingface.co/datasets/forgelab/BLUR",
    "summary": "arXiv:2506.15699v1 Announce Type: cross Abstract: Machine unlearning has the potential to improve the safety of large language models (LLMs) by removing sensitive or harmful information post hoc. A key challenge in unlearning involves balancing between forget quality (effectively unlearning undesirable information) and retain quality (maintaining good performance on other, general tasks). Unfortunately, as we show, current LLM unlearning benchmarks contain highly disparate forget and retain sets -- painting a false picture of the effectiveness of LLM unlearning methods. This can be particularly problematic because it opens the door for benign perturbations, such as relearning attacks, to easily reveal supposedly unlearned knowledge once models are deployed. To address this, we present $texttt{BLUR}$: a benchmark for LLM unlearning that provides more realistic scenarios of forget-retain overlap. $texttt{BLUR}$ significantly expands on existing unlearning benchmarks by providing extended evaluation tasks, combined forget/retain queries, and relearning datasets of varying degrees of difficulty. Despite the benign nature of the queries considered, we find that the performance of existing methods drops significantly when evaluated on $texttt{BLUR}$, with simple approaches performing better on average than more recent methods. These results highlight the importance of robust evaluation and suggest several important directions of future study. Our benchmark is publicly available at: https://huggingface.co/datasets/forgelab/BLUR",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.15699",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Boosting multi-demographic federated learning for chest radiograph analysis using general-purpose self-supervised representations",
    "description": "arXiv:2504.08584v2 Announce Type: replace-cross Abstract: Reliable artificial intelligence (AI) models for medical image analysis often depend on large and diverse labeled datasets. Federated learning (FL) offers a decentralized and privacy-preserving approach to training but struggles in highly non-independent and identically distributed (non-IID) settings, where institutions with more representative data may experience degraded performance. Moreover, existing large-scale FL studies have been limited to adult datasets, neglecting the unique challenges posed by pediatric data, which introduces additional non-IID variability. To address these limitations, we analyzed n=398,523 adult chest radiographs from diverse institutions across multiple countries and n=9,125 pediatric images, leveraging transfer learning from general-purpose self-supervised image representations to classify pneumonia and cases with no abnormality. Using state-of-the-art vision transformers, we found that FL improved performance only for smaller adult datasets (P<0.001) but degraded performance for larger datasets (P<0.064) and pediatric cases (P=0.242). However, equipping FL with self-supervised weights significantly enhanced outcomes across pediatric cases (P=0.031) and most adult datasets (P<0.008), except the largest dataset (P=0.052). These findings underscore the potential of easily deployable general-purpose self-supervised image representations to address non-IID challenges in clinical FL applications and highlight their promise for enhancing patient outcomes and advancing pediatric healthcare, where data scarcity and variability remain persistent obstacles.",
    "summary": "arXiv:2504.08584v2 Announce Type: replace-cross Abstract: Reliable artificial intelligence (AI) models for medical image analysis often depend on large and diverse labeled datasets. Federated learning (FL) offers a decentralized and privacy-preserving approach to training but struggles in highly non-independent and identically distributed (non-IID) settings, where institutions with more representative data may experience degraded performance. Moreover, existing large-scale FL studies have been limited to adult datasets, neglecting the unique challenges posed by pediatric data, which introduces additional non-IID variability. To address these limitations, we analyzed n=398,523 adult chest radiographs from diverse institutions across multiple countries and n=9,125 pediatric images, leveraging transfer learning from general-purpose self-supervised image representations to classify pneumonia and cases with no abnormality. Using state-of-the-art vision transformers, we found that FL improved performance only for smaller adult datasets (P<0.001) but degraded performance for larger datasets (P<0.064) and pediatric cases (P=0.242). However, equipping FL with self-supervised weights significantly enhanced outcomes across pediatric cases (P=0.031) and most adult datasets (P<0.008), except the largest dataset (P=0.052). These findings underscore the potential of easily deployable general-purpose self-supervised image representations to address non-IID challenges in clinical FL applications and highlight their promise for enhancing patient outcomes and advancing pediatric healthcare, where data scarcity and variability remain persistent obstacles.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2504.08584",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Breaking the Compression Ceiling: Data-Free Pipeline for Ultra-Efficient Delta Compression",
    "description": "arXiv:2505.13563v2 Announce Type: replace-cross Abstract: With the rise of the fine-tuned--pretrained paradigm, storing numerous fine-tuned models for multi-tasking creates significant storage overhead. Delta compression alleviates this by storing only the pretrained model and the highly compressed delta weights (the differences between fine-tuned and pretrained model weights). However, existing methods fail to maintain both high compression and performance, and often rely on data. To address these challenges, we propose UltraDelta, the first data-free delta compression pipeline that achieves both ultra-high compression and strong performance. UltraDelta is designed to minimize redundancy, maximize information, and stabilize performance across inter-layer, intra-layer, and global dimensions, using three key components: (1) Variance-Based Mixed Sparsity Allocation assigns sparsity based on variance, giving lower sparsity to high-variance layers to preserve inter-layer information. (2) Distribution-Aware Compression applies uniform quantization and then groups parameters by value, followed by group-wise pruning, to better preserve intra-layer distribution. (3) Trace-Norm-Guided Rescaling uses the trace norm of delta weights to estimate a global rescaling factor, improving model stability under higher compression. Extensive experiments across (a) large language models (fine-tuned on LLaMA-2 7B and 13B) with up to 133x, (b) general NLP models (RoBERTa-base, T5-base) with up to 800x, (c) vision models (ViT-B/32, ViT-L/14) with up to 400x, and (d) multi-modal models (BEiT-3) with 40x compression ratio, demonstrate that UltraDelta consistently outperforms existing methods, especially under ultra-high compression.",
    "summary": "arXiv:2505.13563v2 Announce Type: replace-cross Abstract: With the rise of the fine-tuned--pretrained paradigm, storing numerous fine-tuned models for multi-tasking creates significant storage overhead. Delta compression alleviates this by storing only the pretrained model and the highly compressed delta weights (the differences between fine-tuned and pretrained model weights). However, existing methods fail to maintain both high compression and performance, and often rely on data. To address these challenges, we propose UltraDelta, the first data-free delta compression pipeline that achieves both ultra-high compression and strong performance. UltraDelta is designed to minimize redundancy, maximize information, and stabilize performance across inter-layer, intra-layer, and global dimensions, using three key components: (1) Variance-Based Mixed Sparsity Allocation assigns sparsity based on variance, giving lower sparsity to high-variance layers to preserve inter-layer information. (2) Distribution-Aware Compression applies uniform quantization and then groups parameters by value, followed by group-wise pruning, to better preserve intra-layer distribution. (3) Trace-Norm-Guided Rescaling uses the trace norm of delta weights to estimate a global rescaling factor, improving model stability under higher compression. Extensive experiments across (a) large language models (fine-tuned on LLaMA-2 7B and 13B) with up to 133x, (b) general NLP models (RoBERTa-base, T5-base) with up to 800x, (c) vision models (ViT-B/32, ViT-L/14) with up to 400x, and (d) multi-modal models (BEiT-3) with 40x compression ratio, demonstrate that UltraDelta consistently outperforms existing methods, especially under ultra-high compression.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2505.13563",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "BreastDCEDL: Curating a Comprehensive DCE-MRI Dataset and developing a Transformer Implementation for Breast Cancer Treatment Response Prediction",
    "description": "arXiv:2506.12190v2 Announce Type: replace-cross Abstract: Breast cancer remains a leading cause of cancer-related mortality worldwide, making early detection and accurate treatment response monitoring critical priorities. We present BreastDCEDL, a curated, deep learning-ready dataset comprising pre-treatment 3D Dynamic Contrast-Enhanced MRI (DCE-MRI) scans from 2,070 breast cancer patients drawn from the I-SPY1, I-SPY2, and Duke cohorts, all sourced from The Cancer Imaging Archive. The raw DICOM imaging data were rigorously converted into standardized 3D NIfTI volumes with preserved signal integrity, accompanied by unified tumor annotations and harmonized clinical metadata including pathologic complete response (pCR), hormone receptor (HR), and HER2 status. Although DCE-MRI provides essential diagnostic information and deep learning offers tremendous potential for analyzing such complex data, progress has been limited by lack of accessible, public, multicenter datasets. BreastDCEDL addresses this gap by enabling development of advanced models, including state-of-the-art transformer architectures that require substantial training data. To demonstrate its capacity for robust modeling, we developed the first transformer-based model for breast DCE-MRI, leveraging Vision Transformer (ViT) architecture trained on RGB-fused images from three contrast phases (pre-contrast, early post-contrast, and late post-contrast). Our ViT model achieved state-of-the-art pCR prediction performance in HR+/HER2- patients (AUC 0.94, accuracy 0.93). BreastDCEDL includes predefined benchmark splits, offering a framework for reproducible research and enabling clinically meaningful modeling in breast cancer imaging.",
    "summary": "arXiv:2506.12190v2 Announce Type: replace-cross Abstract: Breast cancer remains a leading cause of cancer-related mortality worldwide, making early detection and accurate treatment response monitoring critical priorities. We present BreastDCEDL, a curated, deep learning-ready dataset comprising pre-treatment 3D Dynamic Contrast-Enhanced MRI (DCE-MRI) scans from 2,070 breast cancer patients drawn from the I-SPY1, I-SPY2, and Duke cohorts, all sourced from The Cancer Imaging Archive. The raw DICOM imaging data were rigorously converted into standardized 3D NIfTI volumes with preserved signal integrity, accompanied by unified tumor annotations and harmonized clinical metadata including pathologic complete response (pCR), hormone receptor (HR), and HER2 status. Although DCE-MRI provides essential diagnostic information and deep learning offers tremendous potential for analyzing such complex data, progress has been limited by lack of accessible, public, multicenter datasets. BreastDCEDL addresses this gap by enabling development of advanced models, including state-of-the-art transformer architectures that require substantial training data. To demonstrate its capacity for robust modeling, we developed the first transformer-based model for breast DCE-MRI, leveraging Vision Transformer (ViT) architecture trained on RGB-fused images from three contrast phases (pre-contrast, early post-contrast, and late post-contrast). Our ViT model achieved state-of-the-art pCR prediction performance in HR+/HER2- patients (AUC 0.94, accuracy 0.93). BreastDCEDL includes predefined benchmark splits, offering a framework for reproducible research and enabling clinically meaningful modeling in breast cancer imaging.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.12190",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Calibrating Pre-trained Language Classifiers on LLM-generated Noisy Labels via Iterative Refinement",
    "description": "arXiv:2505.19675v2 Announce Type: replace-cross Abstract: The traditional process of creating labeled datasets is labor-intensive and expensive. Recent breakthroughs in open-source large language models (LLMs) have opened up a new avenue in generating labeled datasets automatically for various natural language processing (NLP) tasks, providing an alternative to such an expensive annotation process. However, the reliability of such auto-generated labels remains a significant concern due to inherent inaccuracies. When learning from noisy labels, the model's generalization is likely to be harmed as it is prone to overfit to those label noises. While previous studies in learning from noisy labels mainly focus on synthetic noise and real-world noise, LLM-generated label noise receives less attention. In this paper, we propose SiDyP: Simplex Label Diffusion with Dynamic Prior to calibrate the classifier's prediction, thus enhancing its robustness towards LLM-generated noisy labels. SiDyP retrieves potential true label candidates by neighborhood label distribution in text embedding space and iteratively refines noisy candidates using a simplex diffusion model. Our framework can increase the performance of the BERT classifier fine-tuned on both zero-shot and few-shot LLM-generated noisy label datasets by an average of 7.21% and 7.30% respectively. We demonstrate the effectiveness of SiDyP by conducting extensive benchmarking for different LLMs over a variety of NLP tasks. Our code is available on Github.",
    "summary": "arXiv:2505.19675v2 Announce Type: replace-cross Abstract: The traditional process of creating labeled datasets is labor-intensive and expensive. Recent breakthroughs in open-source large language models (LLMs) have opened up a new avenue in generating labeled datasets automatically for various natural language processing (NLP) tasks, providing an alternative to such an expensive annotation process. However, the reliability of such auto-generated labels remains a significant concern due to inherent inaccuracies. When learning from noisy labels, the model's generalization is likely to be harmed as it is prone to overfit to those label noises. While previous studies in learning from noisy labels mainly focus on synthetic noise and real-world noise, LLM-generated label noise receives less attention. In this paper, we propose SiDyP: Simplex Label Diffusion with Dynamic Prior to calibrate the classifier's prediction, thus enhancing its robustness towards LLM-generated noisy labels. SiDyP retrieves potential true label candidates by neighborhood label distribution in text embedding space and iteratively refines noisy candidates using a simplex diffusion model. Our framework can increase the performance of the BERT classifier fine-tuned on both zero-shot and few-shot LLM-generated noisy label datasets by an average of 7.21% and 7.30% respectively. We demonstrate the effectiveness of SiDyP by conducting extensive benchmarking for different LLMs over a variety of NLP tasks. Our code is available on Github.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2505.19675",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Can Large Language Models Replace Human Subjects? A Large-Scale Replication of Scenario-Based Experiments in Psychology and Management",
    "description": "arXiv:2409.00128v3 Announce Type: replace-cross Abstract: Artificial Intelligence (AI) is increasingly being integrated into scientific research, particularly in the social sciences, where understanding human behavior is critical. Large Language Models (LLMs) have shown promise in replicating human-like responses in various psychological experiments. We conducted a large-scale study replicating 156 psychological experiments from top social science journals using three state-of-the-art LLMs (GPT-4, Claude 3.5 Sonnet, and DeepSeek v3). Our results reveal that while LLMs demonstrate high replication rates for main effects (73-81%) and moderate to strong success with interaction effects (46-63%), They consistently produce larger effect sizes than human studies, with Fisher Z values approximately 2-3 times higher than human studies. Notably, LLMs show significantly lower replication rates for studies involving socially sensitive topics such as race, gender and ethics. When original studies reported null findings, LLMs produced significant results at remarkably high rates (68-83%) - while this could reflect cleaner data with less noise, as evidenced by narrower confidence intervals, it also suggests potential risks of effect size overestimation. Our results demonstrate both the promise and challenges of LLMs in psychological research, offering efficient tools for pilot testing and rapid hypothesis validation while enriching rather than replacing traditional human subject studies, yet requiring more nuanced interpretation and human validation for complex social phenomena and culturally sensitive research questions.",
    "summary": "arXiv:2409.00128v3 Announce Type: replace-cross Abstract: Artificial Intelligence (AI) is increasingly being integrated into scientific research, particularly in the social sciences, where understanding human behavior is critical. Large Language Models (LLMs) have shown promise in replicating human-like responses in various psychological experiments. We conducted a large-scale study replicating 156 psychological experiments from top social science journals using three state-of-the-art LLMs (GPT-4, Claude 3.5 Sonnet, and DeepSeek v3). Our results reveal that while LLMs demonstrate high replication rates for main effects (73-81%) and moderate to strong success with interaction effects (46-63%), They consistently produce larger effect sizes than human studies, with Fisher Z values approximately 2-3 times higher than human studies. Notably, LLMs show significantly lower replication rates for studies involving socially sensitive topics such as race, gender and ethics. When original studies reported null findings, LLMs produced significant results at remarkably high rates (68-83%) - while this could reflect cleaner data with less noise, as evidenced by narrower confidence intervals, it also suggests potential risks of effect size overestimation. Our results demonstrate both the promise and challenges of LLMs in psychological research, offering efficient tools for pilot testing and rapid hypothesis validation while enriching rather than replacing traditional human subject studies, yet requiring more nuanced interpretation and human validation for complex social phenomena and culturally sensitive research questions.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2409.00128",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Can structural correspondences ground real world representational content in Large Language Models?",
    "description": "arXiv:2506.16370v1 Announce Type: cross Abstract: Large Language Models (LLMs) such as GPT-4 produce compelling responses to a wide range of prompts. But their representational capacities are uncertain. Many LLMs have no direct contact with extra-linguistic reality: their inputs, outputs and training data consist solely of text, raising the questions (1) can LLMs represent anything and (2) if so, what? In this paper, I explore what it would take to answer these questions according to a structural-correspondence based account of representation, and make an initial survey of this evidence. I argue that the mere existence of structural correspondences between LLMs and worldly entities is insufficient to ground representation of those entities. However, if these structural correspondences play an appropriate role - they are exploited in a way that explains successful task performance - then they could ground real world contents. This requires overcoming a challenge: the text-boundedness of LLMs appears, on the face of it, to prevent them engaging in the right sorts of tasks.",
    "summary": "arXiv:2506.16370v1 Announce Type: cross Abstract: Large Language Models (LLMs) such as GPT-4 produce compelling responses to a wide range of prompts. But their representational capacities are uncertain. Many LLMs have no direct contact with extra-linguistic reality: their inputs, outputs and training data consist solely of text, raising the questions (1) can LLMs represent anything and (2) if so, what? In this paper, I explore what it would take to answer these questions according to a structural-correspondence based account of representation, and make an initial survey of this evidence. I argue that the mere existence of structural correspondences between LLMs and worldly entities is insufficient to ground representation of those entities. However, if these structural correspondences play an appropriate role - they are exploited in a way that explains successful task performance - then they could ground real world contents. This requires overcoming a challenge: the text-boundedness of LLMs appears, on the face of it, to prevent them engaging in the right sorts of tasks.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16370",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Can We Detect Failures Without Failure Data? Uncertainty-Aware Runtime Failure Detection for Imitation Learning Policies",
    "description": "arXiv:2503.08558v3 Announce Type: replace-cross Abstract: Recent years have witnessed impressive robotic manipulation systems driven by advances in imitation learning and generative modeling, such as diffusion- and flow-based approaches. As robot policy performance increases, so does the complexity and time horizon of achievable tasks, inducing unexpected and diverse failure modes that are difficult to predict a priori. To enable trustworthy policy deployment in safety-critical human environments, reliable runtime failure detection becomes important during policy inference. However, most existing failure detection approaches rely on prior knowledge of failure modes and require failure data during training, which imposes a significant challenge in practicality and scalability. In response to these limitations, we present FAIL-Detect, a modular two-stage approach for failure detection in imitation learning-based robotic manipulation. To accurately identify failures from successful training data alone, we frame the problem as sequential out-of-distribution (OOD) detection. We first distill policy inputs and outputs into scalar signals that correlate with policy failures and capture epistemic uncertainty. FAIL-Detect then employs conformal prediction (CP) as a versatile framework for uncertainty quantification with statistical guarantees. Empirically, we thoroughly investigate both learned and post-hoc scalar signal candidates on diverse robotic manipulation tasks. Our experiments show learned signals to be mostly consistently effective, particularly when using our novel flow-based density estimator. Furthermore, our method detects failures more accurately and faster than state-of-the-art (SOTA) failure detection baselines. These results highlight the potential of FAIL-Detect to enhance the safety and reliability of imitation learning-based robotic systems as they progress toward real-world deployment.",
    "summary": "arXiv:2503.08558v3 Announce Type: replace-cross Abstract: Recent years have witnessed impressive robotic manipulation systems driven by advances in imitation learning and generative modeling, such as diffusion- and flow-based approaches. As robot policy performance increases, so does the complexity and time horizon of achievable tasks, inducing unexpected and diverse failure modes that are difficult to predict a priori. To enable trustworthy policy deployment in safety-critical human environments, reliable runtime failure detection becomes important during policy inference. However, most existing failure detection approaches rely on prior knowledge of failure modes and require failure data during training, which imposes a significant challenge in practicality and scalability. In response to these limitations, we present FAIL-Detect, a modular two-stage approach for failure detection in imitation learning-based robotic manipulation. To accurately identify failures from successful training data alone, we frame the problem as sequential out-of-distribution (OOD) detection. We first distill policy inputs and outputs into scalar signals that correlate with policy failures and capture epistemic uncertainty. FAIL-Detect then employs conformal prediction (CP) as a versatile framework for uncertainty quantification with statistical guarantees. Empirically, we thoroughly investigate both learned and post-hoc scalar signal candidates on diverse robotic manipulation tasks. Our experiments show learned signals to be mostly consistently effective, particularly when using our novel flow-based density estimator. Furthermore, our method detects failures more accurately and faster than state-of-the-art (SOTA) failure detection baselines. These results highlight the potential of FAIL-Detect to enhance the safety and reliability of imitation learning-based robotic systems as they progress toward real-world deployment.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2503.08558",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "CapsDT: Diffusion-Transformer for Capsule Robot Manipulation",
    "description": "arXiv:2506.16263v1 Announce Type: cross Abstract: Vision-Language-Action (VLA) models have emerged as a prominent research area, showcasing significant potential across a variety of applications. However, their performance in endoscopy robotics, particularly endoscopy capsule robots that perform actions within the digestive system, remains unexplored. The integration of VLA models into endoscopy robots allows more intuitive and efficient interactions between human operators and medical devices, improving both diagnostic accuracy and treatment outcomes. In this work, we design CapsDT, a Diffusion Transformer model for capsule robot manipulation in the stomach. By processing interleaved visual inputs, and textual instructions, CapsDT can infer corresponding robotic control signals to facilitate endoscopy tasks. In addition, we developed a capsule endoscopy robot system, a capsule robot controlled by a robotic arm-held magnet, addressing different levels of four endoscopy tasks and creating corresponding capsule robot datasets within the stomach simulator. Comprehensive evaluations on various robotic tasks indicate that CapsDT can serve as a robust vision-language generalist, achieving state-of-the-art performance in various levels of endoscopy tasks while achieving a 26.25% success rate in real-world simulation manipulation.",
    "summary": "arXiv:2506.16263v1 Announce Type: cross Abstract: Vision-Language-Action (VLA) models have emerged as a prominent research area, showcasing significant potential across a variety of applications. However, their performance in endoscopy robotics, particularly endoscopy capsule robots that perform actions within the digestive system, remains unexplored. The integration of VLA models into endoscopy robots allows more intuitive and efficient interactions between human operators and medical devices, improving both diagnostic accuracy and treatment outcomes. In this work, we design CapsDT, a Diffusion Transformer model for capsule robot manipulation in the stomach. By processing interleaved visual inputs, and textual instructions, CapsDT can infer corresponding robotic control signals to facilitate endoscopy tasks. In addition, we developed a capsule endoscopy robot system, a capsule robot controlled by a robotic arm-held magnet, addressing different levels of four endoscopy tasks and creating corresponding capsule robot datasets within the stomach simulator. Comprehensive evaluations on various robotic tasks indicate that CapsDT can serve as a robust vision-language generalist, achieving state-of-the-art performance in various levels of endoscopy tasks while achieving a 26.25% success rate in real-world simulation manipulation.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16263",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Capturing Polysemanticity with PRISM: A Multi-Concept Feature Description Framework",
    "description": "arXiv:2506.15538v2 Announce Type: replace-cross Abstract: Automated interpretability research aims to identify concepts encoded in neural network features to enhance human understanding of model behavior. Current feature description methods face two critical challenges: limited robustness and the flawed assumption that each neuron encodes only a single concept (monosemanticity), despite growing evidence that neurons are often polysemantic. This assumption restricts the expressiveness of feature descriptions and limits their ability to capture the full range of behaviors encoded in model internals. To address this, we introduce Polysemantic FeatuRe Identification and Scoring Method (PRISM), a novel framework that captures the inherent complexity of neural network features. Unlike prior approaches that assign a single description per feature, PRISM provides more nuanced descriptions for both polysemantic and monosemantic features. We apply PRISM to language models and, through extensive benchmarking against existing methods, demonstrate that our approach produces more accurate and faithful feature descriptions, improving both overall description quality (via a description score) and the ability to capture distinct concepts when polysemanticity is present (via a polysemanticity score).",
    "summary": "arXiv:2506.15538v2 Announce Type: replace-cross Abstract: Automated interpretability research aims to identify concepts encoded in neural network features to enhance human understanding of model behavior. Current feature description methods face two critical challenges: limited robustness and the flawed assumption that each neuron encodes only a single concept (monosemanticity), despite growing evidence that neurons are often polysemantic. This assumption restricts the expressiveness of feature descriptions and limits their ability to capture the full range of behaviors encoded in model internals. To address this, we introduce Polysemantic FeatuRe Identification and Scoring Method (PRISM), a novel framework that captures the inherent complexity of neural network features. Unlike prior approaches that assign a single description per feature, PRISM provides more nuanced descriptions for both polysemantic and monosemantic features. We apply PRISM to language models and, through extensive benchmarking against existing methods, demonstrate that our approach produces more accurate and faithful feature descriptions, improving both overall description quality (via a description score) and the ability to capture distinct concepts when polysemanticity is present (via a polysemanticity score).",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.15538",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "cAST: Enhancing Code Retrieval-Augmented Generation with Structural Chunking via Abstract Syntax Tree",
    "description": "arXiv:2506.15655v1 Announce Type: cross Abstract: Retrieval-Augmented Generation (RAG) has become essential for large-scale code generation, grounding predictions in external code corpora to improve actuality. However, a critical yet underexplored aspect of RAG pipelines is chunking -- the process of dividing documents into retrievable units. Existing line-based chunking heuristics often break semantic structures, splitting functions or merging unrelated code, which can degrade generation quality. We propose chunking via Abstract Syntax Trees (ourwork), a structure-aware method that recursively breaks large AST nodes into smaller chunks and merges sibling nodes while respecting size limits. This approach generates self-contained, semantically coherent units across programming languages and tasks, improving performance on diverse code generation tasks, e.g., boosting Recall@5 by 4.3 points on RepoEval retrieval and Pass@1 by 2.67 points on SWE-bench generation. Our work highlights the importance of structure-aware chunking for scaling retrieval-enhanced code intelligence.",
    "summary": "arXiv:2506.15655v1 Announce Type: cross Abstract: Retrieval-Augmented Generation (RAG) has become essential for large-scale code generation, grounding predictions in external code corpora to improve actuality. However, a critical yet underexplored aspect of RAG pipelines is chunking -- the process of dividing documents into retrievable units. Existing line-based chunking heuristics often break semantic structures, splitting functions or merging unrelated code, which can degrade generation quality. We propose chunking via Abstract Syntax Trees (ourwork), a structure-aware method that recursively breaks large AST nodes into smaller chunks and merges sibling nodes while respecting size limits. This approach generates self-contained, semantically coherent units across programming languages and tasks, improving performance on diverse code generation tasks, e.g., boosting Recall@5 by 4.3 points on RepoEval retrieval and Pass@1 by 2.67 points on SWE-bench generation. Our work highlights the importance of structure-aware chunking for scaling retrieval-enhanced code intelligence.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.15655",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Category-based Galaxy Image Generation via Diffusion Models",
    "description": "arXiv:2506.16255v1 Announce Type: cross Abstract: Conventional galaxy generation methods rely on semi-analytical models and hydrodynamic simulations, which are highly dependent on physical assumptions and parameter tuning. In contrast, data-driven generative models do not have explicit physical parameters pre-determined, and instead learn them efficiently from observational data, making them alternative solutions to galaxy generation. Among these, diffusion models outperform Variational Autoencoders (VAEs) and Generative Adversarial Networks (GANs) in quality and diversity. Leveraging physical prior knowledge to these models can further enhance their capabilities. In this work, we present GalCatDiff, the first framework in astronomy to leverage both galaxy image features and astrophysical properties in the network design of diffusion models. GalCatDiff incorporates an enhanced U-Net and a novel block entitled Astro-RAB (Residual Attention Block), which dynamically combines attention mechanisms with convolution operations to ensure global consistency and local feature fidelity. Moreover, GalCatDiff uses category embeddings for class-specific galaxy generation, avoiding the high computational costs of training separate models for each category. Our experimental results demonstrate that GalCatDiff significantly outperforms existing methods in terms of the consistency of sample color and size distributions, and the generated galaxies are both visually realistic and physically consistent. This framework will enhance the reliability of galaxy simulations and can potentially serve as a data augmentor to support future galaxy classification algorithm development.",
    "summary": "arXiv:2506.16255v1 Announce Type: cross Abstract: Conventional galaxy generation methods rely on semi-analytical models and hydrodynamic simulations, which are highly dependent on physical assumptions and parameter tuning. In contrast, data-driven generative models do not have explicit physical parameters pre-determined, and instead learn them efficiently from observational data, making them alternative solutions to galaxy generation. Among these, diffusion models outperform Variational Autoencoders (VAEs) and Generative Adversarial Networks (GANs) in quality and diversity. Leveraging physical prior knowledge to these models can further enhance their capabilities. In this work, we present GalCatDiff, the first framework in astronomy to leverage both galaxy image features and astrophysical properties in the network design of diffusion models. GalCatDiff incorporates an enhanced U-Net and a novel block entitled Astro-RAB (Residual Attention Block), which dynamically combines attention mechanisms with convolution operations to ensure global consistency and local feature fidelity. Moreover, GalCatDiff uses category embeddings for class-specific galaxy generation, avoiding the high computational costs of training separate models for each category. Our experimental results demonstrate that GalCatDiff significantly outperforms existing methods in terms of the consistency of sample color and size distributions, and the generated galaxies are both visually realistic and physically consistent. This framework will enhance the reliability of galaxy simulations and can potentially serve as a data augmentor to support future galaxy classification algorithm development.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16255",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "CDS: Knowledge Component-Driven Data Synthesis Guided by Cognitive Diagnosis Theory",
    "description": "arXiv:2501.07674v3 Announce Type: replace Abstract: Large Language Models (LLMs) have achieved significant advancements, but the increasing complexity of tasks and higher performance demands highlight the need for continuous improvement. Some approaches utilize synthetic data generated by advanced LLMs based on evaluation results to train models. However, conventional evaluation methods fail to provide detailed, fine-grained profiles of LLMs, limiting their guidance for data synthesis. In this paper, we introduce the Cognitive Diagnostic Synthesis (CDS) method, which incorporates a diagnostic process inspired by Cognitive Diagnosis Theory (CDT) to refine evaluation results and characterize model profiles at the knowledge component level. Based on these diagnostics, we propose two diagnosis-synthesis strategies for weakness-targeted data synthesis. Additionally, we present an enhanced data augmentation and selection pipeline to improve the quality and diversity of synthesized data. Our experiments with several open-source models show significant improvements across multiple benchmarks, achieving up to 6.00% improvement in code generation, 13.10% in mathematical reasoning, and 5.43% in academic exams. Code and data are available on GitHub.",
    "summary": "arXiv:2501.07674v3 Announce Type: replace Abstract: Large Language Models (LLMs) have achieved significant advancements, but the increasing complexity of tasks and higher performance demands highlight the need for continuous improvement. Some approaches utilize synthetic data generated by advanced LLMs based on evaluation results to train models. However, conventional evaluation methods fail to provide detailed, fine-grained profiles of LLMs, limiting their guidance for data synthesis. In this paper, we introduce the Cognitive Diagnostic Synthesis (CDS) method, which incorporates a diagnostic process inspired by Cognitive Diagnosis Theory (CDT) to refine evaluation results and characterize model profiles at the knowledge component level. Based on these diagnostics, we propose two diagnosis-synthesis strategies for weakness-targeted data synthesis. Additionally, we present an enhanced data augmentation and selection pipeline to improve the quality and diversity of synthesized data. Our experiments with several open-source models show significant improvements across multiple benchmarks, achieving up to 6.00% improvement in code generation, 13.10% in mathematical reasoning, and 5.43% in academic exams. Code and data are available on GitHub.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2501.07674",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Cellular Traffic Prediction via Deep State Space Models with Attention Mechanism",
    "description": "arXiv:2506.15688v1 Announce Type: cross Abstract: Cellular traffic prediction is of great importance for operators to manage network resources and make decisions. Traffic is highly dynamic and influenced by many exogenous factors, which would lead to the degradation of traffic prediction accuracy. This paper proposes an end-to-end framework with two variants to explicitly characterize the spatiotemporal patterns of cellular traffic among neighboring cells. It uses convolutional neural networks with an attention mechanism to capture the spatial dynamics and Kalman filter for temporal modelling. Besides, we can fully exploit the auxiliary information such as social activities to improve prediction performance. We conduct extensive experiments on three real-world datasets. The results show that our proposed models outperform the state-of-the-art machine learning techniques in terms of prediction accuracy.",
    "summary": "arXiv:2506.15688v1 Announce Type: cross Abstract: Cellular traffic prediction is of great importance for operators to manage network resources and make decisions. Traffic is highly dynamic and influenced by many exogenous factors, which would lead to the degradation of traffic prediction accuracy. This paper proposes an end-to-end framework with two variants to explicitly characterize the spatiotemporal patterns of cellular traffic among neighboring cells. It uses convolutional neural networks with an attention mechanism to capture the spatial dynamics and Kalman filter for temporal modelling. Besides, we can fully exploit the auxiliary information such as social activities to improve prediction performance. We conduct extensive experiments on three real-world datasets. The results show that our proposed models outperform the state-of-the-art machine learning techniques in terms of prediction accuracy.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.15688",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "CF-Seg: Counterfactuals meet Segmentation",
    "description": "arXiv:2506.16213v1 Announce Type: cross Abstract: Segmenting anatomical structures in medical images plays an important role in the quantitative assessment of various diseases. However, accurate segmentation becomes significantly more challenging in the presence of disease. Disease patterns can alter the appearance of surrounding healthy tissues, introduce ambiguous boundaries, or even obscure critical anatomical structures. As such, segmentation models trained on real-world datasets may struggle to provide good anatomical segmentation, leading to potential misdiagnosis. In this paper, we generate counterfactual (CF) images to simulate how the same anatomy would appear in the absence of disease without altering the underlying structure. We then use these CF images to segment structures of interest, without requiring any changes to the underlying segmentation model. Our experiments on two real-world clinical chest X-ray datasets show that the use of counterfactual images improves anatomical segmentation, thereby aiding downstream clinical decision-making.",
    "summary": "arXiv:2506.16213v1 Announce Type: cross Abstract: Segmenting anatomical structures in medical images plays an important role in the quantitative assessment of various diseases. However, accurate segmentation becomes significantly more challenging in the presence of disease. Disease patterns can alter the appearance of surrounding healthy tissues, introduce ambiguous boundaries, or even obscure critical anatomical structures. As such, segmentation models trained on real-world datasets may struggle to provide good anatomical segmentation, leading to potential misdiagnosis. In this paper, we generate counterfactual (CF) images to simulate how the same anatomy would appear in the absence of disease without altering the underlying structure. We then use these CF images to segment structures of interest, without requiring any changes to the underlying segmentation model. Our experiments on two real-world clinical chest X-ray datasets show that the use of counterfactual images improves anatomical segmentation, thereby aiding downstream clinical decision-making.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16213",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Chain-of-Trust: A Progressive Trust Evaluation Framework Enabled by Generative AI",
    "description": "arXiv:2506.17130v1 Announce Type: new Abstract: In collaborative systems with complex tasks relying on distributed resources, trust evaluation of potential collaborators has emerged as an effective mechanism for task completion. However, due to the network dynamics and varying information gathering latencies, it is extremely challenging to observe and collect all trust attributes of a collaborating device concurrently for a comprehensive trust assessment. In this paper, a novel progressive trust evaluation framework, namely chain-of-trust, is proposed to make better use of misaligned device attribute data. This framework, designed for effective task completion, divides the trust evaluation process into multiple chained stages based on task decomposition. At each stage, based on the task completion process, the framework only gathers the latest device attribute data relevant to that stage, leading to reduced trust evaluation complexity and overhead. By leveraging advanced in-context learning, few-shot learning, and reasoning capabilities, generative AI is then employed to analyze and interpret the collected data to produce correct evaluation results quickly. Only devices deemed trustworthy at this stage proceed to the next round of trust evaluation. The framework ultimately determines devices that remain trustworthy across all stages. Experimental results demonstrate that the proposed framework achieves high accuracy in trust evaluation.",
    "summary": "arXiv:2506.17130v1 Announce Type: new Abstract: In collaborative systems with complex tasks relying on distributed resources, trust evaluation of potential collaborators has emerged as an effective mechanism for task completion. However, due to the network dynamics and varying information gathering latencies, it is extremely challenging to observe and collect all trust attributes of a collaborating device concurrently for a comprehensive trust assessment. In this paper, a novel progressive trust evaluation framework, namely chain-of-trust, is proposed to make better use of misaligned device attribute data. This framework, designed for effective task completion, divides the trust evaluation process into multiple chained stages based on task decomposition. At each stage, based on the task completion process, the framework only gathers the latest device attribute data relevant to that stage, leading to reduced trust evaluation complexity and overhead. By leveraging advanced in-context learning, few-shot learning, and reasoning capabilities, generative AI is then employed to analyze and interpret the collected data to produce correct evaluation results quickly. Only devices deemed trustworthy at this stage proceed to the next round of trust evaluation. The framework ultimately determines devices that remain trustworthy across all stages. Experimental results demonstrate that the proposed framework achieves high accuracy in trust evaluation.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.17130",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "ChatDBG: Augmenting Debugging with Large Language Models",
    "description": "arXiv:2403.16354v5 Announce Type: replace-cross Abstract: Debugging is a critical but challenging task for programmers. This paper proposes ChatDBG, an AI-powered debugging assistant. ChatDBG integrates large language models (LLMs) to significantly enhance the capabilities and user-friendliness of conventional debuggers. ChatDBG lets programmers engage in a collaborative dialogue with the debugger, allowing them to pose complex questions about program state, perform root cause analysis for crashes or assertion failures, and explore open-ended queries like 'why is x null?'. To handle these queries, ChatDBG grants the LLM autonomy to 'take the wheel': it can act as an independent agent capable of querying and controlling the debugger to navigate through stacks and inspect program state. It then reports its findings and yields back control to the programmer. By leveraging the real-world knowledge embedded in LLMs, ChatDBG can diagnose issues identifiable only through the use of domain-specific reasoning. Our ChatDBG prototype integrates with standard debuggers including LLDB and GDB for native code and Pdb for Python. Our evaluation across a diverse set of code, including C/C++ code with known bugs and a suite of Python code including standalone scripts and Jupyter notebooks, demonstrates that ChatDBG can successfully analyze root causes, explain bugs, and generate accurate fixes for a wide range of real-world errors. For the Python programs, a single query led to an actionable bug fix 67% of the time; one additional follow-up query increased the success rate to 85%. ChatDBG has seen rapid uptake; it has already been downloaded more than 75,000 times.",
    "summary": "arXiv:2403.16354v5 Announce Type: replace-cross Abstract: Debugging is a critical but challenging task for programmers. This paper proposes ChatDBG, an AI-powered debugging assistant. ChatDBG integrates large language models (LLMs) to significantly enhance the capabilities and user-friendliness of conventional debuggers. ChatDBG lets programmers engage in a collaborative dialogue with the debugger, allowing them to pose complex questions about program state, perform root cause analysis for crashes or assertion failures, and explore open-ended queries like 'why is x null?'. To handle these queries, ChatDBG grants the LLM autonomy to 'take the wheel': it can act as an independent agent capable of querying and controlling the debugger to navigate through stacks and inspect program state. It then reports its findings and yields back control to the programmer. By leveraging the real-world knowledge embedded in LLMs, ChatDBG can diagnose issues identifiable only through the use of domain-specific reasoning. Our ChatDBG prototype integrates with standard debuggers including LLDB and GDB for native code and Pdb for Python. Our evaluation across a diverse set of code, including C/C++ code with known bugs and a suite of Python code including standalone scripts and Jupyter notebooks, demonstrates that ChatDBG can successfully analyze root causes, explain bugs, and generate accurate fixes for a wide range of real-world errors. For the Python programs, a single query led to an actionable bug fix 67% of the time; one additional follow-up query increased the success rate to 85%. ChatDBG has seen rapid uptake; it has already been downloaded more than 75,000 times.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2403.16354",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Claude 4 モデル登場！新機能や他社との比較・料金など詳しく解説",
    "description": "<p>Anthropic 社は2025年5月22日、Claude の最新版「Claude 4」の提供を開始しました。プログラミングや推論をはじめ、AIエージェント構築といったシーンで最高水準の能力を実現しています。また、コーデ [&#8230;]</p> <p>The post <a href='https://aismiley.co.jp/ai_news/claude-4-model-new-features/'>Claude 4 モデル登場！新機能や他社との比較・料金など詳しく解説</a> first appeared on <a href='https://aismiley.co.jp'>AIポータルメディアAIsmiley</a>.</p>",
    "summary": "<p>Anthropic 社は2025年5月22日、Claude の最新版「Claude 4」の提供を開始しました。プログラミングや推論をはじめ、AIエージェント構築といったシーンで最高水準の能力を実現しています。また、コーデ [&#8230;]</p> <p>The post <a href='https://aismiley.co.jp/ai_news/claude-4-model-new-features/'>Claude 4 モデル登場！新機能や他社との比較・料金など詳しく解説</a> first appeared on <a href='https://aismiley.co.jp'>AIポータルメディアAIsmiley</a>.</p>",
    "pubDate": "Mon, 23 Jun 2025 03:33:57 +0000",
    "source": "AI Smily",
    "url": "https://aismiley.co.jp/ai_news/claude-4-model-new-features/",
    "thumbnail": "https://aismiley.co.jp/wp-content/uploads/2025/06/claude4.png"
  },
  {
    "title": "CLIP-MG: Guiding Semantic Attention with Skeletal Pose Features and RGB Data for Micro-Gesture Recognition on the iMiGUE Dataset",
    "description": "arXiv:2506.16385v1 Announce Type: cross Abstract: Micro-gesture recognition is a challenging task in affective computing due to the subtle, involuntary nature of the gestures and their low movement amplitude. In this paper, we introduce a Pose-Guided Semantics-Aware CLIP-based architecture, or CLIP for Micro-Gesture recognition (CLIP-MG), a modified CLIP model tailored for micro-gesture classification on the iMiGUE dataset. CLIP-MG integrates human pose (skeleton) information into the CLIP-based recognition pipeline through pose-guided semantic query generation and a gated multi-modal fusion mechanism. The proposed model achieves a Top-1 accuracy of 61.82%. These results demonstrate both the potential of our approach and the remaining difficulty in fully adapting vision-language models like CLIP for micro-gesture recognition.",
    "summary": "arXiv:2506.16385v1 Announce Type: cross Abstract: Micro-gesture recognition is a challenging task in affective computing due to the subtle, involuntary nature of the gestures and their low movement amplitude. In this paper, we introduce a Pose-Guided Semantics-Aware CLIP-based architecture, or CLIP for Micro-Gesture recognition (CLIP-MG), a modified CLIP model tailored for micro-gesture classification on the iMiGUE dataset. CLIP-MG integrates human pose (skeleton) information into the CLIP-based recognition pipeline through pose-guided semantic query generation and a gated multi-modal fusion mechanism. The proposed model achieves a Top-1 accuracy of 61.82%. These results demonstrate both the potential of our approach and the remaining difficulty in fully adapting vision-language models like CLIP for micro-gesture recognition.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16385",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Compiler-R1: Towards Agentic Compiler Auto-tuning with Reinforcement Learning",
    "description": "arXiv:2506.15701v1 Announce Type: cross Abstract: Compiler auto-tuning optimizes pass sequences to improve performance metrics such as Intermediate Representation (IR) instruction count. Although recent advances leveraging Large Language Models (LLMs) have shown promise in automating compiler tuning, two significant challenges still remain: the absence of high-quality reasoning datasets for agents training, and limited effective interactions with the compilation environment. In this work, we introduce Compiler-R1, the first reinforcement learning (RL)-driven framework specifically augmenting LLM capabilities for compiler auto-tuning. Compiler-R1 features a curated, high-quality reasoning dataset and a novel two-stage end-to-end RL training pipeline, enabling efficient environment exploration and learning through an outcome-based reward. Extensive experiments across seven datasets demonstrate Compiler-R1 achieving an average 8.46% IR instruction count reduction compared to opt -Oz, showcasing the strong potential of RL-trained LLMs for compiler optimization. Our code and datasets are publicly available at https://github.com/Panhaolin2001/Compiler-R1.",
    "summary": "arXiv:2506.15701v1 Announce Type: cross Abstract: Compiler auto-tuning optimizes pass sequences to improve performance metrics such as Intermediate Representation (IR) instruction count. Although recent advances leveraging Large Language Models (LLMs) have shown promise in automating compiler tuning, two significant challenges still remain: the absence of high-quality reasoning datasets for agents training, and limited effective interactions with the compilation environment. In this work, we introduce Compiler-R1, the first reinforcement learning (RL)-driven framework specifically augmenting LLM capabilities for compiler auto-tuning. Compiler-R1 features a curated, high-quality reasoning dataset and a novel two-stage end-to-end RL training pipeline, enabling efficient environment exploration and learning through an outcome-based reward. Extensive experiments across seven datasets demonstrate Compiler-R1 achieving an average 8.46% IR instruction count reduction compared to opt -Oz, showcasing the strong potential of RL-trained LLMs for compiler optimization. Our code and datasets are publicly available at https://github.com/Panhaolin2001/Compiler-R1.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.15701",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Conformal Inference under High-Dimensional Covariate Shifts via Likelihood-Ratio Regularization",
    "description": "arXiv:2502.13030v4 Announce Type: replace-cross Abstract: We consider the problem of conformal prediction under covariate shift. Given labeled data from a source domain and unlabeled data from a covariate shifted target domain, we seek to construct prediction sets with valid marginal coverage in the target domain. Most existing methods require estimating the unknown likelihood ratio function, which can be prohibitive for high-dimensional data such as images. To address this challenge, we introduce the likelihood ratio regularized quantile regression (LR-QR) algorithm, which combines the pinball loss with a novel choice of regularization in order to construct a threshold function without directly estimating the unknown likelihood ratio. We show that the LR-QR method has coverage at the desired level in the target domain, up to a small error term that we can control. Our proofs draw on a novel analysis of coverage via stability bounds from learning theory. Our experiments demonstrate that the LR-QR algorithm outperforms existing methods on high-dimensional prediction tasks, including a regression task for the Communities and Crime dataset, an image classification task from the WILDS repository, and an LLM question-answering task on the MMLU benchmark.",
    "summary": "arXiv:2502.13030v4 Announce Type: replace-cross Abstract: We consider the problem of conformal prediction under covariate shift. Given labeled data from a source domain and unlabeled data from a covariate shifted target domain, we seek to construct prediction sets with valid marginal coverage in the target domain. Most existing methods require estimating the unknown likelihood ratio function, which can be prohibitive for high-dimensional data such as images. To address this challenge, we introduce the likelihood ratio regularized quantile regression (LR-QR) algorithm, which combines the pinball loss with a novel choice of regularization in order to construct a threshold function without directly estimating the unknown likelihood ratio. We show that the LR-QR method has coverage at the desired level in the target domain, up to a small error term that we can control. Our proofs draw on a novel analysis of coverage via stability bounds from learning theory. Our experiments demonstrate that the LR-QR algorithm outperforms existing methods on high-dimensional prediction tasks, including a regression task for the Communities and Crime dataset, an image classification task from the WILDS repository, and an LLM question-answering task on the MMLU benchmark.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2502.13030",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Consistency Verification in Ontology-Based Process Models with Parameter Interdependencies",
    "description": "arXiv:2506.16087v1 Announce Type: new Abstract: The formalization of process knowledge using ontologies enables consistent modeling of parameter interdependencies in manufacturing. These interdependencies are typically represented as mathematical expressions that define relations between process parameters, supporting tasks such as calculation, validation, and simulation. To support cross-context application and knowledge reuse, such expressions are often defined in a generic form and applied across multiple process contexts. This highlights the necessity of a consistent and semantically coherent model to ensure the correctness of data retrieval and interpretation. Consequently, dedicated mechanisms are required to address key challenges such as selecting context-relevant data, ensuring unit compatibility between variables and data elements, and verifying the completeness of input data required for evaluating mathematical expressions. This paper presents a set of verification mechanisms for a previously developed ontology-based process model that integrates standardized process semantics, data element definitions, and formal mathematical constructs. The approach includes (i) SPARQL-based filtering to retrieve process-relevant data, (ii) a unit consistency check based on expected-unit annotations and semantic classification, and (iii) a data completeness check to validate the evaluability of interdependencies. The applicability of the approach is demonstrated with a use case from Resin Transfer Molding (RTM), supporting the development of machine-interpretable and verifiable engineering models.",
    "summary": "arXiv:2506.16087v1 Announce Type: new Abstract: The formalization of process knowledge using ontologies enables consistent modeling of parameter interdependencies in manufacturing. These interdependencies are typically represented as mathematical expressions that define relations between process parameters, supporting tasks such as calculation, validation, and simulation. To support cross-context application and knowledge reuse, such expressions are often defined in a generic form and applied across multiple process contexts. This highlights the necessity of a consistent and semantically coherent model to ensure the correctness of data retrieval and interpretation. Consequently, dedicated mechanisms are required to address key challenges such as selecting context-relevant data, ensuring unit compatibility between variables and data elements, and verifying the completeness of input data required for evaluating mathematical expressions. This paper presents a set of verification mechanisms for a previously developed ontology-based process model that integrates standardized process semantics, data element definitions, and formal mathematical constructs. The approach includes (i) SPARQL-based filtering to retrieve process-relevant data, (ii) a unit consistency check based on expected-unit annotations and semantic classification, and (iii) a data completeness check to validate the evaluability of interdependencies. The applicability of the approach is demonstrated with a use case from Resin Transfer Molding (RTM), supporting the development of machine-interpretable and verifiable engineering models.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16087",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Consistent Sampling and Simulation: Molecular Dynamics with Energy-Based Diffusion Models",
    "description": "arXiv:2506.17139v1 Announce Type: cross Abstract: Diffusion models have recently gained significant attention due to their effectiveness in various scientific domains, including biochemistry. When trained on equilibrium molecular distributions, diffusion models provide both: a generative procedure to sample equilibrium conformations and associated forces derived from the model's scores. However, using the forces for coarse-grained molecular dynamics simulations uncovers inconsistencies in the samples generated via classical diffusion inference and simulation, despite both originating from the same model. Particularly at the small diffusion timesteps required for simulations, diffusion models fail to satisfy the Fokker-Planck equation, which governs how the score should evolve over time. We interpret this deviation as an indication of the observed inconsistencies and propose an energy-based diffusion model with a Fokker-Planck-derived regularization term enforcing consistency. We demonstrate the effectiveness of our approach on toy systems, alanine dipeptide, and introduce a state-of-the-art transferable Boltzmann emulator for dipeptides that supports simulation and demonstrates enhanced consistency and efficient sampling.",
    "summary": "arXiv:2506.17139v1 Announce Type: cross Abstract: Diffusion models have recently gained significant attention due to their effectiveness in various scientific domains, including biochemistry. When trained on equilibrium molecular distributions, diffusion models provide both: a generative procedure to sample equilibrium conformations and associated forces derived from the model's scores. However, using the forces for coarse-grained molecular dynamics simulations uncovers inconsistencies in the samples generated via classical diffusion inference and simulation, despite both originating from the same model. Particularly at the small diffusion timesteps required for simulations, diffusion models fail to satisfy the Fokker-Planck equation, which governs how the score should evolve over time. We interpret this deviation as an indication of the observed inconsistencies and propose an energy-based diffusion model with a Fokker-Planck-derived regularization term enforcing consistency. We demonstrate the effectiveness of our approach on toy systems, alanine dipeptide, and introduce a state-of-the-art transferable Boltzmann emulator for dipeptides that supports simulation and demonstrates enhanced consistency and efficient sampling.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.17139",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Consumer-friendly EEG-based Emotion Recognition System: A Multi-scale Convolutional Neural Network Approach",
    "description": "arXiv:2506.16448v1 Announce Type: cross Abstract: EEG is a non-invasive, safe, and low-risk method to record electrophysiological signals inside the brain. Especially with recent technology developments like dry electrodes, consumer-grade EEG devices, and rapid advances in machine learning, EEG is commonly used as a resource for automatic emotion recognition. With the aim to develop a deep learning model that can perform EEG-based emotion recognition in a real-life context, we propose a novel approach to utilize multi-scale convolutional neural networks to accomplish such tasks. By implementing feature extraction kernels with many ratio coefficients as well as a new type of kernel that learns key information from four separate areas of the brain, our model consistently outperforms the state-of-the-art TSception model in predicting valence, arousal, and dominance scores across many performance evaluation metrics.",
    "summary": "arXiv:2506.16448v1 Announce Type: cross Abstract: EEG is a non-invasive, safe, and low-risk method to record electrophysiological signals inside the brain. Especially with recent technology developments like dry electrodes, consumer-grade EEG devices, and rapid advances in machine learning, EEG is commonly used as a resource for automatic emotion recognition. With the aim to develop a deep learning model that can perform EEG-based emotion recognition in a real-life context, we propose a novel approach to utilize multi-scale convolutional neural networks to accomplish such tasks. By implementing feature extraction kernels with many ratio coefficients as well as a new type of kernel that learns key information from four separate areas of the brain, our model consistently outperforms the state-of-the-art TSception model in predicting valence, arousal, and dominance scores across many performance evaluation metrics.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16448",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Context Matters! Relaxing Goals with LLMs for Feasible 3D Scene Planning",
    "description": "arXiv:2506.15828v1 Announce Type: cross Abstract: Classical planning in AI and Robotics addresses complex tasks by shifting from imperative to declarative approaches (e.g., PDDL). However, these methods often fail in real scenarios due to limited robot perception and the need to ground perceptions to planning predicates. This often results in heavily hard-coded behaviors that struggle to adapt, even with scenarios where goals can be achieved through relaxed planning. Meanwhile, Large Language Models (LLMs) lead to planning systems that leverage commonsense reasoning but often at the cost of generating unfeasible and/or unsafe plans. To address these limitations, we present an approach integrating classical planning with LLMs, leveraging their ability to extract commonsense knowledge and ground actions. We propose a hierarchical formulation that enables robots to make unfeasible tasks tractable by defining functionally equivalent goals through gradual relaxation. This mechanism supports partial achievement of the intended objective, suited to the agent's specific context. Our method demonstrates its ability to adapt and execute tasks effectively within environments modeled using 3D Scene Graphs through comprehensive qualitative and quantitative evaluations. We also show how this method succeeds in complex scenarios where other benchmark methods are more likely to fail. Code, dataset, and additional material are released to the community.",
    "summary": "arXiv:2506.15828v1 Announce Type: cross Abstract: Classical planning in AI and Robotics addresses complex tasks by shifting from imperative to declarative approaches (e.g., PDDL). However, these methods often fail in real scenarios due to limited robot perception and the need to ground perceptions to planning predicates. This often results in heavily hard-coded behaviors that struggle to adapt, even with scenarios where goals can be achieved through relaxed planning. Meanwhile, Large Language Models (LLMs) lead to planning systems that leverage commonsense reasoning but often at the cost of generating unfeasible and/or unsafe plans. To address these limitations, we present an approach integrating classical planning with LLMs, leveraging their ability to extract commonsense knowledge and ground actions. We propose a hierarchical formulation that enables robots to make unfeasible tasks tractable by defining functionally equivalent goals through gradual relaxation. This mechanism supports partial achievement of the intended objective, suited to the agent's specific context. Our method demonstrates its ability to adapt and execute tasks effectively within environments modeled using 3D Scene Graphs through comprehensive qualitative and quantitative evaluations. We also show how this method succeeds in complex scenarios where other benchmark methods are more likely to fail. Code, dataset, and additional material are released to the community.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.15828",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "ContextBench: Modifying Contexts for Targeted Latent Activation",
    "description": "arXiv:2506.15735v1 Announce Type: new Abstract: Identifying inputs that trigger specific behaviours or latent features in language models could have a wide range of safety use cases. We investigate a class of methods capable of generating targeted, linguistically fluent inputs that activate specific latent features or elicit model behaviours. We formalise this approach as context modification and present ContextBench -- a benchmark with tasks assessing core method capabilities and potential safety applications. Our evaluation framework measures both elicitation strength (activation of latent features or behaviours) and linguistic fluency, highlighting how current state-of-the-art methods struggle to balance these objectives. We enhance Evolutionary Prompt Optimisation (EPO) with LLM-assistance and diffusion model inpainting, and demonstrate that these variants achieve state-of-the-art performance in balancing elicitation effectiveness and fluency.",
    "summary": "arXiv:2506.15735v1 Announce Type: new Abstract: Identifying inputs that trigger specific behaviours or latent features in language models could have a wide range of safety use cases. We investigate a class of methods capable of generating targeted, linguistically fluent inputs that activate specific latent features or elicit model behaviours. We formalise this approach as context modification and present ContextBench -- a benchmark with tasks assessing core method capabilities and potential safety applications. Our evaluation framework measures both elicitation strength (activation of latent features or behaviours) and linguistic fluency, highlighting how current state-of-the-art methods struggle to balance these objectives. We enhance Evolutionary Prompt Optimisation (EPO) with LLM-assistance and diffusion model inpainting, and demonstrate that these variants achieve state-of-the-art performance in balancing elicitation effectiveness and fluency.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.15735",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Continual Learning with Columnar Spiking Neural Networks",
    "description": "arXiv:2506.17169v1 Announce Type: cross Abstract: This study investigates columnar-organized spiking neural networks (SNNs) for continual learning and catastrophic forgetting. Using CoLaNET (Columnar Layered Network), we show that microcolumns adapt most efficiently to new tasks when they lack shared structure with prior learning. We demonstrate how CoLaNET hyperparameters govern the trade-off between retaining old knowledge (stability) and acquiring new information (plasticity). Our optimal configuration learns ten sequential MNIST tasks effectively, maintaining 92% accuracy on each. It shows low forgetting, with only 4% performance degradation on the first task after training on nine subsequent tasks.",
    "summary": "arXiv:2506.17169v1 Announce Type: cross Abstract: This study investigates columnar-organized spiking neural networks (SNNs) for continual learning and catastrophic forgetting. Using CoLaNET (Columnar Layered Network), we show that microcolumns adapt most efficiently to new tasks when they lack shared structure with prior learning. We demonstrate how CoLaNET hyperparameters govern the trade-off between retaining old knowledge (stability) and acquiring new information (plasticity). Our optimal configuration learns ten sequential MNIST tasks effectively, maintaining 92% accuracy on each. It shows low forgetting, with only 4% performance degradation on the first task after training on nine subsequent tasks.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.17169",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Contraction Actor-Critic: Contraction Metric-Guided Reinforcement Learning for Robust Path Tracking",
    "description": "arXiv:2506.15700v1 Announce Type: cross Abstract: Control contraction metrics (CCMs) provide a framework to co-synthesize a controller and a corresponding contraction metric -- a positive-definite Riemannian metric under which a closed-loop system is guaranteed to be incrementally exponentially stable. However, the synthesized controller only ensures that all the trajectories of the system converge to one single trajectory and, as such, does not impose any notion of optimality across an entire trajectory. Furthermore, constructing CCMs requires a known dynamics model and non-trivial effort in solving an infinite-dimensional convex feasibility problem, which limits its scalability to complex systems featuring high dimensionality with uncertainty. To address these issues, we propose to integrate CCMs into reinforcement learning (RL), where CCMs provide dynamics-informed feedback for learning control policies that minimize cumulative tracking error under unknown dynamics. We show that our algorithm, called contraction actor-critic (CAC), formally enhances the capability of CCMs to provide a set of contracting policies with the long-term optimality of RL in a fully automated setting. Given a pre-trained dynamics model, CAC simultaneously learns a contraction metric generator (CMG) -- which generates a contraction metric -- and uses an actor-critic algorithm to learn an optimal tracking policy guided by that metric. We demonstrate the effectiveness of our algorithm relative to established baselines through extensive empirical studies, including simulated and real-world robot experiments, and provide a theoretical rationale for incorporating contraction theory into RL.",
    "summary": "arXiv:2506.15700v1 Announce Type: cross Abstract: Control contraction metrics (CCMs) provide a framework to co-synthesize a controller and a corresponding contraction metric -- a positive-definite Riemannian metric under which a closed-loop system is guaranteed to be incrementally exponentially stable. However, the synthesized controller only ensures that all the trajectories of the system converge to one single trajectory and, as such, does not impose any notion of optimality across an entire trajectory. Furthermore, constructing CCMs requires a known dynamics model and non-trivial effort in solving an infinite-dimensional convex feasibility problem, which limits its scalability to complex systems featuring high dimensionality with uncertainty. To address these issues, we propose to integrate CCMs into reinforcement learning (RL), where CCMs provide dynamics-informed feedback for learning control policies that minimize cumulative tracking error under unknown dynamics. We show that our algorithm, called contraction actor-critic (CAC), formally enhances the capability of CCMs to provide a set of contracting policies with the long-term optimality of RL in a fully automated setting. Given a pre-trained dynamics model, CAC simultaneously learns a contraction metric generator (CMG) -- which generates a contraction metric -- and uses an actor-critic algorithm to learn an optimal tracking policy guided by that metric. We demonstrate the effectiveness of our algorithm relative to established baselines through extensive empirical studies, including simulated and real-world robot experiments, and provide a theoretical rationale for incorporating contraction theory into RL.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.15700",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Convergent Linear Representations of Emergent Misalignment",
    "description": "arXiv:2506.11618v2 Announce Type: replace-cross Abstract: Fine-tuning large language models on narrow datasets can cause them to develop broadly misaligned behaviours: a phenomena known as emergent misalignment. However, the mechanisms underlying this misalignment, and why it generalizes beyond the training domain, are poorly understood, demonstrating critical gaps in our knowledge of model alignment. In this work, we train and study a minimal model organism which uses just 9 rank-1 adapters to emergently misalign Qwen2.5-14B-Instruct. Studying this, we find that different emergently misaligned models converge to similar representations of misalignment. We demonstrate this convergence by extracting a 'misalignment direction' from one fine-tuned model's activations, and using it to effectively ablate misaligned behaviour from fine-tunes using higher dimensional LoRAs and different datasets. Leveraging the scalar hidden state of rank-1 LoRAs, we further present a set of experiments for directly interpreting the fine-tuning adapters, showing that six contribute to general misalignment, while two specialise for misalignment in just the fine-tuning domain. Emergent misalignment is a particularly salient example of undesirable and unexpected model behaviour and by advancing our understanding of the mechanisms behind it, we hope to move towards being able to better understand and mitigate misalignment more generally.",
    "summary": "arXiv:2506.11618v2 Announce Type: replace-cross Abstract: Fine-tuning large language models on narrow datasets can cause them to develop broadly misaligned behaviours: a phenomena known as emergent misalignment. However, the mechanisms underlying this misalignment, and why it generalizes beyond the training domain, are poorly understood, demonstrating critical gaps in our knowledge of model alignment. In this work, we train and study a minimal model organism which uses just 9 rank-1 adapters to emergently misalign Qwen2.5-14B-Instruct. Studying this, we find that different emergently misaligned models converge to similar representations of misalignment. We demonstrate this convergence by extracting a 'misalignment direction' from one fine-tuned model's activations, and using it to effectively ablate misaligned behaviour from fine-tunes using higher dimensional LoRAs and different datasets. Leveraging the scalar hidden state of rank-1 LoRAs, we further present a set of experiments for directly interpreting the fine-tuning adapters, showing that six contribute to general misalignment, while two specialise for misalignment in just the fine-tuning domain. Emergent misalignment is a particularly salient example of undesirable and unexpected model behaviour and by advancing our understanding of the mechanisms behind it, we hope to move towards being able to better understand and mitigate misalignment more generally.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.11618",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Core Knowledge Deficits in Multi-Modal Language Models",
    "description": "arXiv:2410.10855v4 Announce Type: replace-cross Abstract: While Multi-modal Large Language Models (MLLMs) demonstrate impressive abilities over high-level perception and reasoning, their robustness in the wild remains limited, often falling short on tasks that are intuitive and effortless for humans. We examine the hypothesis that these deficiencies stem from the absence of core knowledge--rudimentary cognitive abilities innate to humans from early childhood. To explore the core knowledge representation in MLLMs, we introduce CoreCognition, a large-scale benchmark encompassing 12 core knowledge concepts grounded in developmental cognitive science. We evaluate 230 models with 11 different prompts, leading to a total of 2,530 data points for analysis. Our experiments uncover four key findings, collectively demonstrating core knowledge deficits in MLLMs: they consistently underperform and show reduced, or even absent, scalability on low-level abilities relative to high-level ones. Finally, we propose Concept Hacking, a novel controlled evaluation method that reveals MLLMs fail to progress toward genuine core knowledge understanding, but instead rely on shortcut learning as they scale.",
    "summary": "arXiv:2410.10855v4 Announce Type: replace-cross Abstract: While Multi-modal Large Language Models (MLLMs) demonstrate impressive abilities over high-level perception and reasoning, their robustness in the wild remains limited, often falling short on tasks that are intuitive and effortless for humans. We examine the hypothesis that these deficiencies stem from the absence of core knowledge--rudimentary cognitive abilities innate to humans from early childhood. To explore the core knowledge representation in MLLMs, we introduce CoreCognition, a large-scale benchmark encompassing 12 core knowledge concepts grounded in developmental cognitive science. We evaluate 230 models with 11 different prompts, leading to a total of 2,530 data points for analysis. Our experiments uncover four key findings, collectively demonstrating core knowledge deficits in MLLMs: they consistently underperform and show reduced, or even absent, scalability on low-level abilities relative to high-level ones. Finally, we propose Concept Hacking, a novel controlled evaluation method that reveals MLLMs fail to progress toward genuine core knowledge understanding, but instead rely on shortcut learning as they scale.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2410.10855",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Cost-effective Instruction Learning for Pathology Vision and Language Analysis",
    "description": "arXiv:2407.17734v2 Announce Type: replace Abstract: The advent of vision-language models fosters the interactive conversations between AI-enabled models and humans. Yet applying these models into clinics must deal with daunting challenges around large-scale training data, financial, and computational resources. Here we propose a cost-effective instruction learning framework for conversational pathology named as CLOVER. CLOVER only trains a lightweight module and uses instruction tuning while freezing the parameters of the large language model. Instead of using costly GPT-4, we propose well-designed prompts on GPT-3.5 for building generation-based instructions, emphasizing the utility of pathological knowledge derived from the Internet source. To augment the use of instructions, we construct a high-quality set of template-based instructions in the context of digital pathology. From two benchmark datasets, our findings reveal the strength of hybrid-form instructions in the visual question-answer in pathology. Extensive results show the cost-effectiveness of CLOVER in answering both open-ended and closed-ended questions, where CLOVER outperforms strong baselines that possess 37 times more training parameters and use instruction data generated from GPT-4. Through the instruction tuning, CLOVER exhibits robustness of few-shot learning in the external clinical dataset. These findings demonstrate that cost-effective modeling of CLOVER could accelerate the adoption of rapid conversational applications in the landscape of digital pathology.",
    "summary": "arXiv:2407.17734v2 Announce Type: replace Abstract: The advent of vision-language models fosters the interactive conversations between AI-enabled models and humans. Yet applying these models into clinics must deal with daunting challenges around large-scale training data, financial, and computational resources. Here we propose a cost-effective instruction learning framework for conversational pathology named as CLOVER. CLOVER only trains a lightweight module and uses instruction tuning while freezing the parameters of the large language model. Instead of using costly GPT-4, we propose well-designed prompts on GPT-3.5 for building generation-based instructions, emphasizing the utility of pathological knowledge derived from the Internet source. To augment the use of instructions, we construct a high-quality set of template-based instructions in the context of digital pathology. From two benchmark datasets, our findings reveal the strength of hybrid-form instructions in the visual question-answer in pathology. Extensive results show the cost-effectiveness of CLOVER in answering both open-ended and closed-ended questions, where CLOVER outperforms strong baselines that possess 37 times more training parameters and use instruction data generated from GPT-4. Through the instruction tuning, CLOVER exhibits robustness of few-shot learning in the external clinical dataset. These findings demonstrate that cost-effective modeling of CLOVER could accelerate the adoption of rapid conversational applications in the landscape of digital pathology.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2407.17734",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "CP$^2$: Leveraging Geometry for Conformal Prediction via Canonicalization",
    "description": "arXiv:2506.16189v1 Announce Type: cross Abstract: We study the problem of conformal prediction (CP) under geometric data shifts, where data samples are susceptible to transformations such as rotations or flips. While CP endows prediction models with post-hoc uncertainty quantification and formal coverage guarantees, their practicality breaks under distribution shifts that deteriorate model performance. To address this issue, we propose integrating geometric information--such as geometric pose--into the conformal procedure to reinstate its guarantees and ensure robustness under geometric shifts. In particular, we explore recent advancements on pose canonicalization as a suitable information extractor for this purpose. Evaluating the combined approach across discrete and continuous shifts and against equivariant and augmentation-based baselines, we find that integrating geometric information with CP yields a principled way to address geometric shifts while maintaining broad applicability to black-box predictors.",
    "summary": "arXiv:2506.16189v1 Announce Type: cross Abstract: We study the problem of conformal prediction (CP) under geometric data shifts, where data samples are susceptible to transformations such as rotations or flips. While CP endows prediction models with post-hoc uncertainty quantification and formal coverage guarantees, their practicality breaks under distribution shifts that deteriorate model performance. To address this issue, we propose integrating geometric information--such as geometric pose--into the conformal procedure to reinstate its guarantees and ensure robustness under geometric shifts. In particular, we explore recent advancements on pose canonicalization as a suitable information extractor for this purpose. Evaluating the combined approach across discrete and continuous shifts and against equivariant and augmentation-based baselines, we find that integrating geometric information with CP yields a principled way to address geometric shifts while maintaining broad applicability to black-box predictors.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16189",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "CRIA: A Cross-View Interaction and Instance-Adapted Pre-training Framework for Generalizable EEG Representations",
    "description": "arXiv:2506.16056v1 Announce Type: cross Abstract: The difficulty of extracting deep features from EEG data and effectively integrating information from multiple views presents significant challenges for developing a generalizable pretraining framework for EEG representation learning. However, most existing pre-training methods rely solely on the contextual semantics of a single view, failing to capture the complex and synergistic interactions among different perspectives, limiting the expressiveness and generalization of learned representations. To address these issues, this paper proposes CRIA, an adaptive framework that utilizes variable-length and variable-channel coding to achieve a unified representation of EEG data across different datasets. In this work, we define cross-view information as the integrated representation that emerges from the interaction among temporal, spectral, and spatial views of EEG signals. The model employs a cross-attention mechanism to fuse temporal, spectral, and spatial features effectively, and combines an attention matrix masking strategy based on the information bottleneck principle with a novel viewpoint masking pre-training scheme. Experimental results on the Temple University EEG corpus and the CHB-MIT dataset show that CRIA outperforms existing methods with the same pre-training conditions, achieving a balanced accuracy of 57.02% for multi-class event classification and 80.03% for anomaly detection, highlighting its strong generalization ability.",
    "summary": "arXiv:2506.16056v1 Announce Type: cross Abstract: The difficulty of extracting deep features from EEG data and effectively integrating information from multiple views presents significant challenges for developing a generalizable pretraining framework for EEG representation learning. However, most existing pre-training methods rely solely on the contextual semantics of a single view, failing to capture the complex and synergistic interactions among different perspectives, limiting the expressiveness and generalization of learned representations. To address these issues, this paper proposes CRIA, an adaptive framework that utilizes variable-length and variable-channel coding to achieve a unified representation of EEG data across different datasets. In this work, we define cross-view information as the integrated representation that emerges from the interaction among temporal, spectral, and spatial views of EEG signals. The model employs a cross-attention mechanism to fuse temporal, spectral, and spatial features effectively, and combines an attention matrix masking strategy based on the information bottleneck principle with a novel viewpoint masking pre-training scheme. Experimental results on the Temple University EEG corpus and the CHB-MIT dataset show that CRIA outperforms existing methods with the same pre-training conditions, achieving a balanced accuracy of 57.02% for multi-class event classification and 80.03% for anomaly detection, highlighting its strong generalization ability.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16056",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Cross-Modality Learning for Predicting IHC Biomarkers from H&E-Stained Whole-Slide Images",
    "description": "arXiv:2506.15853v1 Announce Type: cross Abstract: Hematoxylin and Eosin (H&amp;E) staining is a cornerstone of pathological analysis, offering reliable visualization of cellular morphology and tissue architecture for cancer diagnosis, subtyping, and grading. Immunohistochemistry (IHC) staining provides molecular insights by detecting specific proteins within tissues, enhancing diagnostic accuracy, and improving treatment planning. However, IHC staining is costly, time-consuming, and resource-intensive, requiring specialized expertise. To address these limitations, this study proposes HistoStainAlign, a novel deep learning framework that predicts IHC staining patterns directly from H&amp;E whole-slide images (WSIs) by learning joint representations of morphological and molecular features. The framework integrates paired H&amp;E and IHC embeddings through a contrastive training strategy, capturing complementary features across staining modalities without patch-level annotations or tissue registration. The model was evaluated on gastrointestinal and lung tissue WSIs with three commonly used IHC stains: P53, PD-L1, and Ki-67. HistoStainAlign achieved weighted F1 scores of 0.735 [95% Confidence Interval (CI): 0.670-0.799], 0.830 [95% CI: 0.772-0.886], and 0.723 [95% CI: 0.607-0.836], respectively for these three IHC stains. Embedding analyses demonstrated the robustness of the contrastive alignment in capturing meaningful cross-stain relationships. Comparisons with a baseline model further highlight the advantage of incorporating contrastive learning for improved stain pattern prediction. This study demonstrates the potential of computational approaches to serve as a pre-screening tool, helping prioritize cases for IHC staining and improving workflow efficiency.",
    "summary": "arXiv:2506.15853v1 Announce Type: cross Abstract: Hematoxylin and Eosin (H&amp;E) staining is a cornerstone of pathological analysis, offering reliable visualization of cellular morphology and tissue architecture for cancer diagnosis, subtyping, and grading. Immunohistochemistry (IHC) staining provides molecular insights by detecting specific proteins within tissues, enhancing diagnostic accuracy, and improving treatment planning. However, IHC staining is costly, time-consuming, and resource-intensive, requiring specialized expertise. To address these limitations, this study proposes HistoStainAlign, a novel deep learning framework that predicts IHC staining patterns directly from H&amp;E whole-slide images (WSIs) by learning joint representations of morphological and molecular features. The framework integrates paired H&amp;E and IHC embeddings through a contrastive training strategy, capturing complementary features across staining modalities without patch-level annotations or tissue registration. The model was evaluated on gastrointestinal and lung tissue WSIs with three commonly used IHC stains: P53, PD-L1, and Ki-67. HistoStainAlign achieved weighted F1 scores of 0.735 [95% Confidence Interval (CI): 0.670-0.799], 0.830 [95% CI: 0.772-0.886], and 0.723 [95% CI: 0.607-0.836], respectively for these three IHC stains. Embedding analyses demonstrated the robustness of the contrastive alignment in capturing meaningful cross-stain relationships. Comparisons with a baseline model further highlight the advantage of incorporating contrastive learning for improved stain pattern prediction. This study demonstrates the potential of computational approaches to serve as a pre-screening tool, helping prioritize cases for IHC staining and improving workflow efficiency.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.15853",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "CryoCCD: Conditional Cycle-consistent Diffusion with Biophysical Modeling for Cryo-EM Synthesis",
    "description": "arXiv:2505.23444v2 Announce Type: replace-cross Abstract: Cryo-electron microscopy (cryo-EM) offers near-atomic resolution imaging of macromolecules, but developing robust models for downstream analysis is hindered by the scarcity of high-quality annotated data. While synthetic data generation has emerged as a potential solution, existing methods often fail to capture both the structural diversity of biological specimens and the complex, spatially varying noise inherent in cryo-EM imaging. To overcome these limitations, we propose CryoCCD, a synthesis framework that integrates biophysical modeling with generative techniques. Specifically, CryoCCD produces multi-scale cryo-EM micrographs that reflect realistic biophysical variability through compositional heterogeneity, cellular context, and physics-informed imaging. To generate realistic noise, we employ a conditional diffusion model, enhanced by cycle consistency to preserve structural fidelity and mask-aware contrastive learning to capture spatially adaptive noise patterns. Extensive experiments show that CryoCCD generates structurally accurate micrographs and enhances performance in downstream tasks, outperforming state-of-the-art baselines in both particle picking and reconstruction.",
    "summary": "arXiv:2505.23444v2 Announce Type: replace-cross Abstract: Cryo-electron microscopy (cryo-EM) offers near-atomic resolution imaging of macromolecules, but developing robust models for downstream analysis is hindered by the scarcity of high-quality annotated data. While synthetic data generation has emerged as a potential solution, existing methods often fail to capture both the structural diversity of biological specimens and the complex, spatially varying noise inherent in cryo-EM imaging. To overcome these limitations, we propose CryoCCD, a synthesis framework that integrates biophysical modeling with generative techniques. Specifically, CryoCCD produces multi-scale cryo-EM micrographs that reflect realistic biophysical variability through compositional heterogeneity, cellular context, and physics-informed imaging. To generate realistic noise, we employ a conditional diffusion model, enhanced by cycle consistency to preserve structural fidelity and mask-aware contrastive learning to capture spatially adaptive noise patterns. Extensive experiments show that CryoCCD generates structurally accurate micrographs and enhances performance in downstream tasks, outperforming state-of-the-art baselines in both particle picking and reconstruction.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2505.23444",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Cyclic Vision-Language Manipulator: Towards Reliable and Fine-Grained Image Interpretation for Automated Report Generation",
    "description": "arXiv:2411.05261v3 Announce Type: replace-cross Abstract: Despite significant advancements in automated report generation, the opaqueness of text interpretability continues to cast doubt on the reliability of the content produced. This paper introduces a novel approach to identify specific image features in X-ray images that influence the outputs of report generation models. Specifically, we propose Cyclic Vision-Language Manipulator CVLM, a module to generate a manipulated X-ray from an original X-ray and its report from a designated report generator. The essence of CVLM is that cycling manipulated X-rays to the report generator produces altered reports aligned with the alterations pre-injected into the reports for X-ray generation, achieving the term 'cyclic manipulation'. This process allows direct comparison between original and manipulated X-rays, clarifying the critical image features driving changes in reports and enabling model users to assess the reliability of the generated texts. Empirical evaluations demonstrate that CVLM can identify more precise and reliable features compared to existing explanation methods, significantly enhancing the transparency and applicability of AI-generated reports.",
    "summary": "arXiv:2411.05261v3 Announce Type: replace-cross Abstract: Despite significant advancements in automated report generation, the opaqueness of text interpretability continues to cast doubt on the reliability of the content produced. This paper introduces a novel approach to identify specific image features in X-ray images that influence the outputs of report generation models. Specifically, we propose Cyclic Vision-Language Manipulator CVLM, a module to generate a manipulated X-ray from an original X-ray and its report from a designated report generator. The essence of CVLM is that cycling manipulated X-rays to the report generator produces altered reports aligned with the alterations pre-injected into the reports for X-ray generation, achieving the term 'cyclic manipulation'. This process allows direct comparison between original and manipulated X-rays, clarifying the critical image features driving changes in reports and enabling model users to assess the reliability of the generated texts. Empirical evaluations demonstrate that CVLM can identify more precise and reliable features compared to existing explanation methods, significantly enhancing the transparency and applicability of AI-generated reports.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2411.05261",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "daDPO: Distribution-Aware DPO for Distilling Conversational Abilities",
    "description": "arXiv:2506.15717v1 Announce Type: cross Abstract: Large language models (LLMs) have demonstrated exceptional performance across various applications, but their conversational abilities decline sharply as model size decreases, presenting a barrier to their deployment in resource-constrained environments. Knowledge distillation with Direct Preference Optimization (dDPO) has emerged as a promising approach to enhancing the conversational abilities of smaller models using a larger teacher model. However, current methods primarily focus on 'black-box' KD, which only uses the teacher's responses, overlooking the output distribution offered by the teacher. This paper addresses this gap by introducing daDPO (Distribution-Aware DPO), a unified method for preference optimization and distribution-based distillation. We provide rigorous theoretical analysis and empirical validation, showing that daDPO outperforms existing methods in restoring performance for pruned models and enhancing smaller LLM models. Notably, in in-domain evaluation, our method enables a 20% pruned Vicuna1.5-7B to achieve near-teacher performance (-7.3% preference rate compared to that of dDPO's -31%), and allows Qwen2.5-1.5B to occasionally outperform its 7B teacher model (14.0% win rate).",
    "summary": "arXiv:2506.15717v1 Announce Type: cross Abstract: Large language models (LLMs) have demonstrated exceptional performance across various applications, but their conversational abilities decline sharply as model size decreases, presenting a barrier to their deployment in resource-constrained environments. Knowledge distillation with Direct Preference Optimization (dDPO) has emerged as a promising approach to enhancing the conversational abilities of smaller models using a larger teacher model. However, current methods primarily focus on 'black-box' KD, which only uses the teacher's responses, overlooking the output distribution offered by the teacher. This paper addresses this gap by introducing daDPO (Distribution-Aware DPO), a unified method for preference optimization and distribution-based distillation. We provide rigorous theoretical analysis and empirical validation, showing that daDPO outperforms existing methods in restoring performance for pruned models and enhancing smaller LLM models. Notably, in in-domain evaluation, our method enables a 20% pruned Vicuna1.5-7B to achieve near-teacher performance (-7.3% preference rate compared to that of dDPO's -31%), and allows Qwen2.5-1.5B to occasionally outperform its 7B teacher model (14.0% win rate).",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.15717",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Decentralized Collective World Model for Emergent Communication and Coordination",
    "description": "arXiv:2504.03353v2 Announce Type: replace-cross Abstract: We propose a fully decentralized multi-agent world model that enables both symbol emergence for communication and coordinated behavior through temporal extension of collective predictive coding. Unlike previous research that focuses on either communication or coordination separately, our approach achieves both simultaneously. Our method integrates world models with communication channels, enabling agents to predict environmental dynamics, estimate states from partial observations, and share critical information through bidirectional message exchange with contrastive learning for message alignment. Using a two-agent trajectory drawing task, we demonstrate that our communication-based approach outperforms non-communicative models when agents have divergent perceptual capabilities, achieving the second-best coordination after centralized models. Importantly, our decentralized approach with constraints preventing direct access to other agents' internal states facilitates the emergence of more meaningful symbol systems that accurately reflect environmental states. These findings demonstrate the effectiveness of decentralized communication for supporting coordination while developing shared representations of the environment.",
    "summary": "arXiv:2504.03353v2 Announce Type: replace-cross Abstract: We propose a fully decentralized multi-agent world model that enables both symbol emergence for communication and coordinated behavior through temporal extension of collective predictive coding. Unlike previous research that focuses on either communication or coordination separately, our approach achieves both simultaneously. Our method integrates world models with communication channels, enabling agents to predict environmental dynamics, estimate states from partial observations, and share critical information through bidirectional message exchange with contrastive learning for message alignment. Using a two-agent trajectory drawing task, we demonstrate that our communication-based approach outperforms non-communicative models when agents have divergent perceptual capabilities, achieving the second-best coordination after centralized models. Importantly, our decentralized approach with constraints preventing direct access to other agents' internal states facilitates the emergence of more meaningful symbol systems that accurately reflect environmental states. These findings demonstrate the effectiveness of decentralized communication for supporting coordination while developing shared representations of the environment.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2504.03353",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Decoupled Classifier-Free Guidance for Counterfactual Diffusion Models",
    "description": "arXiv:2506.14399v2 Announce Type: replace-cross Abstract: Counterfactual image generation aims to simulate realistic visual outcomes under specific causal interventions. Diffusion models have recently emerged as a powerful tool for this task, combining DDIM inversion with conditional generation via classifier-free guidance (CFG). However, standard CFG applies a single global weight across all conditioning variables, which can lead to poor identity preservation and spurious attribute changes - a phenomenon known as attribute amplification. To address this, we propose Decoupled Classifier-Free Guidance (DCFG), a flexible and model-agnostic framework that introduces group-wise conditioning control. DCFG builds on an attribute-split embedding strategy that disentangles semantic inputs, enabling selective guidance on user-defined attribute groups. For counterfactual generation, we partition attributes into intervened and invariant sets based on a causal graph and apply distinct guidance to each. Experiments on CelebA-HQ, MIMIC-CXR, and EMBED show that DCFG improves intervention fidelity, mitigates unintended changes, and enhances reversibility, enabling more faithful and interpretable counterfactual image generation.",
    "summary": "arXiv:2506.14399v2 Announce Type: replace-cross Abstract: Counterfactual image generation aims to simulate realistic visual outcomes under specific causal interventions. Diffusion models have recently emerged as a powerful tool for this task, combining DDIM inversion with conditional generation via classifier-free guidance (CFG). However, standard CFG applies a single global weight across all conditioning variables, which can lead to poor identity preservation and spurious attribute changes - a phenomenon known as attribute amplification. To address this, we propose Decoupled Classifier-Free Guidance (DCFG), a flexible and model-agnostic framework that introduces group-wise conditioning control. DCFG builds on an attribute-split embedding strategy that disentangles semantic inputs, enabling selective guidance on user-defined attribute groups. For counterfactual generation, we partition attributes into intervened and invariant sets based on a causal graph and apply distinct guidance to each. Experiments on CelebA-HQ, MIMIC-CXR, and EMBED show that DCFG improves intervention fidelity, mitigates unintended changes, and enhances reversibility, enabling more faithful and interpretable counterfactual image generation.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.14399",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Deep Reinforcement Learning Xiangqi Player with Monte Carlo Tree Search",
    "description": "arXiv:2506.15880v1 Announce Type: new Abstract: This paper presents a Deep Reinforcement Learning (DRL) system for Xiangqi (Chinese Chess) that integrates neural networks with Monte Carlo Tree Search (MCTS) to enable strategic self-play and self-improvement. Addressing the underexplored complexity of Xiangqi, including its unique board layout, piece movement constraints, and victory conditions, our approach combines policy-value networks with MCTS to simulate move consequences and refine decision-making. By overcoming challenges such as Xiangqi's high branching factor and asymmetrical piece dynamics, our work advances AI capabilities in culturally significant strategy games while providing insights for adapting DRL-MCTS frameworks to domain-specific rule systems.",
    "summary": "arXiv:2506.15880v1 Announce Type: new Abstract: This paper presents a Deep Reinforcement Learning (DRL) system for Xiangqi (Chinese Chess) that integrates neural networks with Monte Carlo Tree Search (MCTS) to enable strategic self-play and self-improvement. Addressing the underexplored complexity of Xiangqi, including its unique board layout, piece movement constraints, and victory conditions, our approach combines policy-value networks with MCTS to simulate move consequences and refine decision-making. By overcoming challenges such as Xiangqi's high branching factor and asymmetrical piece dynamics, our work advances AI capabilities in culturally significant strategy games while providing insights for adapting DRL-MCTS frameworks to domain-specific rule systems.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.15880",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "DeepSelective: Interpretable Prognosis Prediction via Feature Selection and Compression in EHR Data",
    "description": "arXiv:2504.11264v2 Announce Type: replace-cross Abstract: The rapid accumulation of Electronic Health Records (EHRs) has transformed healthcare by providing valuable data that enhance clinical predictions and diagnoses. While conventional machine learning models have proven effective, they often lack robust representation learning and depend heavily on expert-crafted features. Although deep learning offers powerful solutions, it is often criticized for its lack of interpretability. To address these challenges, we propose DeepSelective, a novel end to end deep learning framework for predicting patient prognosis using EHR data, with a strong emphasis on enhancing model interpretability. DeepSelective combines data compression techniques with an innovative feature selection approach, integrating custom-designed modules that work together to improve both accuracy and interpretability. Our experiments demonstrate that DeepSelective not only enhances predictive accuracy but also significantly improves interpretability, making it a valuable tool for clinical decision-making. The source code is freely available at http://www.healthinformaticslab.org/supp/resources.php .",
    "summary": "arXiv:2504.11264v2 Announce Type: replace-cross Abstract: The rapid accumulation of Electronic Health Records (EHRs) has transformed healthcare by providing valuable data that enhance clinical predictions and diagnoses. While conventional machine learning models have proven effective, they often lack robust representation learning and depend heavily on expert-crafted features. Although deep learning offers powerful solutions, it is often criticized for its lack of interpretability. To address these challenges, we propose DeepSelective, a novel end to end deep learning framework for predicting patient prognosis using EHR data, with a strong emphasis on enhancing model interpretability. DeepSelective combines data compression techniques with an innovative feature selection approach, integrating custom-designed modules that work together to improve both accuracy and interpretability. Our experiments demonstrate that DeepSelective not only enhances predictive accuracy but also significantly improves interpretability, making it a valuable tool for clinical decision-making. The source code is freely available at http://www.healthinformaticslab.org/supp/resources.php .",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2504.11264",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "DIGMAPPER: A Modular System for Automated Geologic Map Digitization",
    "description": "arXiv:2506.16006v1 Announce Type: cross Abstract: Historical geologic maps contain rich geospatial information, such as rock units, faults, folds, and bedding planes, that is critical for assessing mineral resources essential to renewable energy, electric vehicles, and national security. However, digitizing maps remains a labor-intensive and time-consuming task. We present DIGMAPPER, a modular, scalable system developed in collaboration with the United States Geological Survey (USGS) to automate the digitization of geologic maps. DIGMAPPER features a fully dockerized, workflow-orchestrated architecture that integrates state-of-the-art deep learning models for map layout analysis, feature extraction, and georeferencing. To overcome challenges such as limited training data and complex visual content, our system employs innovative techniques, including in-context learning with large language models, synthetic data generation, and transformer-based models. Evaluations on over 100 annotated maps from the DARPA-USGS dataset demonstrate high accuracy across polygon, line, and point feature extraction, and reliable georeferencing performance. Deployed at USGS, DIGMAPPER significantly accelerates the creation of analysis-ready geospatial datasets, supporting national-scale critical mineral assessments and broader geoscientific applications.",
    "summary": "arXiv:2506.16006v1 Announce Type: cross Abstract: Historical geologic maps contain rich geospatial information, such as rock units, faults, folds, and bedding planes, that is critical for assessing mineral resources essential to renewable energy, electric vehicles, and national security. However, digitizing maps remains a labor-intensive and time-consuming task. We present DIGMAPPER, a modular, scalable system developed in collaboration with the United States Geological Survey (USGS) to automate the digitization of geologic maps. DIGMAPPER features a fully dockerized, workflow-orchestrated architecture that integrates state-of-the-art deep learning models for map layout analysis, feature extraction, and georeferencing. To overcome challenges such as limited training data and complex visual content, our system employs innovative techniques, including in-context learning with large language models, synthetic data generation, and transformer-based models. Evaluations on over 100 annotated maps from the DARPA-USGS dataset demonstrate high accuracy across polygon, line, and point feature extraction, and reliable georeferencing performance. Deployed at USGS, DIGMAPPER significantly accelerates the creation of analysis-ready geospatial datasets, supporting national-scale critical mineral assessments and broader geoscientific applications.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16006",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Dispositions and Roles of Generically Dependent Entities",
    "description": "arXiv:2506.17085v1 Announce Type: new Abstract: BFO 2020 does not support functions, dispositions, and roles of generically dependent continuants (like software or datasets). In this paper, we argue that this is a severe limitation, which prevents, for example, the adequate representation of the functions of computer models or the various roles of datasets during the execution of these models. We discuss the aspects of BFO 2020 that prevent the representation of realizable entities of generically dependent continuants. Two approaches to address the issue are presented: (a) the use of defined classes and (b) a proposal of changes that allow BFO to support functions, dispositions, and roles of generically dependent continuants.",
    "summary": "arXiv:2506.17085v1 Announce Type: new Abstract: BFO 2020 does not support functions, dispositions, and roles of generically dependent continuants (like software or datasets). In this paper, we argue that this is a severe limitation, which prevents, for example, the adequate representation of the functions of computer models or the various roles of datasets during the execution of these models. We discuss the aspects of BFO 2020 that prevent the representation of realizable entities of generically dependent continuants. Two approaches to address the issue are presented: (a) the use of defined classes and (b) a proposal of changes that allow BFO to support functions, dispositions, and roles of generically dependent continuants.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.17085",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Dissecting the SWE-Bench Leaderboards: Profiling Submitters and Architectures of LLM- and Agent-Based Repair Systems",
    "description": "arXiv:2506.17208v1 Announce Type: cross Abstract: The rapid progress in Automated Program Repair (APR) has been driven by advances in AI, particularly large language models (LLMs) and agent-based systems. SWE-Bench is a recent benchmark designed to evaluate LLM-based repair systems using real issues and pull requests mined from 12 popular open-source Python repositories. Its public leaderboards, SWE-Bench Lite and SWE-Bench Verified, have become central platforms for tracking progress and comparing solutions. However, because the submission process does not require detailed documentation, the architectural design and origin of many solutions remain unclear. In this paper, we present the first comprehensive study of all submissions to the SWE-Bench Lite (68 entries) and Verified (79 entries) leaderboards, analyzing 67 unique approaches across dimensions such as submitter type, product availability, LLM usage, and system architecture. Our findings reveal the dominance of proprietary LLMs (especially Claude 3.5/3.7), the presence of both agentic and non-agentic designs, and a contributor base spanning from individual developers to large tech companies.",
    "summary": "arXiv:2506.17208v1 Announce Type: cross Abstract: The rapid progress in Automated Program Repair (APR) has been driven by advances in AI, particularly large language models (LLMs) and agent-based systems. SWE-Bench is a recent benchmark designed to evaluate LLM-based repair systems using real issues and pull requests mined from 12 popular open-source Python repositories. Its public leaderboards, SWE-Bench Lite and SWE-Bench Verified, have become central platforms for tracking progress and comparing solutions. However, because the submission process does not require detailed documentation, the architectural design and origin of many solutions remain unclear. In this paper, we present the first comprehensive study of all submissions to the SWE-Bench Lite (68 entries) and Verified (79 entries) leaderboards, analyzing 67 unique approaches across dimensions such as submitter type, product availability, LLM usage, and system architecture. Our findings reveal the dominance of proprietary LLMs (especially Claude 3.5/3.7), the presence of both agentic and non-agentic designs, and a contributor base spanning from individual developers to large tech companies.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.17208",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Distribution Parameter Actor-Critic: Shifting the Agent-Environment Boundary for Diverse Action Spaces",
    "description": "arXiv:2506.16608v1 Announce Type: cross Abstract: We introduce a novel reinforcement learning (RL) framework that treats distribution parameters as actions, redefining the boundary between agent and environment. This reparameterization makes the new action space continuous, regardless of the original action type (discrete, continuous, mixed, etc.). Under this new parameterization, we develop a generalized deterministic policy gradient estimator, Distribution Parameter Policy Gradient (DPPG), which has lower variance than the gradient in the original action space. Although learning the critic over distribution parameters poses new challenges, we introduce interpolated critic learning (ICL), a simple yet effective strategy to enhance learning, supported by insights from bandit settings. Building on TD3, a strong baseline for continuous control, we propose a practical DPPG-based actor-critic algorithm, Distribution Parameter Actor-Critic (DPAC). Empirically, DPAC outperforms TD3 in MuJoCo continuous control tasks from OpenAI Gym and DeepMind Control Suite, and demonstrates competitive performance on the same environments with discretized action spaces.",
    "summary": "arXiv:2506.16608v1 Announce Type: cross Abstract: We introduce a novel reinforcement learning (RL) framework that treats distribution parameters as actions, redefining the boundary between agent and environment. This reparameterization makes the new action space continuous, regardless of the original action type (discrete, continuous, mixed, etc.). Under this new parameterization, we develop a generalized deterministic policy gradient estimator, Distribution Parameter Policy Gradient (DPPG), which has lower variance than the gradient in the original action space. Although learning the critic over distribution parameters poses new challenges, we introduce interpolated critic learning (ICL), a simple yet effective strategy to enhance learning, supported by insights from bandit settings. Building on TD3, a strong baseline for continuous control, we propose a practical DPPG-based actor-critic algorithm, Distribution Parameter Actor-Critic (DPAC). Empirically, DPAC outperforms TD3 in MuJoCo continuous control tasks from OpenAI Gym and DeepMind Control Suite, and demonstrates competitive performance on the same environments with discretized action spaces.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16608",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Do We Need Large VLMs for Spotting Soccer Actions?",
    "description": "arXiv:2506.17144v1 Announce Type: cross Abstract: Traditional video-based tasks like soccer action spotting rely heavily on visual inputs, often requiring complex and computationally expensive models to process dense video data. In this work, we propose a shift from this video-centric approach to a text-based task, making it lightweight and scalable by utilizing Large Language Models (LLMs) instead of Vision-Language Models (VLMs). We posit that expert commentary, which provides rich, fine-grained descriptions and contextual cues such as excitement and tactical insights, contains enough information to reliably spot key actions in a match. To demonstrate this, we use the SoccerNet Echoes dataset, which provides timestamped commentary, and employ a system of three LLMs acting as judges specializing in outcome, excitement, and tactics. Each LLM evaluates sliding windows of commentary to identify actions like goals, cards, and substitutions, generating accurate timestamps for these events. Our experiments show that this language-centric approach performs effectively in detecting critical match events, providing a lightweight and training-free alternative to traditional video-based methods for action spotting.",
    "summary": "arXiv:2506.17144v1 Announce Type: cross Abstract: Traditional video-based tasks like soccer action spotting rely heavily on visual inputs, often requiring complex and computationally expensive models to process dense video data. In this work, we propose a shift from this video-centric approach to a text-based task, making it lightweight and scalable by utilizing Large Language Models (LLMs) instead of Vision-Language Models (VLMs). We posit that expert commentary, which provides rich, fine-grained descriptions and contextual cues such as excitement and tactical insights, contains enough information to reliably spot key actions in a match. To demonstrate this, we use the SoccerNet Echoes dataset, which provides timestamped commentary, and employ a system of three LLMs acting as judges specializing in outcome, excitement, and tactics. Each LLM evaluates sliding windows of commentary to identify actions like goals, cards, and substitutions, generating accurate timestamps for these events. Our experiments show that this language-centric approach performs effectively in detecting critical match events, providing a lightweight and training-free alternative to traditional video-based methods for action spotting.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.17144",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Do We Talk to Robots Like Therapists, and Do They Respond Accordingly? Language Alignment in AI Emotional Support",
    "description": "arXiv:2506.16473v1 Announce Type: cross Abstract: As conversational agents increasingly engage in emotionally supportive dialogue, it is important to understand how closely their interactions resemble those in traditional therapy settings. This study investigates whether the concerns shared with a robot align with those shared in human-to-human (H2H) therapy sessions, and whether robot responses semantically mirror those of human therapists. We analyzed two datasets: one of interactions between users and professional therapists (Hugging Face's NLP Mental Health Conversations), and another involving supportive conversations with a social robot (QTrobot from LuxAI) powered by a large language model (LLM, GPT-3.5). Using sentence embeddings and K-means clustering, we assessed cross-agent thematic alignment by applying a distance-based cluster-fitting method that evaluates whether responses from one agent type map to clusters derived from the other, and validated it using Euclidean distances. Results showed that 90.88% of robot conversation disclosures could be mapped to clusters from the human therapy dataset, suggesting shared topical structure. For matched clusters, we compared the subjects as well as therapist and robot responses using Transformer, Word2Vec, and BERT embeddings, revealing strong semantic overlap in subjects' disclosures in both datasets, as well as in the responses given to similar human disclosure themes across agent types (robot vs. human therapist). These findings highlight both the parallels and boundaries of robot-led support conversations and their potential for augmenting mental health interventions.",
    "summary": "arXiv:2506.16473v1 Announce Type: cross Abstract: As conversational agents increasingly engage in emotionally supportive dialogue, it is important to understand how closely their interactions resemble those in traditional therapy settings. This study investigates whether the concerns shared with a robot align with those shared in human-to-human (H2H) therapy sessions, and whether robot responses semantically mirror those of human therapists. We analyzed two datasets: one of interactions between users and professional therapists (Hugging Face's NLP Mental Health Conversations), and another involving supportive conversations with a social robot (QTrobot from LuxAI) powered by a large language model (LLM, GPT-3.5). Using sentence embeddings and K-means clustering, we assessed cross-agent thematic alignment by applying a distance-based cluster-fitting method that evaluates whether responses from one agent type map to clusters derived from the other, and validated it using Euclidean distances. Results showed that 90.88% of robot conversation disclosures could be mapped to clusters from the human therapy dataset, suggesting shared topical structure. For matched clusters, we compared the subjects as well as therapist and robot responses using Transformer, Word2Vec, and BERT embeddings, revealing strong semantic overlap in subjects' disclosures in both datasets, as well as in the responses given to similar human disclosure themes across agent types (robot vs. human therapist). These findings highlight both the parallels and boundaries of robot-led support conversations and their potential for augmenting mental health interventions.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16473",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Double Entendre: Robust Audio-Based AI-Generated Lyrics Detection via Multi-View Fusion",
    "description": "arXiv:2506.15981v1 Announce Type: cross Abstract: The rapid advancement of AI-based music generation tools is revolutionizing the music industry but also posing challenges to artists, copyright holders, and providers alike. This necessitates reliable methods for detecting such AI-generated content. However, existing detectors, relying on either audio or lyrics, face key practical limitations: audio-based detectors fail to generalize to new or unseen generators and are vulnerable to audio perturbations; lyrics-based methods require cleanly formatted and accurate lyrics, unavailable in practice. To overcome these limitations, we propose a novel, practically grounded approach: a multimodal, modular late-fusion pipeline that combines automatically transcribed sung lyrics and speech features capturing lyrics-related information within the audio. By relying on lyrical aspects directly from audio, our method enhances robustness, mitigates susceptibility to low-level artifacts, and enables practical applicability. Experiments show that our method, DE-detect, outperforms existing lyrics-based detectors while also being more robust to audio perturbations. Thus, it offers an effective, robust solution for detecting AI-generated music in real-world scenarios. Our code is available at https://github.com/deezer/robust-AI-lyrics-detection.",
    "summary": "arXiv:2506.15981v1 Announce Type: cross Abstract: The rapid advancement of AI-based music generation tools is revolutionizing the music industry but also posing challenges to artists, copyright holders, and providers alike. This necessitates reliable methods for detecting such AI-generated content. However, existing detectors, relying on either audio or lyrics, face key practical limitations: audio-based detectors fail to generalize to new or unseen generators and are vulnerable to audio perturbations; lyrics-based methods require cleanly formatted and accurate lyrics, unavailable in practice. To overcome these limitations, we propose a novel, practically grounded approach: a multimodal, modular late-fusion pipeline that combines automatically transcribed sung lyrics and speech features capturing lyrics-related information within the audio. By relying on lyrical aspects directly from audio, our method enhances robustness, mitigates susceptibility to low-level artifacts, and enables practical applicability. Experiments show that our method, DE-detect, outperforms existing lyrics-based detectors while also being more robust to audio perturbations. Thus, it offers an effective, robust solution for detecting AI-generated music in real-world scenarios. Our code is available at https://github.com/deezer/robust-AI-lyrics-detection.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.15981",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Drag-and-Drop LLMs: Zero-Shot Prompt-to-Weights",
    "description": "arXiv:2506.16406v1 Announce Type: cross Abstract: Modern Parameter-Efficient Fine-Tuning (PEFT) methods such as low-rank adaptation (LoRA) reduce the cost of customizing large language models (LLMs), yet still require a separate optimization run for every downstream dataset. We introduce textbf{Drag-and-Drop LLMs (textit{DnD})}, a prompt-conditioned parameter generator that eliminates per-task training by mapping a handful of unlabeled task prompts directly to LoRA weight updates. A lightweight text encoder distills each prompt batch into condition embeddings, which are then transformed by a cascaded hyper-convolutional decoder into the full set of LoRA matrices. Once trained in a diverse collection of prompt-checkpoint pairs, DnD produces task-specific parameters in seconds, yielding i) up to textbf{12,000$times$} lower overhead than full fine-tuning, ii) average gains up to textbf{30%} in performance over the strongest training LoRAs on unseen common-sense reasoning, math, coding, and multimodal benchmarks, and iii) robust cross-domain generalization despite never seeing the target data or labels. Our results demonstrate that prompt-conditioned parameter generation is a viable alternative to gradient-based adaptation for rapidly specializing LLMs. Our project is available at href{https://jerryliang24.github.io/DnD}{https://jerryliang24.github.io/DnD}.",
    "summary": "arXiv:2506.16406v1 Announce Type: cross Abstract: Modern Parameter-Efficient Fine-Tuning (PEFT) methods such as low-rank adaptation (LoRA) reduce the cost of customizing large language models (LLMs), yet still require a separate optimization run for every downstream dataset. We introduce textbf{Drag-and-Drop LLMs (textit{DnD})}, a prompt-conditioned parameter generator that eliminates per-task training by mapping a handful of unlabeled task prompts directly to LoRA weight updates. A lightweight text encoder distills each prompt batch into condition embeddings, which are then transformed by a cascaded hyper-convolutional decoder into the full set of LoRA matrices. Once trained in a diverse collection of prompt-checkpoint pairs, DnD produces task-specific parameters in seconds, yielding i) up to textbf{12,000$times$} lower overhead than full fine-tuning, ii) average gains up to textbf{30%} in performance over the strongest training LoRAs on unseen common-sense reasoning, math, coding, and multimodal benchmarks, and iii) robust cross-domain generalization despite never seeing the target data or labels. Our results demonstrate that prompt-conditioned parameter generation is a viable alternative to gradient-based adaptation for rapidly specializing LLMs. Our project is available at href{https://jerryliang24.github.io/DnD}{https://jerryliang24.github.io/DnD}.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16406",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Dual-Objective Reinforcement Learning with Novel Hamilton-Jacobi-Bellman Formulations",
    "description": "arXiv:2506.16016v1 Announce Type: new Abstract: Hard constraints in reinforcement learning (RL), whether imposed via the reward function or the model architecture, often degrade policy performance. Lagrangian methods offer a way to blend objectives with constraints, but often require intricate reward engineering and parameter tuning. In this work, we extend recent advances that connect Hamilton-Jacobi (HJ) equations with RL to propose two novel value functions for dual-objective satisfaction. Namely, we address: (1) the Reach-Always-Avoid problem - of achieving distinct reward and penalty thresholds - and (2) the Reach-Reach problem - of achieving thresholds of two distinct rewards. In contrast with temporal logic approaches, which typically involve representing an automaton, we derive explicit, tractable Bellman forms in this context by decomposing our problem into reach, avoid, and reach-avoid problems, as to leverage these aforementioned recent advances. From a mathematical perspective, the Reach-Always-Avoid and Reach-Reach problems are complementary and fundamentally different from standard sum-of-rewards problems and temporal logic problems, providing a new perspective on constrained decision-making. We leverage our analysis to propose a variation of Proximal Policy Optimization (DO-HJ-PPO), which solves these problems. Across a range of tasks for safe-arrival and multi-target achievement, we demonstrate that DO-HJ-PPO produces qualitatively distinct behaviors from previous approaches and out-competes a number of baselines in various metrics.",
    "summary": "arXiv:2506.16016v1 Announce Type: new Abstract: Hard constraints in reinforcement learning (RL), whether imposed via the reward function or the model architecture, often degrade policy performance. Lagrangian methods offer a way to blend objectives with constraints, but often require intricate reward engineering and parameter tuning. In this work, we extend recent advances that connect Hamilton-Jacobi (HJ) equations with RL to propose two novel value functions for dual-objective satisfaction. Namely, we address: (1) the Reach-Always-Avoid problem - of achieving distinct reward and penalty thresholds - and (2) the Reach-Reach problem - of achieving thresholds of two distinct rewards. In contrast with temporal logic approaches, which typically involve representing an automaton, we derive explicit, tractable Bellman forms in this context by decomposing our problem into reach, avoid, and reach-avoid problems, as to leverage these aforementioned recent advances. From a mathematical perspective, the Reach-Always-Avoid and Reach-Reach problems are complementary and fundamentally different from standard sum-of-rewards problems and temporal logic problems, providing a new perspective on constrained decision-making. We leverage our analysis to propose a variation of Proximal Policy Optimization (DO-HJ-PPO), which solves these problems. Across a range of tasks for safe-arrival and multi-target achievement, we demonstrate that DO-HJ-PPO produces qualitatively distinct behaviors from previous approaches and out-competes a number of baselines in various metrics.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16016",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Dual Thinking and Logical Processing -- Are Multi-modal Large Language Models Closing the Gap with Human Vision ?",
    "description": "arXiv:2406.06967v4 Announce Type: replace-cross Abstract: The dual thinking framework considers fast, intuitive, and slower logical processing. The perception of dual thinking in vision requires images where inferences from intuitive and logical processing differ, and the latter is under-explored in current studies. We introduce a novel adversarial dataset to provide evidence for the dual thinking framework in human vision, which also facilitates the study of the qualitative behavior of deep learning models. Our psychophysical studies show the presence of multiple inferences in rapid succession, and analysis of errors shows that the early stopping of visual processing can result in missing relevant information. MLLMs (Multi-modal Large Language Models) and VLMs (Vision Language Models) have made significant progress in correcting errors in intuitive processing in human vision and showed enhanced performance on images requiring logical processing. However, their improvements in logical processing have not kept pace with their advancements in intuitive processing. In contrast, segmentation models exhibit errors similar to those seen in intuitive human processing and lack understanding of sub-structures, as indicated by errors related to sub-components in identified instances. As AI (Artificial Intelligence)-based systems find increasing applications in safety-critical domains like autonomous driving, the integration of logical processing capabilities becomes essential. This not only enhances performance but also addresses the limitations of scaling-based approaches while ensuring robustness and reliability in real-world environments.",
    "summary": "arXiv:2406.06967v4 Announce Type: replace-cross Abstract: The dual thinking framework considers fast, intuitive, and slower logical processing. The perception of dual thinking in vision requires images where inferences from intuitive and logical processing differ, and the latter is under-explored in current studies. We introduce a novel adversarial dataset to provide evidence for the dual thinking framework in human vision, which also facilitates the study of the qualitative behavior of deep learning models. Our psychophysical studies show the presence of multiple inferences in rapid succession, and analysis of errors shows that the early stopping of visual processing can result in missing relevant information. MLLMs (Multi-modal Large Language Models) and VLMs (Vision Language Models) have made significant progress in correcting errors in intuitive processing in human vision and showed enhanced performance on images requiring logical processing. However, their improvements in logical processing have not kept pace with their advancements in intuitive processing. In contrast, segmentation models exhibit errors similar to those seen in intuitive human processing and lack understanding of sub-structures, as indicated by errors related to sub-components in identified instances. As AI (Artificial Intelligence)-based systems find increasing applications in safety-critical domains like autonomous driving, the integration of logical processing capabilities becomes essential. This not only enhances performance but also addresses the limitations of scaling-based approaches while ensuring robustness and reliability in real-world environments.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2406.06967",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "DXの本質は技術導入にあらず　インドネシア小売大手に学ぶ、顧客データの徹底活用",
    "description": "インドネシアの大手小売業アルファマートは、25年間で1万2000店舗から2万2000店舗へと拡大し、国内認知度98%を誇る。同社の戦略とビジネスモデルから、日本企業が学ぶべきこととは。",
    "summary": "インドネシアの大手小売業アルファマートは、25年間で1万2000店舗から2万2000店舗へと拡大し、国内認知度98%を誇る。同社の戦略とビジネスモデルから、日本企業が学ぶべきこととは。",
    "pubDate": "Mon, 23 Jun 2025 07:00:00 +0900",
    "source": "ITmedia AI",
    "url": "https://www.itmedia.co.jp/business/articles/2506/23/news010.html",
    "thumbnail": "https://image.itmedia.co.jp/business/articles/2506/23/cover_news010.jpg"
  },
  {
    "title": "Dynamic Knowledge Integration for Evidence-Driven Counter-Argument Generation with Large Language Models",
    "description": "arXiv:2503.05328v2 Announce Type: replace-cross Abstract: This paper investigates the role of dynamic external knowledge integration in improving counter-argument generation using Large Language Models (LLMs). While LLMs have shown promise in argumentative tasks, their tendency to generate lengthy, potentially unfactual responses highlights the need for more controlled and evidence-based approaches. We introduce a new manually curated dataset of argument and counter-argument pairs specifically designed to balance argumentative complexity with evaluative feasibility. We also propose a new LLM-as-a-Judge evaluation methodology that shows a stronger correlation with human judgments compared to traditional reference-based metrics. Our experimental results demonstrate that integrating dynamic external knowledge from the web significantly improves the quality of generated counter-arguments, particularly in terms of relatedness, persuasiveness, and factuality. The findings suggest that combining LLMs with real-time external knowledge retrieval offers a promising direction for developing more effective and reliable counter-argumentation systems.",
    "summary": "arXiv:2503.05328v2 Announce Type: replace-cross Abstract: This paper investigates the role of dynamic external knowledge integration in improving counter-argument generation using Large Language Models (LLMs). While LLMs have shown promise in argumentative tasks, their tendency to generate lengthy, potentially unfactual responses highlights the need for more controlled and evidence-based approaches. We introduce a new manually curated dataset of argument and counter-argument pairs specifically designed to balance argumentative complexity with evaluative feasibility. We also propose a new LLM-as-a-Judge evaluation methodology that shows a stronger correlation with human judgments compared to traditional reference-based metrics. Our experimental results demonstrate that integrating dynamic external knowledge from the web significantly improves the quality of generated counter-arguments, particularly in terms of relatedness, persuasiveness, and factuality. The findings suggest that combining LLMs with real-time external knowledge retrieval offers a promising direction for developing more effective and reliable counter-argumentation systems.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2503.05328",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Dynamic Risk Assessments for Offensive Cybersecurity Agents",
    "description": "arXiv:2505.18384v2 Announce Type: replace-cross Abstract: Foundation models are increasingly becoming better autonomous programmers, raising the prospect that they could also automate dangerous offensive cyber-operations. Current frontier model audits probe the cybersecurity risks of such agents, but most fail to account for the degrees of freedom available to adversaries in the real world. In particular, with strong verifiers and financial incentives, agents for offensive cybersecurity are amenable to iterative improvement by would-be adversaries. We argue that assessments should take into account an expanded threat model in the context of cybersecurity, emphasizing the varying degrees of freedom that an adversary may possess in stateful and non-stateful environments within a fixed compute budget. We show that even with a relatively small compute budget (8 H100 GPU Hours in our study), adversaries can improve an agent's cybersecurity capability on InterCode CTF by more than 40% relative to the baseline -- without any external assistance. These results highlight the need to evaluate agents' cybersecurity risk in a dynamic manner, painting a more representative picture of risk.",
    "summary": "arXiv:2505.18384v2 Announce Type: replace-cross Abstract: Foundation models are increasingly becoming better autonomous programmers, raising the prospect that they could also automate dangerous offensive cyber-operations. Current frontier model audits probe the cybersecurity risks of such agents, but most fail to account for the degrees of freedom available to adversaries in the real world. In particular, with strong verifiers and financial incentives, agents for offensive cybersecurity are amenable to iterative improvement by would-be adversaries. We argue that assessments should take into account an expanded threat model in the context of cybersecurity, emphasizing the varying degrees of freedom that an adversary may possess in stateful and non-stateful environments within a fixed compute budget. We show that even with a relatively small compute budget (8 H100 GPU Hours in our study), adversaries can improve an agent's cybersecurity capability on InterCode CTF by more than 40% relative to the baseline -- without any external assistance. These results highlight the need to evaluate agents' cybersecurity risk in a dynamic manner, painting a more representative picture of risk.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2505.18384",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "DynScaling: Efficient Verifier-free Inference Scaling via Dynamic and Integrated Sampling",
    "description": "arXiv:2506.16043v1 Announce Type: cross Abstract: Inference-time scaling has proven effective in boosting large language model (LLM) performance through increased test-time computation. Yet, its practical application is often hindered by reliance on external verifiers or a lack of optimization for realistic computational constraints. We propose DynScaling, which addresses these limitations through two primary innovations: an integrated parallel-sequential sampling strategy and a bandit-based dynamic budget allocation framework. The integrated sampling strategy unifies parallel and sequential sampling by constructing synthetic sequential reasoning chains from initially independent parallel responses, promoting diverse and coherent reasoning trajectories. The dynamic budget allocation framework formulates the allocation of computational resources as a multi-armed bandit problem, adaptively distributing the inference budget across queries based on the uncertainty of previously sampled responses, thereby maximizing computational efficiency. By combining these components, DynScaling effectively improves LLM performance under practical resource constraints without the need for external verifiers. Experimental results demonstrate that DynScaling consistently surpasses existing verifier-free inference scaling baselines in both task performance and computational cost.",
    "summary": "arXiv:2506.16043v1 Announce Type: cross Abstract: Inference-time scaling has proven effective in boosting large language model (LLM) performance through increased test-time computation. Yet, its practical application is often hindered by reliance on external verifiers or a lack of optimization for realistic computational constraints. We propose DynScaling, which addresses these limitations through two primary innovations: an integrated parallel-sequential sampling strategy and a bandit-based dynamic budget allocation framework. The integrated sampling strategy unifies parallel and sequential sampling by constructing synthetic sequential reasoning chains from initially independent parallel responses, promoting diverse and coherent reasoning trajectories. The dynamic budget allocation framework formulates the allocation of computational resources as a multi-armed bandit problem, adaptively distributing the inference budget across queries based on the uncertainty of previously sampled responses, thereby maximizing computational efficiency. By combining these components, DynScaling effectively improves LLM performance under practical resource constraints without the need for external verifiers. Experimental results demonstrate that DynScaling consistently surpasses existing verifier-free inference scaling baselines in both task performance and computational cost.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16043",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Each Rank Could be an Expert: Single-Ranked Mixture of Experts LoRA for Multi-Task Learning",
    "description": "arXiv:2501.15103v2 Announce Type: replace-cross Abstract: Low-Rank Adaptation (LoRA) is widely used for adapting large language models (LLMs) to specific domains due to its efficiency and modularity. Meanwhile, vanilla LoRA struggles with task conflicts in multi-task scenarios. Recent works adopt Mixture of Experts (MoE) by treating each LoRA module as an expert, thereby mitigating task interference through multiple specialized LoRA modules. While effective, these methods often isolate knowledge within individual tasks, failing to fully exploit the shared knowledge across related tasks. In this paper, we establish a connection between single LoRA and multi-LoRA MoE, integrating them into a unified framework. We demonstrate that the dynamic routing of multiple LoRAs is functionally equivalent to rank partitioning and block-level activation within a single LoRA. We further empirically demonstrate that finer-grained LoRA partitioning, within the same total and activated parameter constraints, leads to better performance gains across heterogeneous tasks. Building on these findings, we propose Single-ranked Mixture of Experts LoRA (textbf{SMoRA}), which embeds MoE into LoRA by textit{treating each rank as an independent expert}. With a textit{dynamic rank-wise activation} mechanism, SMoRA promotes finer-grained knowledge sharing while mitigating task conflicts. Experiments demonstrate that SMoRA activates fewer parameters yet achieves better performance in multi-task scenarios.",
    "summary": "arXiv:2501.15103v2 Announce Type: replace-cross Abstract: Low-Rank Adaptation (LoRA) is widely used for adapting large language models (LLMs) to specific domains due to its efficiency and modularity. Meanwhile, vanilla LoRA struggles with task conflicts in multi-task scenarios. Recent works adopt Mixture of Experts (MoE) by treating each LoRA module as an expert, thereby mitigating task interference through multiple specialized LoRA modules. While effective, these methods often isolate knowledge within individual tasks, failing to fully exploit the shared knowledge across related tasks. In this paper, we establish a connection between single LoRA and multi-LoRA MoE, integrating them into a unified framework. We demonstrate that the dynamic routing of multiple LoRAs is functionally equivalent to rank partitioning and block-level activation within a single LoRA. We further empirically demonstrate that finer-grained LoRA partitioning, within the same total and activated parameter constraints, leads to better performance gains across heterogeneous tasks. Building on these findings, we propose Single-ranked Mixture of Experts LoRA (textbf{SMoRA}), which embeds MoE into LoRA by textit{treating each rank as an independent expert}. With a textit{dynamic rank-wise activation} mechanism, SMoRA promotes finer-grained knowledge sharing while mitigating task conflicts. Experiments demonstrate that SMoRA activates fewer parameters yet achieves better performance in multi-task scenarios.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2501.15103",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Eau De $Q$-Network: Adaptive Distillation of Neural Networks in Deep Reinforcement Learning",
    "description": "arXiv:2503.01437v2 Announce Type: replace-cross Abstract: Recent works have successfully demonstrated that sparse deep reinforcement learning agents can be competitive against their dense counterparts. This opens up opportunities for reinforcement learning applications in fields where inference time and memory requirements are cost-sensitive or limited by hardware. Until now, dense-to-sparse methods have relied on hand-designed sparsity schedules that are not synchronized with the agent's learning pace. Crucially, the final sparsity level is chosen as a hyperparameter, which requires careful tuning as setting it too high might lead to poor performances. In this work, we address these shortcomings by crafting a dense-to-sparse algorithm that we name Eau De $Q$-Network (EauDeQN). To increase sparsity at the agent's learning pace, we consider multiple online networks with different sparsity levels, where each online network is trained from a shared target network. At each target update, the online network with the smallest loss is chosen as the next target network, while the other networks are replaced by a pruned version of the chosen network. We evaluate the proposed approach on the Atari $2600$ benchmark and the MuJoCo physics simulator, showing that EauDeQN reaches high sparsity levels while keeping performances high.",
    "summary": "arXiv:2503.01437v2 Announce Type: replace-cross Abstract: Recent works have successfully demonstrated that sparse deep reinforcement learning agents can be competitive against their dense counterparts. This opens up opportunities for reinforcement learning applications in fields where inference time and memory requirements are cost-sensitive or limited by hardware. Until now, dense-to-sparse methods have relied on hand-designed sparsity schedules that are not synchronized with the agent's learning pace. Crucially, the final sparsity level is chosen as a hyperparameter, which requires careful tuning as setting it too high might lead to poor performances. In this work, we address these shortcomings by crafting a dense-to-sparse algorithm that we name Eau De $Q$-Network (EauDeQN). To increase sparsity at the agent's learning pace, we consider multiple online networks with different sparsity levels, where each online network is trained from a shared target network. At each target update, the online network with the smallest loss is chosen as the next target network, while the other networks are replaced by a pruned version of the chosen network. We evaluate the proposed approach on the Atari $2600$ benchmark and the MuJoCo physics simulator, showing that EauDeQN reaches high sparsity levels while keeping performances high.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2503.01437",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Efficient and Flexible Neural Network Training through Layer-wise Feedback Propagation",
    "description": "arXiv:2308.12053v3 Announce Type: replace-cross Abstract: Gradient-based optimization has been a cornerstone of machine learning that enabled the vast advances of Artificial Intelligence (AI) development over the past decades. However, this type of optimization requires differentiation, and with recent evidence of the benefits of non-differentiable (e.g. neuromorphic) architectures over classical models w.r.t. efficiency, such constraints can become limiting in the future. We present Layer-wise Feedback Propagation (LFP), a novel training principle for neural network-like predictors that utilizes methods from the domain of explainability to decompose a reward to individual neurons based on their respective contributions. Leveraging these neuron-wise rewards, our method then implements a greedy approach reinforcing helpful parts of the network and weakening harmful ones. While having comparable computational complexity to gradient descent, LFP does not require gradient computation and generates sparse and thereby memory- and energy-efficient parameter updates and models. We establish the convergence of LFP theoretically and empirically, demonstrating its effectiveness on various models and datasets. Via two applications - neural network pruning and the approximation-free training of Spiking Neural Networks (SNNs) - we demonstrate that LFP combines increased efficiency in terms of computation and representation with flexibility w.r.t. choice of model architecture and objective function. Our code is available at https://github.com/leanderweber/layerwise-feedback-propagation.",
    "summary": "arXiv:2308.12053v3 Announce Type: replace-cross Abstract: Gradient-based optimization has been a cornerstone of machine learning that enabled the vast advances of Artificial Intelligence (AI) development over the past decades. However, this type of optimization requires differentiation, and with recent evidence of the benefits of non-differentiable (e.g. neuromorphic) architectures over classical models w.r.t. efficiency, such constraints can become limiting in the future. We present Layer-wise Feedback Propagation (LFP), a novel training principle for neural network-like predictors that utilizes methods from the domain of explainability to decompose a reward to individual neurons based on their respective contributions. Leveraging these neuron-wise rewards, our method then implements a greedy approach reinforcing helpful parts of the network and weakening harmful ones. While having comparable computational complexity to gradient descent, LFP does not require gradient computation and generates sparse and thereby memory- and energy-efficient parameter updates and models. We establish the convergence of LFP theoretically and empirically, demonstrating its effectiveness on various models and datasets. Via two applications - neural network pruning and the approximation-free training of Spiking Neural Networks (SNNs) - we demonstrate that LFP combines increased efficiency in terms of computation and representation with flexibility w.r.t. choice of model architecture and objective function. Our code is available at https://github.com/leanderweber/layerwise-feedback-propagation.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2308.12053",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Efficient but Vulnerable: Benchmarking and Defending LLM Batch Prompting Attack",
    "description": "arXiv:2503.15551v2 Announce Type: replace-cross Abstract: Batch prompting, which combines a batch of multiple queries sharing the same context in one inference, has emerged as a promising solution to reduce inference costs. However, our study reveals a significant security vulnerability in batch prompting: malicious users can inject attack instructions into a batch, leading to unwanted interference across all queries, which can result in the inclusion of harmful content, such as phishing links, or the disruption of logical reasoning. In this paper, we construct BATCHSAFEBENCH, a comprehensive benchmark comprising 150 attack instructions of two types and 8k batch instances, to study the batch prompting vulnerability systematically. Our evaluation of both closed-source and open-weight LLMs demonstrates that all LLMs are susceptible to batch-prompting attacks. We then explore multiple defending approaches. While the prompting-based defense shows limited effectiveness for smaller LLMs, the probing-based approach achieves about 95% accuracy in detecting attacks. Additionally, we perform a mechanistic analysis to understand the attack and identify attention heads that are responsible for it.",
    "summary": "arXiv:2503.15551v2 Announce Type: replace-cross Abstract: Batch prompting, which combines a batch of multiple queries sharing the same context in one inference, has emerged as a promising solution to reduce inference costs. However, our study reveals a significant security vulnerability in batch prompting: malicious users can inject attack instructions into a batch, leading to unwanted interference across all queries, which can result in the inclusion of harmful content, such as phishing links, or the disruption of logical reasoning. In this paper, we construct BATCHSAFEBENCH, a comprehensive benchmark comprising 150 attack instructions of two types and 8k batch instances, to study the batch prompting vulnerability systematically. Our evaluation of both closed-source and open-weight LLMs demonstrates that all LLMs are susceptible to batch-prompting attacks. We then explore multiple defending approaches. While the prompting-based defense shows limited effectiveness for smaller LLMs, the probing-based approach achieves about 95% accuracy in detecting attacks. Additionally, we perform a mechanistic analysis to understand the attack and identify attention heads that are responsible for it.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2503.15551",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Efficient Event-Based Object Detection: A Hybrid Neural Network with Spatial and Temporal Attention",
    "description": "arXiv:2403.10173v4 Announce Type: replace-cross Abstract: Event cameras offer high temporal resolution and dynamic range with minimal motion blur, making them promising for robust object detection. While Spiking Neural Networks (SNNs) on neuromorphic hardware are often considered for energy-efficient and low latency event-based data processing, they often fall short of Artificial Neural Networks (ANNs) in accuracy and flexibility. Here, we introduce Attention-based Hybrid SNN-ANN backbones for event-based object detection to leverage the strengths of both SNN and ANN architectures. A novel Attention-based SNN-ANN bridge module captures sparse spatial and temporal relations from the SNN layer and converts them into dense feature maps for the ANN part of the backbone. Additionally, we present a variant that integrates DWConvL-STMs to the ANN blocks to capture slower dynamics. This multi-timescale network combines fast SNN processing for short timesteps with long-term dense RNN processing, effectively capturing both fast and slow dynamics. Experimental results demonstrate that our proposed method surpasses SNN-based approaches by significant margins, with results comparable to existing ANN and RNN-based methods. Unlike ANN-only networks, the hybrid setup allows us to implement the SNN blocks on digital neuromorphic hardware to investigate the feasibility of our approach. Extensive ablation studies and implementation on neuromorphic hardware confirm the effectiveness of our proposed modules and architectural choices. Our hybrid SNN-ANN architectures pave the way for ANN-like performance at a drastically reduced parameter, latency, and power budget.",
    "summary": "arXiv:2403.10173v4 Announce Type: replace-cross Abstract: Event cameras offer high temporal resolution and dynamic range with minimal motion blur, making them promising for robust object detection. While Spiking Neural Networks (SNNs) on neuromorphic hardware are often considered for energy-efficient and low latency event-based data processing, they often fall short of Artificial Neural Networks (ANNs) in accuracy and flexibility. Here, we introduce Attention-based Hybrid SNN-ANN backbones for event-based object detection to leverage the strengths of both SNN and ANN architectures. A novel Attention-based SNN-ANN bridge module captures sparse spatial and temporal relations from the SNN layer and converts them into dense feature maps for the ANN part of the backbone. Additionally, we present a variant that integrates DWConvL-STMs to the ANN blocks to capture slower dynamics. This multi-timescale network combines fast SNN processing for short timesteps with long-term dense RNN processing, effectively capturing both fast and slow dynamics. Experimental results demonstrate that our proposed method surpasses SNN-based approaches by significant margins, with results comparable to existing ANN and RNN-based methods. Unlike ANN-only networks, the hybrid setup allows us to implement the SNN blocks on digital neuromorphic hardware to investigate the feasibility of our approach. Extensive ablation studies and implementation on neuromorphic hardware confirm the effectiveness of our proposed modules and architectural choices. Our hybrid SNN-ANN architectures pave the way for ANN-like performance at a drastically reduced parameter, latency, and power budget.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2403.10173",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Efficient Mixture-of-Expert for Video-based Driver State and Physiological Multi-task Estimation in Conditional Autonomous Driving",
    "description": "arXiv:2410.21086v2 Announce Type: replace-cross Abstract: Road safety remains a critical challenge worldwide, with approximately 1.35 million fatalities annually attributed to traffic accidents, often due to human errors. As we advance towards higher levels of vehicle automation, challenges still exist, as driving with automation can cognitively over-demand drivers if they engage in non-driving-related tasks (NDRTs), or lead to drowsiness if driving was the sole task. This calls for the urgent need for an effective Driver Monitoring System (DMS) that can evaluate cognitive load and drowsiness in SAE Level-2/3 autonomous driving contexts. In this study, we propose a novel multi-task DMS, termed VDMoE, which leverages RGB video input to monitor driver states non-invasively. By utilizing key facial features to minimize computational load and integrating remote Photoplethysmography (rPPG) for physiological insights, our approach enhances detection accuracy while maintaining efficiency. Additionally, we optimize the Mixture-of-Experts (MoE) framework to accommodate multi-modal inputs and improve performance across different tasks. A novel prior-inclusive regularization method is introduced to align model outputs with statistical priors, thus accelerating convergence and mitigating overfitting risks. We validate our method with the creation of a new dataset (MCDD), which comprises RGB video and physiological indicators from 42 participants, and two public datasets. Our findings demonstrate the effectiveness of VDMoE in monitoring driver states, contributing to safer autonomous driving systems. The code and data will be released.",
    "summary": "arXiv:2410.21086v2 Announce Type: replace-cross Abstract: Road safety remains a critical challenge worldwide, with approximately 1.35 million fatalities annually attributed to traffic accidents, often due to human errors. As we advance towards higher levels of vehicle automation, challenges still exist, as driving with automation can cognitively over-demand drivers if they engage in non-driving-related tasks (NDRTs), or lead to drowsiness if driving was the sole task. This calls for the urgent need for an effective Driver Monitoring System (DMS) that can evaluate cognitive load and drowsiness in SAE Level-2/3 autonomous driving contexts. In this study, we propose a novel multi-task DMS, termed VDMoE, which leverages RGB video input to monitor driver states non-invasively. By utilizing key facial features to minimize computational load and integrating remote Photoplethysmography (rPPG) for physiological insights, our approach enhances detection accuracy while maintaining efficiency. Additionally, we optimize the Mixture-of-Experts (MoE) framework to accommodate multi-modal inputs and improve performance across different tasks. A novel prior-inclusive regularization method is introduced to align model outputs with statistical priors, thus accelerating convergence and mitigating overfitting risks. We validate our method with the creation of a new dataset (MCDD), which comprises RGB video and physiological indicators from 42 participants, and two public datasets. Our findings demonstrate the effectiveness of VDMoE in monitoring driver states, contributing to safer autonomous driving systems. The code and data will be released.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2410.21086",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Efficient Retail Video Annotation: A Robust Key Frame Generation Approach for Product and Customer Interaction Analysis",
    "description": "arXiv:2506.14854v2 Announce Type: replace-cross Abstract: Accurate video annotation plays a vital role in modern retail applications, including customer behavior analysis, product interaction detection, and in-store activity recognition. However, conventional annotation methods heavily rely on time-consuming manual labeling by human annotators, introducing non-robust frame selection and increasing operational costs. To address these challenges in the retail domain, we propose a deep learning-based approach that automates key-frame identification in retail videos and provides automatic annotations of products and customers. Our method leverages deep neural networks to learn discriminative features by embedding video frames and incorporating object detection-based techniques tailored for retail environments. Experimental results showcase the superiority of our approach over traditional methods, achieving accuracy comparable to human annotator labeling while enhancing the overall efficiency of retail video annotation. Remarkably, our approach leads to an average of 2 times cost savings in video annotation. By allowing human annotators to verify/adjust less than 5% of detected frames in the video dataset, while automating the annotation process for the remaining frames without reducing annotation quality, retailers can significantly reduce operational costs. The automation of key-frame detection enables substantial time and effort savings in retail video labeling tasks, proving highly valuable for diverse retail applications such as shopper journey analysis, product interaction detection, and in-store security monitoring.",
    "summary": "arXiv:2506.14854v2 Announce Type: replace-cross Abstract: Accurate video annotation plays a vital role in modern retail applications, including customer behavior analysis, product interaction detection, and in-store activity recognition. However, conventional annotation methods heavily rely on time-consuming manual labeling by human annotators, introducing non-robust frame selection and increasing operational costs. To address these challenges in the retail domain, we propose a deep learning-based approach that automates key-frame identification in retail videos and provides automatic annotations of products and customers. Our method leverages deep neural networks to learn discriminative features by embedding video frames and incorporating object detection-based techniques tailored for retail environments. Experimental results showcase the superiority of our approach over traditional methods, achieving accuracy comparable to human annotator labeling while enhancing the overall efficiency of retail video annotation. Remarkably, our approach leads to an average of 2 times cost savings in video annotation. By allowing human annotators to verify/adjust less than 5% of detected frames in the video dataset, while automating the annotation process for the remaining frames without reducing annotation quality, retailers can significantly reduce operational costs. The automation of key-frame detection enables substantial time and effort savings in retail video labeling tasks, proving highly valuable for diverse retail applications such as shopper journey analysis, product interaction detection, and in-store security monitoring.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.14854",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Efficient Transformations in Deep Learning Convolutional Neural Networks",
    "description": "arXiv:2506.16418v1 Announce Type: cross Abstract: This study investigates the integration of signal processing transformations -- Fast Fourier Transform (FFT), Walsh-Hadamard Transform (WHT), and Discrete Cosine Transform (DCT) -- within the ResNet50 convolutional neural network (CNN) model for image classification. The primary objective is to assess the trade-offs between computational efficiency, energy consumption, and classification accuracy during training and inference. Using the CIFAR-100 dataset (100 classes, 60,000 images), experiments demonstrated that incorporating WHT significantly reduced energy consumption while improving accuracy. Specifically, a baseline ResNet50 model achieved a testing accuracy of 66%, consuming an average of 25,606 kJ per model. In contrast, a modified ResNet50 incorporating WHT in the early convolutional layers achieved 74% accuracy, and an enhanced version with WHT applied to both early and late layers achieved 79% accuracy, with an average energy consumption of only 39 kJ per model. These results demonstrate the potential of WHT as a highly efficient and effective approach for energy-constrained CNN applications.",
    "summary": "arXiv:2506.16418v1 Announce Type: cross Abstract: This study investigates the integration of signal processing transformations -- Fast Fourier Transform (FFT), Walsh-Hadamard Transform (WHT), and Discrete Cosine Transform (DCT) -- within the ResNet50 convolutional neural network (CNN) model for image classification. The primary objective is to assess the trade-offs between computational efficiency, energy consumption, and classification accuracy during training and inference. Using the CIFAR-100 dataset (100 classes, 60,000 images), experiments demonstrated that incorporating WHT significantly reduced energy consumption while improving accuracy. Specifically, a baseline ResNet50 model achieved a testing accuracy of 66%, consuming an average of 25,606 kJ per model. In contrast, a modified ResNet50 incorporating WHT in the early convolutional layers achieved 74% accuracy, and an enhanced version with WHT applied to both early and late layers achieved 79% accuracy, with an average energy consumption of only 39 kJ per model. These results demonstrate the potential of WHT as a highly efficient and effective approach for energy-constrained CNN applications.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16418",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Elevating Styled Mahjong Agents with Learning from Demonstration",
    "description": "arXiv:2506.16995v1 Announce Type: new Abstract: A wide variety of bots in games enriches the gameplay experience and enhances replayability. Recent advancements in game artificial intelligence have predominantly focused on improving the proficiency of bots. Nevertheless, developing highly competent bots with a wide range of distinct play styles remains a relatively under-explored area. We select the Mahjong game environment as a case study. The high degree of randomness inherent in the Mahjong game and the prevalence of out-of-distribution states lead to suboptimal performance of existing offline learning and Learning-from-Demonstration (LfD) algorithms. In this paper, we leverage the gameplay histories of existing Mahjong agents and put forward a novel LfD algorithm that necessitates only minimal modifications to the Proximal Policy Optimization algorithm. The comprehensive empirical results illustrate that our proposed method not only significantly enhances the proficiency of the agents but also effectively preserves their unique play styles.",
    "summary": "arXiv:2506.16995v1 Announce Type: new Abstract: A wide variety of bots in games enriches the gameplay experience and enhances replayability. Recent advancements in game artificial intelligence have predominantly focused on improving the proficiency of bots. Nevertheless, developing highly competent bots with a wide range of distinct play styles remains a relatively under-explored area. We select the Mahjong game environment as a case study. The high degree of randomness inherent in the Mahjong game and the prevalence of out-of-distribution states lead to suboptimal performance of existing offline learning and Learning-from-Demonstration (LfD) algorithms. In this paper, we leverage the gameplay histories of existing Mahjong agents and put forward a novel LfD algorithm that necessitates only minimal modifications to the Proximal Policy Optimization algorithm. The comprehensive empirical results illustrate that our proposed method not only significantly enhances the proficiency of the agents but also effectively preserves their unique play styles.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16995",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Embodied Web Agents: Bridging Physical-Digital Realms for Integrated Agent Intelligence",
    "description": "arXiv:2506.15677v2 Announce Type: replace Abstract: AI agents today are mostly siloed - they either retrieve and reason over vast amount of digital information and knowledge obtained online; or interact with the physical world through embodied perception, planning and action - but rarely both. This separation limits their ability to solve tasks that require integrated physical and digital intelligence, such as cooking from online recipes, navigating with dynamic map data, or interpreting real-world landmarks using web knowledge. We introduce Embodied Web Agents, a novel paradigm for AI agents that fluidly bridge embodiment and web-scale reasoning. To operationalize this concept, we first develop the Embodied Web Agents task environments, a unified simulation platform that tightly integrates realistic 3D indoor and outdoor environments with functional web interfaces. Building upon this platform, we construct and release the Embodied Web Agents Benchmark, which encompasses a diverse suite of tasks including cooking, navigation, shopping, tourism, and geolocation - all requiring coordinated reasoning across physical and digital realms for systematic assessment of cross-domain intelligence. Experimental results reveal significant performance gaps between state-of-the-art AI systems and human capabilities, establishing both challenges and opportunities at the intersection of embodied cognition and web-scale knowledge access. All datasets, codes and websites are publicly available at our project page https://embodied-web-agent.github.io/.",
    "summary": "arXiv:2506.15677v2 Announce Type: replace Abstract: AI agents today are mostly siloed - they either retrieve and reason over vast amount of digital information and knowledge obtained online; or interact with the physical world through embodied perception, planning and action - but rarely both. This separation limits their ability to solve tasks that require integrated physical and digital intelligence, such as cooking from online recipes, navigating with dynamic map data, or interpreting real-world landmarks using web knowledge. We introduce Embodied Web Agents, a novel paradigm for AI agents that fluidly bridge embodiment and web-scale reasoning. To operationalize this concept, we first develop the Embodied Web Agents task environments, a unified simulation platform that tightly integrates realistic 3D indoor and outdoor environments with functional web interfaces. Building upon this platform, we construct and release the Embodied Web Agents Benchmark, which encompasses a diverse suite of tasks including cooking, navigation, shopping, tourism, and geolocation - all requiring coordinated reasoning across physical and digital realms for systematic assessment of cross-domain intelligence. Experimental results reveal significant performance gaps between state-of-the-art AI systems and human capabilities, establishing both challenges and opportunities at the intersection of embodied cognition and web-scale knowledge access. All datasets, codes and websites are publicly available at our project page https://embodied-web-agent.github.io/.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.15677",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Energy-Based Transfer for Reinforcement Learning",
    "description": "arXiv:2506.16590v1 Announce Type: cross Abstract: Reinforcement learning algorithms often suffer from poor sample efficiency, making them challenging to apply in multi-task or continual learning settings. Efficiency can be improved by transferring knowledge from a previously trained teacher policy to guide exploration in new but related tasks. However, if the new task sufficiently differs from the teacher's training task, the transferred guidance may be sub-optimal and bias exploration toward low-reward behaviors. We propose an energy-based transfer learning method that uses out-of-distribution detection to selectively issue guidance, enabling the teacher to intervene only in states within its training distribution. We theoretically show that energy scores reflect the teacher's state-visitation density and empirically demonstrate improved sample efficiency and performance across both single-task and multi-task settings.",
    "summary": "arXiv:2506.16590v1 Announce Type: cross Abstract: Reinforcement learning algorithms often suffer from poor sample efficiency, making them challenging to apply in multi-task or continual learning settings. Efficiency can be improved by transferring knowledge from a previously trained teacher policy to guide exploration in new but related tasks. However, if the new task sufficiently differs from the teacher's training task, the transferred guidance may be sub-optimal and bias exploration toward low-reward behaviors. We propose an energy-based transfer learning method that uses out-of-distribution detection to selectively issue guidance, enabling the teacher to intervene only in states within its training distribution. We theoretically show that energy scores reflect the teacher's state-visitation density and empirically demonstrate improved sample efficiency and performance across both single-task and multi-task settings.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16590",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Enhancing Mathematical Reasoning in Large Language Models with Self-Consistency-Based Hallucination Detection",
    "description": "arXiv:2504.09440v3 Announce Type: replace Abstract: Large language models (LLMs) have demonstrated strong mathematical reasoning capabilities but remain susceptible to hallucinations producing plausible yet incorrect statements especially in theorem proving, symbolic manipulation, and numerical computation. While self-consistency (SC) has been explored as a means to improve factuality in LLMs, existing approaches primarily apply SC to final-answer selection, neglecting the logical consistency of intermediate reasoning steps. In this work, we introduce a structured self-consistency framework designed to enhance the reliability of mathematical reasoning. Our method enforces self-consistency across intermediate steps and final outputs, reducing logical inconsistencies and hallucinations. We evaluate our approach across three core mathematical tasks: theorem proving, symbolic transformation, and numerical computation. Experimental results demonstrate that SC significantly improves proof validity, symbolic reasoning accuracy, and numerical stability while maintaining computational efficiency. Further analysis reveals that structured self-consistency not only enhances problem-solving accuracy but also reduces the variance of model-generated outputs. These findings highlight self-consistency as a robust mechanism for improving mathematical reasoning in LLMs, paving the way for more reliable and interpretable AI-driven mathematics.",
    "summary": "arXiv:2504.09440v3 Announce Type: replace Abstract: Large language models (LLMs) have demonstrated strong mathematical reasoning capabilities but remain susceptible to hallucinations producing plausible yet incorrect statements especially in theorem proving, symbolic manipulation, and numerical computation. While self-consistency (SC) has been explored as a means to improve factuality in LLMs, existing approaches primarily apply SC to final-answer selection, neglecting the logical consistency of intermediate reasoning steps. In this work, we introduce a structured self-consistency framework designed to enhance the reliability of mathematical reasoning. Our method enforces self-consistency across intermediate steps and final outputs, reducing logical inconsistencies and hallucinations. We evaluate our approach across three core mathematical tasks: theorem proving, symbolic transformation, and numerical computation. Experimental results demonstrate that SC significantly improves proof validity, symbolic reasoning accuracy, and numerical stability while maintaining computational efficiency. Further analysis reveals that structured self-consistency not only enhances problem-solving accuracy but also reduces the variance of model-generated outputs. These findings highlight self-consistency as a robust mechanism for improving mathematical reasoning in LLMs, paving the way for more reliable and interpretable AI-driven mathematics.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2504.09440",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Enhancing Step-by-Step and Verifiable Medical Reasoning in MLLMs",
    "description": "arXiv:2506.16962v1 Announce Type: cross Abstract: Multimodal large language models (MLLMs) have begun to demonstrate robust reasoning capabilities on general tasks, yet their application in the medical domain remains in its early stages. Constructing chain-of-thought (CoT) training data is essential for bolstering the reasoning abilities of medical MLLMs. However, existing approaches exhibit a deficiency in offering a comprehensive framework for searching and evaluating effective reasoning paths towards critical diagnosis. To address this challenge, we propose Mentor-Intern Collaborative Search (MICS), a novel reasoning-path searching scheme to generate rigorous and effective medical CoT data. MICS first leverages mentor models to initialize the reasoning, one step at a time, then prompts each intern model to continue the thinking along those initiated paths, and finally selects the optimal reasoning path according to the overall reasoning performance of multiple intern models. The reasoning performance is determined by an MICS-Score, which assesses the quality of generated reasoning paths. Eventually, we construct MMRP, a multi-task medical reasoning dataset with ranked difficulty, and Chiron-o1, a new medical MLLM devised via a curriculum learning strategy, with robust visual question-answering and generalizable reasoning capabilities. Extensive experiments demonstrate that Chiron-o1, trained on our CoT dataset constructed using MICS, achieves state-of-the-art performance across a list of medical visual question answering and reasoning benchmarks. Codes are available at GitHub - manglu097/Chiron-o1: Enhancing Step-by-Step and Verifiable Medical Reasoning in MLLMs",
    "summary": "arXiv:2506.16962v1 Announce Type: cross Abstract: Multimodal large language models (MLLMs) have begun to demonstrate robust reasoning capabilities on general tasks, yet their application in the medical domain remains in its early stages. Constructing chain-of-thought (CoT) training data is essential for bolstering the reasoning abilities of medical MLLMs. However, existing approaches exhibit a deficiency in offering a comprehensive framework for searching and evaluating effective reasoning paths towards critical diagnosis. To address this challenge, we propose Mentor-Intern Collaborative Search (MICS), a novel reasoning-path searching scheme to generate rigorous and effective medical CoT data. MICS first leverages mentor models to initialize the reasoning, one step at a time, then prompts each intern model to continue the thinking along those initiated paths, and finally selects the optimal reasoning path according to the overall reasoning performance of multiple intern models. The reasoning performance is determined by an MICS-Score, which assesses the quality of generated reasoning paths. Eventually, we construct MMRP, a multi-task medical reasoning dataset with ranked difficulty, and Chiron-o1, a new medical MLLM devised via a curriculum learning strategy, with robust visual question-answering and generalizable reasoning capabilities. Extensive experiments demonstrate that Chiron-o1, trained on our CoT dataset constructed using MICS, achieves state-of-the-art performance across a list of medical visual question answering and reasoning benchmarks. Codes are available at GitHub - manglu097/Chiron-o1: Enhancing Step-by-Step and Verifiable Medical Reasoning in MLLMs",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16962",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Essential-Web v1.0: 24T tokens of organized web data",
    "description": "arXiv:2506.14111v2 Announce Type: replace-cross Abstract: Data plays the most prominent role in how language models acquire skills and knowledge. The lack of massive, well-organized pre-training datasets results in costly and inaccessible data pipelines. We present Essential-Web v1.0, a 24-trillion-token dataset in which every document is annotated with a twelve-category taxonomy covering topic, format, content complexity, and quality. Taxonomy labels are produced by EAI-Distill-0.5b, a fine-tuned 0.5b-parameter model that achieves an annotator agreement within 3% of Qwen2.5-32B-Instruct. With nothing more than SQL-style filters, we obtain competitive web-curated datasets in math (-8.0% relative to SOTA), web code (+14.3%), STEM (+24.5%) and medical (+8.6%). Essential-Web v1.0 is available on HuggingFace: https://huggingface.co/datasets/EssentialAI/essential-web-v1.0",
    "summary": "arXiv:2506.14111v2 Announce Type: replace-cross Abstract: Data plays the most prominent role in how language models acquire skills and knowledge. The lack of massive, well-organized pre-training datasets results in costly and inaccessible data pipelines. We present Essential-Web v1.0, a 24-trillion-token dataset in which every document is annotated with a twelve-category taxonomy covering topic, format, content complexity, and quality. Taxonomy labels are produced by EAI-Distill-0.5b, a fine-tuned 0.5b-parameter model that achieves an annotator agreement within 3% of Qwen2.5-32B-Instruct. With nothing more than SQL-style filters, we obtain competitive web-curated datasets in math (-8.0% relative to SOTA), web code (+14.3%), STEM (+24.5%) and medical (+8.6%). Essential-Web v1.0 is available on HuggingFace: https://huggingface.co/datasets/EssentialAI/essential-web-v1.0",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.14111",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Every Rollout Counts: Optimal Resource Allocation for Efficient Test-Time Scaling",
    "description": "arXiv:2506.15707v1 Announce Type: cross Abstract: Test-Time Scaling (TTS) improves the performance of Large Language Models (LLMs) by using additional inference-time computation to explore multiple reasoning paths through search. Yet how to allocate a fixed rollout budget most effectively during search remains underexplored, often resulting in inefficient use of compute at test time. To bridge this gap, we formulate test-time search as a resource allocation problem and derive the optimal allocation strategy that maximizes the probability of obtaining a correct solution under a fixed rollout budget. Within this formulation, we reveal a core limitation of existing search methods: solution-level allocation tends to favor reasoning directions with more candidates, leading to theoretically suboptimal and inefficient use of compute. To address this, we propose Direction-Oriented Resource Allocation (DORA), a provably optimal method that mitigates this bias by decoupling direction quality from candidate count and allocating resources at the direction level. To demonstrate DORA's effectiveness, we conduct extensive experiments on challenging mathematical reasoning benchmarks including MATH500, AIME2024, and AIME2025. The empirical results show that DORA consistently outperforms strong baselines with comparable computational cost, achieving state-of-the-art accuracy. We hope our findings contribute to a broader understanding of optimal TTS for LLMs.",
    "summary": "arXiv:2506.15707v1 Announce Type: cross Abstract: Test-Time Scaling (TTS) improves the performance of Large Language Models (LLMs) by using additional inference-time computation to explore multiple reasoning paths through search. Yet how to allocate a fixed rollout budget most effectively during search remains underexplored, often resulting in inefficient use of compute at test time. To bridge this gap, we formulate test-time search as a resource allocation problem and derive the optimal allocation strategy that maximizes the probability of obtaining a correct solution under a fixed rollout budget. Within this formulation, we reveal a core limitation of existing search methods: solution-level allocation tends to favor reasoning directions with more candidates, leading to theoretically suboptimal and inefficient use of compute. To address this, we propose Direction-Oriented Resource Allocation (DORA), a provably optimal method that mitigates this bias by decoupling direction quality from candidate count and allocating resources at the direction level. To demonstrate DORA's effectiveness, we conduct extensive experiments on challenging mathematical reasoning benchmarks including MATH500, AIME2024, and AIME2025. The empirical results show that DORA consistently outperforms strong baselines with comparable computational cost, achieving state-of-the-art accuracy. We hope our findings contribute to a broader understanding of optimal TTS for LLMs.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.15707",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "EvoLM: In Search of Lost Language Model Training Dynamics",
    "description": "arXiv:2506.16029v1 Announce Type: cross Abstract: Modern language model (LM) training has been divided into multiple stages, making it difficult for downstream developers to evaluate the impact of design choices made at each stage. We present EvoLM, a model suite that enables systematic and transparent analysis of LMs' training dynamics across pre-training, continued pre-training, supervised fine-tuning, and reinforcement learning. By training over 100 LMs with 1B and 4B parameters from scratch, we rigorously evaluate both upstream (language modeling) and downstream (problem-solving) reasoning capabilities, including considerations of both in-domain and out-of-domain generalization. Key insights highlight the diminishing returns from excessive pre-training and post-training, the importance and practices of mitigating forgetting during domain-specific continued pre-training, the crucial role of continued pre-training in bridging pre-training and post-training phases, and various intricate trade-offs when configuring supervised fine-tuning and reinforcement learning. To facilitate open research and reproducibility, we release all pre-trained and post-trained models, training datasets for all stages, and our entire training and evaluation pipeline.",
    "summary": "arXiv:2506.16029v1 Announce Type: cross Abstract: Modern language model (LM) training has been divided into multiple stages, making it difficult for downstream developers to evaluate the impact of design choices made at each stage. We present EvoLM, a model suite that enables systematic and transparent analysis of LMs' training dynamics across pre-training, continued pre-training, supervised fine-tuning, and reinforcement learning. By training over 100 LMs with 1B and 4B parameters from scratch, we rigorously evaluate both upstream (language modeling) and downstream (problem-solving) reasoning capabilities, including considerations of both in-domain and out-of-domain generalization. Key insights highlight the diminishing returns from excessive pre-training and post-training, the importance and practices of mitigating forgetting during domain-specific continued pre-training, the crucial role of continued pre-training in bridging pre-training and post-training phases, and various intricate trade-offs when configuring supervised fine-tuning and reinforcement learning. To facilitate open research and reproducibility, we release all pre-trained and post-trained models, training datasets for all stages, and our entire training and evaluation pipeline.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16029",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Explainable Rule Application via Structured Prompting: A Neural-Symbolic Approach",
    "description": "arXiv:2506.16335v1 Announce Type: new Abstract: Large Language Models (LLMs) excel in complex reasoning tasks but struggle with consistent rule application, exception handling, and explainability, particularly in domains like legal analysis that require both natural language understanding and precise logical inference. This paper introduces a structured prompting framework that decomposes reasoning into three verifiable steps: entity identification, property extraction, and symbolic rule application. By integrating neural and symbolic approaches, our method leverages LLMs' interpretive flexibility while ensuring logical consistency through formal verification. The framework externalizes task definitions, enabling domain experts to refine logical structures without altering the architecture. Evaluated on the LegalBench hearsay determination task, our approach significantly outperformed baselines, with OpenAI o-family models showing substantial improvements - o1 achieving an F1 score of 0.929 and o3-mini reaching 0.867 using structured decomposition with complementary predicates, compared to their few-shot baselines of 0.714 and 0.74 respectively. This hybrid neural-symbolic system offers a promising pathway for transparent and consistent rule-based reasoning, suggesting potential for explainable AI applications in structured legal reasoning tasks.",
    "summary": "arXiv:2506.16335v1 Announce Type: new Abstract: Large Language Models (LLMs) excel in complex reasoning tasks but struggle with consistent rule application, exception handling, and explainability, particularly in domains like legal analysis that require both natural language understanding and precise logical inference. This paper introduces a structured prompting framework that decomposes reasoning into three verifiable steps: entity identification, property extraction, and symbolic rule application. By integrating neural and symbolic approaches, our method leverages LLMs' interpretive flexibility while ensuring logical consistency through formal verification. The framework externalizes task definitions, enabling domain experts to refine logical structures without altering the architecture. Evaluated on the LegalBench hearsay determination task, our approach significantly outperformed baselines, with OpenAI o-family models showing substantial improvements - o1 achieving an F1 score of 0.929 and o3-mini reaching 0.867 using structured decomposition with complementary predicates, compared to their few-shot baselines of 0.714 and 0.74 respectively. This hybrid neural-symbolic system offers a promising pathway for transparent and consistent rule-based reasoning, suggesting potential for explainable AI applications in structured legal reasoning tasks.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16335",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Exploring Big Five Personality and AI Capability Effects in LLM-Simulated Negotiation Dialogues",
    "description": "arXiv:2506.15928v1 Announce Type: new Abstract: This paper presents an evaluation framework for agentic AI systems in mission-critical negotiation contexts, addressing the need for AI agents that can adapt to diverse human operators and stakeholders. Using Sotopia as a simulation testbed, we present two experiments that systematically evaluated how personality traits and AI agent characteristics influence LLM-simulated social negotiation outcomes--a capability essential for a variety of applications involving cross-team coordination and civil-military interactions. Experiment 1 employs causal discovery methods to measure how personality traits impact price bargaining negotiations, through which we found that Agreeableness and Extraversion significantly affect believability, goal achievement, and knowledge acquisition outcomes. Sociocognitive lexical measures extracted from team communications detected fine-grained differences in agents' empathic communication, moral foundations, and opinion patterns, providing actionable insights for agentic AI systems that must operate reliably in high-stakes operational scenarios. Experiment 2 evaluates human-AI job negotiations by manipulating both simulated human personality and AI system characteristics, specifically transparency, competence, adaptability, demonstrating how AI agent trustworthiness impact mission effectiveness. These findings establish a repeatable evaluation methodology for experimenting with AI agent reliability across diverse operator personalities and human-agent team dynamics, directly supporting operational requirements for reliable AI systems. Our work advances the evaluation of agentic AI workflows by moving beyond standard performance metrics to incorporate social dynamics essential for mission success in complex operations.",
    "summary": "arXiv:2506.15928v1 Announce Type: new Abstract: This paper presents an evaluation framework for agentic AI systems in mission-critical negotiation contexts, addressing the need for AI agents that can adapt to diverse human operators and stakeholders. Using Sotopia as a simulation testbed, we present two experiments that systematically evaluated how personality traits and AI agent characteristics influence LLM-simulated social negotiation outcomes--a capability essential for a variety of applications involving cross-team coordination and civil-military interactions. Experiment 1 employs causal discovery methods to measure how personality traits impact price bargaining negotiations, through which we found that Agreeableness and Extraversion significantly affect believability, goal achievement, and knowledge acquisition outcomes. Sociocognitive lexical measures extracted from team communications detected fine-grained differences in agents' empathic communication, moral foundations, and opinion patterns, providing actionable insights for agentic AI systems that must operate reliably in high-stakes operational scenarios. Experiment 2 evaluates human-AI job negotiations by manipulating both simulated human personality and AI system characteristics, specifically transparency, competence, adaptability, demonstrating how AI agent trustworthiness impact mission effectiveness. These findings establish a repeatable evaluation methodology for experimenting with AI agent reliability across diverse operator personalities and human-agent team dynamics, directly supporting operational requirements for reliable AI systems. Our work advances the evaluation of agentic AI workflows by moving beyond standard performance metrics to incorporate social dynamics essential for mission success in complex operations.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.15928",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Facial Landmark Visualization and Emotion Recognition Through Neural Networks",
    "description": "arXiv:2506.17191v1 Announce Type: cross Abstract: Emotion recognition from facial images is a crucial task in human-computer interaction, enabling machines to learn human emotions through facial expressions. Previous studies have shown that facial images can be used to train deep learning models; however, most of these studies do not include a through dataset analysis. Visualizing facial landmarks can be challenging when extracting meaningful dataset insights; to address this issue, we propose facial landmark box plots, a visualization technique designed to identify outliers in facial datasets. Additionally, we compare two sets of facial landmark features: (i) the landmarks' absolute positions and (ii) their displacements from a neutral expression to the peak of an emotional expression. Our results indicate that a neural network achieves better performance than a random forest classifier.",
    "summary": "arXiv:2506.17191v1 Announce Type: cross Abstract: Emotion recognition from facial images is a crucial task in human-computer interaction, enabling machines to learn human emotions through facial expressions. Previous studies have shown that facial images can be used to train deep learning models; however, most of these studies do not include a through dataset analysis. Visualizing facial landmarks can be challenging when extracting meaningful dataset insights; to address this issue, we propose facial landmark box plots, a visualization technique designed to identify outliers in facial datasets. Additionally, we compare two sets of facial landmark features: (i) the landmarks' absolute positions and (ii) their displacements from a neutral expression to the peak of an emotional expression. Our results indicate that a neural network achieves better performance than a random forest classifier.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.17191",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "FALCON: Feedback-driven Adaptive Long/short-term memory reinforced Coding Optimization system",
    "description": "arXiv:2410.21349v5 Announce Type: replace-cross Abstract: Recently, large language models (LLMs) have achieved significant progress in automated code generation. Despite their strong instruction-following capabilities, these models frequently struggled to align with user intent in coding scenarios. In particular, they were hampered by datasets that lacked diversity and failed to address specialized tasks or edge cases. Furthermore, challenges in supervised fine-tuning (SFT) and reinforcement learning from human feedback (RLHF) led to failures in generating precise, human-intent-aligned code. To tackle these challenges and improve the code generation performance for automated programming systems, we propose Feedback-driven Adaptive Long/short-term memory reinforced Coding Optimization (i.e., FALCON). FALCON is structured into two hierarchical levels. From the global level, long-term memory improves code quality by retaining and applying learned knowledge. At the local level, short-term memory allows for the incorporation of immediate feedback from compilers and AI systems. Additionally, we introduce meta-reinforcement learning with feedback rewards to solve the global-local bi-level optimization problem and enhance the model's adaptability across diverse code generation tasks. Extensive experiments demonstrate that our technique achieves state-of-the-art performance, leading other reinforcement learning methods by more than 4.5 percentage points on the MBPP benchmark and 6.1 percentage points on the Humaneval benchmark. The open-sourced code is publicly available at https://github.com/titurte/FALCON.",
    "summary": "arXiv:2410.21349v5 Announce Type: replace-cross Abstract: Recently, large language models (LLMs) have achieved significant progress in automated code generation. Despite their strong instruction-following capabilities, these models frequently struggled to align with user intent in coding scenarios. In particular, they were hampered by datasets that lacked diversity and failed to address specialized tasks or edge cases. Furthermore, challenges in supervised fine-tuning (SFT) and reinforcement learning from human feedback (RLHF) led to failures in generating precise, human-intent-aligned code. To tackle these challenges and improve the code generation performance for automated programming systems, we propose Feedback-driven Adaptive Long/short-term memory reinforced Coding Optimization (i.e., FALCON). FALCON is structured into two hierarchical levels. From the global level, long-term memory improves code quality by retaining and applying learned knowledge. At the local level, short-term memory allows for the incorporation of immediate feedback from compilers and AI systems. Additionally, we introduce meta-reinforcement learning with feedback rewards to solve the global-local bi-level optimization problem and enhance the model's adaptability across diverse code generation tasks. Extensive experiments demonstrate that our technique achieves state-of-the-art performance, leading other reinforcement learning methods by more than 4.5 percentage points on the MBPP benchmark and 6.1 percentage points on the Humaneval benchmark. The open-sourced code is publicly available at https://github.com/titurte/FALCON.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2410.21349",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Fast and Stable Diffusion Planning through Variational Adaptive Weighting",
    "description": "arXiv:2506.16688v1 Announce Type: cross Abstract: Diffusion models have recently shown promise in offline RL. However, these methods often suffer from high training costs and slow convergence, particularly when using transformer-based denoising backbones. While several optimization strategies have been proposed -- such as modified noise schedules, auxiliary prediction targets, and adaptive loss weighting -- challenges remain in achieving stable and efficient training. In particular, existing loss weighting functions typically rely on neural network approximators, which can be ineffective in early training phases due to limited generalization capacity of MLPs when exposed to sparse feedback in the early training stages. In this work, we derive a variationally optimal uncertainty-aware weighting function and introduce a closed-form polynomial approximation method for its online estimation under the flow-based generative modeling framework. We integrate our method into a diffusion planning pipeline and evaluate it on standard offline RL benchmarks. Experimental results on Maze2D and Kitchen tasks show that our method achieves competitive performance with up to 10 times fewer training steps, highlighting its practical effectiveness.",
    "summary": "arXiv:2506.16688v1 Announce Type: cross Abstract: Diffusion models have recently shown promise in offline RL. However, these methods often suffer from high training costs and slow convergence, particularly when using transformer-based denoising backbones. While several optimization strategies have been proposed -- such as modified noise schedules, auxiliary prediction targets, and adaptive loss weighting -- challenges remain in achieving stable and efficient training. In particular, existing loss weighting functions typically rely on neural network approximators, which can be ineffective in early training phases due to limited generalization capacity of MLPs when exposed to sparse feedback in the early training stages. In this work, we derive a variationally optimal uncertainty-aware weighting function and introduce a closed-form polynomial approximation method for its online estimation under the flow-based generative modeling framework. We integrate our method into a diffusion planning pipeline and evaluate it on standard offline RL benchmarks. Experimental results on Maze2D and Kitchen tasks show that our method achieves competitive performance with up to 10 times fewer training steps, highlighting its practical effectiveness.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16688",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "FDLLM: A Dedicated Detector for Black-Box LLMs Fingerprinting",
    "description": "arXiv:2501.16029v3 Announce Type: replace-cross Abstract: Large Language Models (LLMs) are rapidly transforming the landscape of digital content creation. However, the prevalent black-box Application Programming Interface (API) access to many LLMs introduces significant challenges in accountability, governance, and security. LLM fingerprinting, which aims to identify the source model by analyzing statistical and stylistic features of generated text, offers a potential solution. Current progress in this area is hindered by a lack of dedicated datasets and the need for efficient, practical methods that are robust against adversarial manipulations. To address these challenges, we introduce FD-Dataset, a comprehensive bilingual fingerprinting benchmark comprising 90,000 text samples from 20 famous proprietary and open-source LLMs. Furthermore, we present FDLLM, a novel fingerprinting method that leverages parameter-efficient Low-Rank Adaptation (LoRA) to fine-tune a foundation model. This approach enables LoRA to extract deep, persistent features that characterize each source LLM. Through our analysis, we find that LoRA adaptation promotes the aggregation of outputs from the same LLM in representation space while enhancing the separation between different LLMs. This mechanism explains why LoRA proves particularly effective for LLM fingerprinting. Extensive empirical evaluations on FD-Dataset demonstrate FDLLM's superiority, achieving a Macro F1 score 22.1% higher than the strongest baseline. FDLLM also exhibits strong generalization to newly released models, achieving an average accuracy of 95% on unseen models. Notably, FDLLM remains consistently robust under various adversarial attacks, including polishing, translation, and synonym substitution. Experimental results show that FDLLM reduces the average attack success rate from 49.2% (LM-D) to 23.9%.",
    "summary": "arXiv:2501.16029v3 Announce Type: replace-cross Abstract: Large Language Models (LLMs) are rapidly transforming the landscape of digital content creation. However, the prevalent black-box Application Programming Interface (API) access to many LLMs introduces significant challenges in accountability, governance, and security. LLM fingerprinting, which aims to identify the source model by analyzing statistical and stylistic features of generated text, offers a potential solution. Current progress in this area is hindered by a lack of dedicated datasets and the need for efficient, practical methods that are robust against adversarial manipulations. To address these challenges, we introduce FD-Dataset, a comprehensive bilingual fingerprinting benchmark comprising 90,000 text samples from 20 famous proprietary and open-source LLMs. Furthermore, we present FDLLM, a novel fingerprinting method that leverages parameter-efficient Low-Rank Adaptation (LoRA) to fine-tune a foundation model. This approach enables LoRA to extract deep, persistent features that characterize each source LLM. Through our analysis, we find that LoRA adaptation promotes the aggregation of outputs from the same LLM in representation space while enhancing the separation between different LLMs. This mechanism explains why LoRA proves particularly effective for LLM fingerprinting. Extensive empirical evaluations on FD-Dataset demonstrate FDLLM's superiority, achieving a Macro F1 score 22.1% higher than the strongest baseline. FDLLM also exhibits strong generalization to newly released models, achieving an average accuracy of 95% on unseen models. Notably, FDLLM remains consistently robust under various adversarial attacks, including polishing, translation, and synonym substitution. Experimental results show that FDLLM reduces the average attack success rate from 49.2% (LM-D) to 23.9%.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2501.16029",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Federated Incomplete Multi-view Clustering with Globally Fused Graph Guidance",
    "description": "arXiv:2506.15703v1 Announce Type: cross Abstract: Federated multi-view clustering has been proposed to mine the valuable information within multi-view data distributed across different devices and has achieved impressive results while preserving the privacy. Despite great progress, most federated multi-view clustering methods only used global pseudo-labels to guide the downstream clustering process and failed to exploit the global information when extracting features. In addition, missing data problem in federated multi-view clustering task is less explored. To address these problems, we propose a novel Federated Incomplete Multi-view Clustering method with globally Fused Graph guidance (FIMCFG). Specifically, we designed a dual-head graph convolutional encoder at each client to extract two kinds of underlying features containing global and view-specific information. Subsequently, under the guidance of the fused graph, the two underlying features are fused into high-level features, based on which clustering is conducted under the supervision of pseudo-labeling. Finally, the high-level features are uploaded to the server to refine the graph fusion and pseudo-labeling computation. Extensive experimental results demonstrate the effectiveness and superiority of FIMCFG. Our code is publicly available at https://github.com/PaddiHunter/FIMCFG.",
    "summary": "arXiv:2506.15703v1 Announce Type: cross Abstract: Federated multi-view clustering has been proposed to mine the valuable information within multi-view data distributed across different devices and has achieved impressive results while preserving the privacy. Despite great progress, most federated multi-view clustering methods only used global pseudo-labels to guide the downstream clustering process and failed to exploit the global information when extracting features. In addition, missing data problem in federated multi-view clustering task is less explored. To address these problems, we propose a novel Federated Incomplete Multi-view Clustering method with globally Fused Graph guidance (FIMCFG). Specifically, we designed a dual-head graph convolutional encoder at each client to extract two kinds of underlying features containing global and view-specific information. Subsequently, under the guidance of the fused graph, the two underlying features are fused into high-level features, based on which clustering is conducted under the supervision of pseudo-labeling. Finally, the high-level features are uploaded to the server to refine the graph fusion and pseudo-labeling computation. Extensive experimental results demonstrate the effectiveness and superiority of FIMCFG. Our code is publicly available at https://github.com/PaddiHunter/FIMCFG.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.15703",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Federated Learning for MRI-based BrainAGE: a multicenter study on post-stroke functional outcome prediction",
    "description": "arXiv:2506.15626v2 Announce Type: replace-cross Abstract: $textbf{Objective:}$ Brain-predicted age difference (BrainAGE) is a neuroimaging biomarker reflecting brain health. However, training robust BrainAGE models requires large datasets, often restricted by privacy concerns. This study evaluates the performance of federated learning (FL) for BrainAGE estimation in ischemic stroke patients treated with mechanical thrombectomy, and investigates its association with clinical phenotypes and functional outcomes. $textbf{Methods:}$ We used FLAIR brain images from 1674 stroke patients across 16 hospital centers. We implemented standard machine learning and deep learning models for BrainAGE estimates under three data management strategies: centralized learning (pooled data), FL (local training at each site), and single-site learning. We reported prediction errors and examined associations between BrainAGE and vascular risk factors (e.g., diabetes mellitus, hypertension, smoking), as well as functional outcomes at three months post-stroke. Logistic regression evaluated BrainAGE's predictive value for these outcomes, adjusting for age, sex, vascular risk factors, stroke severity, time between MRI and arterial puncture, prior intravenous thrombolysis, and recanalisation outcome. $textbf{Results:}$ While centralized learning yielded the most accurate predictions, FL consistently outperformed single-site models. BrainAGE was significantly higher in patients with diabetes mellitus across all models. Comparisons between patients with good and poor functional outcomes, and multivariate predictions of these outcomes showed the significance of the association between BrainAGE and post-stroke recovery. $textbf{Conclusion:}$ FL enables accurate age predictions without data centralization. The strong association between BrainAGE, vascular risk factors, and post-stroke recovery highlights its potential for prognostic modeling in stroke care.",
    "summary": "arXiv:2506.15626v2 Announce Type: replace-cross Abstract: $textbf{Objective:}$ Brain-predicted age difference (BrainAGE) is a neuroimaging biomarker reflecting brain health. However, training robust BrainAGE models requires large datasets, often restricted by privacy concerns. This study evaluates the performance of federated learning (FL) for BrainAGE estimation in ischemic stroke patients treated with mechanical thrombectomy, and investigates its association with clinical phenotypes and functional outcomes. $textbf{Methods:}$ We used FLAIR brain images from 1674 stroke patients across 16 hospital centers. We implemented standard machine learning and deep learning models for BrainAGE estimates under three data management strategies: centralized learning (pooled data), FL (local training at each site), and single-site learning. We reported prediction errors and examined associations between BrainAGE and vascular risk factors (e.g., diabetes mellitus, hypertension, smoking), as well as functional outcomes at three months post-stroke. Logistic regression evaluated BrainAGE's predictive value for these outcomes, adjusting for age, sex, vascular risk factors, stroke severity, time between MRI and arterial puncture, prior intravenous thrombolysis, and recanalisation outcome. $textbf{Results:}$ While centralized learning yielded the most accurate predictions, FL consistently outperformed single-site models. BrainAGE was significantly higher in patients with diabetes mellitus across all models. Comparisons between patients with good and poor functional outcomes, and multivariate predictions of these outcomes showed the significance of the association between BrainAGE and post-stroke recovery. $textbf{Conclusion:}$ FL enables accurate age predictions without data centralization. The strong association between BrainAGE, vascular risk factors, and post-stroke recovery highlights its potential for prognostic modeling in stroke care.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.15626",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Finance Language Model Evaluation (FLaME)",
    "description": "arXiv:2506.15846v1 Announce Type: cross Abstract: Language Models (LMs) have demonstrated impressive capabilities with core Natural Language Processing (NLP) tasks. The effectiveness of LMs for highly specialized knowledge-intensive tasks in finance remains difficult to assess due to major gaps in the methodologies of existing evaluation frameworks, which have caused an erroneous belief in a far lower bound of LMs' performance on common Finance NLP (FinNLP) tasks. To demonstrate the potential of LMs for these FinNLP tasks, we present the first holistic benchmarking suite for Financial Language Model Evaluation (FLaME). We are the first research paper to comprehensively study LMs against 'reasoning-reinforced' LMs, with an empirical study of 23 foundation LMs over 20 core NLP tasks in finance. We open-source our framework software along with all data and results.",
    "summary": "arXiv:2506.15846v1 Announce Type: cross Abstract: Language Models (LMs) have demonstrated impressive capabilities with core Natural Language Processing (NLP) tasks. The effectiveness of LMs for highly specialized knowledge-intensive tasks in finance remains difficult to assess due to major gaps in the methodologies of existing evaluation frameworks, which have caused an erroneous belief in a far lower bound of LMs' performance on common Finance NLP (FinNLP) tasks. To demonstrate the potential of LMs for these FinNLP tasks, we present the first holistic benchmarking suite for Financial Language Model Evaluation (FLaME). We are the first research paper to comprehensively study LMs against 'reasoning-reinforced' LMs, with an empirical study of 23 foundation LMs over 20 core NLP tasks in finance. We open-source our framework software along with all data and results.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.15846",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "FLAME: Towards Federated Fine-Tuning Large Language Models Through Adaptive SMoE",
    "description": "arXiv:2506.16600v1 Announce Type: cross Abstract: Existing resource-adaptive LoRA federated fine-tuning methods enable clients to fine-tune models using compressed versions of global LoRA matrices, in order to accommodate various compute resources across clients. This compression requirement will lead to suboptimal performance due to information loss. To address this, we propose FLAME, a novel federated learning framework based on the Sparse Mixture-of-Experts (SMoE) architecture. Unlike prior approaches, FLAME retains full (uncompressed) global LoRA matrices and achieves client-side adaptability by varying the number of activated experts per client. However, incorporating SMoE into federated learning introduces unique challenges, specifically, the mismatch in output magnitude from partial expert activation and the imbalance in expert training quality across clients. FLAME tackles these challenges through a lightweight rescaling mechanism and an activation-aware aggregation scheme. Empirical results across diverse computational settings demonstrate that FLAME consistently outperforms existing methods, providing a robust and effective solution for resource-adaptive federated learning.",
    "summary": "arXiv:2506.16600v1 Announce Type: cross Abstract: Existing resource-adaptive LoRA federated fine-tuning methods enable clients to fine-tune models using compressed versions of global LoRA matrices, in order to accommodate various compute resources across clients. This compression requirement will lead to suboptimal performance due to information loss. To address this, we propose FLAME, a novel federated learning framework based on the Sparse Mixture-of-Experts (SMoE) architecture. Unlike prior approaches, FLAME retains full (uncompressed) global LoRA matrices and achieves client-side adaptability by varying the number of activated experts per client. However, incorporating SMoE into federated learning introduces unique challenges, specifically, the mismatch in output magnitude from partial expert activation and the imbalance in expert training quality across clients. FLAME tackles these challenges through a lightweight rescaling mechanism and an activation-aware aggregation scheme. Empirical results across diverse computational settings demonstrate that FLAME consistently outperforms existing methods, providing a robust and effective solution for resource-adaptive federated learning.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16600",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Flow-Based Non-stationary Temporal Regime Causal Structure Learning",
    "description": "arXiv:2506.17065v1 Announce Type: cross Abstract: Understanding causal relationships in multivariate time series is crucial in many scenarios, such as those dealing with financial or neurological data. Many such time series exhibit multiple regimes, i.e., consecutive temporal segments with a priori unknown boundaries, with each regime having its own causal structure. Inferring causal dependencies and regime shifts is critical for analyzing the underlying processes. However, causal structure learning in this setting is challenging due to (1) non stationarity, i.e., each regime can have its own causal graph and mixing function, and (2) complex noise distributions, which may be non Gaussian or heteroscedastic. Existing causal discovery approaches cannot address these challenges, since generally assume stationarity or Gaussian noise with constant variance. Hence, we introduce FANTOM, a unified framework for causal discovery that handles non stationary processes along with non Gaussian and heteroscedastic noises. FANTOM simultaneously infers the number of regimes and their corresponding indices and learns each regime's Directed Acyclic Graph. It uses a Bayesian Expectation Maximization algorithm that maximizes the evidence lower bound of the data log likelihood. On the theoretical side, we prove, under mild assumptions, that temporal heteroscedastic causal models, introduced in FANTOM's formulation, are identifiable in both stationary and non stationary settings. In addition, extensive experiments on synthetic and real data show that FANTOM outperforms existing methods.",
    "summary": "arXiv:2506.17065v1 Announce Type: cross Abstract: Understanding causal relationships in multivariate time series is crucial in many scenarios, such as those dealing with financial or neurological data. Many such time series exhibit multiple regimes, i.e., consecutive temporal segments with a priori unknown boundaries, with each regime having its own causal structure. Inferring causal dependencies and regime shifts is critical for analyzing the underlying processes. However, causal structure learning in this setting is challenging due to (1) non stationarity, i.e., each regime can have its own causal graph and mixing function, and (2) complex noise distributions, which may be non Gaussian or heteroscedastic. Existing causal discovery approaches cannot address these challenges, since generally assume stationarity or Gaussian noise with constant variance. Hence, we introduce FANTOM, a unified framework for causal discovery that handles non stationary processes along with non Gaussian and heteroscedastic noises. FANTOM simultaneously infers the number of regimes and their corresponding indices and learns each regime's Directed Acyclic Graph. It uses a Bayesian Expectation Maximization algorithm that maximizes the evidence lower bound of the data log likelihood. On the theoretical side, we prove, under mild assumptions, that temporal heteroscedastic causal models, introduced in FANTOM's formulation, are identifiable in both stationary and non stationary settings. In addition, extensive experiments on synthetic and real data show that FANTOM outperforms existing methods.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.17065",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Formal Control for Uncertain Systems via Contract-Based Probabilistic Surrogates (Extended Version)",
    "description": "arXiv:2506.16971v1 Announce Type: cross Abstract: The requirement for identifying accurate system representations has not only been a challenge to fulfill, but it has compromised the scalability of formal methods, as the resulting models are often too complex for effective decision making with formal correctness and performance guarantees. Focusing on probabilistic simulation relations and surrogate models of stochastic systems, we propose an approach that significantly enhances the scalability and practical applicability of such simulation relations by eliminating the need to compute error bounds directly. As a result, we provide an abstraction-based technique that scales effectively to higher dimensions while addressing complex nonlinear agent-environment interactions with infinite-horizon temporal logic guarantees amidst uncertainty. Our approach trades scalability for conservatism favorably, as demonstrated on a complex high-dimensional vehicle intersection case study.",
    "summary": "arXiv:2506.16971v1 Announce Type: cross Abstract: The requirement for identifying accurate system representations has not only been a challenge to fulfill, but it has compromised the scalability of formal methods, as the resulting models are often too complex for effective decision making with formal correctness and performance guarantees. Focusing on probabilistic simulation relations and surrogate models of stochastic systems, we propose an approach that significantly enhances the scalability and practical applicability of such simulation relations by eliminating the need to compute error bounds directly. As a result, we provide an abstraction-based technique that scales effectively to higher dimensions while addressing complex nonlinear agent-environment interactions with infinite-horizon temporal logic guarantees amidst uncertainty. Our approach trades scalability for conservatism favorably, as demonstrated on a complex high-dimensional vehicle intersection case study.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16971",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Fractional Reasoning via Latent Steering Vectors Improves Inference Time Compute",
    "description": "arXiv:2506.15882v1 Announce Type: cross Abstract: Test-time compute has emerged as a powerful paradigm for improving the performance of large language models (LLMs), where generating multiple outputs or refining individual chains can significantly boost answer accuracy. However, existing methods like Best-of-N, majority voting, and self-reflection typically apply reasoning in a uniform way across inputs, overlooking the fact that different problems may require different levels of reasoning depth. In this work, we propose Fractional Reasoning, a training-free and model-agnostic framework that enables continuous control over reasoning intensity at inference time, going beyond the limitations of fixed instructional prompts. Our method operates by extracting the latent steering vector associated with deeper reasoning and reapplying it with a tunable scaling factor, allowing the model to tailor its reasoning process to the complexity of each input. This supports two key modes of test-time scaling: (1) improving output quality in breadth-based strategies (e.g., Best-of-N, majority voting), and (2) enhancing the correctness of individual reasoning chains in depth-based strategies (e.g., self-reflection). Experiments on GSM8K, MATH500, and GPQA demonstrate that Fractional Reasoning consistently improves performance across diverse reasoning tasks and models.",
    "summary": "arXiv:2506.15882v1 Announce Type: cross Abstract: Test-time compute has emerged as a powerful paradigm for improving the performance of large language models (LLMs), where generating multiple outputs or refining individual chains can significantly boost answer accuracy. However, existing methods like Best-of-N, majority voting, and self-reflection typically apply reasoning in a uniform way across inputs, overlooking the fact that different problems may require different levels of reasoning depth. In this work, we propose Fractional Reasoning, a training-free and model-agnostic framework that enables continuous control over reasoning intensity at inference time, going beyond the limitations of fixed instructional prompts. Our method operates by extracting the latent steering vector associated with deeper reasoning and reapplying it with a tunable scaling factor, allowing the model to tailor its reasoning process to the complexity of each input. This supports two key modes of test-time scaling: (1) improving output quality in breadth-based strategies (e.g., Best-of-N, majority voting), and (2) enhancing the correctness of individual reasoning chains in depth-based strategies (e.g., self-reflection). Experiments on GSM8K, MATH500, and GPQA demonstrate that Fractional Reasoning consistently improves performance across diverse reasoning tasks and models.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.15882",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "FRIDA to the Rescue! Analyzing Synthetic Data Effectiveness in Object-Based Common Sense Reasoning for Disaster Response",
    "description": "arXiv:2502.18452v2 Announce Type: replace-cross Abstract: During Human Robot Interactions in disaster relief scenarios, Large Language Models (LLMs) have the potential for substantial physical reasoning to assist in mission objectives. However, these capabilities are often found only in larger models, which are frequently not reasonable to deploy on robotic systems. To meet our problem space requirements, we introduce a dataset and pipeline to create Field Reasoning and Instruction Decoding Agent (FRIDA) models. In our pipeline, domain experts and linguists combine their knowledge to make high-quality few-shot prompts used to generate synthetic data for fine-tuning. We hand-curate datasets for this few-shot prompting and for evaluation to improve LLM reasoning on both general and disaster-specific objects. We concurrently run an ablation study to understand which kinds of synthetic data most affect performance. We fine-tune several small instruction-tuned models and find that ablated FRIDA models only trained on objects' physical state and function data outperformed both the FRIDA models trained on all synthetic data and the base models in our customized evaluation. We demonstrate that the FRIDA pipeline is capable of instilling physical common sense with minimal data.",
    "summary": "arXiv:2502.18452v2 Announce Type: replace-cross Abstract: During Human Robot Interactions in disaster relief scenarios, Large Language Models (LLMs) have the potential for substantial physical reasoning to assist in mission objectives. However, these capabilities are often found only in larger models, which are frequently not reasonable to deploy on robotic systems. To meet our problem space requirements, we introduce a dataset and pipeline to create Field Reasoning and Instruction Decoding Agent (FRIDA) models. In our pipeline, domain experts and linguists combine their knowledge to make high-quality few-shot prompts used to generate synthetic data for fine-tuning. We hand-curate datasets for this few-shot prompting and for evaluation to improve LLM reasoning on both general and disaster-specific objects. We concurrently run an ablation study to understand which kinds of synthetic data most affect performance. We fine-tune several small instruction-tuned models and find that ablated FRIDA models only trained on objects' physical state and function data outperformed both the FRIDA models trained on all synthetic data and the base models in our customized evaluation. We demonstrate that the FRIDA pipeline is capable of instilling physical common sense with minimal data.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2502.18452",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "From Concepts to Components: Concept-Agnostic Attention Module Discovery in Transformers",
    "description": "arXiv:2506.17052v1 Announce Type: cross Abstract: Transformers have achieved state-of-the-art performance across language and vision tasks. This success drives the imperative to interpret their internal mechanisms with the dual goals of enhancing performance and improving behavioral control. Attribution methods help advance interpretability by assigning model outputs associated with a target concept to specific model components. Current attribution research primarily studies multi-layer perceptron neurons and addresses relatively simple concepts such as factual associations (e.g., Paris is located in France). This focus tends to overlook the impact of the attention mechanism and lacks a unified approach for analyzing more complex concepts. To fill these gaps, we introduce Scalable Attention Module Discovery (SAMD), a concept-agnostic method for mapping arbitrary, complex concepts to specific attention heads of general transformer models. We accomplish this by representing each concept as a vector, calculating its cosine similarity with each attention head, and selecting the TopK-scoring heads to construct the concept-associated attention module. We then propose Scalar Attention Module Intervention (SAMI), a simple strategy to diminish or amplify the effects of a concept by adjusting the attention module using only a single scalar parameter. Empirically, we demonstrate SAMD on concepts of varying complexity, and visualize the locations of their corresponding modules. Our results demonstrate that module locations remain stable before and after LLM post-training, and confirm prior work on the mechanics of LLM multilingualism. Through SAMI, we facilitate jailbreaking on HarmBench (+72.7%) by diminishing 'safety' and improve performance on the GSM8K benchmark (+1.6%) by amplifying 'reasoning'. Lastly, we highlight the domain-agnostic nature of our approach by suppressing the image classification accuracy of vision transformers on ImageNet.",
    "summary": "arXiv:2506.17052v1 Announce Type: cross Abstract: Transformers have achieved state-of-the-art performance across language and vision tasks. This success drives the imperative to interpret their internal mechanisms with the dual goals of enhancing performance and improving behavioral control. Attribution methods help advance interpretability by assigning model outputs associated with a target concept to specific model components. Current attribution research primarily studies multi-layer perceptron neurons and addresses relatively simple concepts such as factual associations (e.g., Paris is located in France). This focus tends to overlook the impact of the attention mechanism and lacks a unified approach for analyzing more complex concepts. To fill these gaps, we introduce Scalable Attention Module Discovery (SAMD), a concept-agnostic method for mapping arbitrary, complex concepts to specific attention heads of general transformer models. We accomplish this by representing each concept as a vector, calculating its cosine similarity with each attention head, and selecting the TopK-scoring heads to construct the concept-associated attention module. We then propose Scalar Attention Module Intervention (SAMI), a simple strategy to diminish or amplify the effects of a concept by adjusting the attention module using only a single scalar parameter. Empirically, we demonstrate SAMD on concepts of varying complexity, and visualize the locations of their corresponding modules. Our results demonstrate that module locations remain stable before and after LLM post-training, and confirm prior work on the mechanics of LLM multilingualism. Through SAMI, we facilitate jailbreaking on HarmBench (+72.7%) by diminishing 'safety' and improve performance on the GSM8K benchmark (+1.6%) by amplifying 'reasoning'. Lastly, we highlight the domain-agnostic nature of our approach by suppressing the image classification accuracy of vision transformers on ImageNet.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.17052",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "From General to Targeted Rewards: Surpassing GPT-4 in Open-Ended Long-Context Generation",
    "description": "arXiv:2506.16024v1 Announce Type: cross Abstract: Current research on long-form context in Large Language Models (LLMs) primarily focuses on the understanding of long-contexts, the Open-ended Long Text Generation (Open-LTG) remains insufficiently explored. Training a long-context generation model requires curation of gold standard reference data, which is typically nonexistent for informative Open-LTG tasks. However, previous methods only utilize general assessments as reward signals, which limits accuracy. To bridge this gap, we introduce ProxyReward, an innovative reinforcement learning (RL) based framework, which includes a dataset and a reward signal computation method. Firstly, ProxyReward Dataset generation is accomplished through simple prompts that enables the model to create automatically, obviating extensive labeled data or significant manual effort. Secondly, ProxyReward Signal offers a targeted evaluation of information comprehensiveness and accuracy for specific questions. The experimental results indicate that our method ProxyReward surpasses even GPT-4-Turbo. It can significantly enhance performance by 20% on the Open-LTG task when training widely used open-source models, while also surpassing the LLM-as-a-Judge approach. Our work presents effective methods to enhance the ability of LLMs to address complex open-ended questions posed by human.",
    "summary": "arXiv:2506.16024v1 Announce Type: cross Abstract: Current research on long-form context in Large Language Models (LLMs) primarily focuses on the understanding of long-contexts, the Open-ended Long Text Generation (Open-LTG) remains insufficiently explored. Training a long-context generation model requires curation of gold standard reference data, which is typically nonexistent for informative Open-LTG tasks. However, previous methods only utilize general assessments as reward signals, which limits accuracy. To bridge this gap, we introduce ProxyReward, an innovative reinforcement learning (RL) based framework, which includes a dataset and a reward signal computation method. Firstly, ProxyReward Dataset generation is accomplished through simple prompts that enables the model to create automatically, obviating extensive labeled data or significant manual effort. Secondly, ProxyReward Signal offers a targeted evaluation of information comprehensiveness and accuracy for specific questions. The experimental results indicate that our method ProxyReward surpasses even GPT-4-Turbo. It can significantly enhance performance by 20% on the Open-LTG task when training widely used open-source models, while also surpassing the LLM-as-a-Judge approach. Our work presents effective methods to enhance the ability of LLMs to address complex open-ended questions posed by human.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16024",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "From LLM-anation to LLM-orchestrator: Coordinating Small Models for Data Labeling",
    "description": "arXiv:2506.16393v1 Announce Type: cross Abstract: Although the annotation paradigm based on Large Language Models (LLMs) has made significant breakthroughs in recent years, its actual deployment still has two core bottlenecks: first, the cost of calling commercial APIs in large-scale annotation is very expensive; second, in scenarios that require fine-grained semantic understanding, such as sentiment classification and toxicity classification, the annotation accuracy of LLMs is even lower than that of Small Language Models (SLMs) dedicated to this field. To address these problems, we propose a new paradigm of multi-model cooperative annotation and design a fully automatic annotation framework AutoAnnotator based on this. Specifically, AutoAnnotator consists of two layers. The upper-level meta-controller layer uses the generation and reasoning capabilities of LLMs to select SLMs for annotation, automatically generate annotation code and verify difficult samples; the lower-level task-specialist layer consists of multiple SLMs that perform annotation through multi-model voting. In addition, we use the difficult samples obtained by the secondary review of the meta-controller layer as the reinforcement learning set and fine-tune the SLMs in stages through a continual learning strategy, thereby improving the generalization of SLMs. Extensive experiments show that AutoAnnotator outperforms existing open-source/API LLMs in zero-shot, one-shot, CoT, and majority voting settings. Notably, AutoAnnotator reduces the annotation cost by 74.15% compared to directly annotating with GPT-3.5-turbo, while still improving the accuracy by 6.21%. Project page: https://github.com/Zhaiyuan-Ji/AutoAnnotator.",
    "summary": "arXiv:2506.16393v1 Announce Type: cross Abstract: Although the annotation paradigm based on Large Language Models (LLMs) has made significant breakthroughs in recent years, its actual deployment still has two core bottlenecks: first, the cost of calling commercial APIs in large-scale annotation is very expensive; second, in scenarios that require fine-grained semantic understanding, such as sentiment classification and toxicity classification, the annotation accuracy of LLMs is even lower than that of Small Language Models (SLMs) dedicated to this field. To address these problems, we propose a new paradigm of multi-model cooperative annotation and design a fully automatic annotation framework AutoAnnotator based on this. Specifically, AutoAnnotator consists of two layers. The upper-level meta-controller layer uses the generation and reasoning capabilities of LLMs to select SLMs for annotation, automatically generate annotation code and verify difficult samples; the lower-level task-specialist layer consists of multiple SLMs that perform annotation through multi-model voting. In addition, we use the difficult samples obtained by the secondary review of the meta-controller layer as the reinforcement learning set and fine-tune the SLMs in stages through a continual learning strategy, thereby improving the generalization of SLMs. Extensive experiments show that AutoAnnotator outperforms existing open-source/API LLMs in zero-shot, one-shot, CoT, and majority voting settings. Notably, AutoAnnotator reduces the annotation cost by 74.15% compared to directly annotating with GPT-3.5-turbo, while still improving the accuracy by 6.21%. Project page: https://github.com/Zhaiyuan-Ji/AutoAnnotator.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16393",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "From Prompts to Constructs: A Dual-Validity Framework for LLM Research in Psychology",
    "description": "arXiv:2506.16697v1 Announce Type: cross Abstract: Large language models (LLMs) are rapidly being adopted across psychology, serving as research tools, experimental subjects, human simulators, and computational models of cognition. However, the application of human measurement tools to these systems can produce contradictory results, raising concerns that many findings are measurement phantoms--statistical artifacts rather than genuine psychological phenomena. In this Perspective, we argue that building a robust science of AI psychology requires integrating two of our field's foundational pillars: the principles of reliable measurement and the standards for sound causal inference. We present a dual-validity framework to guide this integration, which clarifies how the evidence needed to support a claim scales with its scientific ambition. Using an LLM to classify text may require only basic accuracy checks, whereas claiming it can simulate anxiety demands a far more rigorous validation process. Current practice systematically fails to meet these requirements, often treating statistical pattern matching as evidence of psychological phenomena. The same model output--endorsing 'I am anxious'--requires different validation strategies depending on whether researchers claim to measure, characterize, simulate, or model psychological constructs. Moving forward requires developing computational analogues of psychological constructs and establishing clear, scalable standards of evidence rather than the uncritical application of human measurement tools.",
    "summary": "arXiv:2506.16697v1 Announce Type: cross Abstract: Large language models (LLMs) are rapidly being adopted across psychology, serving as research tools, experimental subjects, human simulators, and computational models of cognition. However, the application of human measurement tools to these systems can produce contradictory results, raising concerns that many findings are measurement phantoms--statistical artifacts rather than genuine psychological phenomena. In this Perspective, we argue that building a robust science of AI psychology requires integrating two of our field's foundational pillars: the principles of reliable measurement and the standards for sound causal inference. We present a dual-validity framework to guide this integration, which clarifies how the evidence needed to support a claim scales with its scientific ambition. Using an LLM to classify text may require only basic accuracy checks, whereas claiming it can simulate anxiety demands a far more rigorous validation process. Current practice systematically fails to meet these requirements, often treating statistical pattern matching as evidence of psychological phenomena. The same model output--endorsing 'I am anxious'--requires different validation strategies depending on whether researchers claim to measure, characterize, simulate, or model psychological constructs. Moving forward requires developing computational analogues of psychological constructs and establishing clear, scalable standards of evidence rather than the uncritical application of human measurement tools.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16697",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "From RAG to Memory: Non-Parametric Continual Learning for Large Language Models",
    "description": "arXiv:2502.14802v2 Announce Type: replace-cross Abstract: Our ability to continuously acquire, organize, and leverage knowledge is a key feature of human intelligence that AI systems must approximate to unlock their full potential. Given the challenges in continual learning with large language models (LLMs), retrieval-augmented generation (RAG) has become the dominant way to introduce new information. However, its reliance on vector retrieval hinders its ability to mimic the dynamic and interconnected nature of human long-term memory. Recent RAG approaches augment vector embeddings with various structures like knowledge graphs to address some of these gaps, namely sense-making and associativity. However, their performance on more basic factual memory tasks drops considerably below standard RAG. We address this unintended deterioration and propose HippoRAG 2, a framework that outperforms standard RAG comprehensively on factual, sense-making, and associative memory tasks. HippoRAG 2 builds upon the Personalized PageRank algorithm used in HippoRAG and enhances it with deeper passage integration and more effective online use of an LLM. This combination pushes this RAG system closer to the effectiveness of human long-term memory, achieving a 7% improvement in associative memory tasks over the state-of-the-art embedding model while also exhibiting superior factual knowledge and sense-making memory capabilities. This work paves the way for non-parametric continual learning for LLMs. Code and data are available at https://github.com/OSU-NLP-Group/HippoRAG.",
    "summary": "arXiv:2502.14802v2 Announce Type: replace-cross Abstract: Our ability to continuously acquire, organize, and leverage knowledge is a key feature of human intelligence that AI systems must approximate to unlock their full potential. Given the challenges in continual learning with large language models (LLMs), retrieval-augmented generation (RAG) has become the dominant way to introduce new information. However, its reliance on vector retrieval hinders its ability to mimic the dynamic and interconnected nature of human long-term memory. Recent RAG approaches augment vector embeddings with various structures like knowledge graphs to address some of these gaps, namely sense-making and associativity. However, their performance on more basic factual memory tasks drops considerably below standard RAG. We address this unintended deterioration and propose HippoRAG 2, a framework that outperforms standard RAG comprehensively on factual, sense-making, and associative memory tasks. HippoRAG 2 builds upon the Personalized PageRank algorithm used in HippoRAG and enhances it with deeper passage integration and more effective online use of an LLM. This combination pushes this RAG system closer to the effectiveness of human long-term memory, achieving a 7% improvement in associative memory tasks over the state-of-the-art embedding model while also exhibiting superior factual knowledge and sense-making memory capabilities. This work paves the way for non-parametric continual learning for LLMs. Code and data are available at https://github.com/OSU-NLP-Group/HippoRAG.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2502.14802",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "From Semantic To Instance: A Semi-Self-Supervised Learning Approach",
    "description": "arXiv:2506.16563v1 Announce Type: cross Abstract: Instance segmentation is essential for applications such as automated monitoring of plant health, growth, and yield. However, extensive effort is required to create large-scale datasets with pixel-level annotations of each object instance for developing instance segmentation models that restrict the use of deep learning in these areas. This challenge is more significant in images with densely packed, self-occluded objects, which are common in agriculture. To address this challenge, we propose a semi-self-supervised learning approach that requires minimal manual annotation to develop a high-performing instance segmentation model. We design GLMask, an image-mask representation for the model to focus on shape, texture, and pattern while minimizing its dependence on color features. We develop a pipeline to generate semantic segmentation and then transform it into instance-level segmentation. The proposed approach substantially outperforms the conventional instance segmentation models, establishing a state-of-the-art wheat head instance segmentation model with mAP@50 of 98.5%. Additionally, we assessed the proposed methodology on the general-purpose Microsoft COCO dataset, achieving a significant performance improvement of over 12.6% mAP@50. This highlights that the utility of our proposed approach extends beyond precision agriculture and applies to other domains, specifically those with similar data characteristics.",
    "summary": "arXiv:2506.16563v1 Announce Type: cross Abstract: Instance segmentation is essential for applications such as automated monitoring of plant health, growth, and yield. However, extensive effort is required to create large-scale datasets with pixel-level annotations of each object instance for developing instance segmentation models that restrict the use of deep learning in these areas. This challenge is more significant in images with densely packed, self-occluded objects, which are common in agriculture. To address this challenge, we propose a semi-self-supervised learning approach that requires minimal manual annotation to develop a high-performing instance segmentation model. We design GLMask, an image-mask representation for the model to focus on shape, texture, and pattern while minimizing its dependence on color features. We develop a pipeline to generate semantic segmentation and then transform it into instance-level segmentation. The proposed approach substantially outperforms the conventional instance segmentation models, establishing a state-of-the-art wheat head instance segmentation model with mAP@50 of 98.5%. Additionally, we assessed the proposed methodology on the general-purpose Microsoft COCO dataset, achieving a significant performance improvement of over 12.6% mAP@50. This highlights that the utility of our proposed approach extends beyond precision agriculture and applies to other domains, specifically those with similar data characteristics.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16563",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "From Teacher to Student: Tracking Memorization Through Model Distillation",
    "description": "arXiv:2506.16170v1 Announce Type: cross Abstract: Large language models (LLMs) are known to memorize parts of their training data, raising important concerns around privacy and security. While previous research has focused on studying memorization in pre-trained models, much less is known about how knowledge distillation (KD) affects memorization.In this study, we explore how different KD methods influence the memorization of fine-tuned task data when a large teacher model is distilled into smaller student variants.This study demonstrates that distilling a larger teacher model, fine-tuned on a dataset, into a smaller variant not only lowers computational costs and model size but also significantly reduces the memorization risks compared to standard fine-tuning approaches.",
    "summary": "arXiv:2506.16170v1 Announce Type: cross Abstract: Large language models (LLMs) are known to memorize parts of their training data, raising important concerns around privacy and security. While previous research has focused on studying memorization in pre-trained models, much less is known about how knowledge distillation (KD) affects memorization.In this study, we explore how different KD methods influence the memorization of fine-tuned task data when a large teacher model is distilled into smaller student variants.This study demonstrates that distilling a larger teacher model, fine-tuned on a dataset, into a smaller variant not only lowers computational costs and model size but also significantly reduces the memorization risks compared to standard fine-tuning approaches.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16170",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Generalisation Bounds of Zero-Shot Economic Forecasting using Time Series Foundation Models",
    "description": "arXiv:2506.15705v1 Announce Type: cross Abstract: This study investigates zero-shot forecasting capabilities of Time Series Foundation Models (TSFMs) for macroeconomic indicators. We apply TSFMs to forecasting economic indicators under univariate conditions, bypassing the need for train bespoke econometric models using and extensive training datasets. Our experiments were conducted on a case study dataset, without additional customisation. We rigorously back-tested three state-of-the-art TSFMs (Chronos, TimeGPT and Moirai) under data-scarce conditions and structural breaks. Our results demonstrate that appropriately engineered TSFMs can internalise rich economic dynamics, accommodate regime shifts, and deliver well-behaved uncertainty estimates out of the box, while matching state-of-the-art multivariate models on this domain. Our findings suggest that, without any fine-tuning, TSFMs can match or exceed classical models during stable economic conditions. However, they are vulnerable to degradation in performances during periods of rapid shocks. The findings offer guidance to practitioners on when zero-shot deployments are viable for macroeconomic monitoring and strategic planning.",
    "summary": "arXiv:2506.15705v1 Announce Type: cross Abstract: This study investigates zero-shot forecasting capabilities of Time Series Foundation Models (TSFMs) for macroeconomic indicators. We apply TSFMs to forecasting economic indicators under univariate conditions, bypassing the need for train bespoke econometric models using and extensive training datasets. Our experiments were conducted on a case study dataset, without additional customisation. We rigorously back-tested three state-of-the-art TSFMs (Chronos, TimeGPT and Moirai) under data-scarce conditions and structural breaks. Our results demonstrate that appropriately engineered TSFMs can internalise rich economic dynamics, accommodate regime shifts, and deliver well-behaved uncertainty estimates out of the box, while matching state-of-the-art multivariate models on this domain. Our findings suggest that, without any fine-tuning, TSFMs can match or exceed classical models during stable economic conditions. However, they are vulnerable to degradation in performances during periods of rapid shocks. The findings offer guidance to practitioners on when zero-shot deployments are viable for macroeconomic monitoring and strategic planning.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.15705",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Generalizable Agent Modeling for Agent Collaboration-Competition Adaptation with Multi-Retrieval and Dynamic Generation",
    "description": "arXiv:2506.16718v1 Announce Type: cross Abstract: Adapting a single agent to a new multi-agent system brings challenges, necessitating adjustments across various tasks, environments, and interactions with unknown teammates and opponents. Addressing this challenge is highly complex, and researchers have proposed two simplified scenarios, Multi-agent reinforcement learning for zero-shot learning and Ad-Hoc Teamwork. Building on these foundations, we propose a more comprehensive setting, Agent Collaborative-Competitive Adaptation (ACCA), which evaluates an agent to generalize across diverse scenarios, tasks, and interactions with both unfamiliar opponents and teammates. In ACCA, agents adjust to task and environmental changes, collaborate with unseen teammates, and compete against unknown opponents. We introduce a new modeling approach, Multi-Retrieval and Dynamic Generation (MRDG), that effectively models both teammates and opponents using their behavioral trajectories. This method incorporates a positional encoder for varying team sizes and a hypernetwork module to boost agents' learning and adaptive capabilities. Additionally, a viewpoint alignment module harmonizes the observational perspectives of retrieved teammates and opponents with the learning agent. Extensive tests in benchmark scenarios like SMAC, Overcooked-AI, and Melting Pot show that MRDG significantly improves robust collaboration and competition with unseen teammates and opponents, surpassing established baselines. Our code is available at: https://github.com/vcis-wangchenxu/MRDG.git",
    "summary": "arXiv:2506.16718v1 Announce Type: cross Abstract: Adapting a single agent to a new multi-agent system brings challenges, necessitating adjustments across various tasks, environments, and interactions with unknown teammates and opponents. Addressing this challenge is highly complex, and researchers have proposed two simplified scenarios, Multi-agent reinforcement learning for zero-shot learning and Ad-Hoc Teamwork. Building on these foundations, we propose a more comprehensive setting, Agent Collaborative-Competitive Adaptation (ACCA), which evaluates an agent to generalize across diverse scenarios, tasks, and interactions with both unfamiliar opponents and teammates. In ACCA, agents adjust to task and environmental changes, collaborate with unseen teammates, and compete against unknown opponents. We introduce a new modeling approach, Multi-Retrieval and Dynamic Generation (MRDG), that effectively models both teammates and opponents using their behavioral trajectories. This method incorporates a positional encoder for varying team sizes and a hypernetwork module to boost agents' learning and adaptive capabilities. Additionally, a viewpoint alignment module harmonizes the observational perspectives of retrieved teammates and opponents with the learning agent. Extensive tests in benchmark scenarios like SMAC, Overcooked-AI, and Melting Pot show that MRDG significantly improves robust collaboration and competition with unseen teammates and opponents, surpassing established baselines. Our code is available at: https://github.com/vcis-wangchenxu/MRDG.git",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16718",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "GeoGuess: Multimodal Reasoning based on Hierarchy of Visual Information in Street View",
    "description": "arXiv:2506.16633v1 Announce Type: cross Abstract: Multimodal reasoning is a process of understanding, integrating and inferring information across different data modalities. It has recently attracted surging academic attention as a benchmark for Artificial Intelligence (AI). Although there are various tasks for evaluating multimodal reasoning ability, they still have limitations. Lack of reasoning on hierarchical visual clues at different levels of granularity, e.g., local details and global context, is of little discussion, despite its frequent involvement in real scenarios. To bridge the gap, we introduce a novel and challenging task for multimodal reasoning, namely GeoGuess. Given a street view image, the task is to identify its location and provide a detailed explanation. A system that succeeds in GeoGuess should be able to detect tiny visual clues, perceive the broader landscape, and associate with vast geographic knowledge. Therefore, GeoGuess would require the ability to reason between hierarchical visual information and geographic knowledge. In this work, we establish a benchmark for GeoGuess by introducing a specially curated dataset GeoExplain which consists of panoramas-geocoordinates-explanation tuples. Additionally, we present a multimodal and multilevel reasoning method, namely SightSense which can make prediction and generate comprehensive explanation based on hierarchy of visual information and external knowledge. Our analysis and experiments demonstrate their outstanding performance in GeoGuess.",
    "summary": "arXiv:2506.16633v1 Announce Type: cross Abstract: Multimodal reasoning is a process of understanding, integrating and inferring information across different data modalities. It has recently attracted surging academic attention as a benchmark for Artificial Intelligence (AI). Although there are various tasks for evaluating multimodal reasoning ability, they still have limitations. Lack of reasoning on hierarchical visual clues at different levels of granularity, e.g., local details and global context, is of little discussion, despite its frequent involvement in real scenarios. To bridge the gap, we introduce a novel and challenging task for multimodal reasoning, namely GeoGuess. Given a street view image, the task is to identify its location and provide a detailed explanation. A system that succeeds in GeoGuess should be able to detect tiny visual clues, perceive the broader landscape, and associate with vast geographic knowledge. Therefore, GeoGuess would require the ability to reason between hierarchical visual information and geographic knowledge. In this work, we establish a benchmark for GeoGuess by introducing a specially curated dataset GeoExplain which consists of panoramas-geocoordinates-explanation tuples. Additionally, we present a multimodal and multilevel reasoning method, namely SightSense which can make prediction and generate comprehensive explanation based on hierarchy of visual information and external knowledge. Our analysis and experiments demonstrate their outstanding performance in GeoGuess.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16633",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Geometric Learning in Black-Box Optimization: A GNN Framework for Algorithm Performance Prediction",
    "description": "arXiv:2506.16144v1 Announce Type: new Abstract: Automated algorithm performance prediction in numerical blackbox optimization often relies on problem characterizations, such as exploratory landscape analysis features. These features are typically used as inputs to machine learning models and are represented in a tabular format. However, such approaches often overlook algorithm configurations, a key factor influencing performance. The relationships between algorithm operators, parameters, problem characteristics, and performance outcomes form a complex structure best represented as a graph. This work explores the use of heterogeneous graph data structures and graph neural networks to predict the performance of optimization algorithms by capturing the complex dependencies between problems, algorithm configurations, and performance outcomes. We focus on two modular frameworks, modCMA-ES and modDE, which decompose two widely used derivative-free optimization algorithms: the covariance matrix adaptation evolution strategy (CMA-ES) and differential evolution (DE). We evaluate 324 modCMA-ES and 576 modDE variants on 24 BBOB problems across six runtime budgets and two problem dimensions. Achieving up to 36.6% improvement in MSE over traditional tabular-based methods, this work highlights the potential of geometric learning in black-box optimization.",
    "summary": "arXiv:2506.16144v1 Announce Type: new Abstract: Automated algorithm performance prediction in numerical blackbox optimization often relies on problem characterizations, such as exploratory landscape analysis features. These features are typically used as inputs to machine learning models and are represented in a tabular format. However, such approaches often overlook algorithm configurations, a key factor influencing performance. The relationships between algorithm operators, parameters, problem characteristics, and performance outcomes form a complex structure best represented as a graph. This work explores the use of heterogeneous graph data structures and graph neural networks to predict the performance of optimization algorithms by capturing the complex dependencies between problems, algorithm configurations, and performance outcomes. We focus on two modular frameworks, modCMA-ES and modDE, which decompose two widely used derivative-free optimization algorithms: the covariance matrix adaptation evolution strategy (CMA-ES) and differential evolution (DE). We evaluate 324 modCMA-ES and 576 modDE variants on 24 BBOB problems across six runtime budgets and two problem dimensions. Achieving up to 36.6% improvement in MSE over traditional tabular-based methods, this work highlights the potential of geometric learning in black-box optimization.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16144",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "GFlowGR: Fine-tuning Generative Recommendation Frameworks with Generative Flow Networks",
    "description": "arXiv:2506.16114v1 Announce Type: cross Abstract: Generative recommendations (GR), which usually include item tokenizers and generative Large Language Models (LLMs), have demonstrated remarkable success across a wide range of scenarios. The majority of existing research efforts primarily concentrate on developing powerful item tokenizers or advancing LLM decoding strategies to attain superior performance. However, the critical fine-tuning step in GR frameworks, which is essential for adapting LLMs to recommendation data, remains largely unexplored. Current approaches predominantly rely on either the next-token prediction loss of supervised fine-tuning (SFT) or recommendationspecific direct preference optimization (DPO) strategies. Both methods ignore the exploration of possible positive unobserved samples, which is commonly referred to as the exposure bias problem. To mitigate this problem, this paper treats the GR as a multi-step generation task and constructs a GFlowNets-based fine-tuning framework (GFlowGR). The proposed framework integrates collaborative knowledge from traditional recommender systems to create an adaptive trajectory sampler and a comprehensive reward model. Leveraging the diverse generation property of GFlowNets, along with sampling and heuristic weighting techniques, GFlowGR emerges as a promising approach to mitigate the exposure bias problem. Extensive empirical results on two real-world datasets and with two different GR backbones highlight the effectiveness and robustness of GFlowGR.",
    "summary": "arXiv:2506.16114v1 Announce Type: cross Abstract: Generative recommendations (GR), which usually include item tokenizers and generative Large Language Models (LLMs), have demonstrated remarkable success across a wide range of scenarios. The majority of existing research efforts primarily concentrate on developing powerful item tokenizers or advancing LLM decoding strategies to attain superior performance. However, the critical fine-tuning step in GR frameworks, which is essential for adapting LLMs to recommendation data, remains largely unexplored. Current approaches predominantly rely on either the next-token prediction loss of supervised fine-tuning (SFT) or recommendationspecific direct preference optimization (DPO) strategies. Both methods ignore the exploration of possible positive unobserved samples, which is commonly referred to as the exposure bias problem. To mitigate this problem, this paper treats the GR as a multi-step generation task and constructs a GFlowNets-based fine-tuning framework (GFlowGR). The proposed framework integrates collaborative knowledge from traditional recommender systems to create an adaptive trajectory sampler and a comprehensive reward model. Leveraging the diverse generation property of GFlowNets, along with sampling and heuristic weighting techniques, GFlowGR emerges as a promising approach to mitigate the exposure bias problem. Extensive empirical results on two real-world datasets and with two different GR backbones highlight the effectiveness and robustness of GFlowGR.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16114",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Graph Diffusion that can Insert and Delete",
    "description": "arXiv:2506.15725v1 Announce Type: cross Abstract: Generative models of graphs based on discrete Denoising Diffusion Probabilistic Models (DDPMs) offer a principled approach to molecular generation by systematically removing structural noise through iterative atom and bond adjustments. However, existing formulations are fundamentally limited by their inability to adapt the graph size (that is, the number of atoms) during the diffusion process, severely restricting their effectiveness in conditional generation scenarios such as property-driven molecular design, where the targeted property often correlates with the molecular size. In this paper, we reformulate the noising and denoising processes to support monotonic insertion and deletion of nodes. The resulting model, which we call GrIDDD, dynamically grows or shrinks the chemical graph during generation. GrIDDD matches or exceeds the performance of existing graph diffusion models on molecular property targeting despite being trained on a more difficult problem. Furthermore, when applied to molecular optimization, GrIDDD exhibits competitive performance compared to specialized optimization models. This work paves the way for size-adaptive molecular generation with graph diffusion.",
    "summary": "arXiv:2506.15725v1 Announce Type: cross Abstract: Generative models of graphs based on discrete Denoising Diffusion Probabilistic Models (DDPMs) offer a principled approach to molecular generation by systematically removing structural noise through iterative atom and bond adjustments. However, existing formulations are fundamentally limited by their inability to adapt the graph size (that is, the number of atoms) during the diffusion process, severely restricting their effectiveness in conditional generation scenarios such as property-driven molecular design, where the targeted property often correlates with the molecular size. In this paper, we reformulate the noising and denoising processes to support monotonic insertion and deletion of nodes. The resulting model, which we call GrIDDD, dynamically grows or shrinks the chemical graph during generation. GrIDDD matches or exceeds the performance of existing graph diffusion models on molecular property targeting despite being trained on a more difficult problem. Furthermore, when applied to molecular optimization, GrIDDD exhibits competitive performance compared to specialized optimization models. This work paves the way for size-adaptive molecular generation with graph diffusion.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.15725",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Graphics4Science: Computer Graphics for Scientific Impacts",
    "description": "arXiv:2506.15786v1 Announce Type: cross Abstract: Computer graphics, often associated with films, games, and visual effects, has long been a powerful tool for addressing scientific challenges--from its origins in 3D visualization for medical imaging to its role in modern computational modeling and simulation. This course explores the deep and evolving relationship between computer graphics and science, highlighting past achievements, ongoing contributions, and open questions that remain. We show how core methods, such as geometric reasoning and physical modeling, provide inductive biases that help address challenges in both fields, especially in data-scarce settings. To that end, we aim to reframe graphics as a modeling language for science by bridging vocabulary gaps between the two communities. Designed for both newcomers and experts, Graphics4Science invites the graphics community to engage with science, tackle high-impact problems where graphics expertise can make a difference, and contribute to the future of scientific discovery. Additional details are available on the course website: https://graphics4science.github.io",
    "summary": "arXiv:2506.15786v1 Announce Type: cross Abstract: Computer graphics, often associated with films, games, and visual effects, has long been a powerful tool for addressing scientific challenges--from its origins in 3D visualization for medical imaging to its role in modern computational modeling and simulation. This course explores the deep and evolving relationship between computer graphics and science, highlighting past achievements, ongoing contributions, and open questions that remain. We show how core methods, such as geometric reasoning and physical modeling, provide inductive biases that help address challenges in both fields, especially in data-scarce settings. To that end, we aim to reframe graphics as a modeling language for science by bridging vocabulary gaps between the two communities. Designed for both newcomers and experts, Graphics4Science invites the graphics community to engage with science, tackle high-impact problems where graphics expertise can make a difference, and contribute to the future of scientific discovery. Additional details are available on the course website: https://graphics4science.github.io",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.15786",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "GraphRAG-Bench: Challenging Domain-Specific Reasoning for Evaluating Graph Retrieval-Augmented Generation",
    "description": "arXiv:2506.02404v3 Announce Type: replace-cross Abstract: Graph Retrieval Augmented Generation (GraphRAG) has garnered increasing recognition for its potential to enhance large language models (LLMs) by structurally organizing domain-specific corpora and facilitating complex reasoning. However, current evaluations of GraphRAG models predominantly rely on traditional question-answering datasets. Their limited scope in questions and evaluation metrics fails to comprehensively assess the reasoning capacity improvements enabled by GraphRAG models. To address this gap, we introduce GraphRAG-Bench, a large-scale, domain-specific benchmark designed to rigorously evaluate GraphRAG models. Our benchmark offers three key superiorities: ((i)) Challenging question design. Featuring college-level, domain-specific questions that demand multi-hop reasoning, the benchmark ensures that simple content retrieval is insufficient for problem-solving. For example, some questions require mathematical reasoning or programming. ((ii)) Diverse task coverage. The dataset includes a broad spectrum of reasoning tasks, multiple-choice, true/false, multi-select, open-ended, and fill-in-the-blank. It spans 16 disciplines in twenty core textbooks. ((iii)) Holistic evaluation framework. GraphRAG-Bench provides comprehensive assessment across the entire GraphRAG pipeline, including graph construction, knowledge retrieval, and answer generation. Beyond final-answer correctness, it evaluates the logical coherence of the reasoning process. By applying nine contemporary GraphRAG methods to GraphRAG-Bench, we demonstrate its utility in quantifying how graph-based structuring improves model reasoning capabilities. Our analysis reveals critical insights about graph architectures, retrieval efficacy, and reasoning capabilities, offering actionable guidance for the research community.",
    "summary": "arXiv:2506.02404v3 Announce Type: replace-cross Abstract: Graph Retrieval Augmented Generation (GraphRAG) has garnered increasing recognition for its potential to enhance large language models (LLMs) by structurally organizing domain-specific corpora and facilitating complex reasoning. However, current evaluations of GraphRAG models predominantly rely on traditional question-answering datasets. Their limited scope in questions and evaluation metrics fails to comprehensively assess the reasoning capacity improvements enabled by GraphRAG models. To address this gap, we introduce GraphRAG-Bench, a large-scale, domain-specific benchmark designed to rigorously evaluate GraphRAG models. Our benchmark offers three key superiorities: ((i)) Challenging question design. Featuring college-level, domain-specific questions that demand multi-hop reasoning, the benchmark ensures that simple content retrieval is insufficient for problem-solving. For example, some questions require mathematical reasoning or programming. ((ii)) Diverse task coverage. The dataset includes a broad spectrum of reasoning tasks, multiple-choice, true/false, multi-select, open-ended, and fill-in-the-blank. It spans 16 disciplines in twenty core textbooks. ((iii)) Holistic evaluation framework. GraphRAG-Bench provides comprehensive assessment across the entire GraphRAG pipeline, including graph construction, knowledge retrieval, and answer generation. Beyond final-answer correctness, it evaluates the logical coherence of the reasoning process. By applying nine contemporary GraphRAG methods to GraphRAG-Bench, we demonstrate its utility in quantifying how graph-based structuring improves model reasoning capabilities. Our analysis reveals critical insights about graph architectures, retrieval efficacy, and reasoning capabilities, offering actionable guidance for the research community.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.02404",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Grounding Language Models with Semantic Digital Twins for Robotic Planning",
    "description": "arXiv:2506.16493v1 Announce Type: cross Abstract: We introduce a novel framework that integrates Semantic Digital Twins (SDTs) with Large Language Models (LLMs) to enable adaptive and goal-driven robotic task execution in dynamic environments. The system decomposes natural language instructions into structured action triplets, which are grounded in contextual environmental data provided by the SDT. This semantic grounding allows the robot to interpret object affordances and interaction rules, enabling action planning and real-time adaptability. In case of execution failures, the LLM utilizes error feedback and SDT insights to generate recovery strategies and iteratively revise the action plan. We evaluate our approach using tasks from the ALFRED benchmark, demonstrating robust performance across various household scenarios. The proposed framework effectively combines high-level reasoning with semantic environment understanding, achieving reliable task completion in the face of uncertainty and failure.",
    "summary": "arXiv:2506.16493v1 Announce Type: cross Abstract: We introduce a novel framework that integrates Semantic Digital Twins (SDTs) with Large Language Models (LLMs) to enable adaptive and goal-driven robotic task execution in dynamic environments. The system decomposes natural language instructions into structured action triplets, which are grounded in contextual environmental data provided by the SDT. This semantic grounding allows the robot to interpret object affordances and interaction rules, enabling action planning and real-time adaptability. In case of execution failures, the LLM utilizes error feedback and SDT insights to generate recovery strategies and iteratively revise the action plan. We evaluate our approach using tasks from the ALFRED benchmark, demonstrating robust performance across various household scenarios. The proposed framework effectively combines high-level reasoning with semantic environment understanding, achieving reliable task completion in the face of uncertainty and failure.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16493",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "GRPO-CARE: Consistency-Aware Reinforcement Learning for Multimodal Reasoning",
    "description": "arXiv:2506.16141v1 Announce Type: cross Abstract: Recent reinforcement learning approaches, such as outcome-supervised GRPO, have advanced Chain-of-Thought reasoning in large language models (LLMs), yet their adaptation to multimodal LLMs (MLLMs) is unexplored. To address the lack of rigorous evaluation for MLLM post-training methods, we introduce SEED-Bench-R1, a benchmark with complex real-world videos requiring balanced perception and reasoning. It offers a large training set and evaluates generalization across three escalating challenges: in-distribution, cross-environment, and cross-environment-task scenarios. Using SEED-Bench-R1, we find that standard GRPO, while improving answer accuracy, often reduces logical coherence between reasoning steps and answers, with only a 57.9% consistency rate. This stems from reward signals focusing solely on final answers, encouraging shortcuts, and strict KL penalties limiting exploration.To address this, we propose GRPO-CARE, a consistency-aware RL framework optimizing both answer correctness and reasoning coherence without explicit supervision. GRPO-CARE introduces a two-tiered reward: (1) a base reward for answer correctness, and (2) an adaptive consistency bonus, computed by comparing the model's reasoning-to-answer likelihood (via a slowly-evolving reference model) against group peers.This dual mechanism amplifies rewards for reasoning paths that are both correct and logically consistent. Replacing KL penalties with this adaptive bonus, GRPO-CARE outperforms standard GRPO on SEED-Bench-R1, achieving a 6.7% performance gain on the hardest evaluation level and a 24.5% improvement in consistency. It also shows strong transferability, improving model performance across diverse video understanding benchmarks. Our work contributes a systematically designed benchmark and a generalizable post-training framework, advancing the development of more interpretable and robust MLLMs.",
    "summary": "arXiv:2506.16141v1 Announce Type: cross Abstract: Recent reinforcement learning approaches, such as outcome-supervised GRPO, have advanced Chain-of-Thought reasoning in large language models (LLMs), yet their adaptation to multimodal LLMs (MLLMs) is unexplored. To address the lack of rigorous evaluation for MLLM post-training methods, we introduce SEED-Bench-R1, a benchmark with complex real-world videos requiring balanced perception and reasoning. It offers a large training set and evaluates generalization across three escalating challenges: in-distribution, cross-environment, and cross-environment-task scenarios. Using SEED-Bench-R1, we find that standard GRPO, while improving answer accuracy, often reduces logical coherence between reasoning steps and answers, with only a 57.9% consistency rate. This stems from reward signals focusing solely on final answers, encouraging shortcuts, and strict KL penalties limiting exploration.To address this, we propose GRPO-CARE, a consistency-aware RL framework optimizing both answer correctness and reasoning coherence without explicit supervision. GRPO-CARE introduces a two-tiered reward: (1) a base reward for answer correctness, and (2) an adaptive consistency bonus, computed by comparing the model's reasoning-to-answer likelihood (via a slowly-evolving reference model) against group peers.This dual mechanism amplifies rewards for reasoning paths that are both correct and logically consistent. Replacing KL penalties with this adaptive bonus, GRPO-CARE outperforms standard GRPO on SEED-Bench-R1, achieving a 6.7% performance gain on the hardest evaluation level and a 24.5% improvement in consistency. It also shows strong transferability, improving model performance across diverse video understanding benchmarks. Our work contributes a systematically designed benchmark and a generalizable post-training framework, advancing the development of more interpretable and robust MLLMs.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16141",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Guaranteed prediction sets for functional surrogate models",
    "description": "arXiv:2501.18426v2 Announce Type: replace-cross Abstract: We propose a method for obtaining statistically guaranteed prediction sets for functional machine learning methods: surrogate models which map between function spaces, motivated by the need to build reliable PDE emulators. The method constructs nested prediction sets on a low-dimensional representation (an SVD) of the surrogate model's error, and then maps these sets to the prediction space using set-propagation techniques. This results in prediction sets for functional surrogate models with conformal prediction coverage guarantees. We use zonotopes as basis of the set construction, which allow an exact linear propagation and are closed under Cartesian products, making them well-suited to this high-dimensional problem. The method is model agnostic and can thus be applied to complex Sci-ML models, including Neural Operators, but also in simpler settings. We also introduce a technique to capture the truncation error of the SVD, preserving the guarantees of the method.",
    "summary": "arXiv:2501.18426v2 Announce Type: replace-cross Abstract: We propose a method for obtaining statistically guaranteed prediction sets for functional machine learning methods: surrogate models which map between function spaces, motivated by the need to build reliable PDE emulators. The method constructs nested prediction sets on a low-dimensional representation (an SVD) of the surrogate model's error, and then maps these sets to the prediction space using set-propagation techniques. This results in prediction sets for functional surrogate models with conformal prediction coverage guarantees. We use zonotopes as basis of the set construction, which allow an exact linear propagation and are closed under Cartesian products, making them well-suited to this high-dimensional problem. The method is model agnostic and can thus be applied to complex Sci-ML models, including Neural Operators, but also in simpler settings. We also introduce a technique to capture the truncation error of the SVD, preserving the guarantees of the method.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2501.18426",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Guided AbsoluteGrad: Magnitude of Gradients Matters to Explanation's Localization and Saliency",
    "description": "arXiv:2404.15564v2 Announce Type: replace-cross Abstract: This paper proposes a new gradient-based XAI method called Guided AbsoluteGrad for saliency map explanations. We utilize both positive and negative gradient magnitudes and employ gradient variance to distinguish the important areas for noise deduction. We also introduce a novel evaluation metric named ReCover And Predict (RCAP), which considers the Localization and Visual Noise Level objectives of the explanations. We propose two propositions for these two objectives and prove the necessity of evaluating them. We evaluate Guided AbsoluteGrad with seven gradient-based XAI methods using the RCAP metric and other SOTA metrics in three case studies: (1) ImageNet dataset with ResNet50 model; (2) International Skin Imaging Collaboration (ISIC) dataset with EfficientNet model; (3) the Places365 dataset with DenseNet161 model. Our method surpasses other gradient-based approaches, showcasing the quality of enhanced saliency map explanations through gradient magnitude.",
    "summary": "arXiv:2404.15564v2 Announce Type: replace-cross Abstract: This paper proposes a new gradient-based XAI method called Guided AbsoluteGrad for saliency map explanations. We utilize both positive and negative gradient magnitudes and employ gradient variance to distinguish the important areas for noise deduction. We also introduce a novel evaluation metric named ReCover And Predict (RCAP), which considers the Localization and Visual Noise Level objectives of the explanations. We propose two propositions for these two objectives and prove the necessity of evaluating them. We evaluate Guided AbsoluteGrad with seven gradient-based XAI methods using the RCAP metric and other SOTA metrics in three case studies: (1) ImageNet dataset with ResNet50 model; (2) International Skin Imaging Collaboration (ISIC) dataset with EfficientNet model; (3) the Places365 dataset with DenseNet161 model. Our method surpasses other gradient-based approaches, showcasing the quality of enhanced saliency map explanations through gradient magnitude.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2404.15564",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Heterogeneous-Modal Unsupervised Domain Adaptation via Latent Space Bridging",
    "description": "arXiv:2506.15971v1 Announce Type: cross Abstract: Unsupervised domain adaptation (UDA) methods effectively bridge domain gaps but become struggled when the source and target domains belong to entirely distinct modalities. To address this limitation, we propose a novel setting called Heterogeneous-Modal Unsupervised Domain Adaptation (HMUDA), which enables knowledge transfer between completely different modalities by leveraging a bridge domain containing unlabeled samples from both modalities. To learn under the HMUDA setting, we propose Latent Space Bridging (LSB), a specialized framework designed for the semantic segmentation task. Specifically, LSB utilizes a dual-branch architecture, incorporating a feature consistency loss to align representations across modalities and a domain alignment loss to reduce discrepancies between class centroids across domains. Extensive experiments conducted on six benchmark datasets demonstrate that LSB achieves state-of-the-art performance.",
    "summary": "arXiv:2506.15971v1 Announce Type: cross Abstract: Unsupervised domain adaptation (UDA) methods effectively bridge domain gaps but become struggled when the source and target domains belong to entirely distinct modalities. To address this limitation, we propose a novel setting called Heterogeneous-Modal Unsupervised Domain Adaptation (HMUDA), which enables knowledge transfer between completely different modalities by leveraging a bridge domain containing unlabeled samples from both modalities. To learn under the HMUDA setting, we propose Latent Space Bridging (LSB), a specialized framework designed for the semantic segmentation task. Specifically, LSB utilizes a dual-branch architecture, incorporating a feature consistency loss to align representations across modalities and a domain alignment loss to reduce discrepancies between class centroids across domains. Extensive experiments conducted on six benchmark datasets demonstrate that LSB achieves state-of-the-art performance.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.15971",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Hierarchical and Modular Network on Non-prehensile Manipulation in General Environments",
    "description": "arXiv:2502.20843v2 Announce Type: replace-cross Abstract: For robots to operate in general environments like households, they must be able to perform non-prehensile manipulation actions such as toppling and rolling to manipulate ungraspable objects. However, prior works on non-prehensile manipulation cannot yet generalize across environments with diverse geometries. The main challenge lies in adapting to varying environmental constraints: within a cabinet, the robot must avoid walls and ceilings; to lift objects to the top of a step, the robot must account for the step's pose and extent. While deep reinforcement learning (RL) has demonstrated impressive success in non-prehensile manipulation, accounting for such variability presents a challenge for the generalist policy, as it must learn diverse strategies for each new combination of constraints. To address this, we propose a modular and reconfigurable architecture that adaptively reconfigures network modules based on task requirements. To capture the geometric variability in environments, we extend the contact-based object representation (CORN) to environment geometries, and propose a procedural algorithm for generating diverse environments to train our agent. Taken together, the resulting policy can zero-shot transfer to novel real-world environments and objects despite training entirely within a simulator. We additionally release a simulation-based benchmark featuring nine digital twins of real-world scenes with 353 objects to facilitate non-prehensile manipulation research in realistic domains.",
    "summary": "arXiv:2502.20843v2 Announce Type: replace-cross Abstract: For robots to operate in general environments like households, they must be able to perform non-prehensile manipulation actions such as toppling and rolling to manipulate ungraspable objects. However, prior works on non-prehensile manipulation cannot yet generalize across environments with diverse geometries. The main challenge lies in adapting to varying environmental constraints: within a cabinet, the robot must avoid walls and ceilings; to lift objects to the top of a step, the robot must account for the step's pose and extent. While deep reinforcement learning (RL) has demonstrated impressive success in non-prehensile manipulation, accounting for such variability presents a challenge for the generalist policy, as it must learn diverse strategies for each new combination of constraints. To address this, we propose a modular and reconfigurable architecture that adaptively reconfigures network modules based on task requirements. To capture the geometric variability in environments, we extend the contact-based object representation (CORN) to environment geometries, and propose a procedural algorithm for generating diverse environments to train our agent. Taken together, the resulting policy can zero-shot transfer to novel real-world environments and objects despite training entirely within a simulator. We additionally release a simulation-based benchmark featuring nine digital twins of real-world scenes with 353 objects to facilitate non-prehensile manipulation research in realistic domains.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2502.20843",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "History-Augmented Vision-Language Models for Frontier-Based Zero-Shot Object Navigation",
    "description": "arXiv:2506.16623v1 Announce Type: cross Abstract: Object Goal Navigation (ObjectNav) challenges robots to find objects in unseen environments, demanding sophisticated reasoning. While Vision-Language Models (VLMs) show potential, current ObjectNav methods often employ them superficially, primarily using vision-language embeddings for object-scene similarity checks rather than leveraging deeper reasoning. This limits contextual understanding and leads to practical issues like repetitive navigation behaviors. This paper introduces a novel zero-shot ObjectNav framework that pioneers the use of dynamic, history-aware prompting to more deeply integrate VLM reasoning into frontier-based exploration. Our core innovation lies in providing the VLM with action history context, enabling it to generate semantic guidance scores for navigation actions while actively avoiding decision loops. We also introduce a VLM-assisted waypoint generation mechanism for refining the final approach to detected objects. Evaluated on the HM3D dataset within Habitat, our approach achieves a 46% Success Rate (SR) and 24.8% Success weighted by Path Length (SPL). These results are comparable to state-of-the-art zero-shot methods, demonstrating the significant potential of our history-augmented VLM prompting strategy for more robust and context-aware robotic navigation.",
    "summary": "arXiv:2506.16623v1 Announce Type: cross Abstract: Object Goal Navigation (ObjectNav) challenges robots to find objects in unseen environments, demanding sophisticated reasoning. While Vision-Language Models (VLMs) show potential, current ObjectNav methods often employ them superficially, primarily using vision-language embeddings for object-scene similarity checks rather than leveraging deeper reasoning. This limits contextual understanding and leads to practical issues like repetitive navigation behaviors. This paper introduces a novel zero-shot ObjectNav framework that pioneers the use of dynamic, history-aware prompting to more deeply integrate VLM reasoning into frontier-based exploration. Our core innovation lies in providing the VLM with action history context, enabling it to generate semantic guidance scores for navigation actions while actively avoiding decision loops. We also introduce a VLM-assisted waypoint generation mechanism for refining the final approach to detected objects. Evaluated on the HM3D dataset within Habitat, our approach achieves a 46% Success Rate (SR) and 24.8% Success weighted by Path Length (SPL). These results are comparable to state-of-the-art zero-shot methods, demonstrating the significant potential of our history-augmented VLM prompting strategy for more robust and context-aware robotic navigation.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16623",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "How to Train your Text-to-Image Model: Evaluating Design Choices for Synthetic Training Captions",
    "description": "arXiv:2506.16679v1 Announce Type: cross Abstract: Training data is at the core of any successful text-to-image models. The quality and descriptiveness of image text are crucial to a model's performance. Given the noisiness and inconsistency in web-scraped datasets, recent works shifted towards synthetic training captions. While this setup is generally believed to produce more capable models, current literature does not provide any insights into its design choices. This study closes this gap by systematically investigating how different synthetic captioning strategies impact the downstream performance of text-to-image models. Our experiments demonstrate that dense, high-quality captions enhance text alignment but may introduce trade-offs in output aesthetics and diversity. Conversely, captions of randomized lengths yield balanced improvements across aesthetics and alignment without compromising sample diversity. We also demonstrate that varying caption distributions introduce significant shifts in the output bias of a trained model. Our findings underscore the importance of caption design in achieving optimal model performance and provide practical insights for more effective training data strategies in text-to-image generation.",
    "summary": "arXiv:2506.16679v1 Announce Type: cross Abstract: Training data is at the core of any successful text-to-image models. The quality and descriptiveness of image text are crucial to a model's performance. Given the noisiness and inconsistency in web-scraped datasets, recent works shifted towards synthetic training captions. While this setup is generally believed to produce more capable models, current literature does not provide any insights into its design choices. This study closes this gap by systematically investigating how different synthetic captioning strategies impact the downstream performance of text-to-image models. Our experiments demonstrate that dense, high-quality captions enhance text alignment but may introduce trade-offs in output aesthetics and diversity. Conversely, captions of randomized lengths yield balanced improvements across aesthetics and alignment without compromising sample diversity. We also demonstrate that varying caption distributions introduce significant shifts in the output bias of a trained model. Our findings underscore the importance of caption design in achieving optimal model performance and provide practical insights for more effective training data strategies in text-to-image generation.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16679",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Human-like Forgetting Curves in Deep Neural Networks",
    "description": "arXiv:2506.12034v2 Announce Type: replace-cross Abstract: This study bridges cognitive science and neural network design by examining whether artificial models exhibit human-like forgetting curves. Drawing upon Ebbinghaus' seminal work on memory decay and principles of spaced repetition, we propose a quantitative framework to measure information retention in neural networks. Our approach computes the recall probability by evaluating the similarity between a network's current hidden state and previously stored prototype representations. This retention metric facilitates the scheduling of review sessions, thereby mitigating catastrophic forgetting during deployment and enhancing training efficiency by prompting targeted reviews. Our experiments with Multi-Layer Perceptrons reveal human-like forgetting curves, with knowledge becoming increasingly robust through scheduled reviews. This alignment between neural network forgetting curves and established human memory models identifies neural networks as an architecture that naturally emulates human memory decay and can inform state-of-the-art continual learning algorithms.",
    "summary": "arXiv:2506.12034v2 Announce Type: replace-cross Abstract: This study bridges cognitive science and neural network design by examining whether artificial models exhibit human-like forgetting curves. Drawing upon Ebbinghaus' seminal work on memory decay and principles of spaced repetition, we propose a quantitative framework to measure information retention in neural networks. Our approach computes the recall probability by evaluating the similarity between a network's current hidden state and previously stored prototype representations. This retention metric facilitates the scheduling of review sessions, thereby mitigating catastrophic forgetting during deployment and enhancing training efficiency by prompting targeted reviews. Our experiments with Multi-Layer Perceptrons reveal human-like forgetting curves, with knowledge becoming increasingly robust through scheduled reviews. This alignment between neural network forgetting curves and established human memory models identifies neural networks as an architecture that naturally emulates human memory decay and can inform state-of-the-art continual learning algorithms.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.12034",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Human2LocoMan: Learning Versatile Quadrupedal Manipulation with Human Pretraining",
    "description": "arXiv:2506.16475v1 Announce Type: cross Abstract: Quadrupedal robots have demonstrated impressive locomotion capabilities in complex environments, but equipping them with autonomous versatile manipulation skills in a scalable way remains a significant challenge. In this work, we introduce a cross-embodiment imitation learning system for quadrupedal manipulation, leveraging data collected from both humans and LocoMan, a quadruped equipped with multiple manipulation modes. Specifically, we develop a teleoperation and data collection pipeline, which unifies and modularizes the observation and action spaces of the human and the robot. To effectively leverage the collected data, we propose an efficient modularized architecture that supports co-training and pretraining on structured modality-aligned data across different embodiments. Additionally, we construct the first manipulation dataset for the LocoMan robot, covering various household tasks in both unimanual and bimanual modes, supplemented by a corresponding human dataset. We validate our system on six real-world manipulation tasks, where it achieves an average success rate improvement of 41.9% overall and 79.7% under out-of-distribution (OOD) settings compared to the baseline. Pretraining with human data contributes a 38.6% success rate improvement overall and 82.7% under OOD settings, enabling consistently better performance with only half the amount of robot data. Our code, hardware, and data are open-sourced at: https://human2bots.github.io.",
    "summary": "arXiv:2506.16475v1 Announce Type: cross Abstract: Quadrupedal robots have demonstrated impressive locomotion capabilities in complex environments, but equipping them with autonomous versatile manipulation skills in a scalable way remains a significant challenge. In this work, we introduce a cross-embodiment imitation learning system for quadrupedal manipulation, leveraging data collected from both humans and LocoMan, a quadruped equipped with multiple manipulation modes. Specifically, we develop a teleoperation and data collection pipeline, which unifies and modularizes the observation and action spaces of the human and the robot. To effectively leverage the collected data, we propose an efficient modularized architecture that supports co-training and pretraining on structured modality-aligned data across different embodiments. Additionally, we construct the first manipulation dataset for the LocoMan robot, covering various household tasks in both unimanual and bimanual modes, supplemented by a corresponding human dataset. We validate our system on six real-world manipulation tasks, where it achieves an average success rate improvement of 41.9% overall and 79.7% under out-of-distribution (OOD) settings compared to the baseline. Pretraining with human data contributes a 38.6% success rate improvement overall and 82.7% under OOD settings, enabling consistently better performance with only half the amount of robot data. Our code, hardware, and data are open-sourced at: https://human2bots.github.io.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16475",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Hunyuan3D 2.5: Towards High-Fidelity 3D Assets Generation with Ultimate Details",
    "description": "arXiv:2506.16504v1 Announce Type: cross Abstract: In this report, we present Hunyuan3D 2.5, a robust suite of 3D diffusion models aimed at generating high-fidelity and detailed textured 3D assets. Hunyuan3D 2.5 follows two-stages pipeline of its previous version Hunyuan3D 2.0, while demonstrating substantial advancements in both shape and texture generation. In terms of shape generation, we introduce a new shape foundation model -- LATTICE, which is trained with scaled high-quality datasets, model-size, and compute. Our largest model reaches 10B parameters and generates sharp and detailed 3D shape with precise image-3D following while keeping mesh surface clean and smooth, significantly closing the gap between generated and handcrafted 3D shapes. In terms of texture generation, it is upgraded with phyiscal-based rendering (PBR) via a novel multi-view architecture extended from Hunyuan3D 2.0 Paint model. Our extensive evaluation shows that Hunyuan3D 2.5 significantly outperforms previous methods in both shape and end-to-end texture generation.",
    "summary": "arXiv:2506.16504v1 Announce Type: cross Abstract: In this report, we present Hunyuan3D 2.5, a robust suite of 3D diffusion models aimed at generating high-fidelity and detailed textured 3D assets. Hunyuan3D 2.5 follows two-stages pipeline of its previous version Hunyuan3D 2.0, while demonstrating substantial advancements in both shape and texture generation. In terms of shape generation, we introduce a new shape foundation model -- LATTICE, which is trained with scaled high-quality datasets, model-size, and compute. Our largest model reaches 10B parameters and generates sharp and detailed 3D shape with precise image-3D following while keeping mesh surface clean and smooth, significantly closing the gap between generated and handcrafted 3D shapes. In terms of texture generation, it is upgraded with phyiscal-based rendering (PBR) via a novel multi-view architecture extended from Hunyuan3D 2.0 Paint model. Our extensive evaluation shows that Hunyuan3D 2.5 significantly outperforms previous methods in both shape and end-to-end texture generation.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16504",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Hybrid Attention Network for Accurate Breast Tumor Segmentation in Ultrasound Images",
    "description": "arXiv:2506.16592v1 Announce Type: cross Abstract: Breast ultrasound imaging is a valuable tool for early breast cancer detection, but automated tumor segmentation is challenging due to inherent noise, variations in scale of lesions, and fuzzy boundaries. To address these challenges, we propose a novel hybrid attention-based network for lesion segmentation. Our proposed architecture integrates a pre-trained DenseNet121 in the encoder part for robust feature extraction with a multi-branch attention-enhanced decoder tailored for breast ultrasound images. The bottleneck incorporates Global Spatial Attention (GSA), Position Encoding (PE), and Scaled Dot-Product Attention (SDPA) to learn global context, spatial relationships, and relative positional features. The Spatial Feature Enhancement Block (SFEB) is embedded at skip connections to refine and enhance spatial features, enabling the network to focus more effectively on tumor regions. A hybrid loss function combining Binary Cross-Entropy (BCE) and Jaccard Index loss optimizes both pixel-level accuracy and region-level overlap metrics, enhancing robustness to class imbalance and irregular tumor shapes. Experiments on public datasets demonstrate that our method outperforms existing approaches, highlighting its potential to assist radiologists in early and accurate breast cancer diagnosis.",
    "summary": "arXiv:2506.16592v1 Announce Type: cross Abstract: Breast ultrasound imaging is a valuable tool for early breast cancer detection, but automated tumor segmentation is challenging due to inherent noise, variations in scale of lesions, and fuzzy boundaries. To address these challenges, we propose a novel hybrid attention-based network for lesion segmentation. Our proposed architecture integrates a pre-trained DenseNet121 in the encoder part for robust feature extraction with a multi-branch attention-enhanced decoder tailored for breast ultrasound images. The bottleneck incorporates Global Spatial Attention (GSA), Position Encoding (PE), and Scaled Dot-Product Attention (SDPA) to learn global context, spatial relationships, and relative positional features. The Spatial Feature Enhancement Block (SFEB) is embedded at skip connections to refine and enhance spatial features, enabling the network to focus more effectively on tumor regions. A hybrid loss function combining Binary Cross-Entropy (BCE) and Jaccard Index loss optimizes both pixel-level accuracy and region-level overlap metrics, enhancing robustness to class imbalance and irregular tumor shapes. Experiments on public datasets demonstrate that our method outperforms existing approaches, highlighting its potential to assist radiologists in early and accurate breast cancer diagnosis.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16592",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Identifiability of Deep Polynomial Neural Networks",
    "description": "arXiv:2506.17093v1 Announce Type: cross Abstract: Polynomial Neural Networks (PNNs) possess a rich algebraic and geometric structure. However, their identifiability -- a key property for ensuring interpretability -- remains poorly understood. In this work, we present a comprehensive analysis of the identifiability of deep PNNs, including architectures with and without bias terms. Our results reveal an intricate interplay between activation degrees and layer widths in achieving identifiability. As special cases, we show that architectures with non-increasing layer widths are generically identifiable under mild conditions, while encoder-decoder networks are identifiable when the decoder widths do not grow too rapidly. Our proofs are constructive and center on a connection between deep PNNs and low-rank tensor decompositions, and Kruskal-type uniqueness theorems. This yields both generic conditions determined by the architecture, and effective conditions that depend on the network's parameters. We also settle an open conjecture on the expected dimension of PNN's neurovarieties, and provide new bounds on the activation degrees required for it to reach its maximum.",
    "summary": "arXiv:2506.17093v1 Announce Type: cross Abstract: Polynomial Neural Networks (PNNs) possess a rich algebraic and geometric structure. However, their identifiability -- a key property for ensuring interpretability -- remains poorly understood. In this work, we present a comprehensive analysis of the identifiability of deep PNNs, including architectures with and without bias terms. Our results reveal an intricate interplay between activation degrees and layer widths in achieving identifiability. As special cases, we show that architectures with non-increasing layer widths are generically identifiable under mild conditions, while encoder-decoder networks are identifiable when the decoder widths do not grow too rapidly. Our proofs are constructive and center on a connection between deep PNNs and low-rank tensor decompositions, and Kruskal-type uniqueness theorems. This yields both generic conditions determined by the architecture, and effective conditions that depend on the network's parameters. We also settle an open conjecture on the expected dimension of PNN's neurovarieties, and provide new bounds on the activation degrees required for it to reach its maximum.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.17093",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Ignition Phase : Standard Training for Fast Adversarial Robustness",
    "description": "arXiv:2506.15685v1 Announce Type: cross Abstract: Adversarial Training (AT) is a cornerstone defense, but many variants overlook foundational feature representations by primarily focusing on stronger attack generation. We introduce Adversarial Evolution Training (AET), a simple yet powerful framework that strategically prepends an Empirical Risk Minimization (ERM) phase to conventional AT. We hypothesize this initial ERM phase cultivates a favorable feature manifold, enabling more efficient and effective robustness acquisition. Empirically, AET achieves comparable or superior robustness more rapidly, improves clean accuracy, and cuts training costs by 8-25%. Its effectiveness is shown across multiple datasets, architectures, and when augmenting established AT methods. Our findings underscore the impact of feature pre-conditioning via standard training for developing more efficient, principled robust defenses. Code is available in the supplementary material.",
    "summary": "arXiv:2506.15685v1 Announce Type: cross Abstract: Adversarial Training (AT) is a cornerstone defense, but many variants overlook foundational feature representations by primarily focusing on stronger attack generation. We introduce Adversarial Evolution Training (AET), a simple yet powerful framework that strategically prepends an Empirical Risk Minimization (ERM) phase to conventional AT. We hypothesize this initial ERM phase cultivates a favorable feature manifold, enabling more efficient and effective robustness acquisition. Empirically, AET achieves comparable or superior robustness more rapidly, improves clean accuracy, and cuts training costs by 8-25%. Its effectiveness is shown across multiple datasets, architectures, and when augmenting established AT methods. Our findings underscore the impact of feature pre-conditioning via standard training for developing more efficient, principled robust defenses. Code is available in the supplementary material.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.15685",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Improved Exploration in GFlownets via Enhanced Epistemic Neural Networks",
    "description": "arXiv:2506.16313v1 Announce Type: cross Abstract: Efficiently identifying the right trajectories for training remains an open problem in GFlowNets. To address this, it is essential to prioritize exploration in regions of the state space where the reward distribution has not been sufficiently learned. This calls for uncertainty-driven exploration, in other words, the agent should be aware of what it does not know. This attribute can be measured by joint predictions, which are particularly important for combinatorial and sequential decision problems. In this research, we integrate epistemic neural networks (ENN) with the conventional architecture of GFlowNets to enable more efficient joint predictions and better uncertainty quantification, thereby improving exploration and the identification of optimal trajectories. Our proposed algorithm, ENN-GFN-Enhanced, is compared to the baseline method in GFlownets and evaluated in grid environments and structured sequence generation in various settings, demonstrating both its efficacy and efficiency.",
    "summary": "arXiv:2506.16313v1 Announce Type: cross Abstract: Efficiently identifying the right trajectories for training remains an open problem in GFlowNets. To address this, it is essential to prioritize exploration in regions of the state space where the reward distribution has not been sufficiently learned. This calls for uncertainty-driven exploration, in other words, the agent should be aware of what it does not know. This attribute can be measured by joint predictions, which are particularly important for combinatorial and sequential decision problems. In this research, we integrate epistemic neural networks (ENN) with the conventional architecture of GFlowNets to enable more efficient joint predictions and better uncertainty quantification, thereby improving exploration and the identification of optimal trajectories. Our proposed algorithm, ENN-GFN-Enhanced, is compared to the baseline method in GFlownets and evaluated in grid environments and structured sequence generation in various settings, demonstrating both its efficacy and efficiency.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16313",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Improved Intelligibility of Dysarthric Speech using Conditional Flow Matching",
    "description": "arXiv:2506.16127v1 Announce Type: cross Abstract: Dysarthria is a neurological disorder that significantly impairs speech intelligibility, often rendering affected individuals unable to communicate effectively. This necessitates the development of robust dysarthric-to-regular speech conversion techniques. In this work, we investigate the utility and limitations of self-supervised learning (SSL) features and their quantized representations as an alternative to mel-spectrograms for speech generation. Additionally, we explore methods to mitigate speaker variability by generating clean speech in a single-speaker voice using features extracted from WavLM. To this end, we propose a fully non-autoregressive approach that leverages Conditional Flow Matching (CFM) with Diffusion Transformers to learn a direct mapping from dysarthric to clean speech. Our findings highlight the effectiveness of discrete acoustic units in improving intelligibility while achieving faster convergence compared to traditional mel-spectrogram-based approaches.",
    "summary": "arXiv:2506.16127v1 Announce Type: cross Abstract: Dysarthria is a neurological disorder that significantly impairs speech intelligibility, often rendering affected individuals unable to communicate effectively. This necessitates the development of robust dysarthric-to-regular speech conversion techniques. In this work, we investigate the utility and limitations of self-supervised learning (SSL) features and their quantized representations as an alternative to mel-spectrograms for speech generation. Additionally, we explore methods to mitigate speaker variability by generating clean speech in a single-speaker voice using features extracted from WavLM. To this end, we propose a fully non-autoregressive approach that leverages Conditional Flow Matching (CFM) with Diffusion Transformers to learn a direct mapping from dysarthric to clean speech. Our findings highlight the effectiveness of discrete acoustic units in improving intelligibility while achieving faster convergence compared to traditional mel-spectrogram-based approaches.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16127",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Incentivizing High-quality Participation From Federated Learning Agents",
    "description": "arXiv:2506.16731v1 Announce Type: new Abstract: Federated learning (FL) provides a promising paradigm for facilitating collaboration between multiple clients that jointly learn a global model without directly sharing their local data. However, existing research suffers from two caveats: 1) From the perspective of agents, voluntary and unselfish participation is often assumed. But self-interested agents may opt out of the system or provide low-quality contributions without proper incentives; 2) From the mechanism designer's perspective, the aggregated models can be unsatisfactory as the existing game-theoretical federated learning approach for data collection ignores the potential heterogeneous effort caused by contributed data. To alleviate above challenges, we propose an incentive-aware framework for agent participation that considers data heterogeneity to accelerate the convergence process. Specifically, we first introduce the notion of Wasserstein distance to explicitly illustrate the heterogeneous effort and reformulate the existing upper bound of convergence. To induce truthful reporting from agents, we analyze and measure the generalization error gap of any two agents by leveraging the peer prediction mechanism to develop score functions. We further present a two-stage Stackelberg game model that formalizes the process and examines the existence of equilibrium. Extensive experiments on real-world datasets demonstrate the effectiveness of our proposed mechanism.",
    "summary": "arXiv:2506.16731v1 Announce Type: new Abstract: Federated learning (FL) provides a promising paradigm for facilitating collaboration between multiple clients that jointly learn a global model without directly sharing their local data. However, existing research suffers from two caveats: 1) From the perspective of agents, voluntary and unselfish participation is often assumed. But self-interested agents may opt out of the system or provide low-quality contributions without proper incentives; 2) From the mechanism designer's perspective, the aggregated models can be unsatisfactory as the existing game-theoretical federated learning approach for data collection ignores the potential heterogeneous effort caused by contributed data. To alleviate above challenges, we propose an incentive-aware framework for agent participation that considers data heterogeneity to accelerate the convergence process. Specifically, we first introduce the notion of Wasserstein distance to explicitly illustrate the heterogeneous effort and reformulate the existing upper bound of convergence. To induce truthful reporting from agents, we analyze and measure the generalization error gap of any two agents by leveraging the peer prediction mechanism to develop score functions. We further present a two-stage Stackelberg game model that formalizes the process and examines the existence of equilibrium. Extensive experiments on real-world datasets demonstrate the effectiveness of our proposed mechanism.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16731",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Incivility and Rigidity: The Risks of Fine-Tuning LLMs for Political Argumentation",
    "description": "arXiv:2411.16813v3 Announce Type: replace-cross Abstract: The incivility prevalent on platforms like Twitter (now X) and Reddit poses a challenge for developing AI systems that can support productive and rhetorically sound political argumentation. In this study, we report experiments with GPT-3.5 Turbo, fine-tuned on two contrasting datasets of political discussions: high-variance, high-incivility Twitter replies to U.S. Congress, and low-variance, low-incivility posts from Reddit's r/ChangeMyView. We systematically evaluate how these data sources and prompting strategies shape the rhetorical framing and deliberative quality of model-generated arguments. Our results show that Reddit-finetuned models produce safer but rhetorically rigid arguments, while cross-platform fine-tuning amplifies toxicity. Prompting reduces specific toxic behaviors, such as personal attacks, but fails to fully mitigate the influence of high-incivility training data. We introduce and validate a rhetorical evaluation rubric and provide practical guidelines for deploying LLMs in content authoring, moderation, and deliberation support.",
    "summary": "arXiv:2411.16813v3 Announce Type: replace-cross Abstract: The incivility prevalent on platforms like Twitter (now X) and Reddit poses a challenge for developing AI systems that can support productive and rhetorically sound political argumentation. In this study, we report experiments with GPT-3.5 Turbo, fine-tuned on two contrasting datasets of political discussions: high-variance, high-incivility Twitter replies to U.S. Congress, and low-variance, low-incivility posts from Reddit's r/ChangeMyView. We systematically evaluate how these data sources and prompting strategies shape the rhetorical framing and deliberative quality of model-generated arguments. Our results show that Reddit-finetuned models produce safer but rhetorically rigid arguments, while cross-platform fine-tuning amplifies toxicity. Prompting reduces specific toxic behaviors, such as personal attacks, but fails to fully mitigate the influence of high-incivility training data. We introduce and validate a rhetorical evaluation rubric and provide practical guidelines for deploying LLMs in content authoring, moderation, and deliberation support.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2411.16813",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Info-Coevolution: An Efficient Framework for Data Model Coevolution",
    "description": "arXiv:2506.08070v2 Announce Type: replace-cross Abstract: Machine learning relies heavily on data, yet the continuous growth of real-world data poses challenges for efficient dataset construction and training. A fundamental yet unsolved question is: given our current model and data, does a new data (sample/batch) need annotation/learning? Conventional approaches retain all available data, leading to non-optimal data and training efficiency. Active learning aims to reduce data redundancy by selecting a subset of samples to annotate, while it increases pipeline complexity and introduces bias. In this work, we propose Info-Coevolution, a novel framework that efficiently enables models and data to coevolve through online selective annotation with no bias. Leveraging task-specific models (and open-source models), it selectively annotates and integrates online and web data to improve datasets efficiently. For real-world datasets like ImageNet-1K, Info-Coevolution reduces annotation and training costs by 32% without performance loss. It is able to automatically give the saving ratio without tuning the ratio. It can further reduce the annotation ratio to 50% with semi-supervised learning. We also explore retrieval-based dataset enhancement using unlabeled open-source data. Code is available at https://github.com/NUS-HPC-AI-Lab/Info-Coevolution/.",
    "summary": "arXiv:2506.08070v2 Announce Type: replace-cross Abstract: Machine learning relies heavily on data, yet the continuous growth of real-world data poses challenges for efficient dataset construction and training. A fundamental yet unsolved question is: given our current model and data, does a new data (sample/batch) need annotation/learning? Conventional approaches retain all available data, leading to non-optimal data and training efficiency. Active learning aims to reduce data redundancy by selecting a subset of samples to annotate, while it increases pipeline complexity and introduces bias. In this work, we propose Info-Coevolution, a novel framework that efficiently enables models and data to coevolve through online selective annotation with no bias. Leveraging task-specific models (and open-source models), it selectively annotates and integrates online and web data to improve datasets efficiently. For real-world datasets like ImageNet-1K, Info-Coevolution reduces annotation and training costs by 32% without performance loss. It is able to automatically give the saving ratio without tuning the ratio. It can further reduce the annotation ratio to 50% with semi-supervised learning. We also explore retrieval-based dataset enhancement using unlabeled open-source data. Code is available at https://github.com/NUS-HPC-AI-Lab/Info-Coevolution/.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.08070",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "InfomaticaがAIエージェントに本気　日本に向け「挑戦はリスク、だが待っていては追い付けない」",
    "description": "米Informaticaは年次イベント「Informatica World 2025」で、AIエージェントに関連する取り組みの大幅強化を発表した。日本に向けては、失敗を恐れず挑戦するよう訴えかけている。",
    "summary": "米Informaticaは年次イベント「Informatica World 2025」で、AIエージェントに関連する取り組みの大幅強化を発表した。日本に向けては、失敗を恐れず挑戦するよう訴えかけている。",
    "pubDate": "Mon, 23 Jun 2025 10:00:00 +0900",
    "source": "ITmedia AI",
    "url": "https://www.itmedia.co.jp/enterprise/articles/2506/23/news033.html",
    "thumbnail": "https://image.itmedia.co.jp/enterprise/articles/2506/23/cover_news033.jpg"
  },
  {
    "title": "InformaticaがAIエージェントに本気　日本に向け「挑戦はリスク、だが待っていては追い付けない」",
    "description": "米Informaticaは年次イベント「Informatica World 2025」で、AIエージェントに関連する取り組みの大幅強化を発表した。日本に向けては、失敗を恐れず挑戦するよう訴えかけている。",
    "summary": "米Informaticaは年次イベント「Informatica World 2025」で、AIエージェントに関連する取り組みの大幅強化を発表した。日本に向けては、失敗を恐れず挑戦するよう訴えかけている。",
    "pubDate": "Mon, 23 Jun 2025 10:00:00 +0900",
    "source": "ITmedia AI",
    "url": "https://www.itmedia.co.jp/enterprise/articles/2506/23/news033.html",
    "thumbnail": "https://image.itmedia.co.jp/enterprise/articles/2506/23/cover_news033.jpg"
  },
  {
    "title": "Infrastructure for AI Agents",
    "description": "arXiv:2501.10114v3 Announce Type: replace Abstract: AI agents plan and execute interactions in open-ended environments. For example, OpenAI's Operator can use a web browser to do product comparisons and buy online goods. Much research on making agents useful and safe focuses on directly modifying their behaviour, such as by training them to follow user instructions. Direct behavioural modifications are useful, but do not fully address how heterogeneous agents will interact with each other and other actors. Rather, we will need external protocols and systems to shape such interactions. For instance, agents will need more efficient protocols to communicate with each other and form agreements. Attributing an agent's actions to a particular human or other legal entity can help to establish trust, and also disincentivize misuse. Given this motivation, we propose the concept of textbf{agent infrastructure}: technical systems and shared protocols external to agents that are designed to mediate and influence their interactions with and impacts on their environments. Just as the Internet relies on protocols like HTTPS, our work argues that agent infrastructure will be similarly indispensable to ecosystems of agents. We identify three functions for agent infrastructure: 1) attributing actions, properties, and other information to specific agents, their users, or other actors; 2) shaping agents' interactions; and 3) detecting and remedying harmful actions from agents. We provide an incomplete catalog of research directions for such functions. For each direction, we include analysis of use cases, infrastructure adoption, relationships to existing (internet) infrastructure, limitations, and open questions. Making progress on agent infrastructure can prepare society for the adoption of more advanced agents.",
    "summary": "arXiv:2501.10114v3 Announce Type: replace Abstract: AI agents plan and execute interactions in open-ended environments. For example, OpenAI's Operator can use a web browser to do product comparisons and buy online goods. Much research on making agents useful and safe focuses on directly modifying their behaviour, such as by training them to follow user instructions. Direct behavioural modifications are useful, but do not fully address how heterogeneous agents will interact with each other and other actors. Rather, we will need external protocols and systems to shape such interactions. For instance, agents will need more efficient protocols to communicate with each other and form agreements. Attributing an agent's actions to a particular human or other legal entity can help to establish trust, and also disincentivize misuse. Given this motivation, we propose the concept of textbf{agent infrastructure}: technical systems and shared protocols external to agents that are designed to mediate and influence their interactions with and impacts on their environments. Just as the Internet relies on protocols like HTTPS, our work argues that agent infrastructure will be similarly indispensable to ecosystems of agents. We identify three functions for agent infrastructure: 1) attributing actions, properties, and other information to specific agents, their users, or other actors; 2) shaping agents' interactions; and 3) detecting and remedying harmful actions from agents. We provide an incomplete catalog of research directions for such functions. For each direction, we include analysis of use cases, infrastructure adoption, relationships to existing (internet) infrastructure, limitations, and open questions. Making progress on agent infrastructure can prepare society for the adoption of more advanced agents.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2501.10114",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Instituto de Telecomunicac{c}~oes at IWSLT 2025: Aligning Small-Scale Speech and Language Models for Speech-to-Text Learning",
    "description": "arXiv:2506.17019v1 Announce Type: cross Abstract: This paper presents the IT-IST submission to the IWSLT 2025 Shared Task on Instruction Following Speech Processing. We submit results for the Short Track, i.e., speech recognition, translation, and spoken question answering. Our model is a unified speech-to-text model that integrates a pre-trained continuous speech encoder and text decoder through a first phase of modality alignment and a second phase of instruction fine-tuning. Crucially, we focus on using small-scale language model backbones (< 2B) and restrict to high-quality, CC-BY data along with synthetic data generation to supplement existing resources.",
    "summary": "arXiv:2506.17019v1 Announce Type: cross Abstract: This paper presents the IT-IST submission to the IWSLT 2025 Shared Task on Instruction Following Speech Processing. We submit results for the Short Track, i.e., speech recognition, translation, and spoken question answering. Our model is a unified speech-to-text model that integrates a pre-trained continuous speech encoder and text decoder through a first phase of modality alignment and a second phase of instruction fine-tuning. Crucially, we focus on using small-scale language model backbones (< 2B) and restrict to high-quality, CC-BY data along with synthetic data generation to supplement existing resources.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.17019",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Interpretable Low-Dimensional Modeling of Spatiotemporal Agent States for Decision Making in Football Tactics",
    "description": "arXiv:2506.16696v1 Announce Type: new Abstract: Understanding football tactics is crucial for managers and analysts. Previous research has proposed models based on spatial and kinematic equations, but these are computationally expensive. Also, Reinforcement learning approaches use player positions and velocities but lack interpretability and require large datasets. Rule-based models align with expert knowledge but have not fully considered all players' states. This study explores whether low-dimensional, rule-based models using spatiotemporal data can effectively capture football tactics. Our approach defines interpretable state variables for both the ball-holder and potential pass receivers, based on criteria that explore options like passing. Through discussions with a manager, we identified key variables representing the game state. We then used StatsBomb event data and SkillCorner tracking data from the 2023$/$24 LaLiga season to train an XGBoost model to predict pass success. The analysis revealed that the distance between the player and the ball, as well as the player's space score, were key factors in determining successful passes. Our interpretable low-dimensional modeling facilitates tactical analysis through the use of intuitive variables and provides practical value as a tool to support decision-making in football.",
    "summary": "arXiv:2506.16696v1 Announce Type: new Abstract: Understanding football tactics is crucial for managers and analysts. Previous research has proposed models based on spatial and kinematic equations, but these are computationally expensive. Also, Reinforcement learning approaches use player positions and velocities but lack interpretability and require large datasets. Rule-based models align with expert knowledge but have not fully considered all players' states. This study explores whether low-dimensional, rule-based models using spatiotemporal data can effectively capture football tactics. Our approach defines interpretable state variables for both the ball-holder and potential pass receivers, based on criteria that explore options like passing. Through discussions with a manager, we identified key variables representing the game state. We then used StatsBomb event data and SkillCorner tracking data from the 2023$/$24 LaLiga season to train an XGBoost model to predict pass success. The analysis revealed that the distance between the player and the ball, as well as the player's space score, were key factors in determining successful passes. Our interpretable low-dimensional modeling facilitates tactical analysis through the use of intuitive variables and provides practical value as a tool to support decision-making in football.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16696",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "IS-Bench: Evaluating Interactive Safety of VLM-Driven Embodied Agents in Daily Household Tasks",
    "description": "arXiv:2506.16402v1 Announce Type: new Abstract: Flawed planning from VLM-driven embodied agents poses significant safety hazards, hindering their deployment in real-world household tasks. However, existing static, non-interactive evaluation paradigms fail to adequately assess risks within these interactive environments, since they cannot simulate dynamic risks that emerge from an agent's actions and rely on unreliable post-hoc evaluations that ignore unsafe intermediate steps. To bridge this critical gap, we propose evaluating an agent's interactive safety: its ability to perceive emergent risks and execute mitigation steps in the correct procedural order. We thus present IS-Bench, the first multi-modal benchmark designed for interactive safety, featuring 161 challenging scenarios with 388 unique safety risks instantiated in a high-fidelity simulator. Crucially, it facilitates a novel process-oriented evaluation that verifies whether risk mitigation actions are performed before/after specific risk-prone steps. Extensive experiments on leading VLMs, including the GPT-4o and Gemini-2.5 series, reveal that current agents lack interactive safety awareness, and that while safety-aware Chain-of-Thought can improve performance, it often compromises task completion. By highlighting these critical limitations, IS-Bench provides a foundation for developing safer and more reliable embodied AI systems.",
    "summary": "arXiv:2506.16402v1 Announce Type: new Abstract: Flawed planning from VLM-driven embodied agents poses significant safety hazards, hindering their deployment in real-world household tasks. However, existing static, non-interactive evaluation paradigms fail to adequately assess risks within these interactive environments, since they cannot simulate dynamic risks that emerge from an agent's actions and rely on unreliable post-hoc evaluations that ignore unsafe intermediate steps. To bridge this critical gap, we propose evaluating an agent's interactive safety: its ability to perceive emergent risks and execute mitigation steps in the correct procedural order. We thus present IS-Bench, the first multi-modal benchmark designed for interactive safety, featuring 161 challenging scenarios with 388 unique safety risks instantiated in a high-fidelity simulator. Crucially, it facilitates a novel process-oriented evaluation that verifies whether risk mitigation actions are performed before/after specific risk-prone steps. Extensive experiments on leading VLMs, including the GPT-4o and Gemini-2.5 series, reveal that current agents lack interactive safety awareness, and that while safety-aware Chain-of-Thought can improve performance, it often compromises task completion. By highlighting these critical limitations, IS-Bench provides a foundation for developing safer and more reliable embodied AI systems.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16402",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "JETHICS: Japanese Ethics Understanding Evaluation Dataset",
    "description": "arXiv:2506.16187v1 Announce Type: cross Abstract: In this work, we propose JETHICS, a Japanese dataset for evaluating ethics understanding of AI models. JETHICS contains 78K examples and is built by following the construction methods of the existing English ETHICS dataset. It includes four categories based normative theories and concepts from ethics and political philosophy; and one representing commonsense morality. Our evaluation experiments on non-proprietary large language models (LLMs) and on GPT-4o reveal that even GPT-4o achieves only an average score of about 0.7, while the best-performing Japanese LLM attains around 0.5, indicating a relatively large room for improvement in current LLMs.",
    "summary": "arXiv:2506.16187v1 Announce Type: cross Abstract: In this work, we propose JETHICS, a Japanese dataset for evaluating ethics understanding of AI models. JETHICS contains 78K examples and is built by following the construction methods of the existing English ETHICS dataset. It includes four categories based normative theories and concepts from ethics and political philosophy; and one representing commonsense morality. Our evaluation experiments on non-proprietary large language models (LLMs) and on GPT-4o reveal that even GPT-4o achieves only an average score of about 0.7, while the best-performing Japanese LLM attains around 0.5, indicating a relatively large room for improvement in current LLMs.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16187",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Joint Tensor-Train Parameterization for Efficient and Expressive Low-Rank Adaptation",
    "description": "arXiv:2506.16456v1 Announce Type: cross Abstract: Low-Rank Adaptation (LoRA) is widely recognized for its parameter-efficient fine-tuning of large-scale neural models. However, standard LoRA independently optimizes low-rank matrices, which inherently limits its expressivity and generalization capabilities. While classical tensor-train (TT) decomposition can be separately employed on individual LoRA matrices, this work demonstrates that the classical TT-based approach neither significantly improves parameter efficiency nor achieves substantial performance gains. This paper proposes TensorGuide, a novel tensor-train-guided adaptation framework to overcome these limitations. TensorGuide generates two correlated low-rank LoRA matrices through a unified TT structure driven by controlled Gaussian noise. The resulting joint TT representation inherently provides structured, low-rank adaptations, significantly enhancing expressivity, generalization, and parameter efficiency without increasing the number of trainable parameters. Theoretically, we justify these improvements through neural tangent kernel analyses, demonstrating superior optimization dynamics and enhanced generalization. Extensive experiments on quantum dot classification and GPT-2 fine-tuning benchmarks demonstrate that TensorGuide-based LoRA consistently outperforms standard LoRA and TT-LoRA, achieving improved accuracy and scalability with fewer parameters.",
    "summary": "arXiv:2506.16456v1 Announce Type: cross Abstract: Low-Rank Adaptation (LoRA) is widely recognized for its parameter-efficient fine-tuning of large-scale neural models. However, standard LoRA independently optimizes low-rank matrices, which inherently limits its expressivity and generalization capabilities. While classical tensor-train (TT) decomposition can be separately employed on individual LoRA matrices, this work demonstrates that the classical TT-based approach neither significantly improves parameter efficiency nor achieves substantial performance gains. This paper proposes TensorGuide, a novel tensor-train-guided adaptation framework to overcome these limitations. TensorGuide generates two correlated low-rank LoRA matrices through a unified TT structure driven by controlled Gaussian noise. The resulting joint TT representation inherently provides structured, low-rank adaptations, significantly enhancing expressivity, generalization, and parameter efficiency without increasing the number of trainable parameters. Theoretically, we justify these improvements through neural tangent kernel analyses, demonstrating superior optimization dynamics and enhanced generalization. Extensive experiments on quantum dot classification and GPT-2 fine-tuning benchmarks demonstrate that TensorGuide-based LoRA consistently outperforms standard LoRA and TT-LoRA, achieving improved accuracy and scalability with fewer parameters.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16456",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "KG-FGNN: Knowledge-guided GNN Foundation Model for Fertilisation-oriented Soil GHG Flux Prediction",
    "description": "arXiv:2506.15896v1 Announce Type: cross Abstract: Precision soil greenhouse gas (GHG) flux prediction is essential in agricultural systems for assessing environmental impacts, developing emission mitigation strategies and promoting sustainable agriculture. Due to the lack of advanced sensor and network technologies on majority of farms, there are challenges in obtaining comprehensive and diverse agricultural data. As a result, the scarcity of agricultural data seriously obstructs the application of machine learning approaches in precision soil GHG flux prediction. This research proposes a knowledge-guided graph neural network framework that addresses the above challenges by integrating knowledge embedded in an agricultural process-based model and graph neural network techniques. Specifically, we utilise the agricultural process-based model to simulate and generate multi-dimensional agricultural datasets for 47 countries that cover a wide range of agricultural variables. To extract key agricultural features and integrate correlations among agricultural features in the prediction process, we propose a machine learning framework that integrates the autoencoder and multi-target multi-graph based graph neural networks, which utilises the autoencoder to selectively extract significant agricultural features from the agricultural process-based model simulation data and the graph neural network to integrate correlations among agricultural features for accurately predict fertilisation-oriented soil GHG fluxes. Comprehensive experiments were conducted with both the agricultural simulation dataset and real-world agricultural dataset to evaluate the proposed approach in comparison with well-known baseline and state-of-the-art regression methods. The results demonstrate that our proposed approach provides superior accuracy and stability in fertilisation-oriented soil GHG prediction.",
    "summary": "arXiv:2506.15896v1 Announce Type: cross Abstract: Precision soil greenhouse gas (GHG) flux prediction is essential in agricultural systems for assessing environmental impacts, developing emission mitigation strategies and promoting sustainable agriculture. Due to the lack of advanced sensor and network technologies on majority of farms, there are challenges in obtaining comprehensive and diverse agricultural data. As a result, the scarcity of agricultural data seriously obstructs the application of machine learning approaches in precision soil GHG flux prediction. This research proposes a knowledge-guided graph neural network framework that addresses the above challenges by integrating knowledge embedded in an agricultural process-based model and graph neural network techniques. Specifically, we utilise the agricultural process-based model to simulate and generate multi-dimensional agricultural datasets for 47 countries that cover a wide range of agricultural variables. To extract key agricultural features and integrate correlations among agricultural features in the prediction process, we propose a machine learning framework that integrates the autoencoder and multi-target multi-graph based graph neural networks, which utilises the autoencoder to selectively extract significant agricultural features from the agricultural process-based model simulation data and the graph neural network to integrate correlations among agricultural features for accurately predict fertilisation-oriented soil GHG fluxes. Comprehensive experiments were conducted with both the agricultural simulation dataset and real-world agricultural dataset to evaluate the proposed approach in comparison with well-known baseline and state-of-the-art regression methods. The results demonstrate that our proposed approach provides superior accuracy and stability in fertilisation-oriented soil GHG prediction.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.15896",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "KVCache Cache in the Wild: Characterizing and Optimizing KVCache Cache at a Large Cloud Provider",
    "description": "arXiv:2506.02634v3 Announce Type: replace-cross Abstract: Serving large language models (LLMs) is important for cloud providers, and caching intermediate results (KV$) after processing each request substantially improves serving throughput and latency. However, there is limited understanding of how LLM serving benefits from KV$ caching, where system design decisions like cache eviction policies are highly workload-dependent. In this paper, we present the first systematic characterization of the KV$ workload patterns from one of the leading LLM service providers. We draw observations that were not covered by previous studies focusing on synthetic workloads, including: KV$ reuses are skewed across requests, where reuses between single-turn requests are equally important as multi-turn requests; the reuse time and probability are diverse considering all requests, but for a specific request category, the pattern tends to be predictable; and the overall cache size required for an ideal cache hit ratio is moderate. Based on the characterization, we further propose a workload-aware cache eviction policy that improves the serving performance under real-world traces, especially with limited cache capacity.",
    "summary": "arXiv:2506.02634v3 Announce Type: replace-cross Abstract: Serving large language models (LLMs) is important for cloud providers, and caching intermediate results (KV$) after processing each request substantially improves serving throughput and latency. However, there is limited understanding of how LLM serving benefits from KV$ caching, where system design decisions like cache eviction policies are highly workload-dependent. In this paper, we present the first systematic characterization of the KV$ workload patterns from one of the leading LLM service providers. We draw observations that were not covered by previous studies focusing on synthetic workloads, including: KV$ reuses are skewed across requests, where reuses between single-turn requests are equally important as multi-turn requests; the reuse time and probability are diverse considering all requests, but for a specific request category, the pattern tends to be predictable; and the overall cache size required for an ideal cache hit ratio is moderate. Based on the characterization, we further propose a workload-aware cache eviction policy that improves the serving performance under real-world traces, especially with limited cache capacity.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.02634",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "LAECIPS: Large Vision Model Assisted Adaptive Edge-Cloud Collaboration for IoT-based Embodied Intelligence System",
    "description": "arXiv:2404.10498v2 Announce Type: replace Abstract: Embodied intelligence (EI) enables manufacturing systems to flexibly perceive, reason, adapt, and operate within dynamic shop floor environments. In smart manufacturing, a representative EI scenario is robotic visual inspection, where industrial robots must accurately inspect components on rapidly changing, heterogeneous production lines. This task requires both high inference accuracy especially for uncommon defects and low latency to match production speeds, despite evolving lighting, part geometries, and surface conditions. To meet these needs, we propose LAECIPS, a large vision model-assisted adaptive edge-cloud collaboration framework for IoT-based embodied intelligence systems. LAECIPS decouples large vision models in the cloud from lightweight models on the edge, enabling plug-and-play model adaptation and continual learning. Through a hard input mining-based inference strategy, LAECIPS routes complex and uncertain inspection cases to the cloud while handling routine tasks at the edge, achieving both high accuracy and low latency. Experiments conducted on a real-world robotic semantic segmentation system for visual inspection demonstrate significant improvements in accuracy, processing latency, and communication overhead compared to state-of-the-art methods. LAECIPS provides a practical and scalable foundation for embodied intelligence in smart manufacturing, especially in adaptive robotic inspection and quality control scenarios.",
    "summary": "arXiv:2404.10498v2 Announce Type: replace Abstract: Embodied intelligence (EI) enables manufacturing systems to flexibly perceive, reason, adapt, and operate within dynamic shop floor environments. In smart manufacturing, a representative EI scenario is robotic visual inspection, where industrial robots must accurately inspect components on rapidly changing, heterogeneous production lines. This task requires both high inference accuracy especially for uncommon defects and low latency to match production speeds, despite evolving lighting, part geometries, and surface conditions. To meet these needs, we propose LAECIPS, a large vision model-assisted adaptive edge-cloud collaboration framework for IoT-based embodied intelligence systems. LAECIPS decouples large vision models in the cloud from lightweight models on the edge, enabling plug-and-play model adaptation and continual learning. Through a hard input mining-based inference strategy, LAECIPS routes complex and uncertain inspection cases to the cloud while handling routine tasks at the edge, achieving both high accuracy and low latency. Experiments conducted on a real-world robotic semantic segmentation system for visual inspection demonstrate significant improvements in accuracy, processing latency, and communication overhead compared to state-of-the-art methods. LAECIPS provides a practical and scalable foundation for embodied intelligence in smart manufacturing, especially in adaptive robotic inspection and quality control scenarios.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2404.10498",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Language Bottleneck Models: A Framework for Interpretable Knowledge Tracing and Beyond",
    "description": "arXiv:2506.16982v1 Announce Type: cross Abstract: Accurately assessing student knowledge is critical for effective education, yet traditional Knowledge Tracing (KT) methods rely on opaque latent embeddings, limiting interpretability. Even LLM-based approaches generate direct predictions or summaries that may hallucinate without any accuracy guarantees. We recast KT as an inverse problem: learning the minimum natural-language summary that makes past answers explainable and future answers predictable. Our Language Bottleneck Model (LBM) consists of an encoder LLM that writes an interpretable knowledge summary and a frozen decoder LLM that must reconstruct and predict student responses using only that summary text. By constraining all predictive information to pass through a short natural-language bottleneck, LBMs ensure that the summary contains accurate information while remaining human-interpretable. Experiments on synthetic arithmetic benchmarks and the large-scale Eedi dataset show that LBMs rival the accuracy of state-of-the-art KT and direct LLM methods while requiring orders-of-magnitude fewer student trajectories. We demonstrate that training the encoder with group-relative policy optimization, using downstream decoding accuracy as a reward signal, effectively improves summary quality.",
    "summary": "arXiv:2506.16982v1 Announce Type: cross Abstract: Accurately assessing student knowledge is critical for effective education, yet traditional Knowledge Tracing (KT) methods rely on opaque latent embeddings, limiting interpretability. Even LLM-based approaches generate direct predictions or summaries that may hallucinate without any accuracy guarantees. We recast KT as an inverse problem: learning the minimum natural-language summary that makes past answers explainable and future answers predictable. Our Language Bottleneck Model (LBM) consists of an encoder LLM that writes an interpretable knowledge summary and a frozen decoder LLM that must reconstruct and predict student responses using only that summary text. By constraining all predictive information to pass through a short natural-language bottleneck, LBMs ensure that the summary contains accurate information while remaining human-interpretable. Experiments on synthetic arithmetic benchmarks and the large-scale Eedi dataset show that LBMs rival the accuracy of state-of-the-art KT and direct LLM methods while requiring orders-of-magnitude fewer student trajectories. We demonstrate that training the encoder with group-relative policy optimization, using downstream decoding accuracy as a reward signal, effectively improves summary quality.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16982",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Language-Informed Synthesis of Rational Agent Models for Grounded Theory-of-Mind Reasoning On-The-Fly",
    "description": "arXiv:2506.16755v1 Announce Type: cross Abstract: Drawing real world social inferences usually requires taking into account information from multiple modalities. Language is a particularly powerful source of information in social settings, especially in novel situations where language can provide both abstract information about the environment dynamics and concrete specifics about an agent that cannot be easily visually observed. In this paper, we propose Language-Informed Rational Agent Synthesis (LIRAS), a framework for drawing context-specific social inferences that integrate linguistic and visual inputs. LIRAS frames multimodal social reasoning as a process of constructing structured but situation-specific agent and environment representations - leveraging multimodal language models to parse language and visual inputs into unified symbolic representations, over which a Bayesian inverse planning engine can be run to produce granular probabilistic judgments. On a range of existing and new social reasoning tasks derived from cognitive science experiments, we find that our model (instantiated with a comparatively lightweight VLM) outperforms ablations and state-of-the-art models in capturing human judgments across all domains.",
    "summary": "arXiv:2506.16755v1 Announce Type: cross Abstract: Drawing real world social inferences usually requires taking into account information from multiple modalities. Language is a particularly powerful source of information in social settings, especially in novel situations where language can provide both abstract information about the environment dynamics and concrete specifics about an agent that cannot be easily visually observed. In this paper, we propose Language-Informed Rational Agent Synthesis (LIRAS), a framework for drawing context-specific social inferences that integrate linguistic and visual inputs. LIRAS frames multimodal social reasoning as a process of constructing structured but situation-specific agent and environment representations - leveraging multimodal language models to parse language and visual inputs into unified symbolic representations, over which a Bayesian inverse planning engine can be run to produce granular probabilistic judgments. On a range of existing and new social reasoning tasks derived from cognitive science experiments, we find that our model (instantiated with a comparatively lightweight VLM) outperforms ablations and state-of-the-art models in capturing human judgments across all domains.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16755",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Language Models can perform Single-Utterance Self-Correction of Perturbed Reasoning",
    "description": "arXiv:2506.15894v1 Announce Type: cross Abstract: Large Language Models (LLMs) have demonstrated impressive mathematical reasoning capabilities, yet their performance remains brittle to minor variations in problem description and prompting strategy. Furthermore, reasoning is vulnerable to sampling-induced errors which autoregressive models must primarily address using self-correction via additionally-generated tokens. To better understand self-correction capabilities of recent models, we conduct experiments measuring models' ability to self-correct synthetic perturbations introduced into their Chain of Thought (CoT) reasoning. We observe robust single-utterance intrinsic self-correction behavior across a range of open-weight models and datasets, ranging from subtle, implicit corrections to explicit acknowledgments and corrections of errors. Our findings suggest that LLMs, including those not finetuned for long CoT, may possess stronger intrinsic self-correction capabilities than commonly shown in the literature. The presence of this ability suggests that recent 'reasoning' model work involves amplification of traits already meaningfully present in models.",
    "summary": "arXiv:2506.15894v1 Announce Type: cross Abstract: Large Language Models (LLMs) have demonstrated impressive mathematical reasoning capabilities, yet their performance remains brittle to minor variations in problem description and prompting strategy. Furthermore, reasoning is vulnerable to sampling-induced errors which autoregressive models must primarily address using self-correction via additionally-generated tokens. To better understand self-correction capabilities of recent models, we conduct experiments measuring models' ability to self-correct synthetic perturbations introduced into their Chain of Thought (CoT) reasoning. We observe robust single-utterance intrinsic self-correction behavior across a range of open-weight models and datasets, ranging from subtle, implicit corrections to explicit acknowledgments and corrections of errors. Our findings suggest that LLMs, including those not finetuned for long CoT, may possess stronger intrinsic self-correction capabilities than commonly shown in the literature. The presence of this ability suggests that recent 'reasoning' model work involves amplification of traits already meaningfully present in models.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.15894",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Large Language Models are Near-Optimal Decision-Makers with a Non-Human Learning Behavior",
    "description": "arXiv:2506.16163v1 Announce Type: new Abstract: Human decision-making belongs to the foundation of our society and civilization, but we are on the verge of a future where much of it will be delegated to artificial intelligence. The arrival of Large Language Models (LLMs) has transformed the nature and scope of AI-supported decision-making; however, the process by which they learn to make decisions, compared to humans, remains poorly understood. In this study, we examined the decision-making behavior of five leading LLMs across three core dimensions of real-world decision-making: uncertainty, risk, and set-shifting. Using three well-established experimental psychology tasks designed to probe these dimensions, we benchmarked LLMs against 360 newly recruited human participants. Across all tasks, LLMs often outperformed humans, approaching near-optimal performance. Moreover, the processes underlying their decisions diverged fundamentally from those of humans. On the one hand, our finding demonstrates the ability of LLMs to manage uncertainty, calibrate risk, and adapt to changes. On the other hand, this disparity highlights the risks of relying on them as substitutes for human judgment, calling for further inquiry.",
    "summary": "arXiv:2506.16163v1 Announce Type: new Abstract: Human decision-making belongs to the foundation of our society and civilization, but we are on the verge of a future where much of it will be delegated to artificial intelligence. The arrival of Large Language Models (LLMs) has transformed the nature and scope of AI-supported decision-making; however, the process by which they learn to make decisions, compared to humans, remains poorly understood. In this study, we examined the decision-making behavior of five leading LLMs across three core dimensions of real-world decision-making: uncertainty, risk, and set-shifting. Using three well-established experimental psychology tasks designed to probe these dimensions, we benchmarked LLMs against 360 newly recruited human participants. Across all tasks, LLMs often outperformed humans, approaching near-optimal performance. Moreover, the processes underlying their decisions diverged fundamentally from those of humans. On the one hand, our finding demonstrates the ability of LLMs to manage uncertainty, calibrate risk, and adapt to changes. On the other hand, this disparity highlights the risks of relying on them as substitutes for human judgment, calling for further inquiry.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16163",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Large Language Models as Psychological Simulators: A Methodological Guide",
    "description": "arXiv:2506.16702v1 Announce Type: cross Abstract: Large language models (LLMs) offer emerging opportunities for psychological and behavioral research, but methodological guidance is lacking. This article provides a framework for using LLMs as psychological simulators across two primary applications: simulating roles and personas to explore diverse contexts, and serving as computational models to investigate cognitive processes. For simulation, we present methods for developing psychologically grounded personas that move beyond demographic categories, with strategies for validation against human data and use cases ranging from studying inaccessible populations to prototyping research instruments. For cognitive modeling, we synthesize emerging approaches for probing internal representations, methodological advances in causal interventions, and strategies for relating model behavior to human cognition. We address overarching challenges including prompt sensitivity, temporal limitations from training data cutoffs, and ethical considerations that extend beyond traditional human subjects review. Throughout, we emphasize the need for transparency about model capabilities and constraints. Together, this framework integrates emerging empirical evidence about LLM performance--including systematic biases, cultural limitations, and prompt brittleness--to help researchers wrangle these challenges and leverage the unique capabilities of LLMs in psychological research.",
    "summary": "arXiv:2506.16702v1 Announce Type: cross Abstract: Large language models (LLMs) offer emerging opportunities for psychological and behavioral research, but methodological guidance is lacking. This article provides a framework for using LLMs as psychological simulators across two primary applications: simulating roles and personas to explore diverse contexts, and serving as computational models to investigate cognitive processes. For simulation, we present methods for developing psychologically grounded personas that move beyond demographic categories, with strategies for validation against human data and use cases ranging from studying inaccessible populations to prototyping research instruments. For cognitive modeling, we synthesize emerging approaches for probing internal representations, methodological advances in causal interventions, and strategies for relating model behavior to human cognition. We address overarching challenges including prompt sensitivity, temporal limitations from training data cutoffs, and ethical considerations that extend beyond traditional human subjects review. Throughout, we emphasize the need for transparency about model capabilities and constraints. Together, this framework integrates emerging empirical evidence about LLM performance--including systematic biases, cultural limitations, and prompt brittleness--to help researchers wrangle these challenges and leverage the unique capabilities of LLMs in psychological research.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16702",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "LaRS: Latent Reasoning Skills for Chain-of-Thought Reasoning",
    "description": "arXiv:2312.04684v4 Announce Type: replace-cross Abstract: Chain-of-thought (CoT) prompting is a popular in-context learning (ICL) approach for large language models (LLMs), especially when tackling complex reasoning tasks. Traditional ICL approaches construct prompts using examples that contain questions similar to the input question. However, CoT prompting, which includes crucial intermediate reasoning steps (rationales) within its examples, necessitates selecting examples based on these rationales rather than the questions themselves. Existing methods require human experts or pre-trained LLMs to describe the skill, a high-level abstraction of rationales, to guide the selection. These methods, however, are often costly and difficult to scale. Instead, this paper introduces a new approach named Latent Reasoning Skills (LaRS) that employs unsupervised learning to create a latent space representation of rationales, with a latent variable called a reasoning skill. Concurrently, LaRS learns a reasoning policy to determine the required reasoning skill for a given question. Then the ICL examples are selected by aligning the reasoning skills between past examples and the question. This approach is theoretically grounded and compute-efficient, eliminating the need for auxiliary LLM inference or manual prompt design. Empirical results demonstrate that LaRS consistently outperforms SOTA skill-based selection methods, processing example banks four times faster, reducing LLM inferences during the selection stage by half, and showing greater robustness to sub-optimal example banks.",
    "summary": "arXiv:2312.04684v4 Announce Type: replace-cross Abstract: Chain-of-thought (CoT) prompting is a popular in-context learning (ICL) approach for large language models (LLMs), especially when tackling complex reasoning tasks. Traditional ICL approaches construct prompts using examples that contain questions similar to the input question. However, CoT prompting, which includes crucial intermediate reasoning steps (rationales) within its examples, necessitates selecting examples based on these rationales rather than the questions themselves. Existing methods require human experts or pre-trained LLMs to describe the skill, a high-level abstraction of rationales, to guide the selection. These methods, however, are often costly and difficult to scale. Instead, this paper introduces a new approach named Latent Reasoning Skills (LaRS) that employs unsupervised learning to create a latent space representation of rationales, with a latent variable called a reasoning skill. Concurrently, LaRS learns a reasoning policy to determine the required reasoning skill for a given question. Then the ICL examples are selected by aligning the reasoning skills between past examples and the question. This approach is theoretically grounded and compute-efficient, eliminating the need for auxiliary LLM inference or manual prompt design. Empirical results demonstrate that LaRS consistently outperforms SOTA skill-based selection methods, processing example banks four times faster, reducing LLM inferences during the selection stage by half, and showing greater robustness to sub-optimal example banks.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2312.04684",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Latent Concept Disentanglement in Transformer-based Language Models",
    "description": "arXiv:2506.16975v1 Announce Type: cross Abstract: When large language models (LLMs) use in-context learning (ICL) to solve a new task, they seem to grasp not only the goal of the task but also core, latent concepts in the demonstration examples. This begs the question of whether transformers represent latent structures as part of their computation or whether they take shortcuts to solve the problem. Prior mechanistic work on ICL does not address this question because it does not sufficiently examine the relationship between the learned representation and the latent concept, and the considered problem settings often involve only single-step reasoning. In this work, we examine how transformers disentangle and use latent concepts. We show that in 2-hop reasoning tasks with a latent, discrete concept, the model successfully identifies the latent concept and does step-by-step concept composition. In tasks parameterized by a continuous latent concept, we find low-dimensional subspaces in the representation space where the geometry mimics the underlying parameterization. Together, these results refine our understanding of ICL and the representation of transformers, and they provide evidence for highly localized structures in the model that disentangle latent concepts in ICL tasks.",
    "summary": "arXiv:2506.16975v1 Announce Type: cross Abstract: When large language models (LLMs) use in-context learning (ICL) to solve a new task, they seem to grasp not only the goal of the task but also core, latent concepts in the demonstration examples. This begs the question of whether transformers represent latent structures as part of their computation or whether they take shortcuts to solve the problem. Prior mechanistic work on ICL does not address this question because it does not sufficiently examine the relationship between the learned representation and the latent concept, and the considered problem settings often involve only single-step reasoning. In this work, we examine how transformers disentangle and use latent concepts. We show that in 2-hop reasoning tasks with a latent, discrete concept, the model successfully identifies the latent concept and does step-by-step concept composition. In tasks parameterized by a continuous latent concept, we find low-dimensional subspaces in the representation space where the geometry mimics the underlying parameterization. Together, these results refine our understanding of ICL and the representation of transformers, and they provide evidence for highly localized structures in the model that disentangle latent concepts in ICL tasks.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16975",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Latent Noise Injection for Private and Statistically Aligned Synthetic Data Generation",
    "description": "arXiv:2506.16636v1 Announce Type: cross Abstract: Synthetic Data Generation has become essential for scalable, privacy-preserving statistical analysis. While standard approaches based on generative models, such as Normalizing Flows, have been widely used, they often suffer from slow convergence in high-dimensional settings, frequently converging more slowly than the canonical $1/sqrt{n}$ rate when approximating the true data distribution. To overcome these limitations, we propose a Latent Noise Injection method using Masked Autoregressive Flows (MAF). Instead of directly sampling from the trained model, our method perturbs each data point in the latent space and maps it back to the data domain. This construction preserves a one to one correspondence between observed and synthetic data, enabling synthetic outputs that closely reflect the underlying distribution, particularly in challenging high-dimensional regimes where traditional sampling struggles. Our procedure satisfies local $(epsilon, delta)$-differential privacy and introduces a single perturbation parameter to control the privacy-utility trade-off. Although estimators based on individual synthetic datasets may converge slowly, we show both theoretically and empirically that aggregating across $K$ studies in a meta analysis framework restores classical efficiency and yields consistent, reliable inference. We demonstrate that with a well-calibrated perturbation parameter, Latent Noise Injection achieves strong statistical alignment with the original data and robustness against membership inference attacks. These results position our method as a compelling alternative to conventional flow-based sampling for synthetic data sharing in decentralized and privacy-sensitive domains, such as biomedical research.",
    "summary": "arXiv:2506.16636v1 Announce Type: cross Abstract: Synthetic Data Generation has become essential for scalable, privacy-preserving statistical analysis. While standard approaches based on generative models, such as Normalizing Flows, have been widely used, they often suffer from slow convergence in high-dimensional settings, frequently converging more slowly than the canonical $1/sqrt{n}$ rate when approximating the true data distribution. To overcome these limitations, we propose a Latent Noise Injection method using Masked Autoregressive Flows (MAF). Instead of directly sampling from the trained model, our method perturbs each data point in the latent space and maps it back to the data domain. This construction preserves a one to one correspondence between observed and synthetic data, enabling synthetic outputs that closely reflect the underlying distribution, particularly in challenging high-dimensional regimes where traditional sampling struggles. Our procedure satisfies local $(epsilon, delta)$-differential privacy and introduces a single perturbation parameter to control the privacy-utility trade-off. Although estimators based on individual synthetic datasets may converge slowly, we show both theoretically and empirically that aggregating across $K$ studies in a meta analysis framework restores classical efficiency and yields consistent, reliable inference. We demonstrate that with a well-calibrated perturbation parameter, Latent Noise Injection achieves strong statistical alignment with the original data and robustness against membership inference attacks. These results position our method as a compelling alternative to conventional flow-based sampling for synthetic data sharing in decentralized and privacy-sensitive domains, such as biomedical research.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16636",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Learn from the Past: Fast Sparse Indexing for Large Language Model Decoding",
    "description": "arXiv:2506.15704v1 Announce Type: cross Abstract: As large language models (LLMs) continue to support increasingly longer contexts, the memory demand for key-value (KV) caches during decoding grows rapidly, becoming a critical bottleneck in both GPU memory capacity and PCIe bandwidth. Sparse attention mechanisms alleviate this issue by computing attention weights only for selected key-value pairs. However, their indexing computation typically requires traversing all key vectors, resulting in significant computational and data transfer overhead. To reduce the cost of index retrieval, existing methods often treat each decoding step as an independent process, failing to exploit the temporal correlations embedded in historical decoding information. To this end, we propose LFPS(Learn From the Past for Sparse Indexing), an acceleration method that dynamically constructs sparse indexing candidates based on historical attention patterns. LFPS captures two prevalent trends in decoder attention -vertical patterns (attending to fixed positions) and slash patterns (attending to relative positions) -and incorporates a positional expansion strategy to effectively predict the Top-k indices for the current step. We validate LFPS on challenging long-context benchmarks such as LongBench-RULER, using Llama-3.1-8B-Instruct as the base model. Experimental results show that LFPS achieves up to 22.8$times$ speedup over full attention and 9.6$times$ speedup over exact Top-k retrieval on an RTX 4090 GPU and a single CPU core of a Xeon Gold 6430, respectively, while preserving generation accuracy. These results demonstrate that LFPS offers a practical and efficient solution for decoding optimization in long-context LLM inference.",
    "summary": "arXiv:2506.15704v1 Announce Type: cross Abstract: As large language models (LLMs) continue to support increasingly longer contexts, the memory demand for key-value (KV) caches during decoding grows rapidly, becoming a critical bottleneck in both GPU memory capacity and PCIe bandwidth. Sparse attention mechanisms alleviate this issue by computing attention weights only for selected key-value pairs. However, their indexing computation typically requires traversing all key vectors, resulting in significant computational and data transfer overhead. To reduce the cost of index retrieval, existing methods often treat each decoding step as an independent process, failing to exploit the temporal correlations embedded in historical decoding information. To this end, we propose LFPS(Learn From the Past for Sparse Indexing), an acceleration method that dynamically constructs sparse indexing candidates based on historical attention patterns. LFPS captures two prevalent trends in decoder attention -vertical patterns (attending to fixed positions) and slash patterns (attending to relative positions) -and incorporates a positional expansion strategy to effectively predict the Top-k indices for the current step. We validate LFPS on challenging long-context benchmarks such as LongBench-RULER, using Llama-3.1-8B-Instruct as the base model. Experimental results show that LFPS achieves up to 22.8$times$ speedup over full attention and 9.6$times$ speedup over exact Top-k retrieval on an RTX 4090 GPU and a single CPU core of a Xeon Gold 6430, respectively, while preserving generation accuracy. These results demonstrate that LFPS offers a practical and efficient solution for decoding optimization in long-context LLM inference.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.15704",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "LearnAlign: Reasoning Data Selection for Reinforcement Learning in Large Language Models Based on Improved Gradient Alignment",
    "description": "arXiv:2506.11480v2 Announce Type: replace-cross Abstract: Reinforcement learning (RL) has become a key technique for enhancing LLMs' reasoning abilities, yet its data inefficiency remains a major bottleneck. To address this critical yet challenging issue, we present a novel gradient-alignment-based method, named LearnAlign, which intelligently selects the learnable and representative training reasoning data for RL post-training. To overcome the issue of response-length bias in gradient norms, we introduce the data learnability based on the success rate, which can indicate the learning potential of each data point. Experiments across three mathematical reasoning benchmarks demonstrate that our method significantly reduces training data requirements while achieving minor performance degradation or even improving performance compared to full-data training. For example, it reduces data requirements by up to 1,000 data points with better performance (77.53%) than that on the full dataset on GSM8K benchmark (77.04%). Furthermore, we show its effectiveness in the staged RL setting. This work provides valuable insights into data-efficient RL post-training and establishes a foundation for future research in optimizing reasoning data selection. To facilitate future work, we will release code.",
    "summary": "arXiv:2506.11480v2 Announce Type: replace-cross Abstract: Reinforcement learning (RL) has become a key technique for enhancing LLMs' reasoning abilities, yet its data inefficiency remains a major bottleneck. To address this critical yet challenging issue, we present a novel gradient-alignment-based method, named LearnAlign, which intelligently selects the learnable and representative training reasoning data for RL post-training. To overcome the issue of response-length bias in gradient norms, we introduce the data learnability based on the success rate, which can indicate the learning potential of each data point. Experiments across three mathematical reasoning benchmarks demonstrate that our method significantly reduces training data requirements while achieving minor performance degradation or even improving performance compared to full-data training. For example, it reduces data requirements by up to 1,000 data points with better performance (77.53%) than that on the full dataset on GSM8K benchmark (77.04%). Furthermore, we show its effectiveness in the staged RL setting. This work provides valuable insights into data-efficient RL post-training and establishes a foundation for future research in optimizing reasoning data selection. To facilitate future work, we will release code.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.11480",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Learning Dexterous Object Handover",
    "description": "arXiv:2506.16822v1 Announce Type: cross Abstract: Object handover is an important skill that we use daily when interacting with other humans. To deploy robots in collaborative setting, like houses, being able to receive and handing over objects safely and efficiently becomes a crucial skill. In this work, we demonstrate the use of Reinforcement Learning (RL) for dexterous object handover between two multi-finger hands. Key to this task is the use of a novel reward function based on dual quaternions to minimize the rotation distance, which outperforms other rotation representations such as Euler and rotation matrices. The robustness of the trained policy is experimentally evaluated by testing w.r.t. objects that are not included in the training distribution, and perturbations during the handover process. The results demonstrate that the trained policy successfully perform this task, achieving a total success rate of 94% in the best-case scenario after 100 experiments, thereby showing the robustness of our policy with novel objects. In addition, the best-case performance of the policy decreases by only 13.8% when the other robot moves during the handover, proving that our policy is also robust to this type of perturbation, which is common in real-world object handovers.",
    "summary": "arXiv:2506.16822v1 Announce Type: cross Abstract: Object handover is an important skill that we use daily when interacting with other humans. To deploy robots in collaborative setting, like houses, being able to receive and handing over objects safely and efficiently becomes a crucial skill. In this work, we demonstrate the use of Reinforcement Learning (RL) for dexterous object handover between two multi-finger hands. Key to this task is the use of a novel reward function based on dual quaternions to minimize the rotation distance, which outperforms other rotation representations such as Euler and rotation matrices. The robustness of the trained policy is experimentally evaluated by testing w.r.t. objects that are not included in the training distribution, and perturbations during the handover process. The results demonstrate that the trained policy successfully perform this task, achieving a total success rate of 94% in the best-case scenario after 100 experiments, thereby showing the robustness of our policy with novel objects. In addition, the best-case performance of the policy decreases by only 13.8% when the other robot moves during the handover, proving that our policy is also robust to this type of perturbation, which is common in real-world object handovers.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16822",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Learning Dynamics in Continual Pre-Training for Large Language Models",
    "description": "arXiv:2505.07796v2 Announce Type: replace-cross Abstract: Continual Pre-Training (CPT) has become a popular and effective method to apply strong foundation models to specific downstream tasks. In this work, we explore the learning dynamics throughout the CPT process for large language models. We specifically focus on how general and downstream domain performance evolves at each training step, with domain performance measured via validation losses. We have observed that the CPT loss curve fundamentally characterizes the transition from one curve to another hidden curve, and could be described by decoupling the effects of distribution shift and learning rate annealing. We derive a CPT scaling law that combines the two factors, enabling the prediction of loss at any (continual) training steps and across learning rate schedules (LRS) in CPT. Our formulation presents a comprehensive understanding of several critical factors in CPT, including loss potential, peak learning rate, training steps, replay ratio, etc. Moreover, our approach can be adapted to customize training hyper-parameters to different CPT goals such as balancing general and domain-specific performance. Extensive experiments demonstrate that our scaling law holds across various CPT datasets and training hyper-parameters.",
    "summary": "arXiv:2505.07796v2 Announce Type: replace-cross Abstract: Continual Pre-Training (CPT) has become a popular and effective method to apply strong foundation models to specific downstream tasks. In this work, we explore the learning dynamics throughout the CPT process for large language models. We specifically focus on how general and downstream domain performance evolves at each training step, with domain performance measured via validation losses. We have observed that the CPT loss curve fundamentally characterizes the transition from one curve to another hidden curve, and could be described by decoupling the effects of distribution shift and learning rate annealing. We derive a CPT scaling law that combines the two factors, enabling the prediction of loss at any (continual) training steps and across learning rate schedules (LRS) in CPT. Our formulation presents a comprehensive understanding of several critical factors in CPT, including loss potential, peak learning rate, training steps, replay ratio, etc. Moreover, our approach can be adapted to customize training hyper-parameters to different CPT goals such as balancing general and domain-specific performance. Extensive experiments demonstrate that our scaling law holds across various CPT datasets and training hyper-parameters.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2505.07796",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Learning from M-Tuple Dominant Positive and Unlabeled Data",
    "description": "arXiv:2506.15686v1 Announce Type: cross Abstract: Label Proportion Learning (LLP) addresses the classification problem where multiple instances are grouped into bags and each bag contains information about the proportion of each class. However, in practical applications, obtaining precise supervisory information regarding the proportion of instances in a specific class is challenging. To better align with real-world application scenarios and effectively leverage the proportional constraints of instances within tuples, this paper proposes a generalized learning framework emph{MDPU}. Specifically, we first mathematically model the distribution of instances within tuples of arbitrary size, under the constraint that the number of positive instances is no less than that of negative instances. Then we derive an unbiased risk estimator that satisfies risk consistency based on the empirical risk minimization (ERM) method. To mitigate the inevitable overfitting issue during training, a risk correction method is introduced, leading to the development of a corrected risk estimator. The generalization error bounds of the unbiased risk estimator theoretically demonstrate the consistency of the proposed method. Extensive experiments on multiple datasets and comparisons with other relevant baseline methods comprehensively validate the effectiveness of the proposed learning framework.",
    "summary": "arXiv:2506.15686v1 Announce Type: cross Abstract: Label Proportion Learning (LLP) addresses the classification problem where multiple instances are grouped into bags and each bag contains information about the proportion of each class. However, in practical applications, obtaining precise supervisory information regarding the proportion of instances in a specific class is challenging. To better align with real-world application scenarios and effectively leverage the proportional constraints of instances within tuples, this paper proposes a generalized learning framework emph{MDPU}. Specifically, we first mathematically model the distribution of instances within tuples of arbitrary size, under the constraint that the number of positive instances is no less than that of negative instances. Then we derive an unbiased risk estimator that satisfies risk consistency based on the empirical risk minimization (ERM) method. To mitigate the inevitable overfitting issue during training, a risk correction method is introduced, leading to the development of a corrected risk estimator. The generalization error bounds of the unbiased risk estimator theoretically demonstrate the consistency of the proposed method. Extensive experiments on multiple datasets and comparisons with other relevant baseline methods comprehensively validate the effectiveness of the proposed learning framework.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.15686",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Learning from other domains to advance AI evaluation and testing",
    "description": "<p>As generative AI becomes more capable and widely deployed, familiar questions from the governance of other transformative technologies have resurfaced. Which opportunities, capabilities, risks, and impacts should be evaluated? Who should conduct evaluations, and at what stages of the technology lifecycle? What tests or measurements should be used? And how can we know if the [&#8230;]</p> <p>The post <a href='https://www.microsoft.com/en-us/research/blog/learning-from-other-domains-to-advance-ai-evaluation-and-testing/'>Learning from other domains to advance AI evaluation and testing</a> appeared first on <a href='https://www.microsoft.com/en-us/research'>Microsoft Research</a>.</p>",
    "summary": "<p>As generative AI becomes more capable and widely deployed, familiar questions from the governance of other transformative technologies have resurfaced. Which opportunities, capabilities, risks, and impacts should be evaluated? Who should conduct evaluations, and at what stages of the technology lifecycle? What tests or measurements should be used? And how can we know if the [&#8230;]</p> <p>The post <a href='https://www.microsoft.com/en-us/research/blog/learning-from-other-domains-to-advance-ai-evaluation-and-testing/'>Learning from other domains to advance AI evaluation and testing</a> appeared first on <a href='https://www.microsoft.com/en-us/research'>Microsoft Research</a>.</p>",
    "pubDate": "Mon, 23 Jun 2025 16:35:06 +0000",
    "source": "Microsoft Research Blog",
    "url": "https://www.microsoft.com/en-us/research/blog/learning-from-other-domains-to-advance-ai-evaluation-and-testing/",
    "thumbnail": "https://img-prod-cms-rt-microsoft-com.akamaized.net/cms/api/am/imageFileData/RE1Mu3b?ver=5c31&h=30"
  },
  {
    "title": "Learning Multi-Branch Cooperation for Enhanced Click-Through Rate Prediction at Taobao",
    "description": "arXiv:2411.13057v2 Announce Type: replace-cross Abstract: Existing click-through rate (CTR) prediction works have studied the role of feature interaction through a variety of techniques. Each interaction technique exhibits its own strength, and solely using one type usually constrains the model's capability to capture the complex feature relationships, especially for industrial data with enormous input feature fields. Recent research shows that effective CTR models often combine an MLP network with a dedicated feature interaction network in a two-parallel structure. However, the interplay and cooperative dynamics between different streams or branches remain under-researched. In this work, we introduce a novel Multi-Branch Cooperation Network (MBCnet) which enables multiple branch networks to collaborate with each other for better complex feature interaction modeling. Specifically, MBCnet consists of three branches: the Extensible Feature Grouping and Crossing (EFGC) branch that promotes the model's memorization ability of specific feature fields, the low rank Cross Net branch and Deep branch to enhance explicit and implicit feature crossing for improved generalization. Among these branches, a novel cooperation scheme is proposed based on two principles: Branch co-teaching and moderate differentiation. Branch co-teaching encourages well-learned branches to support poorly-learned ones on specific training samples. Moderate differentiation advocates branches to maintain a reasonable level of difference in their feature representations on the same inputs. This cooperation strategy improves learning through mutual knowledge sharing and boosts the discovery of diverse feature interactions across branches. Experiments on large-scale industrial datasets and online A/B test at Taobao app demonstrate MBCnet's superior performance, delivering a 0.09 point increase in CTR, 1.49% growth in deals, and 1.62% rise in GMV. Core codes are available online.",
    "summary": "arXiv:2411.13057v2 Announce Type: replace-cross Abstract: Existing click-through rate (CTR) prediction works have studied the role of feature interaction through a variety of techniques. Each interaction technique exhibits its own strength, and solely using one type usually constrains the model's capability to capture the complex feature relationships, especially for industrial data with enormous input feature fields. Recent research shows that effective CTR models often combine an MLP network with a dedicated feature interaction network in a two-parallel structure. However, the interplay and cooperative dynamics between different streams or branches remain under-researched. In this work, we introduce a novel Multi-Branch Cooperation Network (MBCnet) which enables multiple branch networks to collaborate with each other for better complex feature interaction modeling. Specifically, MBCnet consists of three branches: the Extensible Feature Grouping and Crossing (EFGC) branch that promotes the model's memorization ability of specific feature fields, the low rank Cross Net branch and Deep branch to enhance explicit and implicit feature crossing for improved generalization. Among these branches, a novel cooperation scheme is proposed based on two principles: Branch co-teaching and moderate differentiation. Branch co-teaching encourages well-learned branches to support poorly-learned ones on specific training samples. Moderate differentiation advocates branches to maintain a reasonable level of difference in their feature representations on the same inputs. This cooperation strategy improves learning through mutual knowledge sharing and boosts the discovery of diverse feature interactions across branches. Experiments on large-scale industrial datasets and online A/B test at Taobao app demonstrate MBCnet's superior performance, delivering a 0.09 point increase in CTR, 1.49% growth in deals, and 1.62% rise in GMV. Core codes are available online.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2411.13057",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Learning Multi-scale Spatial-frequency Features for Image Denoising",
    "description": "arXiv:2506.16307v1 Announce Type: cross Abstract: Recent advancements in multi-scale architectures have demonstrated exceptional performance in image denoising tasks. However, existing architectures mainly depends on a fixed single-input single-output Unet architecture, ignoring the multi-scale representations of pixel level. In addition, previous methods treat the frequency domain uniformly, ignoring the different characteristics of high-frequency and low-frequency noise. In this paper, we propose a novel multi-scale adaptive dual-domain network (MADNet) for image denoising. We use image pyramid inputs to restore noise-free results from low-resolution images. In order to realize the interaction of high-frequency and low-frequency information, we design an adaptive spatial-frequency learning unit (ASFU), where a learnable mask is used to separate the information into high-frequency and low-frequency components. In the skip connections, we design a global feature fusion block to enhance the features at different scales. Extensive experiments on both synthetic and real noisy image datasets verify the effectiveness of MADNet compared with current state-of-the-art denoising approaches.",
    "summary": "arXiv:2506.16307v1 Announce Type: cross Abstract: Recent advancements in multi-scale architectures have demonstrated exceptional performance in image denoising tasks. However, existing architectures mainly depends on a fixed single-input single-output Unet architecture, ignoring the multi-scale representations of pixel level. In addition, previous methods treat the frequency domain uniformly, ignoring the different characteristics of high-frequency and low-frequency noise. In this paper, we propose a novel multi-scale adaptive dual-domain network (MADNet) for image denoising. We use image pyramid inputs to restore noise-free results from low-resolution images. In order to realize the interaction of high-frequency and low-frequency information, we design an adaptive spatial-frequency learning unit (ASFU), where a learnable mask is used to separate the information into high-frequency and low-frequency components. In the skip connections, we design a global feature fusion block to enhance the features at different scales. Extensive experiments on both synthetic and real noisy image datasets verify the effectiveness of MADNet compared with current state-of-the-art denoising approaches.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16307",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Learning to Route LLMs with Confidence Tokens",
    "description": "arXiv:2410.13284v3 Announce Type: replace-cross Abstract: Large language models (LLMs) have demonstrated impressive performance on several tasks and are increasingly deployed in real-world applications. However, especially in high-stakes settings, it becomes vital to know when the output of an LLM may be unreliable. Depending on whether an answer is trustworthy, a system can then choose to route the question to another expert, or otherwise fall back on a safe default behavior. In this work, we study the extent to which LLMs can reliably indicate confidence in their answers, and how this notion of confidence can translate into downstream accuracy gains. We propose Self-Reflection with Error-based Feedback (Self-REF), a lightweight training strategy to teach LLMs to express confidence in whether their answers are correct in a reliable manner. Self-REF introduces confidence tokens into the LLM, from which a confidence score can be extracted. Compared to conventional approaches such as verbalizing confidence and examining token probabilities, we demonstrate empirically that confidence tokens show significant improvements in downstream routing and rejection learning tasks.",
    "summary": "arXiv:2410.13284v3 Announce Type: replace-cross Abstract: Large language models (LLMs) have demonstrated impressive performance on several tasks and are increasingly deployed in real-world applications. However, especially in high-stakes settings, it becomes vital to know when the output of an LLM may be unreliable. Depending on whether an answer is trustworthy, a system can then choose to route the question to another expert, or otherwise fall back on a safe default behavior. In this work, we study the extent to which LLMs can reliably indicate confidence in their answers, and how this notion of confidence can translate into downstream accuracy gains. We propose Self-Reflection with Error-based Feedback (Self-REF), a lightweight training strategy to teach LLMs to express confidence in whether their answers are correct in a reliable manner. Self-REF introduces confidence tokens into the LLM, from which a confidence score can be extracted. Compared to conventional approaches such as verbalizing confidence and examining token probabilities, we demonstrate empirically that confidence tokens show significant improvements in downstream routing and rejection learning tasks.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2410.13284",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "LEGO-Puzzles: How Good Are MLLMs at Multi-Step Spatial Reasoning?",
    "description": "arXiv:2503.19990v3 Announce Type: replace Abstract: Multi-step spatial reasoning entails understanding and reasoning about spatial relationships across multiple sequential steps, which is crucial for tackling complex real-world applications, such as robotic manipulation, autonomous navigation, and automated assembly. To assess how well current Multimodal Large Language Models (MLLMs) have acquired this fundamental capability, we introduce LEGO-Puzzles, a scalable benchmark designed to evaluate both spatial understanding and sequential reasoning in MLLMs through LEGO-based tasks. LEGO-Puzzles consists of 1,100 carefully curated visual question-answering (VQA) samples spanning 11 distinct tasks, ranging from basic spatial understanding to complex multi-step reasoning. Based on LEGO-Puzzles, we conduct a comprehensive evaluation of 20 state-of-the-art MLLMs and uncover significant limitations in their spatial reasoning capabilities: even the most powerful MLLMs can answer only about half of the test cases, whereas human participants achieve over 90% accuracy. Furthermore, based on LEGO-Puzzles, we design generation tasks to investigate whether MLLMs can transfer their spatial understanding and reasoning abilities to image generation. Our experiments show that only GPT-4o and Gemini-2.0-Flash exhibit a limited ability to follow these instructions, while other MLLMs either replicate the input image or generate completely irrelevant outputs. Overall, LEGO-Puzzles exposes critical deficiencies in existing MLLMs' spatial understanding and sequential reasoning capabilities, and underscores the need for further advancements in multimodal spatial reasoning.",
    "summary": "arXiv:2503.19990v3 Announce Type: replace Abstract: Multi-step spatial reasoning entails understanding and reasoning about spatial relationships across multiple sequential steps, which is crucial for tackling complex real-world applications, such as robotic manipulation, autonomous navigation, and automated assembly. To assess how well current Multimodal Large Language Models (MLLMs) have acquired this fundamental capability, we introduce LEGO-Puzzles, a scalable benchmark designed to evaluate both spatial understanding and sequential reasoning in MLLMs through LEGO-based tasks. LEGO-Puzzles consists of 1,100 carefully curated visual question-answering (VQA) samples spanning 11 distinct tasks, ranging from basic spatial understanding to complex multi-step reasoning. Based on LEGO-Puzzles, we conduct a comprehensive evaluation of 20 state-of-the-art MLLMs and uncover significant limitations in their spatial reasoning capabilities: even the most powerful MLLMs can answer only about half of the test cases, whereas human participants achieve over 90% accuracy. Furthermore, based on LEGO-Puzzles, we design generation tasks to investigate whether MLLMs can transfer their spatial understanding and reasoning abilities to image generation. Our experiments show that only GPT-4o and Gemini-2.0-Flash exhibit a limited ability to follow these instructions, while other MLLMs either replicate the input image or generate completely irrelevant outputs. Overall, LEGO-Puzzles exposes critical deficiencies in existing MLLMs' spatial understanding and sequential reasoning capabilities, and underscores the need for further advancements in multimodal spatial reasoning.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2503.19990",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Leveraging Influence Functions for Resampling Data in Physics-Informed Neural Networks",
    "description": "arXiv:2506.16443v1 Announce Type: cross Abstract: Physics-informed neural networks (PINNs) offer a powerful approach to solving partial differential equations (PDEs), which are ubiquitous in the quantitative sciences. Applied to both forward and inverse problems across various scientific domains, PINNs have recently emerged as a valuable tool in the field of scientific machine learning. A key aspect of their training is that the data -- spatio-temporal points sampled from the PDE's input domain -- are readily available. Influence functions, a tool from the field of explainable AI (XAI), approximate the effect of individual training points on the model, enhancing interpretability. In the present work, we explore the application of influence function-based sampling approaches for the training data. Our results indicate that such targeted resampling based on data attribution methods has the potential to enhance prediction accuracy in physics-informed neural networks, demonstrating a practical application of an XAI method in PINN training.",
    "summary": "arXiv:2506.16443v1 Announce Type: cross Abstract: Physics-informed neural networks (PINNs) offer a powerful approach to solving partial differential equations (PDEs), which are ubiquitous in the quantitative sciences. Applied to both forward and inverse problems across various scientific domains, PINNs have recently emerged as a valuable tool in the field of scientific machine learning. A key aspect of their training is that the data -- spatio-temporal points sampled from the PDE's input domain -- are readily available. Influence functions, a tool from the field of explainable AI (XAI), approximate the effect of individual training points on the model, enhancing interpretability. In the present work, we explore the application of influence function-based sampling approaches for the training data. Our results indicate that such targeted resampling based on data attribution methods has the potential to enhance prediction accuracy in physics-informed neural networks, demonstrating a practical application of an XAI method in PINN training.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16443",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "LeVERB: Humanoid Whole-Body Control with Latent Vision-Language Instruction",
    "description": "arXiv:2506.13751v2 Announce Type: replace-cross Abstract: Vision-language-action (VLA) models have demonstrated strong semantic understanding and zero-shot generalization, yet most existing systems assume an accurate low-level controller with hand-crafted action 'vocabulary' such as end-effector pose or root velocity. This assumption confines prior work to quasi-static tasks and precludes the agile, whole-body behaviors required by humanoid whole-body control (WBC) tasks. To capture this gap in the literature, we start by introducing the first sim-to-real-ready, vision-language, closed-loop benchmark for humanoid WBC, comprising over 150 tasks from 10 categories. We then propose LeVERB: Latent Vision-Language-Encoded Robot Behavior, a hierarchical latent instruction-following framework for humanoid vision-language WBC, the first of its kind. At the top level, a vision-language policy learns a latent action vocabulary from synthetically rendered kinematic demonstrations; at the low level, a reinforcement-learned WBC policy consumes these latent verbs to generate dynamics-level commands. In our benchmark, LeVERB can zero-shot attain a 80% success rate on simple visual navigation tasks, and 58.5% success rate overall, outperforming naive hierarchical whole-body VLA implementation by 7.8 times.",
    "summary": "arXiv:2506.13751v2 Announce Type: replace-cross Abstract: Vision-language-action (VLA) models have demonstrated strong semantic understanding and zero-shot generalization, yet most existing systems assume an accurate low-level controller with hand-crafted action 'vocabulary' such as end-effector pose or root velocity. This assumption confines prior work to quasi-static tasks and precludes the agile, whole-body behaviors required by humanoid whole-body control (WBC) tasks. To capture this gap in the literature, we start by introducing the first sim-to-real-ready, vision-language, closed-loop benchmark for humanoid WBC, comprising over 150 tasks from 10 categories. We then propose LeVERB: Latent Vision-Language-Encoded Robot Behavior, a hierarchical latent instruction-following framework for humanoid vision-language WBC, the first of its kind. At the top level, a vision-language policy learns a latent action vocabulary from synthetically rendered kinematic demonstrations; at the low level, a reinforcement-learned WBC policy consumes these latent verbs to generate dynamics-level commands. In our benchmark, LeVERB can zero-shot attain a 80% success rate on simple visual navigation tasks, and 58.5% success rate overall, outperforming naive hierarchical whole-body VLA implementation by 7.8 times.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.13751",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Linear-Time Primitives for Algorithm Development in Graphical Causal Inference",
    "description": "arXiv:2506.15758v1 Announce Type: new Abstract: We introduce CIfly, a framework for efficient algorithmic primitives in graphical causal inference that isolates reachability as a reusable core operation. It builds on the insight that many causal reasoning tasks can be reduced to reachability in purpose-built state-space graphs that can be constructed on the fly during traversal. We formalize a rule table schema for specifying such algorithms and prove they run in linear time. We establish CIfly as a more efficient alternative to the common primitives moralization and latent projection, which we show are computationally equivalent to Boolean matrix multiplication. Our open-source Rust implementation parses rule table text files and runs the specified CIfly algorithms providing high-performance execution accessible from Python and R. We demonstrate CIfly's utility by re-implementing a range of established causal inference tasks within the framework and by developing new algorithms for instrumental variables. These contributions position CIfly as a flexible and scalable backbone for graphical causal inference, guiding algorithm development and enabling easy and efficient deployment.",
    "summary": "arXiv:2506.15758v1 Announce Type: new Abstract: We introduce CIfly, a framework for efficient algorithmic primitives in graphical causal inference that isolates reachability as a reusable core operation. It builds on the insight that many causal reasoning tasks can be reduced to reachability in purpose-built state-space graphs that can be constructed on the fly during traversal. We formalize a rule table schema for specifying such algorithms and prove they run in linear time. We establish CIfly as a more efficient alternative to the common primitives moralization and latent projection, which we show are computationally equivalent to Boolean matrix multiplication. Our open-source Rust implementation parses rule table text files and runs the specified CIfly algorithms providing high-performance execution accessible from Python and R. We demonstrate CIfly's utility by re-implementing a range of established causal inference tasks within the framework and by developing new algorithms for instrumental variables. These contributions position CIfly as a flexible and scalable backbone for graphical causal inference, guiding algorithm development and enabling easy and efficient deployment.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.15758",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Linearithmic Clean-up for Vector-Symbolic Key-Value Memory with Kroneker Rotation Products",
    "description": "arXiv:2506.15793v1 Announce Type: cross Abstract: A computational bottleneck in current Vector-Symbolic Architectures (VSAs) is the ``clean-up'' step, which decodes the noisy vectors retrieved from the architecture. Clean-up typically compares noisy vectors against a ``codebook'' of prototype vectors, incurring computational complexity that is quadratic or similar. We present a new codebook representation that supports efficient clean-up, based on Kroneker products of rotation-like matrices. The resulting clean-up time complexity is linearithmic, i.e. $mathcal{O}(N,text{log},N)$, where $N$ is the vector dimension and also the number of vectors in the codebook. Clean-up space complexity is $mathcal{O}(N)$. Furthermore, the codebook is not stored explicitly in computer memory: It can be represented in $mathcal{O}(text{log},N)$ space, and individual vectors in the codebook can be materialized in $mathcal{O}(N)$ time and space. At the same time, asymptotic memory capacity remains comparable to standard approaches. Computer experiments confirm these results, demonstrating several orders of magnitude more scalability than baseline VSA techniques.",
    "summary": "arXiv:2506.15793v1 Announce Type: cross Abstract: A computational bottleneck in current Vector-Symbolic Architectures (VSAs) is the ``clean-up'' step, which decodes the noisy vectors retrieved from the architecture. Clean-up typically compares noisy vectors against a ``codebook'' of prototype vectors, incurring computational complexity that is quadratic or similar. We present a new codebook representation that supports efficient clean-up, based on Kroneker products of rotation-like matrices. The resulting clean-up time complexity is linearithmic, i.e. $mathcal{O}(N,text{log},N)$, where $N$ is the vector dimension and also the number of vectors in the codebook. Clean-up space complexity is $mathcal{O}(N)$. Furthermore, the codebook is not stored explicitly in computer memory: It can be represented in $mathcal{O}(text{log},N)$ space, and individual vectors in the codebook can be materialized in $mathcal{O}(N)$ time and space. At the same time, asymptotic memory capacity remains comparable to standard approaches. Computer experiments confirm these results, demonstrating several orders of magnitude more scalability than baseline VSA techniques.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.15793",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "LLM-Based Bot Broadens the Range of Arguments in Online Discussions, Even When Transparently Disclosed as AI",
    "description": "arXiv:2506.17073v1 Announce Type: cross Abstract: A wide range of participation is essential for democracy, as it helps prevent the dominance of extreme views, erosion of legitimacy, and political polarization. However, engagement in online political discussions often features a limited spectrum of views due to high levels of self-selection and the tendency of online platforms to facilitate exchanges primarily among like-minded individuals. This study examines whether an LLM-based bot can widen the scope of perspectives expressed by participants in online discussions through two pre-registered randomized experiments conducted in a chatroom. We evaluate the impact of a bot that actively monitors discussions, identifies missing arguments, and introduces them into the conversation. The results indicate that our bot significantly expands the range of arguments, as measured by both objective and subjective metrics. Furthermore, disclosure of the bot as AI does not significantly alter these effects. These findings suggest that LLM-based moderation tools can positively influence online political discourse.",
    "summary": "arXiv:2506.17073v1 Announce Type: cross Abstract: A wide range of participation is essential for democracy, as it helps prevent the dominance of extreme views, erosion of legitimacy, and political polarization. However, engagement in online political discussions often features a limited spectrum of views due to high levels of self-selection and the tendency of online platforms to facilitate exchanges primarily among like-minded individuals. This study examines whether an LLM-based bot can widen the scope of perspectives expressed by participants in online discussions through two pre-registered randomized experiments conducted in a chatroom. We evaluate the impact of a bot that actively monitors discussions, identifies missing arguments, and introduces them into the conversation. The results indicate that our bot significantly expands the range of arguments, as measured by both objective and subjective metrics. Furthermore, disclosure of the bot as AI does not significantly alter these effects. These findings suggest that LLM-based moderation tools can positively influence online political discourse.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.17073",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "LLM-Guided Indoor Navigation with Multimodal Map Understanding",
    "description": "arXiv:2503.11702v4 Announce Type: replace Abstract: Indoor navigation presents unique challenges due to complex layouts and the unavailability of GNSS signals. Existing solutions often struggle with contextual adaptation, and typically require dedicated hardware. In this work, we explore the potential of a Large Language Model (LLM), i.e., ChatGPT, to generate natural, context-aware navigation instructions from indoor map images. We design and evaluate test cases across different real-world environments, analyzing the effectiveness of LLMs in interpreting spatial layouts, handling user constraints, and planning efficient routes. Our findings demonstrate the potential of LLMs for supporting personalized indoor navigation, with an average of 86.59% correct indications and a maximum of 97.14%. The proposed system achieves high accuracy and reasoning performance. These results have key implications for AI-driven navigation and assistive technologies.",
    "summary": "arXiv:2503.11702v4 Announce Type: replace Abstract: Indoor navigation presents unique challenges due to complex layouts and the unavailability of GNSS signals. Existing solutions often struggle with contextual adaptation, and typically require dedicated hardware. In this work, we explore the potential of a Large Language Model (LLM), i.e., ChatGPT, to generate natural, context-aware navigation instructions from indoor map images. We design and evaluate test cases across different real-world environments, analyzing the effectiveness of LLMs in interpreting spatial layouts, handling user constraints, and planning efficient routes. Our findings demonstrate the potential of LLMs for supporting personalized indoor navigation, with an average of 86.59% correct indications and a maximum of 97.14%. The proposed system achieves high accuracy and reasoning performance. These results have key implications for AI-driven navigation and assistive technologies.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2503.11702",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "LLM Web Dynamics: Tracing Model Collapse in a Network of LLMs",
    "description": "arXiv:2506.15690v1 Announce Type: cross Abstract: The increasing use of synthetic data from the public Internet has enhanced data usage efficiency in large language model (LLM) training. However, the potential threat of model collapse remains insufficiently explored. Existing studies primarily examine model collapse in a single model setting or rely solely on statistical surrogates. In this work, we introduce LLM Web Dynamics (LWD), an efficient framework for investigating model collapse at the network level. By simulating the Internet with a retrieval-augmented generation (RAG) database, we analyze the convergence pattern of model outputs. Furthermore, we provide theoretical guarantees for this convergence by drawing an analogy to interacting Gaussian Mixture Models.",
    "summary": "arXiv:2506.15690v1 Announce Type: cross Abstract: The increasing use of synthetic data from the public Internet has enhanced data usage efficiency in large language model (LLM) training. However, the potential threat of model collapse remains insufficiently explored. Existing studies primarily examine model collapse in a single model setting or rely solely on statistical surrogates. In this work, we introduce LLM Web Dynamics (LWD), an efficient framework for investigating model collapse at the network level. By simulating the Internet with a retrieval-augmented generation (RAG) database, we analyze the convergence pattern of model outputs. Furthermore, we provide theoretical guarantees for this convergence by drawing an analogy to interacting Gaussian Mixture Models.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.15690",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "LLMs and Stack Overflow Discussions: Reliability, Impact, and Challenges",
    "description": "arXiv:2402.08801v2 Announce Type: replace-cross Abstract: Since its release in November 2022, ChatGPT has shaken up Stack Overflow, the premier platform for developers queries on programming and software development. Demonstrating an ability to generate instant, human-like responses to technical questions, ChatGPT has ignited debates within the developer community about the evolving role of human-driven platforms in the age of generative AI. Two months after ChatGPT release, Meta released its answer with its own Large Language Model (LLM) called LLaMA: the race was on. We conducted an empirical study analyzing questions from Stack Overflow and using these LLMs to address them. This way, we aim to (i) quantify the reliability of LLMs answers and their potential to replace Stack Overflow in the long term; (ii) identify and understand why LLMs fail; (iii) measure users activity evolution with Stack Overflow over time; and (iv) compare LLMs together. Our empirical results are unequivocal: ChatGPT and LLaMA challenge human expertise, yet do not outperform it for some domains, while a significant decline in user posting activity has been observed. Furthermore, we also discuss the impact of our findings regarding the usage and development of new LLMs and provide guidelines for future challenges faced by users and researchers.",
    "summary": "arXiv:2402.08801v2 Announce Type: replace-cross Abstract: Since its release in November 2022, ChatGPT has shaken up Stack Overflow, the premier platform for developers queries on programming and software development. Demonstrating an ability to generate instant, human-like responses to technical questions, ChatGPT has ignited debates within the developer community about the evolving role of human-driven platforms in the age of generative AI. Two months after ChatGPT release, Meta released its answer with its own Large Language Model (LLM) called LLaMA: the race was on. We conducted an empirical study analyzing questions from Stack Overflow and using these LLMs to address them. This way, we aim to (i) quantify the reliability of LLMs answers and their potential to replace Stack Overflow in the long term; (ii) identify and understand why LLMs fail; (iii) measure users activity evolution with Stack Overflow over time; and (iv) compare LLMs together. Our empirical results are unequivocal: ChatGPT and LLaMA challenge human expertise, yet do not outperform it for some domains, while a significant decline in user posting activity has been observed. Furthermore, we also discuss the impact of our findings regarding the usage and development of new LLMs and provide guidelines for future challenges faced by users and researchers.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2402.08801",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "LLMs factor in unrelated information when recommending medical treatments",
    "description": "Researchers find nonclinical information in patient messages — like typos, extra white space, and colorful language — reduces the accuracy of an AI model.",
    "summary": "Researchers find nonclinical information in patient messages — like typos, extra white space, and colorful language — reduces the accuracy of an AI model.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/llms-factor-unrelated-information-when-recommending-medical-treatments-0623",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202506/MIT_Medium-Message-01-press.jpg"
  },
  {
    "title": "LLMs in Coding and their Impact on the Commercial Software Engineering Landscape",
    "description": "arXiv:2506.16653v1 Announce Type: cross Abstract: Large-language-model coding tools are now mainstream in software engineering. But as these same tools move human effort up the development stack, they present fresh dangers: 10% of real prompts leak private data, 42% of generated snippets hide security flaws, and the models can even ``agree'' with wrong ideas, a trait called sycophancy. We argue that firms must tag and review every AI-generated line of code, keep prompts and outputs inside private or on-premises deployments, obey emerging safety regulations, and add tests that catch sycophantic answers -- so they can gain speed without losing security and accuracy.",
    "summary": "arXiv:2506.16653v1 Announce Type: cross Abstract: Large-language-model coding tools are now mainstream in software engineering. But as these same tools move human effort up the development stack, they present fresh dangers: 10% of real prompts leak private data, 42% of generated snippets hide security flaws, and the models can even ``agree'' with wrong ideas, a trait called sycophancy. We argue that firms must tag and review every AI-generated line of code, keep prompts and outputs inside private or on-premises deployments, obey emerging safety regulations, and add tests that catch sycophantic answers -- so they can gain speed without losing security and accuracy.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16653",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "LLMs in Disease Diagnosis: A Comparative Study of DeepSeek-R1 and O3 Mini Across Chronic Health Conditions",
    "description": "arXiv:2503.10486v2 Announce Type: replace-cross Abstract: Large Language Models (LLMs) are revolutionizing medical diagnostics by enhancing both disease classification and clinical decision-making. In this study, we evaluate the performance of two LLM- based diagnostic tools, DeepSeek R1 and O3 Mini, using a structured dataset of symptoms and diagnoses. We assessed their predictive accuracy at both the disease and category levels, as well as the reliability of their confidence scores. DeepSeek R1 achieved a disease-level accuracy of 76% and an overall accuracy of 82%, outperforming O3 Mini, which attained 72% and 75% respectively. Notably, DeepSeek R1 demonstrated exceptional performance in Mental Health, Neurological Disorders, and Oncology, where it reached 100% accuracy, while O3 Mini excelled in Autoimmune Disease classification with 100% accuracy. Both models, however, struggled with Respiratory Disease classification, recording accuracies of only 40% for DeepSeek R1 and 20% for O3 Mini. Additionally, the analysis of confidence scores revealed that DeepSeek R1 provided high-confidence predictions in 92% of cases, compared to 68% for O3 Mini. Ethical considerations regarding bias, model interpretability, and data privacy are also discussed to ensure the responsible integration of LLMs into clinical practice. Overall, our findings offer valuable insights into the strengths and limitations of LLM-based diagnostic systems and provide a roadmap for future enhancements in AI-driven healthcare.",
    "summary": "arXiv:2503.10486v2 Announce Type: replace-cross Abstract: Large Language Models (LLMs) are revolutionizing medical diagnostics by enhancing both disease classification and clinical decision-making. In this study, we evaluate the performance of two LLM- based diagnostic tools, DeepSeek R1 and O3 Mini, using a structured dataset of symptoms and diagnoses. We assessed their predictive accuracy at both the disease and category levels, as well as the reliability of their confidence scores. DeepSeek R1 achieved a disease-level accuracy of 76% and an overall accuracy of 82%, outperforming O3 Mini, which attained 72% and 75% respectively. Notably, DeepSeek R1 demonstrated exceptional performance in Mental Health, Neurological Disorders, and Oncology, where it reached 100% accuracy, while O3 Mini excelled in Autoimmune Disease classification with 100% accuracy. Both models, however, struggled with Respiratory Disease classification, recording accuracies of only 40% for DeepSeek R1 and 20% for O3 Mini. Additionally, the analysis of confidence scores revealed that DeepSeek R1 provided high-confidence predictions in 92% of cases, compared to 68% for O3 Mini. Ethical considerations regarding bias, model interpretability, and data privacy are also discussed to ensure the responsible integration of LLMs into clinical practice. Overall, our findings offer valuable insights into the strengths and limitations of LLM-based diagnostic systems and provide a roadmap for future enhancements in AI-driven healthcare.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2503.10486",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "LLMs Struggle to Perform Counterfactual Reasoning with Parametric Knowledge",
    "description": "arXiv:2506.15732v1 Announce Type: new Abstract: Large Language Models have been shown to contain extensive world knowledge in their parameters, enabling impressive performance on many knowledge intensive tasks. However, when deployed in novel settings, LLMs often encounter situations where they must integrate parametric knowledge with new or unfamiliar information. In this work, we explore whether LLMs can combine knowledge in-context with their parametric knowledge through the lens of counterfactual reasoning. Through synthetic and real experiments in multi-hop reasoning problems, we show that LLMs generally struggle with counterfactual reasoning, often resorting to exclusively using their parametric knowledge. Moreover, we show that simple post-hoc finetuning can struggle to instill counterfactual reasoning ability -- often leading to degradation in stored parametric knowledge. Ultimately, our work reveals important limitations of current LLM's abilities to re-purpose parametric knowledge in novel settings.",
    "summary": "arXiv:2506.15732v1 Announce Type: new Abstract: Large Language Models have been shown to contain extensive world knowledge in their parameters, enabling impressive performance on many knowledge intensive tasks. However, when deployed in novel settings, LLMs often encounter situations where they must integrate parametric knowledge with new or unfamiliar information. In this work, we explore whether LLMs can combine knowledge in-context with their parametric knowledge through the lens of counterfactual reasoning. Through synthetic and real experiments in multi-hop reasoning problems, we show that LLMs generally struggle with counterfactual reasoning, often resorting to exclusively using their parametric knowledge. Moreover, we show that simple post-hoc finetuning can struggle to instill counterfactual reasoning ability -- often leading to degradation in stored parametric knowledge. Ultimately, our work reveals important limitations of current LLM's abilities to re-purpose parametric knowledge in novel settings.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.15732",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "LM-SPT: LM-Aligned Semantic Distillation for Speech Tokenization",
    "description": "arXiv:2506.16738v1 Announce Type: cross Abstract: With the rapid progress of speech language models (SLMs), discrete speech tokens have emerged as a core interface between speech and text, enabling unified modeling across modalities. Recent speech tokenization approaches aim to isolate semantic information from low-level acoustics to better align with language models. In particular, previous methods use SSL teachers such as HuBERT to extract semantic representations, which are then distilled into a semantic quantizer to suppress acoustic redundancy as well as capture content-related latent structures. However, they still produce speech token sequences significantly longer than their textual counterparts, creating challenges for efficient speech-language modeling. Reducing the frame rate is a natural solution, but standard techniques, such as rigid average pooling across frames, can distort or dilute the semantic structure required for effective LM alignment. To address this, we propose LM-SPT, a speech tokenization method that introduces a novel semantic distillation. Instead of directly matching teacher and student features via pooling, we reconstruct speech solely from semantic tokens and minimize the discrepancy between the encoded representations of the original and reconstructed waveforms, obtained from a frozen automatic speech recognition (ASR) encoder. This indirect yet data-driven supervision enables the tokenizer to learn discrete units that are more semantically aligned with language models. LM-SPT further incorporates architectural improvements to the encoder and decoder for speech tokenization, and supports multiple frame rates, including 25Hz, 12.5Hz, and 6.25Hz. Experimental results show that LM-SPT achieves superior reconstruction fidelity compared to baselines, and that SLMs trained with LM-SPT tokens achieve competitive performances on speech-to-text and consistently outperform baselines on text-to-speech tasks.",
    "summary": "arXiv:2506.16738v1 Announce Type: cross Abstract: With the rapid progress of speech language models (SLMs), discrete speech tokens have emerged as a core interface between speech and text, enabling unified modeling across modalities. Recent speech tokenization approaches aim to isolate semantic information from low-level acoustics to better align with language models. In particular, previous methods use SSL teachers such as HuBERT to extract semantic representations, which are then distilled into a semantic quantizer to suppress acoustic redundancy as well as capture content-related latent structures. However, they still produce speech token sequences significantly longer than their textual counterparts, creating challenges for efficient speech-language modeling. Reducing the frame rate is a natural solution, but standard techniques, such as rigid average pooling across frames, can distort or dilute the semantic structure required for effective LM alignment. To address this, we propose LM-SPT, a speech tokenization method that introduces a novel semantic distillation. Instead of directly matching teacher and student features via pooling, we reconstruct speech solely from semantic tokens and minimize the discrepancy between the encoded representations of the original and reconstructed waveforms, obtained from a frozen automatic speech recognition (ASR) encoder. This indirect yet data-driven supervision enables the tokenizer to learn discrete units that are more semantically aligned with language models. LM-SPT further incorporates architectural improvements to the encoder and decoder for speech tokenization, and supports multiple frame rates, including 25Hz, 12.5Hz, and 6.25Hz. Experimental results show that LM-SPT achieves superior reconstruction fidelity compared to baselines, and that SLMs trained with LM-SPT tokens achieve competitive performances on speech-to-text and consistently outperform baselines on text-to-speech tasks.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16738",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "LogProber: Disentangling confidence from contamination in LLM responses",
    "description": "arXiv:2408.14352v3 Announce Type: replace-cross Abstract: In machine learning, contamination refers to situations where testing data leak into the training set. The issue is particularly relevant for the evaluation of the performance of Large Language Models (LLMs), which are generally trained on gargantuan, and generally opaque, corpora of text scraped from the world wide web. Developing tools to detect contamination is therefore crucial to be able to fairly and properly track the evolution of the performance of LLMs. To date, only a few recent studies have attempted to address the issue of quantifying and detecting contamination in short text sequences, such as those commonly found in benchmarks. However, these methods have limitations that can sometimes render them impractical. In the present paper, we introduce LogProber, a novel, efficient algorithm that we show to be able to detect contamination in a black box setting that tries to tackle some of these drawbacks by focusing on the familiarity with the question rather than the answer. Here, we explore the properties of the proposed method in comparison with concurrent approaches, identify its advantages and limitations, and illustrate how different forms of contamination can go undetected depending on the design of the detection algorithm.",
    "summary": "arXiv:2408.14352v3 Announce Type: replace-cross Abstract: In machine learning, contamination refers to situations where testing data leak into the training set. The issue is particularly relevant for the evaluation of the performance of Large Language Models (LLMs), which are generally trained on gargantuan, and generally opaque, corpora of text scraped from the world wide web. Developing tools to detect contamination is therefore crucial to be able to fairly and properly track the evolution of the performance of LLMs. To date, only a few recent studies have attempted to address the issue of quantifying and detecting contamination in short text sequences, such as those commonly found in benchmarks. However, these methods have limitations that can sometimes render them impractical. In the present paper, we introduce LogProber, a novel, efficient algorithm that we show to be able to detect contamination in a black box setting that tries to tackle some of these drawbacks by focusing on the familiarity with the question rather than the answer. Here, we explore the properties of the proposed method in comparison with concurrent approaches, identify its advantages and limitations, and illustrate how different forms of contamination can go undetected depending on the design of the detection algorithm.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2408.14352",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Long-Context Generalization with Sparse Attention",
    "description": "arXiv:2506.16640v1 Announce Type: cross Abstract: Transformer-based architectures traditionally employ softmax to compute attention weights, which produces dense distributions over all tokens in a sequence. While effective in many settings, this density has been shown to be detrimental for tasks that demand precise focus on fixed-size patterns: as sequence length increases, non-informative tokens accumulate attention probability mass, leading to dispersion and representational collapse. We show in this paper that sparse attention mechanisms using $alpha$-entmax can avoid these issues, due to their ability to assign exact zeros to irrelevant tokens. Furthermore, we introduce Adaptive-Scalable Entmax (ASEntmax), which endows $alpha$-entmax with a learnable temperature parameter, allowing the attention distribution to interpolate between sparse (pattern-focused) and dense (softmax-like) regimes. Finally, we show that the ability to locate and generalize fixed-size patterns can be further improved through a careful design of position encodings, which impacts both dense and sparse attention methods. By integrating ASEntmax into standard transformer layers alongside proper positional encodings, we show that our models greatly outperform softmax, scalable softmax, and fixed-temperature $alpha$-entmax baselines on long-context generalization.",
    "summary": "arXiv:2506.16640v1 Announce Type: cross Abstract: Transformer-based architectures traditionally employ softmax to compute attention weights, which produces dense distributions over all tokens in a sequence. While effective in many settings, this density has been shown to be detrimental for tasks that demand precise focus on fixed-size patterns: as sequence length increases, non-informative tokens accumulate attention probability mass, leading to dispersion and representational collapse. We show in this paper that sparse attention mechanisms using $alpha$-entmax can avoid these issues, due to their ability to assign exact zeros to irrelevant tokens. Furthermore, we introduce Adaptive-Scalable Entmax (ASEntmax), which endows $alpha$-entmax with a learnable temperature parameter, allowing the attention distribution to interpolate between sparse (pattern-focused) and dense (softmax-like) regimes. Finally, we show that the ability to locate and generalize fixed-size patterns can be further improved through a careful design of position encodings, which impacts both dense and sparse attention methods. By integrating ASEntmax into standard transformer layers alongside proper positional encodings, we show that our models greatly outperform softmax, scalable softmax, and fixed-temperature $alpha$-entmax baselines on long-context generalization.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16640",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Long-term Traffic Simulation with Interleaved Autoregressive Motion and Scenario Generation",
    "description": "arXiv:2506.17213v1 Announce Type: cross Abstract: An ideal traffic simulator replicates the realistic long-term point-to-point trip that a self-driving system experiences during deployment. Prior models and benchmarks focus on closed-loop motion simulation for initial agents in a scene. This is problematic for long-term simulation. Agents enter and exit the scene as the ego vehicle enters new regions. We propose InfGen, a unified next-token prediction model that performs interleaved closed-loop motion simulation and scene generation. InfGen automatically switches between closed-loop motion simulation and scene generation mode. It enables stable long-term rollout simulation. InfGen performs at the state-of-the-art in short-term (9s) traffic simulation, and significantly outperforms all other methods in long-term (30s) simulation. The code and model of InfGen will be released at https://orangesodahub.github.io/InfGen",
    "summary": "arXiv:2506.17213v1 Announce Type: cross Abstract: An ideal traffic simulator replicates the realistic long-term point-to-point trip that a self-driving system experiences during deployment. Prior models and benchmarks focus on closed-loop motion simulation for initial agents in a scene. This is problematic for long-term simulation. Agents enter and exit the scene as the ego vehicle enters new regions. We propose InfGen, a unified next-token prediction model that performs interleaved closed-loop motion simulation and scene generation. InfGen automatically switches between closed-loop motion simulation and scene generation mode. It enables stable long-term rollout simulation. InfGen performs at the state-of-the-art in short-term (9s) traffic simulation, and significantly outperforms all other methods in long-term (30s) simulation. The code and model of InfGen will be released at https://orangesodahub.github.io/InfGen",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.17213",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Loupe: A Generalizable and Adaptive Framework for Image Forgery Detection",
    "description": "arXiv:2506.16819v1 Announce Type: cross Abstract: The proliferation of generative models has raised serious concerns about visual content forgery. Existing deepfake detection methods primarily target either image-level classification or pixel-wise localization. While some achieve high accuracy, they often suffer from limited generalization across manipulation types or rely on complex architectures. In this paper, we propose Loupe, a lightweight yet effective framework for joint deepfake detection and localization. Loupe integrates a patch-aware classifier and a segmentation module with conditional queries, allowing simultaneous global authenticity classification and fine-grained mask prediction. To enhance robustness against distribution shifts of test set, Loupe introduces a pseudo-label-guided test-time adaptation mechanism by leveraging patch-level predictions to supervise the segmentation head. Extensive experiments on the DDL dataset demonstrate that Loupe achieves state-of-the-art performance, securing the first place in the IJCAI 2025 Deepfake Detection and Localization Challenge with an overall score of 0.846. Our results validate the effectiveness of the proposed patch-level fusion and conditional query design in improving both classification accuracy and spatial localization under diverse forgery patterns. The code is available at https://github.com/Kamichanw/Loupe.",
    "summary": "arXiv:2506.16819v1 Announce Type: cross Abstract: The proliferation of generative models has raised serious concerns about visual content forgery. Existing deepfake detection methods primarily target either image-level classification or pixel-wise localization. While some achieve high accuracy, they often suffer from limited generalization across manipulation types or rely on complex architectures. In this paper, we propose Loupe, a lightweight yet effective framework for joint deepfake detection and localization. Loupe integrates a patch-aware classifier and a segmentation module with conditional queries, allowing simultaneous global authenticity classification and fine-grained mask prediction. To enhance robustness against distribution shifts of test set, Loupe introduces a pseudo-label-guided test-time adaptation mechanism by leveraging patch-level predictions to supervise the segmentation head. Extensive experiments on the DDL dataset demonstrate that Loupe achieves state-of-the-art performance, securing the first place in the IJCAI 2025 Deepfake Detection and Localization Challenge with an overall score of 0.846. Our results validate the effectiveness of the proposed patch-level fusion and conditional query design in improving both classification accuracy and spatial localization under diverse forgery patterns. The code is available at https://github.com/Kamichanw/Loupe.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16819",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "LSCD: Lomb-Scargle Conditioned Diffusion for Time series Imputation",
    "description": "arXiv:2506.17039v1 Announce Type: cross Abstract: Time series with missing or irregularly sampled data are a persistent challenge in machine learning. Many methods operate on the frequency-domain, relying on the Fast Fourier Transform (FFT) which assumes uniform sampling, therefore requiring prior interpolation that can distort the spectra. To address this limitation, we introduce a differentiable Lomb--Scargle layer that enables a reliable computation of the power spectrum of irregularly sampled data. We integrate this layer into a novel score-based diffusion model (LSCD) for time series imputation conditioned on the entire signal spectrum. Experiments on synthetic and real-world benchmarks demonstrate that our method recovers missing data more accurately than purely time-domain baselines, while simultaneously producing consistent frequency estimates. Crucially, our method can be easily integrated into learning frameworks, enabling broader adoption of spectral guidance in machine learning approaches involving incomplete or irregular data.",
    "summary": "arXiv:2506.17039v1 Announce Type: cross Abstract: Time series with missing or irregularly sampled data are a persistent challenge in machine learning. Many methods operate on the frequency-domain, relying on the Fast Fourier Transform (FFT) which assumes uniform sampling, therefore requiring prior interpolation that can distort the spectra. To address this limitation, we introduce a differentiable Lomb--Scargle layer that enables a reliable computation of the power spectrum of irregularly sampled data. We integrate this layer into a novel score-based diffusion model (LSCD) for time series imputation conditioned on the entire signal spectrum. Experiments on synthetic and real-world benchmarks demonstrate that our method recovers missing data more accurately than purely time-domain baselines, while simultaneously producing consistent frequency estimates. Crucially, our method can be easily integrated into learning frameworks, enabling broader adoption of spectral guidance in machine learning approaches involving incomplete or irregular data.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.17039",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Machine Learning Methods for Small Data and Upstream Bioprocessing Applications: A Comprehensive Review",
    "description": "arXiv:2506.12322v2 Announce Type: replace-cross Abstract: Data is crucial for machine learning (ML) applications, yet acquiring large datasets can be costly and time-consuming, especially in complex, resource-intensive fields like biopharmaceuticals. A key process in this industry is upstream bioprocessing, where living cells are cultivated and optimised to produce therapeutic proteins and biologics. The intricate nature of these processes, combined with high resource demands, often limits data collection, resulting in smaller datasets. This comprehensive review explores ML methods designed to address the challenges posed by small data and classifies them into a taxonomy to guide practical applications. Furthermore, each method in the taxonomy was thoroughly analysed, with a detailed discussion of its core concepts and an evaluation of its effectiveness in tackling small data challenges, as demonstrated by application results in the upstream bioprocessing and other related domains. By analysing how these methods tackle small data challenges from different perspectives, this review provides actionable insights, identifies current research gaps, and offers guidance for leveraging ML in data-constrained environments.",
    "summary": "arXiv:2506.12322v2 Announce Type: replace-cross Abstract: Data is crucial for machine learning (ML) applications, yet acquiring large datasets can be costly and time-consuming, especially in complex, resource-intensive fields like biopharmaceuticals. A key process in this industry is upstream bioprocessing, where living cells are cultivated and optimised to produce therapeutic proteins and biologics. The intricate nature of these processes, combined with high resource demands, often limits data collection, resulting in smaller datasets. This comprehensive review explores ML methods designed to address the challenges posed by small data and classifies them into a taxonomy to guide practical applications. Furthermore, each method in the taxonomy was thoroughly analysed, with a detailed discussion of its core concepts and an evaluation of its effectiveness in tackling small data challenges, as demonstrated by application results in the upstream bioprocessing and other related domains. By analysing how these methods tackle small data challenges from different perspectives, this review provides actionable insights, identifies current research gaps, and offers guidance for leveraging ML in data-constrained environments.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.12322",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Machine Mental Imagery: Empower Multimodal Reasoning with Latent Visual Tokens",
    "description": "arXiv:2506.17218v1 Announce Type: cross Abstract: Vision-language models (VLMs) excel at multimodal understanding, yet their text-only decoding forces them to verbalize visual reasoning, limiting performance on tasks that demand visual imagination. Recent attempts train VLMs to render explicit images, but the heavy image-generation pre-training often hinders the reasoning ability. Inspired by the way humans reason with mental imagery-the internal construction and manipulation of visual cues-we investigate whether VLMs can reason through interleaved multimodal trajectories without producing explicit images. To this end, we present a Machine Mental Imagery framework, dubbed as Mirage, which augments VLM decoding with latent visual tokens alongside ordinary text. Concretely, whenever the model chooses to ``think visually'', it recasts its hidden states as next tokens, thereby continuing a multimodal trajectory without generating pixel-level images. Begin by supervising the latent tokens through distillation from ground-truth image embeddings, we then switch to text-only supervision to make the latent trajectory align tightly with the task objective. A subsequent reinforcement learning stage further enhances the multimodal reasoning capability. Experiments on diverse benchmarks demonstrate that Mirage unlocks stronger multimodal reasoning without explicit image generation.",
    "summary": "arXiv:2506.17218v1 Announce Type: cross Abstract: Vision-language models (VLMs) excel at multimodal understanding, yet their text-only decoding forces them to verbalize visual reasoning, limiting performance on tasks that demand visual imagination. Recent attempts train VLMs to render explicit images, but the heavy image-generation pre-training often hinders the reasoning ability. Inspired by the way humans reason with mental imagery-the internal construction and manipulation of visual cues-we investigate whether VLMs can reason through interleaved multimodal trajectories without producing explicit images. To this end, we present a Machine Mental Imagery framework, dubbed as Mirage, which augments VLM decoding with latent visual tokens alongside ordinary text. Concretely, whenever the model chooses to ``think visually'', it recasts its hidden states as next tokens, thereby continuing a multimodal trajectory without generating pixel-level images. Begin by supervising the latent tokens through distillation from ground-truth image embeddings, we then switch to text-only supervision to make the latent trajectory align tightly with the task objective. A subsequent reinforcement learning stage further enhances the multimodal reasoning capability. Experiments on diverse benchmarks demonstrate that Mirage unlocks stronger multimodal reasoning without explicit image generation.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.17218",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "MadaKV: Adaptive Modality-Perception KV Cache Eviction for Efficient Multimodal Long-Context Inference",
    "description": "arXiv:2506.15724v1 Announce Type: cross Abstract: This paper introduces MadaKV, a modality-adaptive key-value (KV) cache eviction strategy designed to enhance the efficiency of multimodal large language models (MLLMs) in long-context inference. In multimodal scenarios, attention heads exhibit varying preferences for different modalities, resulting in significant disparities in modality importance across attention heads. Traditional KV cache eviction methods, which are tailored for unimodal settings, fail to capture modality-specific information, thereby yielding suboptimal performance. MadaKV addresses these challenges through two key components: modality preference adaptation and hierarchical compression compensation. By dynamically sensing modality information within attention heads and adaptively retaining critical tokens, MadaKV achieves substantial reductions in KV cache memory footprint and model inference decoding latency (1.3 to 1.5 times improvement) while maintaining high accuracy across various multimodal long-context tasks. Extensive experiments on representative MLLMs and the MileBench benchmark demonstrate the effectiveness of MadaKV compared to existing KV cache eviction methods.",
    "summary": "arXiv:2506.15724v1 Announce Type: cross Abstract: This paper introduces MadaKV, a modality-adaptive key-value (KV) cache eviction strategy designed to enhance the efficiency of multimodal large language models (MLLMs) in long-context inference. In multimodal scenarios, attention heads exhibit varying preferences for different modalities, resulting in significant disparities in modality importance across attention heads. Traditional KV cache eviction methods, which are tailored for unimodal settings, fail to capture modality-specific information, thereby yielding suboptimal performance. MadaKV addresses these challenges through two key components: modality preference adaptation and hierarchical compression compensation. By dynamically sensing modality information within attention heads and adaptively retaining critical tokens, MadaKV achieves substantial reductions in KV cache memory footprint and model inference decoding latency (1.3 to 1.5 times improvement) while maintaining high accuracy across various multimodal long-context tasks. Extensive experiments on representative MLLMs and the MileBench benchmark demonstrate the effectiveness of MadaKV compared to existing KV cache eviction methods.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.15724",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "MaPPER: Multimodal Prior-guided Parameter Efficient Tuning for Referring Expression Comprehension",
    "description": "arXiv:2409.13609v4 Announce Type: replace-cross Abstract: Referring Expression Comprehension (REC), which aims to ground a local visual region via natural language, is a task that heavily relies on multimodal alignment. Most existing methods utilize powerful pre-trained models to transfer visual/linguistic knowledge by full fine-tuning. However, full fine-tuning the entire backbone not only breaks the rich prior knowledge embedded in the pre-training, but also incurs significant computational costs. Motivated by the recent emergence of Parameter-Efficient Transfer Learning (PETL) methods, we aim to solve the REC task in an effective and efficient manner. Directly applying these PETL methods to the REC task is inappropriate, as they lack the specific-domain abilities for precise local visual perception and visual-language alignment. Therefore, we propose a novel framework of Multimodal Prior-guided Parameter Efficient Tuning, namely MaPPER. Specifically, MaPPER comprises Dynamic Prior Adapters guided by an aligned prior, and Local Convolution Adapters to extract precise local semantics for better visual perception. Moreover, the Prior-Guided Text module is proposed to further utilize the prior for facilitating the cross-modal alignment. Experimental results on three widely-used benchmarks demonstrate that MaPPER achieves the best accuracy compared to the full fine-tuning and other PETL methods with only 1.41% tunable backbone parameters. Our code is available at https://github.com/liuting20/MaPPER.",
    "summary": "arXiv:2409.13609v4 Announce Type: replace-cross Abstract: Referring Expression Comprehension (REC), which aims to ground a local visual region via natural language, is a task that heavily relies on multimodal alignment. Most existing methods utilize powerful pre-trained models to transfer visual/linguistic knowledge by full fine-tuning. However, full fine-tuning the entire backbone not only breaks the rich prior knowledge embedded in the pre-training, but also incurs significant computational costs. Motivated by the recent emergence of Parameter-Efficient Transfer Learning (PETL) methods, we aim to solve the REC task in an effective and efficient manner. Directly applying these PETL methods to the REC task is inappropriate, as they lack the specific-domain abilities for precise local visual perception and visual-language alignment. Therefore, we propose a novel framework of Multimodal Prior-guided Parameter Efficient Tuning, namely MaPPER. Specifically, MaPPER comprises Dynamic Prior Adapters guided by an aligned prior, and Local Convolution Adapters to extract precise local semantics for better visual perception. Moreover, the Prior-Guided Text module is proposed to further utilize the prior for facilitating the cross-modal alignment. Experimental results on three widely-used benchmarks demonstrate that MaPPER achieves the best accuracy compared to the full fine-tuning and other PETL methods with only 1.41% tunable backbone parameters. Our code is available at https://github.com/liuting20/MaPPER.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2409.13609",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Mask-PINNs: Regulating Feature Distributions in Physics-Informed Neural Networks",
    "description": "arXiv:2505.06331v2 Announce Type: replace-cross Abstract: Physics-Informed Neural Networks (PINNs) have emerged as a powerful framework for solving partial differential equations (PDEs) by embedding physical laws directly into the loss function. However, effective training of PINNs remains challenging due to internal covariate shift, which destabilizes feature distributions and impairs model expressiveness. While normalization techniques like Batch Normalization and Layer Normalization are standard remedies in deep learning, they disrupt the pointwise input-output mappings critical to preserving the physical consistency in PINNs. In this work, we introduce Mask-PINNs, a novel architecture that regulates internal feature distributions through a smooth, learnable mask function applied pointwise across hidden layers. Unlike conventional normalization methods, the proposed mask function preserves the deterministic nature of input-output relationships while suppressing activation drift and saturation. Theoretically, we demonstrate that Mask-PINNs control feature spread near initialization by attenuating gradient variance growth through a tailored modulation mechanism. Empirically, we validate the method on multiple PDE benchmarks across diverse activation functions. Our results show consistent improvements in prediction accuracy, convergence stability, and robustness, with relative L2 errors reduced by up to two orders of magnitude over baseline models. Furthermore, we demonstrate that Mask-PINNs enable the effective use of wider networks, overcoming a key limitation in existing PINN frameworks.",
    "summary": "arXiv:2505.06331v2 Announce Type: replace-cross Abstract: Physics-Informed Neural Networks (PINNs) have emerged as a powerful framework for solving partial differential equations (PDEs) by embedding physical laws directly into the loss function. However, effective training of PINNs remains challenging due to internal covariate shift, which destabilizes feature distributions and impairs model expressiveness. While normalization techniques like Batch Normalization and Layer Normalization are standard remedies in deep learning, they disrupt the pointwise input-output mappings critical to preserving the physical consistency in PINNs. In this work, we introduce Mask-PINNs, a novel architecture that regulates internal feature distributions through a smooth, learnable mask function applied pointwise across hidden layers. Unlike conventional normalization methods, the proposed mask function preserves the deterministic nature of input-output relationships while suppressing activation drift and saturation. Theoretically, we demonstrate that Mask-PINNs control feature spread near initialization by attenuating gradient variance growth through a tailored modulation mechanism. Empirically, we validate the method on multiple PDE benchmarks across diverse activation functions. Our results show consistent improvements in prediction accuracy, convergence stability, and robustness, with relative L2 errors reduced by up to two orders of magnitude over baseline models. Furthermore, we demonstrate that Mask-PINNs enable the effective use of wider networks, overcoming a key limitation in existing PINN frameworks.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2505.06331",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Mathematical Proof as a Litmus Test: Revealing Failure Modes of Advanced Large Reasoning Models",
    "description": "arXiv:2506.17114v1 Announce Type: new Abstract: Large reasoning models (e.g., R1, o3) have demonstrated remarkable mathematical problem-solving abilities. However, the high reported accuracy of these advanced models on popular datasets, reliance on purely numerical evaluation and potential benchmark leakage, often masks their true reasoning shortcomings. To address this, we propose leveraging the inherent rigor and methodological complexity of mathematical proofs as a diagnostic tool to expose these hidden failures. Specifically, we introduce the RFMDataset (Reveal Failure Modes), a collection of 200 diverse mathematical proof problems, and thoroughly evaluate advanced models' performance on it. Our in-depth analysis of their failures uncovers 10 fine-grained error types, which shows fundamental limitations in current large reasoning models: 1) large reasoning models grapple profoundly with mathematical proofs, with some generating entirely correct proofs for less than 20% of problems and failing even on basic ones; 2) models exhibit a diverse spectrum of reasoning failures, prominently demonstrating the lack of guarantees for the correctness and rigor of single-step reasoning; and 3) models show hallucination and incompleteness during the reasoning process. Our findings reveal that models' self-reflection is insufficient to resolve the current logical dilemmas, necessitating formalized and fine-grained logical training.",
    "summary": "arXiv:2506.17114v1 Announce Type: new Abstract: Large reasoning models (e.g., R1, o3) have demonstrated remarkable mathematical problem-solving abilities. However, the high reported accuracy of these advanced models on popular datasets, reliance on purely numerical evaluation and potential benchmark leakage, often masks their true reasoning shortcomings. To address this, we propose leveraging the inherent rigor and methodological complexity of mathematical proofs as a diagnostic tool to expose these hidden failures. Specifically, we introduce the RFMDataset (Reveal Failure Modes), a collection of 200 diverse mathematical proof problems, and thoroughly evaluate advanced models' performance on it. Our in-depth analysis of their failures uncovers 10 fine-grained error types, which shows fundamental limitations in current large reasoning models: 1) large reasoning models grapple profoundly with mathematical proofs, with some generating entirely correct proofs for less than 20% of problems and failing even on basic ones; 2) models exhibit a diverse spectrum of reasoning failures, prominently demonstrating the lack of guarantees for the correctness and rigor of single-step reasoning; and 3) models show hallucination and incompleteness during the reasoning process. Our findings reveal that models' self-reflection is insufficient to resolve the current logical dilemmas, necessitating formalized and fine-grained logical training.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.17114",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "MAWIFlow Benchmark: Realistic Flow-Based Evaluation for Network Intrusion Detection",
    "description": "arXiv:2506.17041v1 Announce Type: cross Abstract: Benchmark datasets for network intrusion detection commonly rely on synthetically generated traffic, which fails to reflect the statistical variability and temporal drift encountered in operational environments. This paper introduces MAWIFlow, a flow-based benchmark derived from the MAWILAB v1.1 dataset, designed to enable realistic and reproducible evaluation of anomaly detection methods. A reproducible preprocessing pipeline is presented that transforms raw packet captures into flow representations conforming to the CICFlowMeter format, while preserving MAWILab's original anomaly labels. The resulting datasets comprise temporally distinct samples from January 2011, 2016, and 2021, drawn from trans-Pacific backbone traffic. To establish reference baselines, traditional machine learning methods, including Decision Trees, Random Forests, XGBoost, and Logistic Regression, are compared to a deep learning model based on a CNN-BiLSTM architecture. Empirical results demonstrate that tree-based classifiers perform well on temporally static data but experience significant performance degradation over time. In contrast, the CNN-BiLSTM model maintains better performance, thus showing improved generalization. These findings underscore the limitations of synthetic benchmarks and static models, and motivate the adoption of realistic datasets with explicit temporal structure. All datasets, pipeline code, and model implementations are made publicly available to foster transparency and reproducibility.",
    "summary": "arXiv:2506.17041v1 Announce Type: cross Abstract: Benchmark datasets for network intrusion detection commonly rely on synthetically generated traffic, which fails to reflect the statistical variability and temporal drift encountered in operational environments. This paper introduces MAWIFlow, a flow-based benchmark derived from the MAWILAB v1.1 dataset, designed to enable realistic and reproducible evaluation of anomaly detection methods. A reproducible preprocessing pipeline is presented that transforms raw packet captures into flow representations conforming to the CICFlowMeter format, while preserving MAWILab's original anomaly labels. The resulting datasets comprise temporally distinct samples from January 2011, 2016, and 2021, drawn from trans-Pacific backbone traffic. To establish reference baselines, traditional machine learning methods, including Decision Trees, Random Forests, XGBoost, and Logistic Regression, are compared to a deep learning model based on a CNN-BiLSTM architecture. Empirical results demonstrate that tree-based classifiers perform well on temporally static data but experience significant performance degradation over time. In contrast, the CNN-BiLSTM model maintains better performance, thus showing improved generalization. These findings underscore the limitations of synthetic benchmarks and static models, and motivate the adoption of realistic datasets with explicit temporal structure. All datasets, pipeline code, and model implementations are made publicly available to foster transparency and reproducibility.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.17041",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "MDPO: Multi-Granularity Direct Preference Optimization for Mathematical Reasoning",
    "description": "arXiv:2506.15706v1 Announce Type: cross Abstract: Mathematical reasoning presents a significant challenge for Large Language Models (LLMs) as it requires ensuring the correctness of each reasoning step. Researchers have been strengthening the mathematical reasoning abilities of LLMs through supervised fine-tuning, but due to the inability to suppress incorrect outputs, illusions can easily arise. Recently, Direct Preference Optimization (DPO) has been widely adopted for aligning human intent by using preference data to prevent LLMs from generating incorrect outputs. However, it has shown limited benefits in long-chain mathematical reasoning, mainly because DPO struggles to effectively capture the differences between accepted and rejected answers from preferences in long-chain data. The inconsistency between DPO training and LLMs' generation metrics also affects the effectiveness of suppressing incorrect outputs. We propose the Multi-Granularity Direct Preference Optimization (MDPO) method, optimizing the mathematical reasoning of LLMs at three granularities: Solution2Solution, Inference2Inference, and Step2Step. Solution2Solution focuses on the correctness of entire long-chain reasoning; Inference2Inference concentrates on logical reasoning between steps; Step2Step corrects computational errors in steps, enhancing the computational capabilities of LLMs. Additionally, we unify the training objectives of the three granularities to align with the generation metrics. We conducted experiments on the open-source models Qwen2 and Llama3, achieving improvements of 1.7% and 0.9% on the GSM8K dataset, and 2.3% and 1.2% on the MATH dataset, outperforming DPO and other DPO variant methods. Furthermore, we also provide a pipeline for constructing MDPO training data that is simple and does not require manual annotation costs.",
    "summary": "arXiv:2506.15706v1 Announce Type: cross Abstract: Mathematical reasoning presents a significant challenge for Large Language Models (LLMs) as it requires ensuring the correctness of each reasoning step. Researchers have been strengthening the mathematical reasoning abilities of LLMs through supervised fine-tuning, but due to the inability to suppress incorrect outputs, illusions can easily arise. Recently, Direct Preference Optimization (DPO) has been widely adopted for aligning human intent by using preference data to prevent LLMs from generating incorrect outputs. However, it has shown limited benefits in long-chain mathematical reasoning, mainly because DPO struggles to effectively capture the differences between accepted and rejected answers from preferences in long-chain data. The inconsistency between DPO training and LLMs' generation metrics also affects the effectiveness of suppressing incorrect outputs. We propose the Multi-Granularity Direct Preference Optimization (MDPO) method, optimizing the mathematical reasoning of LLMs at three granularities: Solution2Solution, Inference2Inference, and Step2Step. Solution2Solution focuses on the correctness of entire long-chain reasoning; Inference2Inference concentrates on logical reasoning between steps; Step2Step corrects computational errors in steps, enhancing the computational capabilities of LLMs. Additionally, we unify the training objectives of the three granularities to align with the generation metrics. We conducted experiments on the open-source models Qwen2 and Llama3, achieving improvements of 1.7% and 0.9% on the GSM8K dataset, and 2.3% and 1.2% on the MATH dataset, outperforming DPO and other DPO variant methods. Furthermore, we also provide a pipeline for constructing MDPO training data that is simple and does not require manual annotation costs.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.15706",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Measuring (a Sufficient) World Model in LLMs: A Variance Decomposition Framework",
    "description": "arXiv:2506.16584v1 Announce Type: cross Abstract: Understanding whether large language models (LLMs) possess a world model-a structured understanding of the world that supports generalization beyond surface-level patterns-is central to assessing their reliability, especially in high-stakes applications. We propose a formal framework for evaluating whether an LLM exhibits a sufficiently robust world model, defined as producing consistent outputs across semantically equivalent prompts while distinguishing between prompts that express different intents. We introduce a new evaluation approach to measure this that decomposes model response variability into three components: variability due to user purpose, user articulation, and model instability. An LLM with a strong world model should attribute most of the variability in its responses to changes in foundational purpose rather than superficial changes in articulation. This approach allows us to quantify how much of a model's behavior is semantically grounded rather than driven by model instability or alternative wording. We apply this framework to evaluate LLMs across diverse domains. Our results show how larger models attribute a greater share of output variability to changes in user purpose, indicating a more robust world model. This improvement is not uniform, however: larger models do not consistently outperform smaller ones across all domains, and their advantage in robustness is often modest. These findings highlight the importance of moving beyond accuracy-based benchmarks toward semantic diagnostics that more directly assess the structure and stability of a model's internal understanding of the world.",
    "summary": "arXiv:2506.16584v1 Announce Type: cross Abstract: Understanding whether large language models (LLMs) possess a world model-a structured understanding of the world that supports generalization beyond surface-level patterns-is central to assessing their reliability, especially in high-stakes applications. We propose a formal framework for evaluating whether an LLM exhibits a sufficiently robust world model, defined as producing consistent outputs across semantically equivalent prompts while distinguishing between prompts that express different intents. We introduce a new evaluation approach to measure this that decomposes model response variability into three components: variability due to user purpose, user articulation, and model instability. An LLM with a strong world model should attribute most of the variability in its responses to changes in foundational purpose rather than superficial changes in articulation. This approach allows us to quantify how much of a model's behavior is semantically grounded rather than driven by model instability or alternative wording. We apply this framework to evaluate LLMs across diverse domains. Our results show how larger models attribute a greater share of output variability to changes in user purpose, indicating a more robust world model. This improvement is not uniform, however: larger models do not consistently outperform smaller ones across all domains, and their advantage in robustness is often modest. These findings highlight the importance of moving beyond accuracy-based benchmarks toward semantic diagnostics that more directly assess the structure and stability of a model's internal understanding of the world.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16584",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Med-U1: Incentivizing Unified Medical Reasoning in LLMs via Large-scale Reinforcement Learning",
    "description": "arXiv:2506.12307v2 Announce Type: replace-cross Abstract: Medical Question-Answering (QA) encompasses a broad spectrum of tasks, including multiple choice questions (MCQ), open-ended text generation, and complex computational reasoning. Despite this variety, a unified framework for delivering high-quality medical QA has yet to emerge. Although recent progress in reasoning-augmented large language models (LLMs) has shown promise, their ability to achieve comprehensive medical understanding is still largely unexplored. In this paper, we present Med-U1, a unified framework for robust reasoning across medical QA tasks with diverse output formats, ranging from MCQs to complex generation and computation tasks. Med-U1 employs pure large-scale reinforcement learning with mixed rule-based binary reward functions, incorporating a length penalty to manage output verbosity. With multi-objective reward optimization, Med-U1 directs LLMs to produce concise and verifiable reasoning chains. Empirical results reveal that Med-U1 significantly improves performance across multiple challenging Med-QA benchmarks, surpassing even larger specialized and proprietary models. Furthermore, Med-U1 demonstrates robust generalization to out-of-distribution (OOD) tasks. Extensive analysis presents insights into training strategies, reasoning chain length control, and reward design for medical LLMs. Our code is available here.",
    "summary": "arXiv:2506.12307v2 Announce Type: replace-cross Abstract: Medical Question-Answering (QA) encompasses a broad spectrum of tasks, including multiple choice questions (MCQ), open-ended text generation, and complex computational reasoning. Despite this variety, a unified framework for delivering high-quality medical QA has yet to emerge. Although recent progress in reasoning-augmented large language models (LLMs) has shown promise, their ability to achieve comprehensive medical understanding is still largely unexplored. In this paper, we present Med-U1, a unified framework for robust reasoning across medical QA tasks with diverse output formats, ranging from MCQs to complex generation and computation tasks. Med-U1 employs pure large-scale reinforcement learning with mixed rule-based binary reward functions, incorporating a length penalty to manage output verbosity. With multi-objective reward optimization, Med-U1 directs LLMs to produce concise and verifiable reasoning chains. Empirical results reveal that Med-U1 significantly improves performance across multiple challenging Med-QA benchmarks, surpassing even larger specialized and proprietary models. Furthermore, Med-U1 demonstrates robust generalization to out-of-distribution (OOD) tasks. Extensive analysis presents insights into training strategies, reasoning chain length control, and reward design for medical LLMs. Our code is available here.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.12307",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "MeDi: Metadata-Guided Diffusion Models for Mitigating Biases in Tumor Classification",
    "description": "arXiv:2506.17140v1 Announce Type: cross Abstract: Deep learning models have made significant advances in histological prediction tasks in recent years. However, for adaptation in clinical practice, their lack of robustness to varying conditions such as staining, scanner, hospital, and demographics is still a limiting factor: if trained on overrepresented subpopulations, models regularly struggle with less frequent patterns, leading to shortcut learning and biased predictions. Large-scale foundation models have not fully eliminated this issue. Therefore, we propose a novel approach explicitly modeling such metadata into a Metadata-guided generative Diffusion model framework (MeDi). MeDi allows for a targeted augmentation of underrepresented subpopulations with synthetic data, which balances limited training data and mitigates biases in downstream models. We experimentally show that MeDi generates high-quality histopathology images for unseen subpopulations in TCGA, boosts the overall fidelity of the generated images, and enables improvements in performance for downstream classifiers on datasets with subpopulation shifts. Our work is a proof-of-concept towards better mitigating data biases with generative models.",
    "summary": "arXiv:2506.17140v1 Announce Type: cross Abstract: Deep learning models have made significant advances in histological prediction tasks in recent years. However, for adaptation in clinical practice, their lack of robustness to varying conditions such as staining, scanner, hospital, and demographics is still a limiting factor: if trained on overrepresented subpopulations, models regularly struggle with less frequent patterns, leading to shortcut learning and biased predictions. Large-scale foundation models have not fully eliminated this issue. Therefore, we propose a novel approach explicitly modeling such metadata into a Metadata-guided generative Diffusion model framework (MeDi). MeDi allows for a targeted augmentation of underrepresented subpopulations with synthetic data, which balances limited training data and mitigates biases in downstream models. We experimentally show that MeDi generates high-quality histopathology images for unseen subpopulations in TCGA, boosts the overall fidelity of the generated images, and enables improvements in performance for downstream classifiers on datasets with subpopulation shifts. Our work is a proof-of-concept towards better mitigating data biases with generative models.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.17140",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "MEM1: Learning to Synergize Memory and Reasoning for Efficient Long-Horizon Agents",
    "description": "arXiv:2506.15841v1 Announce Type: cross Abstract: Modern language agents must operate over long-horizon, multi-turn interactions, where they retrieve external information, adapt to observations, and answer interdependent queries. Yet, most LLM systems rely on full-context prompting, appending all past turns regardless of their relevance. This leads to unbounded memory growth, increased computational costs, and degraded reasoning performance on out-of-distribution input lengths. We introduce MEM1, an end-to-end reinforcement learning framework that enables agents to operate with constant memory across long multi-turn tasks. At each turn, MEM1 updates a compact shared internal state that jointly supports memory consolidation and reasoning. This state integrates prior memory with new observations from the environment while strategically discarding irrelevant or redundant information. To support training in more realistic and compositional settings, we propose a simple yet effective and scalable approach to constructing multi-turn environments by composing existing datasets into arbitrarily complex task sequences. Experiments across three domains, including internal retrieval QA, open-domain web QA, and multi-turn web shopping, show that MEM1-7B improves performance by 3.5x while reducing memory usage by 3.7x compared to Qwen2.5-14B-Instruct on a 16-objective multi-hop QA task, and generalizes beyond the training horizon. Our results demonstrate the promise of reasoning-driven memory consolidation as a scalable alternative to existing solutions for training long-horizon interactive agents, where both efficiency and performance are optimized.",
    "summary": "arXiv:2506.15841v1 Announce Type: cross Abstract: Modern language agents must operate over long-horizon, multi-turn interactions, where they retrieve external information, adapt to observations, and answer interdependent queries. Yet, most LLM systems rely on full-context prompting, appending all past turns regardless of their relevance. This leads to unbounded memory growth, increased computational costs, and degraded reasoning performance on out-of-distribution input lengths. We introduce MEM1, an end-to-end reinforcement learning framework that enables agents to operate with constant memory across long multi-turn tasks. At each turn, MEM1 updates a compact shared internal state that jointly supports memory consolidation and reasoning. This state integrates prior memory with new observations from the environment while strategically discarding irrelevant or redundant information. To support training in more realistic and compositional settings, we propose a simple yet effective and scalable approach to constructing multi-turn environments by composing existing datasets into arbitrarily complex task sequences. Experiments across three domains, including internal retrieval QA, open-domain web QA, and multi-turn web shopping, show that MEM1-7B improves performance by 3.5x while reducing memory usage by 3.7x compared to Qwen2.5-14B-Instruct on a 16-objective multi-hop QA task, and generalizes beyond the training horizon. Our results demonstrate the promise of reasoning-driven memory consolidation as a scalable alternative to existing solutions for training long-horizon interactive agents, where both efficiency and performance are optimized.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.15841",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Metapath-based Hyperbolic Contrastive Learning for Heterogeneous Graph Embedding",
    "description": "arXiv:2506.16754v1 Announce Type: cross Abstract: The hyperbolic space, characterized by a constant negative curvature and exponentially expanding space, aligns well with the structural properties of heterogeneous graphs. However, although heterogeneous graphs inherently possess diverse power-law structures, most hyperbolic heterogeneous graph embedding models rely on a single hyperbolic space. This approach may fail to effectively capture the diverse power-law structures within heterogeneous graphs. To address this limitation, we propose a Metapath-based Hyperbolic Contrastive Learning framework (MHCL), which uses multiple hyperbolic spaces to capture diverse complex structures within heterogeneous graphs. Specifically, by learning each hyperbolic space to describe the distribution of complex structures corresponding to each metapath, it is possible to capture semantic information effectively. Since metapath embeddings represent distinct semantic information, preserving their discriminability is important when aggregating them to obtain node representations. Therefore, we use a contrastive learning approach to optimize MHCL and improve the discriminability of metapath embeddings. In particular, our contrastive learning method minimizes the distance between embeddings of the same metapath and maximizes the distance between those of different metapaths in hyperbolic space, thereby improving the separability of metapath embeddings with distinct semantic information. We conduct comprehensive experiments to evaluate the effectiveness of MHCL. The experimental results demonstrate that MHCL outperforms state-of-the-art baselines in various graph machine learning tasks, effectively capturing the complex structures of heterogeneous graphs.",
    "summary": "arXiv:2506.16754v1 Announce Type: cross Abstract: The hyperbolic space, characterized by a constant negative curvature and exponentially expanding space, aligns well with the structural properties of heterogeneous graphs. However, although heterogeneous graphs inherently possess diverse power-law structures, most hyperbolic heterogeneous graph embedding models rely on a single hyperbolic space. This approach may fail to effectively capture the diverse power-law structures within heterogeneous graphs. To address this limitation, we propose a Metapath-based Hyperbolic Contrastive Learning framework (MHCL), which uses multiple hyperbolic spaces to capture diverse complex structures within heterogeneous graphs. Specifically, by learning each hyperbolic space to describe the distribution of complex structures corresponding to each metapath, it is possible to capture semantic information effectively. Since metapath embeddings represent distinct semantic information, preserving their discriminability is important when aggregating them to obtain node representations. Therefore, we use a contrastive learning approach to optimize MHCL and improve the discriminability of metapath embeddings. In particular, our contrastive learning method minimizes the distance between embeddings of the same metapath and maximizes the distance between those of different metapaths in hyperbolic space, thereby improving the separability of metapath embeddings with distinct semantic information. We conduct comprehensive experiments to evaluate the effectiveness of MHCL. The experimental results demonstrate that MHCL outperforms state-of-the-art baselines in various graph machine learning tasks, effectively capturing the complex structures of heterogeneous graphs.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16754",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "MEXA: Towards General Multimodal Reasoning with Dynamic Multi-Expert Aggregation",
    "description": "arXiv:2506.17113v1 Announce Type: cross Abstract: Combining pre-trained expert models offers substantial potential for scalable multimodal reasoning, but building a unified framework remains challenging due to the increasing diversity of input modalities and task complexity. For instance, medical diagnosis requires precise reasoning over structured clinical tables, while financial forecasting depends on interpreting plot-based data to make informed predictions. To tackle this challenge, we introduce MEXA, a training-free framework that performs modality- and task-aware aggregation of multiple expert models to enable effective multimodal reasoning across diverse and distinct domains. MEXA dynamically selects expert models based on the input modality and the task-specific reasoning demands (i.e., skills). Each expert model, specialized in a modality task pair, generates interpretable textual reasoning outputs. MEXA then aggregates and reasons over these outputs using a Large Reasoning Model (LRM) to produce the final answer. This modular design allows flexible and transparent multimodal reasoning across diverse domains without additional training overhead. We extensively evaluate our approach on diverse multimodal benchmarks, including Video Reasoning, Audio Reasoning, 3D Understanding, and Medical QA. MEXA consistently delivers performance improvements over strong multimodal baselines, highlighting the effectiveness and broad applicability of our expert-driven selection and aggregation in diverse multimodal reasoning tasks.",
    "summary": "arXiv:2506.17113v1 Announce Type: cross Abstract: Combining pre-trained expert models offers substantial potential for scalable multimodal reasoning, but building a unified framework remains challenging due to the increasing diversity of input modalities and task complexity. For instance, medical diagnosis requires precise reasoning over structured clinical tables, while financial forecasting depends on interpreting plot-based data to make informed predictions. To tackle this challenge, we introduce MEXA, a training-free framework that performs modality- and task-aware aggregation of multiple expert models to enable effective multimodal reasoning across diverse and distinct domains. MEXA dynamically selects expert models based on the input modality and the task-specific reasoning demands (i.e., skills). Each expert model, specialized in a modality task pair, generates interpretable textual reasoning outputs. MEXA then aggregates and reasons over these outputs using a Large Reasoning Model (LRM) to produce the final answer. This modular design allows flexible and transparent multimodal reasoning across diverse domains without additional training overhead. We extensively evaluate our approach on diverse multimodal benchmarks, including Video Reasoning, Audio Reasoning, 3D Understanding, and Medical QA. MEXA consistently delivers performance improvements over strong multimodal baselines, highlighting the effectiveness and broad applicability of our expert-driven selection and aggregation in diverse multimodal reasoning tasks.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.17113",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Minifinetuning: Low-Data Generation Domain Adaptation through Corrective Self-Distillation",
    "description": "arXiv:2506.15702v1 Announce Type: cross Abstract: Finetuning language models for a new domain inevitably leads to the deterioration of their general performance. This becomes more pronounced the more limited the finetuning data resource. We introduce minifinetuning (MFT), a method for language model domain adaptation that considerably reduces the effects of overfitting-induced degeneralization in low-data settings and which does so in the absence of any pre-training data for replay. MFT demonstrates 2-10x more favourable specialization-to-degeneralization ratios than standard finetuning across a wide range of models and domains and exhibits an intrinsic robustness to overfitting when data in the new domain is scarce and down to as little as 500 samples. Employing corrective self-distillation that is individualized on the sample level, MFT outperforms parameter-efficient finetuning methods, demonstrates replay-like degeneralization mitigation properties, and is composable with either for a combined effect.",
    "summary": "arXiv:2506.15702v1 Announce Type: cross Abstract: Finetuning language models for a new domain inevitably leads to the deterioration of their general performance. This becomes more pronounced the more limited the finetuning data resource. We introduce minifinetuning (MFT), a method for language model domain adaptation that considerably reduces the effects of overfitting-induced degeneralization in low-data settings and which does so in the absence of any pre-training data for replay. MFT demonstrates 2-10x more favourable specialization-to-degeneralization ratios than standard finetuning across a wide range of models and domains and exhibits an intrinsic robustness to overfitting when data in the new domain is scarce and down to as little as 500 samples. Employing corrective self-distillation that is individualized on the sample level, MFT outperforms parameter-efficient finetuning methods, demonstrates replay-like degeneralization mitigation properties, and is composable with either for a combined effect.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.15702",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "MIST: Jailbreaking Black-box Large Language Models via Iterative Semantic Tuning",
    "description": "arXiv:2506.16792v1 Announce Type: cross Abstract: Despite efforts to align large language models (LLMs) with societal and moral values, these models remain susceptible to jailbreak attacks--methods designed to elicit harmful responses. Jailbreaking black-box LLMs is considered challenging due to the discrete nature of token inputs, restricted access to the target LLM, and limited query budget. To address the issues above, we propose an effective method for jailbreaking black-box large language Models via Iterative Semantic Tuning, named MIST. MIST enables attackers to iteratively refine prompts that preserve the original semantic intent while inducing harmful content. Specifically, to balance semantic similarity with computational efficiency, MIST incorporates two key strategies: sequential synonym search, and its advanced version--order-determining optimization. Extensive experiments across two open-source models and four closed-source models demonstrate that MIST achieves competitive attack success rates and attack transferability compared with other state-of-the-art white-box and black-box jailbreak methods. Additionally, we conduct experiments on computational efficiency to validate the practical viability of MIST.",
    "summary": "arXiv:2506.16792v1 Announce Type: cross Abstract: Despite efforts to align large language models (LLMs) with societal and moral values, these models remain susceptible to jailbreak attacks--methods designed to elicit harmful responses. Jailbreaking black-box LLMs is considered challenging due to the discrete nature of token inputs, restricted access to the target LLM, and limited query budget. To address the issues above, we propose an effective method for jailbreaking black-box large language Models via Iterative Semantic Tuning, named MIST. MIST enables attackers to iteratively refine prompts that preserve the original semantic intent while inducing harmful content. Specifically, to balance semantic similarity with computational efficiency, MIST incorporates two key strategies: sequential synonym search, and its advanced version--order-determining optimization. Extensive experiments across two open-source models and four closed-source models demonstrate that MIST achieves competitive attack success rates and attack transferability compared with other state-of-the-art white-box and black-box jailbreak methods. Additionally, we conduct experiments on computational efficiency to validate the practical viability of MIST.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16792",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "ML-Master: Towards AI-for-AI via Integration of Exploration and Reasoning",
    "description": "arXiv:2506.16499v1 Announce Type: new Abstract: As AI capabilities advance toward and potentially beyond human-level performance, a natural transition emerges where AI-driven development becomes more efficient than human-centric approaches. A promising pathway toward this transition lies in AI-for-AI (AI4AI), which leverages AI techniques to automate and optimize the design, training, and deployment of AI systems themselves. While LLM-based agents have shown the potential to realize AI4AI, they are often unable to fully leverage the experience accumulated by agents during the exploration of solutions in the reasoning process, leading to inefficiencies and suboptimal performance. To address this limitation, we propose ML-Master, a novel AI4AI agent that seamlessly integrates exploration and reasoning by employing a selectively scoped memory mechanism. This approach allows ML-Master to efficiently combine diverse insights from parallel solution trajectories with analytical reasoning, guiding further exploration without overwhelming the agent with excessive context. We evaluate ML-Master on the MLE-Bench, where it achieves a 29.3% average medal rate, significantly surpassing existing methods, particularly in medium-complexity tasks, while accomplishing this superior performance within a strict 12-hour time constraint-half the 24-hour limit used by previous baselines. These results demonstrate ML-Master's potential as a powerful tool for advancing AI4AI.",
    "summary": "arXiv:2506.16499v1 Announce Type: new Abstract: As AI capabilities advance toward and potentially beyond human-level performance, a natural transition emerges where AI-driven development becomes more efficient than human-centric approaches. A promising pathway toward this transition lies in AI-for-AI (AI4AI), which leverages AI techniques to automate and optimize the design, training, and deployment of AI systems themselves. While LLM-based agents have shown the potential to realize AI4AI, they are often unable to fully leverage the experience accumulated by agents during the exploration of solutions in the reasoning process, leading to inefficiencies and suboptimal performance. To address this limitation, we propose ML-Master, a novel AI4AI agent that seamlessly integrates exploration and reasoning by employing a selectively scoped memory mechanism. This approach allows ML-Master to efficiently combine diverse insights from parallel solution trajectories with analytical reasoning, guiding further exploration without overwhelming the agent with excessive context. We evaluate ML-Master on the MLE-Bench, where it achieves a 29.3% average medal rate, significantly surpassing existing methods, particularly in medium-complexity tasks, while accomplishing this superior performance within a strict 12-hour time constraint-half the 24-hour limit used by previous baselines. These results demonstrate ML-Master's potential as a powerful tool for advancing AI4AI.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16499",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Modeling Public Perceptions of Science in Media",
    "description": "arXiv:2506.16622v1 Announce Type: cross Abstract: Effectively engaging the public with science is vital for fostering trust and understanding in our scientific community. Yet, with an ever-growing volume of information, science communicators struggle to anticipate how audiences will perceive and interact with scientific news. In this paper, we introduce a computational framework that models public perception across twelve dimensions, such as newsworthiness, importance, and surprisingness. Using this framework, we create a large-scale science news perception dataset with 10,489 annotations from 2,101 participants from diverse US and UK populations, providing valuable insights into public responses to scientific information across domains. We further develop NLP models that predict public perception scores with a strong performance. Leveraging the dataset and model, we examine public perception of science from two perspectives: (1) Perception as an outcome: What factors affect the public perception of scientific information? (2) Perception as a predictor: Can we use the estimated perceptions to predict public engagement with science? We find that individuals' frequency of science news consumption is the driver of perception, whereas demographic factors exert minimal influence. More importantly, through a large-scale analysis and carefully designed natural experiment on Reddit, we demonstrate that the estimated public perception of scientific information has direct connections with the final engagement pattern. Posts with more positive perception scores receive significantly more comments and upvotes, which is consistent across different scientific information and for the same science, but are framed differently. Overall, this research underscores the importance of nuanced perception modeling in science communication, offering new pathways to predict public interest and engagement with scientific content.",
    "summary": "arXiv:2506.16622v1 Announce Type: cross Abstract: Effectively engaging the public with science is vital for fostering trust and understanding in our scientific community. Yet, with an ever-growing volume of information, science communicators struggle to anticipate how audiences will perceive and interact with scientific news. In this paper, we introduce a computational framework that models public perception across twelve dimensions, such as newsworthiness, importance, and surprisingness. Using this framework, we create a large-scale science news perception dataset with 10,489 annotations from 2,101 participants from diverse US and UK populations, providing valuable insights into public responses to scientific information across domains. We further develop NLP models that predict public perception scores with a strong performance. Leveraging the dataset and model, we examine public perception of science from two perspectives: (1) Perception as an outcome: What factors affect the public perception of scientific information? (2) Perception as a predictor: Can we use the estimated perceptions to predict public engagement with science? We find that individuals' frequency of science news consumption is the driver of perception, whereas demographic factors exert minimal influence. More importantly, through a large-scale analysis and carefully designed natural experiment on Reddit, we demonstrate that the estimated public perception of scientific information has direct connections with the final engagement pattern. Posts with more positive perception scores receive significantly more comments and upvotes, which is consistent across different scientific information and for the same science, but are framed differently. Overall, this research underscores the importance of nuanced perception modeling in science communication, offering new pathways to predict public interest and engagement with scientific content.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16622",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Moir'eXNet: Adaptive Multi-Scale Demoir'eing with Linear Attention Test-Time Training and Truncated Flow Matching Prior",
    "description": "arXiv:2506.15929v1 Announce Type: cross Abstract: This paper introduces a novel framework for image and video demoir'eing by integrating Maximum A Posteriori (MAP) estimation with advanced deep learning techniques. Demoir'eing addresses inherently nonlinear degradation processes, which pose significant challenges for existing methods. Traditional supervised learning approaches either fail to remove moir'e patterns completely or produce overly smooth results. This stems from constrained model capacity and scarce training data, which inadequately represent the clean image distribution and hinder accurate reconstruction of ground-truth images. While generative models excel in image restoration for linear degradations, they struggle with nonlinear cases such as demoir'eing and often introduce artifacts. To address these limitations, we propose a hybrid MAP-based framework that integrates two complementary components. The first is a supervised learning model enhanced with efficient linear attention Test-Time Training (TTT) modules, which directly learn nonlinear mappings for RAW-to-sRGB demoir'eing. The second is a Truncated Flow Matching Prior (TFMP) that further refines the outputs by aligning them with the clean image distribution, effectively restoring high-frequency details and suppressing artifacts. These two components combine the computational efficiency of linear attention with the refinement abilities of generative models, resulting in improved restoration performance.",
    "summary": "arXiv:2506.15929v1 Announce Type: cross Abstract: This paper introduces a novel framework for image and video demoir'eing by integrating Maximum A Posteriori (MAP) estimation with advanced deep learning techniques. Demoir'eing addresses inherently nonlinear degradation processes, which pose significant challenges for existing methods. Traditional supervised learning approaches either fail to remove moir'e patterns completely or produce overly smooth results. This stems from constrained model capacity and scarce training data, which inadequately represent the clean image distribution and hinder accurate reconstruction of ground-truth images. While generative models excel in image restoration for linear degradations, they struggle with nonlinear cases such as demoir'eing and often introduce artifacts. To address these limitations, we propose a hybrid MAP-based framework that integrates two complementary components. The first is a supervised learning model enhanced with efficient linear attention Test-Time Training (TTT) modules, which directly learn nonlinear mappings for RAW-to-sRGB demoir'eing. The second is a Truncated Flow Matching Prior (TFMP) that further refines the outputs by aligning them with the clean image distribution, effectively restoring high-frequency details and suppressing artifacts. These two components combine the computational efficiency of linear attention with the refinement abilities of generative models, resulting in improved restoration performance.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.15929",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "MoNetV2: Enhanced Motion Network for Freehand 3D Ultrasound Reconstruction",
    "description": "arXiv:2506.15835v1 Announce Type: cross Abstract: Three-dimensional (3D) ultrasound (US) aims to provide sonographers with the spatial relationships of anatomical structures, playing a crucial role in clinical diagnosis. Recently, deep-learning-based freehand 3D US has made significant advancements. It reconstructs volumes by estimating transformations between images without external tracking. However, image-only reconstruction poses difficulties in reducing cumulative drift and further improving reconstruction accuracy, particularly in scenarios involving complex motion trajectories. In this context, we propose an enhanced motion network (MoNetV2) to enhance the accuracy and generalizability of reconstruction under diverse scanning velocities and tactics. First, we propose a sensor-based temporal and multi-branch structure that fuses image and motion information from a velocity perspective to improve image-only reconstruction accuracy. Second, we devise an online multi-level consistency constraint that exploits the inherent consistency of scans to handle various scanning velocities and tactics. This constraint exploits both scan-level velocity consistency, path-level appearance consistency, and patch-level motion consistency to supervise inter-frame transformation estimation. Third, we distill an online multi-modal self-supervised strategy that leverages the correlation between network estimation and motion information to further reduce cumulative errors. Extensive experiments clearly demonstrate that MoNetV2 surpasses existing methods in both reconstruction quality and generalizability performance across three large datasets.",
    "summary": "arXiv:2506.15835v1 Announce Type: cross Abstract: Three-dimensional (3D) ultrasound (US) aims to provide sonographers with the spatial relationships of anatomical structures, playing a crucial role in clinical diagnosis. Recently, deep-learning-based freehand 3D US has made significant advancements. It reconstructs volumes by estimating transformations between images without external tracking. However, image-only reconstruction poses difficulties in reducing cumulative drift and further improving reconstruction accuracy, particularly in scenarios involving complex motion trajectories. In this context, we propose an enhanced motion network (MoNetV2) to enhance the accuracy and generalizability of reconstruction under diverse scanning velocities and tactics. First, we propose a sensor-based temporal and multi-branch structure that fuses image and motion information from a velocity perspective to improve image-only reconstruction accuracy. Second, we devise an online multi-level consistency constraint that exploits the inherent consistency of scans to handle various scanning velocities and tactics. This constraint exploits both scan-level velocity consistency, path-level appearance consistency, and patch-level motion consistency to supervise inter-frame transformation estimation. Third, we distill an online multi-modal self-supervised strategy that leverages the correlation between network estimation and motion information to further reduce cumulative errors. Extensive experiments clearly demonstrate that MoNetV2 surpasses existing methods in both reconstruction quality and generalizability performance across three large datasets.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.15835",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "MonoSOWA: Scalable monocular 3D Object detector Without human Annotations",
    "description": "arXiv:2501.09481v3 Announce Type: replace-cross Abstract: Inferring object 3D position and orientation from a single RGB camera is a foundational task in computer vision with many important applications. Traditionally, 3D object detection methods are trained in a fully-supervised setup, requiring LiDAR and vast amounts of human annotations, which are laborious, costly, and do not scale well with the ever-increasing amounts of data being captured. We present a novel method to train a 3D object detector from a single RGB camera without domain-specific human annotations, making orders of magnitude more data available for training. The method uses newly proposed Local Object Motion Model to disentangle object movement source between subsequent frames, is approximately 700 times faster than previous work and compensates camera focal length differences to aggregate multiple datasets. The method is evaluated on three public datasets, where despite using no human labels, it outperforms prior work by a significant margin. It also shows its versatility as a pre-training tool for fully-supervised training and shows that combining pseudo-labels from multiple datasets can achieve comparable accuracy to using human labels from a single dataset. The source code and model are available at https://github.com/jskvrna/MonoSOWA.",
    "summary": "arXiv:2501.09481v3 Announce Type: replace-cross Abstract: Inferring object 3D position and orientation from a single RGB camera is a foundational task in computer vision with many important applications. Traditionally, 3D object detection methods are trained in a fully-supervised setup, requiring LiDAR and vast amounts of human annotations, which are laborious, costly, and do not scale well with the ever-increasing amounts of data being captured. We present a novel method to train a 3D object detector from a single RGB camera without domain-specific human annotations, making orders of magnitude more data available for training. The method uses newly proposed Local Object Motion Model to disentangle object movement source between subsequent frames, is approximately 700 times faster than previous work and compensates camera focal length differences to aggregate multiple datasets. The method is evaluated on three public datasets, where despite using no human labels, it outperforms prior work by a significant margin. It also shows its versatility as a pre-training tool for fully-supervised training and shows that combining pseudo-labels from multiple datasets can achieve comparable accuracy to using human labels from a single dataset. The source code and model are available at https://github.com/jskvrna/MonoSOWA.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2501.09481",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "MoR: Better Handling Diverse Queries with a Mixture of Sparse, Dense, and Human Retrievers",
    "description": "arXiv:2506.15862v1 Announce Type: cross Abstract: Retrieval-augmented Generation (RAG) is powerful, but its effectiveness hinges on which retrievers we use and how. Different retrievers offer distinct, often complementary signals: BM25 captures lexical matches; dense retrievers, semantic similarity. Yet in practice, we typically fix a single retriever based on heuristics, which fails to generalize across diverse information needs. Can we dynamically select and integrate multiple retrievers for each individual query, without the need for manual selection? In our work, we validate this intuition with quantitative analysis and introduce mixture of retrievers: a zero-shot, weighted combination of heterogeneous retrievers. Extensive experiments show that such mixtures are effective and efficient: Despite totaling just 0.8B parameters, this mixture outperforms every individual retriever and even larger 7B models by +10.8% and +3.9% on average, respectively. Further analysis also shows that this mixture framework can help incorporate specialized non-oracle human information sources as retrievers to achieve good collaboration, with a 58.9% relative performance improvement over simulated humans alone.",
    "summary": "arXiv:2506.15862v1 Announce Type: cross Abstract: Retrieval-augmented Generation (RAG) is powerful, but its effectiveness hinges on which retrievers we use and how. Different retrievers offer distinct, often complementary signals: BM25 captures lexical matches; dense retrievers, semantic similarity. Yet in practice, we typically fix a single retriever based on heuristics, which fails to generalize across diverse information needs. Can we dynamically select and integrate multiple retrievers for each individual query, without the need for manual selection? In our work, we validate this intuition with quantitative analysis and introduce mixture of retrievers: a zero-shot, weighted combination of heterogeneous retrievers. Extensive experiments show that such mixtures are effective and efficient: Despite totaling just 0.8B parameters, this mixture outperforms every individual retriever and even larger 7B models by +10.8% and +3.9% on average, respectively. Further analysis also shows that this mixture framework can help incorporate specialized non-oracle human information sources as retrievers to achieve good collaboration, with a 58.9% relative performance improvement over simulated humans alone.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.15862",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "More Thinking, Less Seeing? Assessing Amplified Hallucination in Multimodal Reasoning Models",
    "description": "arXiv:2505.21523v3 Announce Type: replace-cross Abstract: Test-time compute has empowered multimodal large language models to generate extended reasoning chains, yielding strong performance on tasks such as multimodal math reasoning. However, this improved reasoning ability often comes with increased hallucination: as generations become longer, models tend to drift away from image-grounded content and rely more heavily on language priors. Attention analysis shows that longer reasoning chains lead to reduced focus on visual inputs, which contributes to hallucination. To systematically study this phenomenon, we introduce RH-AUC, a metric that quantifies how a model's perception accuracy changes with reasoning length, allowing us to evaluate whether the model preserves visual grounding during reasoning. We also release RH-Bench, a diagnostic benchmark that spans a variety of multimodal tasks, designed to assess the trade-off between reasoning ability and hallucination. Our analysis reveals that (i) larger models typically achieve a better balance between reasoning and perception, and (ii) this balance is influenced more by the types and domains of training data than by its overall volume. These findings underscore the importance of evaluation frameworks that jointly consider both reasoning quality and perceptual fidelity.",
    "summary": "arXiv:2505.21523v3 Announce Type: replace-cross Abstract: Test-time compute has empowered multimodal large language models to generate extended reasoning chains, yielding strong performance on tasks such as multimodal math reasoning. However, this improved reasoning ability often comes with increased hallucination: as generations become longer, models tend to drift away from image-grounded content and rely more heavily on language priors. Attention analysis shows that longer reasoning chains lead to reduced focus on visual inputs, which contributes to hallucination. To systematically study this phenomenon, we introduce RH-AUC, a metric that quantifies how a model's perception accuracy changes with reasoning length, allowing us to evaluate whether the model preserves visual grounding during reasoning. We also release RH-Bench, a diagnostic benchmark that spans a variety of multimodal tasks, designed to assess the trade-off between reasoning ability and hallucination. Our analysis reveals that (i) larger models typically achieve a better balance between reasoning and perception, and (ii) this balance is influenced more by the types and domains of training data than by its overall volume. These findings underscore the importance of evaluation frameworks that jointly consider both reasoning quality and perceptual fidelity.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2505.21523",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Multi-Preference Optimization: Generalizing DPO via Set-Level Contrasts",
    "description": "arXiv:2412.04628v4 Announce Type: replace-cross Abstract: Direct Preference Optimization (DPO) has become a popular approach for aligning language models using pairwise preferences. However, in practical post-training pipelines, on-policy generation typically yields multiple candidate responses per prompt, which are scored by a reward model to guide learning. In this setting, we propose $textbf{Multi-Preference Optimization (MPO)}$, a generalization of DPO that optimizes over entire sets of responses by extending the Bradley-Terry model to groupwise comparisons between chosen and rejected sets. To further enhance learning, MPO employs deviation-based weighting, which emphasizes outlier responses that deviate most from the mean reward, effectively inducing a self-paced curriculum. We theoretically prove that MPO reduces alignment bias at a rate of $mathcal{O}left(frac{1}{sqrt{n}}right)$ with respect to the number of responses per query. Empirically, MPO achieves state-of-the-art performance on the UltraFeedback benchmark and yields up to $sim 17.5%$ improvement over the state-of-the-art baseline in length-controlled win rate on AlpacaEval2, establishing a new baseline for preference-based alignment",
    "summary": "arXiv:2412.04628v4 Announce Type: replace-cross Abstract: Direct Preference Optimization (DPO) has become a popular approach for aligning language models using pairwise preferences. However, in practical post-training pipelines, on-policy generation typically yields multiple candidate responses per prompt, which are scored by a reward model to guide learning. In this setting, we propose $textbf{Multi-Preference Optimization (MPO)}$, a generalization of DPO that optimizes over entire sets of responses by extending the Bradley-Terry model to groupwise comparisons between chosen and rejected sets. To further enhance learning, MPO employs deviation-based weighting, which emphasizes outlier responses that deviate most from the mean reward, effectively inducing a self-paced curriculum. We theoretically prove that MPO reduces alignment bias at a rate of $mathcal{O}left(frac{1}{sqrt{n}}right)$ with respect to the number of responses per query. Empirically, MPO achieves state-of-the-art performance on the UltraFeedback benchmark and yields up to $sim 17.5%$ improvement over the state-of-the-art baseline in length-controlled win rate on AlpacaEval2, establishing a new baseline for preference-based alignment",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2412.04628",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Multimodal Fused Learning for Solving the Generalized Traveling Salesman Problem in Robotic Task Planning",
    "description": "arXiv:2506.16931v1 Announce Type: new Abstract: Effective and efficient task planning is essential for mobile robots, especially in applications like warehouse retrieval and environmental monitoring. These tasks often involve selecting one location from each of several target clusters, forming a Generalized Traveling Salesman Problem (GTSP) that remains challenging to solve both accurately and efficiently. To address this, we propose a Multimodal Fused Learning (MMFL) framework that leverages both graph and image-based representations to capture complementary aspects of the problem, and learns a policy capable of generating high-quality task planning schemes in real time. Specifically, we first introduce a coordinate-based image builder that transforms GTSP instances into spatially informative representations. We then design an adaptive resolution scaling strategy to enhance adaptability across different problem scales, and develop a multimodal fusion module with dedicated bottlenecks that enables effective integration of geometric and spatial features. Extensive experiments show that our MMFL approach significantly outperforms state-of-the-art methods across various GTSP instances while maintaining the computational efficiency required for real-time robotic applications. Physical robot tests further validate its practical effectiveness in real-world scenarios.",
    "summary": "arXiv:2506.16931v1 Announce Type: new Abstract: Effective and efficient task planning is essential for mobile robots, especially in applications like warehouse retrieval and environmental monitoring. These tasks often involve selecting one location from each of several target clusters, forming a Generalized Traveling Salesman Problem (GTSP) that remains challenging to solve both accurately and efficiently. To address this, we propose a Multimodal Fused Learning (MMFL) framework that leverages both graph and image-based representations to capture complementary aspects of the problem, and learns a policy capable of generating high-quality task planning schemes in real time. Specifically, we first introduce a coordinate-based image builder that transforms GTSP instances into spatially informative representations. We then design an adaptive resolution scaling strategy to enhance adaptability across different problem scales, and develop a multimodal fusion module with dedicated bottlenecks that enables effective integration of geometric and spatial features. Extensive experiments show that our MMFL approach significantly outperforms state-of-the-art methods across various GTSP instances while maintaining the computational efficiency required for real-time robotic applications. Physical robot tests further validate its practical effectiveness in real-world scenarios.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16931",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Nature Language Model: Deciphering the Language of Nature for Scientific Discovery",
    "description": "arXiv:2502.07527v3 Announce Type: replace Abstract: Foundation models have revolutionized natural language processing and artificial intelligence, significantly enhancing how machines comprehend and generate human languages. Inspired by the success of these foundation models, researchers have developed foundation models for individual scientific domains, including small molecules, materials, proteins, DNA, RNA and even cells. However, these models are typically trained in isolation, lacking the ability to integrate across different scientific domains. Recognizing that entities within these domains can all be represented as sequences, which together form the 'language of nature', we introduce Nature Language Model (NatureLM), a sequence-based science foundation model designed for scientific discovery. Pre-trained with data from multiple scientific domains, NatureLM offers a unified, versatile model that enables various applications including: (i) generating and optimizing small molecules, proteins, RNA, and materials using text instructions; (ii) cross-domain generation/design, such as protein-to-molecule and protein-to-RNA generation; and (iii) top performance across different domains, matching or surpassing state-of-the-art specialist models. NatureLM offers a promising generalist approach for various scientific tasks, including drug discovery (hit generation/optimization, ADMET optimization, synthesis), novel material design, and the development of therapeutic proteins or nucleotides. We have developed NatureLM models in different sizes (1 billion, 8 billion, and 46.7 billion parameters) and observed a clear improvement in performance as the model size increases.",
    "summary": "arXiv:2502.07527v3 Announce Type: replace Abstract: Foundation models have revolutionized natural language processing and artificial intelligence, significantly enhancing how machines comprehend and generate human languages. Inspired by the success of these foundation models, researchers have developed foundation models for individual scientific domains, including small molecules, materials, proteins, DNA, RNA and even cells. However, these models are typically trained in isolation, lacking the ability to integrate across different scientific domains. Recognizing that entities within these domains can all be represented as sequences, which together form the 'language of nature', we introduce Nature Language Model (NatureLM), a sequence-based science foundation model designed for scientific discovery. Pre-trained with data from multiple scientific domains, NatureLM offers a unified, versatile model that enables various applications including: (i) generating and optimizing small molecules, proteins, RNA, and materials using text instructions; (ii) cross-domain generation/design, such as protein-to-molecule and protein-to-RNA generation; and (iii) top performance across different domains, matching or surpassing state-of-the-art specialist models. NatureLM offers a promising generalist approach for various scientific tasks, including drug discovery (hit generation/optimization, ADMET optimization, synthesis), novel material design, and the development of therapeutic proteins or nucleotides. We have developed NatureLM models in different sizes (1 billion, 8 billion, and 46.7 billion parameters) and observed a clear improvement in performance as the model size increases.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2502.07527",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "NepaliGPT: A Generative Language Model for the Nepali Language",
    "description": "arXiv:2506.16399v1 Announce Type: cross Abstract: After the release of ChatGPT, Large Language Models (LLMs) have gained huge popularity in recent days and thousands of variants of LLMs have been released. However, there is no generative language model for the Nepali language, due to which other downstream tasks, including fine-tuning, have not been explored yet. To fill this research gap in the Nepali NLP space, this research proposes textit{NepaliGPT}, a generative large language model tailored specifically for the Nepali language. This research introduces an advanced corpus for the Nepali language collected from several sources, called the Devanagari Corpus. Likewise, the research introduces the first NepaliGPT benchmark dataset comprised of 4,296 question-answer pairs in the Nepali language. The proposed LLM NepaliGPT achieves the following metrics in text generation: Perplexity of 26.32245, ROUGE-1 score of 0.2604, causal coherence of 81.25%, and causal consistency of 85.41%.",
    "summary": "arXiv:2506.16399v1 Announce Type: cross Abstract: After the release of ChatGPT, Large Language Models (LLMs) have gained huge popularity in recent days and thousands of variants of LLMs have been released. However, there is no generative language model for the Nepali language, due to which other downstream tasks, including fine-tuning, have not been explored yet. To fill this research gap in the Nepali NLP space, this research proposes textit{NepaliGPT}, a generative large language model tailored specifically for the Nepali language. This research introduces an advanced corpus for the Nepali language collected from several sources, called the Devanagari Corpus. Likewise, the research introduces the first NepaliGPT benchmark dataset comprised of 4,296 question-answer pairs in the Nepali language. The proposed LLM NepaliGPT achieves the following metrics in text generation: Perplexity of 26.32245, ROUGE-1 score of 0.2604, causal coherence of 81.25%, and causal consistency of 85.41%.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16399",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Network Sparsity Unlocks the Scaling Potential of Deep Reinforcement Learning",
    "description": "arXiv:2506.17204v1 Announce Type: cross Abstract: Effectively scaling up deep reinforcement learning models has proven notoriously difficult due to network pathologies during training, motivating various targeted interventions such as periodic reset and architectural advances such as layer normalization. Instead of pursuing more complex modifications, we show that introducing static network sparsity alone can unlock further scaling potential beyond their dense counterparts with state-of-the-art architectures. This is achieved through simple one-shot random pruning, where a predetermined percentage of network weights are randomly removed once before training. Our analysis reveals that, in contrast to naively scaling up dense DRL networks, such sparse networks achieve both higher parameter efficiency for network expressivity and stronger resistance to optimization challenges like plasticity loss and gradient interference. We further extend our evaluation to visual and streaming RL scenarios, demonstrating the consistent benefits of network sparsity.",
    "summary": "arXiv:2506.17204v1 Announce Type: cross Abstract: Effectively scaling up deep reinforcement learning models has proven notoriously difficult due to network pathologies during training, motivating various targeted interventions such as periodic reset and architectural advances such as layer normalization. Instead of pursuing more complex modifications, we show that introducing static network sparsity alone can unlock further scaling potential beyond their dense counterparts with state-of-the-art architectures. This is achieved through simple one-shot random pruning, where a predetermined percentage of network weights are randomly removed once before training. Our analysis reveals that, in contrast to naively scaling up dense DRL networks, such sparse networks achieve both higher parameter efficiency for network expressivity and stronger resistance to optimization challenges like plasticity loss and gradient interference. We further extend our evaluation to visual and streaming RL scenarios, demonstrating the consistent benefits of network sparsity.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.17204",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "NeuronSeek: On Stability and Expressivity of Task-driven Neurons",
    "description": "arXiv:2506.15715v1 Announce Type: cross Abstract: Drawing inspiration from our human brain that designs different neurons for different tasks, recent advances in deep learning have explored modifying a network's neurons to develop so-called task-driven neurons. Prototyping task-driven neurons (referred to as NeuronSeek) employs symbolic regression (SR) to discover the optimal neuron formulation and construct a network from these optimized neurons. Along this direction, this work replaces symbolic regression with tensor decomposition (TD) to discover optimal neuronal formulations, offering enhanced stability and faster convergence. Furthermore, we establish theoretical guarantees that modifying the aggregation functions with common activation functions can empower a network with a fixed number of parameters to approximate any continuous function with an arbitrarily small error, providing a rigorous mathematical foundation for the NeuronSeek framework. Extensive empirical evaluations demonstrate that our NeuronSeek-TD framework not only achieves superior stability, but also is competitive relative to the state-of-the-art models across diverse benchmarks. The code is available at https://github.com/HanyuPei22/NeuronSeek.",
    "summary": "arXiv:2506.15715v1 Announce Type: cross Abstract: Drawing inspiration from our human brain that designs different neurons for different tasks, recent advances in deep learning have explored modifying a network's neurons to develop so-called task-driven neurons. Prototyping task-driven neurons (referred to as NeuronSeek) employs symbolic regression (SR) to discover the optimal neuron formulation and construct a network from these optimized neurons. Along this direction, this work replaces symbolic regression with tensor decomposition (TD) to discover optimal neuronal formulations, offering enhanced stability and faster convergence. Furthermore, we establish theoretical guarantees that modifying the aggregation functions with common activation functions can empower a network with a fixed number of parameters to approximate any continuous function with an arbitrarily small error, providing a rigorous mathematical foundation for the NeuronSeek framework. Extensive empirical evaluations demonstrate that our NeuronSeek-TD framework not only achieves superior stability, but also is competitive relative to the state-of-the-art models across diverse benchmarks. The code is available at https://github.com/HanyuPei22/NeuronSeek.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.15715",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Next-Token Prediction Should be Ambiguity-Sensitive: A Meta-Learning Perspective",
    "description": "arXiv:2506.16288v1 Announce Type: cross Abstract: The rapid adaptation ability of auto-regressive foundation models is often attributed to the diversity of their pre-training data. This is because, from a Bayesian standpoint, minimizing prediction error in such settings requires integrating over all plausible latent hypotheses consistent with observations. While this behavior is desirable in principle, it often proves too ambitious in practice: under high ambiguity, the number of plausible latent alternatives makes Bayes-optimal prediction computationally intractable. Cognitive science has long recognized this limitation, suggesting that under such conditions, heuristics or information-seeking strategies are preferable to exhaustive inference. Translating this insight to next-token prediction, we hypothesize that low- and high-ambiguity predictions pose different computational demands, making ambiguity-agnostic next-token prediction a detrimental inductive bias. To test this, we introduce MetaHMM, a synthetic sequence meta-learning benchmark with rich compositional structure and a tractable Bayesian oracle. We show that Transformers indeed struggle with high-ambiguity predictions across model sizes. Motivated by cognitive theories, we propose a method to convert pre-trained models into Monte Carlo predictors that decouple task inference from token prediction. Preliminary results show substantial gains in ambiguous contexts through improved capacity allocation and test-time scalable inference, though challenges remain.",
    "summary": "arXiv:2506.16288v1 Announce Type: cross Abstract: The rapid adaptation ability of auto-regressive foundation models is often attributed to the diversity of their pre-training data. This is because, from a Bayesian standpoint, minimizing prediction error in such settings requires integrating over all plausible latent hypotheses consistent with observations. While this behavior is desirable in principle, it often proves too ambitious in practice: under high ambiguity, the number of plausible latent alternatives makes Bayes-optimal prediction computationally intractable. Cognitive science has long recognized this limitation, suggesting that under such conditions, heuristics or information-seeking strategies are preferable to exhaustive inference. Translating this insight to next-token prediction, we hypothesize that low- and high-ambiguity predictions pose different computational demands, making ambiguity-agnostic next-token prediction a detrimental inductive bias. To test this, we introduce MetaHMM, a synthetic sequence meta-learning benchmark with rich compositional structure and a tractable Bayesian oracle. We show that Transformers indeed struggle with high-ambiguity predictions across model sizes. Motivated by cognitive theories, we propose a method to convert pre-trained models into Monte Carlo predictors that decouple task inference from token prediction. Preliminary results show substantial gains in ambiguous contexts through improved capacity allocation and test-time scalable inference, though challenges remain.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16288",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "No Free Lunch: Rethinking Internal Feedback for LLM Reasoning",
    "description": "arXiv:2506.17219v1 Announce Type: cross Abstract: Reinforcement learning has emerged as a powerful paradigm for post-training large language models (LLMs) to improve reasoning. Approaches like Reinforcement Learning from Human Feedback (RLHF) and Reinforcement Learning with Verifiable Rewards (RLVR) have shown strong results, but they require extensive external supervision. We investigate an alternative class of methods, Reinforcement Learning from Internal Feedback (RLIF), which relies solely on intrinsic model-derived signals instead of external rewards. In particular, we leverage unsupervised reward proxies such as token-level entropy, trajectory-level entropy, and self-certainty. Our theoretical analysis shows these internal objectives are partially equivalent, and we empirically evaluate various RLIF strategies on challenging math reasoning benchmarks. Experimental results demonstrate that RLIF can boost the reasoning performance of base LLMs at the beginning phase of the training, matching or surpassing RLVR techniques on these tasks. However, when training progresses, performance degrades even below the model before training. Moreover, we find that RLIF yields little improvement for instruction-tuned models, indicating diminishing returns of intrinsic feedback once an LLM is already instruction-tuned. We further analyze this limitation by mixing model weights and explain the reason of RLIF's training behaviors, providing practical guidelines for integrating internal feedback signals into LLM training. We hope our analysis of internal feedback will inform more principled and effective strategies for LLM post-training.",
    "summary": "arXiv:2506.17219v1 Announce Type: cross Abstract: Reinforcement learning has emerged as a powerful paradigm for post-training large language models (LLMs) to improve reasoning. Approaches like Reinforcement Learning from Human Feedback (RLHF) and Reinforcement Learning with Verifiable Rewards (RLVR) have shown strong results, but they require extensive external supervision. We investigate an alternative class of methods, Reinforcement Learning from Internal Feedback (RLIF), which relies solely on intrinsic model-derived signals instead of external rewards. In particular, we leverage unsupervised reward proxies such as token-level entropy, trajectory-level entropy, and self-certainty. Our theoretical analysis shows these internal objectives are partially equivalent, and we empirically evaluate various RLIF strategies on challenging math reasoning benchmarks. Experimental results demonstrate that RLIF can boost the reasoning performance of base LLMs at the beginning phase of the training, matching or surpassing RLVR techniques on these tasks. However, when training progresses, performance degrades even below the model before training. Moreover, we find that RLIF yields little improvement for instruction-tuned models, indicating diminishing returns of intrinsic feedback once an LLM is already instruction-tuned. We further analyze this limitation by mixing model weights and explain the reason of RLIF's training behaviors, providing practical guidelines for integrating internal feedback signals into LLM training. We hope our analysis of internal feedback will inform more principled and effective strategies for LLM post-training.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.17219",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "NTT Comも参入　NTTグループはAIエージェント事業に総力を結集できるか？",
    "description": "“百花繚乱”のAIエージェント市場において、NTT Comが業務、業界別のソリューションを打ち出した。NTTデータも既にAIエージェント市場に参入しているが、NTTグループとしてこの分野に総力を結集する態勢になり得るのだろうか。",
    "summary": "“百花繚乱”のAIエージェント市場において、NTT Comが業務、業界別のソリューションを打ち出した。NTTデータも既にAIエージェント市場に参入しているが、NTTグループとしてこの分野に総力を結集する態勢になり得るのだろうか。",
    "pubDate": "Mon, 23 Jun 2025 16:00:00 +0900",
    "source": "ITmedia AI",
    "url": "https://www.itmedia.co.jp/enterprise/articles/2506/23/news064.html",
    "thumbnail": "https://image.itmedia.co.jp/enterprise/articles/2506/23/cover_news064.jpg"
  },
  {
    "title": "OAgents: An Empirical Study of Building Effective Agents",
    "description": "arXiv:2506.15741v1 Announce Type: new Abstract: Recently, Agentic AI has become an increasingly popular research field. However, we argue that current agent research practices lack standardization and scientific rigor, making it hard to conduct fair comparisons among methods. As a result, it is still unclear how different design choices in agent frameworks affect effectiveness, and measuring their progress remains challenging. In this work, we conduct a systematic empirical study on GAIA benchmark and BrowseComp to examine the impact of popular design choices in key agent components in a fair and rigorous manner. We find that the lack of a standard evaluation protocol makes previous works, even open-sourced ones, non-reproducible, with significant variance between random runs. Therefore, we introduce a more robust evaluation protocol to stabilize comparisons. Our study reveals which components and designs are crucial for effective agents, while others are redundant, despite seeming logical. Based on our findings, we build and open-source OAgents, a new foundation agent framework that achieves state-of-the-art performance among open-source projects. OAgents offers a modular design for various agent components, promoting future research in Agentic AI.",
    "summary": "arXiv:2506.15741v1 Announce Type: new Abstract: Recently, Agentic AI has become an increasingly popular research field. However, we argue that current agent research practices lack standardization and scientific rigor, making it hard to conduct fair comparisons among methods. As a result, it is still unclear how different design choices in agent frameworks affect effectiveness, and measuring their progress remains challenging. In this work, we conduct a systematic empirical study on GAIA benchmark and BrowseComp to examine the impact of popular design choices in key agent components in a fair and rigorous manner. We find that the lack of a standard evaluation protocol makes previous works, even open-sourced ones, non-reproducible, with significant variance between random runs. Therefore, we introduce a more robust evaluation protocol to stabilize comparisons. Our study reveals which components and designs are crucial for effective agents, while others are redundant, despite seeming logical. Based on our findings, we build and open-source OAgents, a new foundation agent framework that achieves state-of-the-art performance among open-source projects. OAgents offers a modular design for various agent components, promoting future research in Agentic AI.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.15741",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Off-Policy Actor-Critic for Adversarial Observation Robustness: Virtual Alternative Training via Symmetric Policy Evaluation",
    "description": "arXiv:2506.16753v1 Announce Type: cross Abstract: Recently, robust reinforcement learning (RL) methods designed to handle adversarial input observations have received significant attention, motivated by RL's inherent vulnerabilities. While existing approaches have demonstrated reasonable success, addressing worst-case scenarios over long time horizons requires both minimizing the agent's cumulative rewards for adversaries and training agents to counteract them through alternating learning. However, this process introduces mutual dependencies between the agent and the adversary, making interactions with the environment inefficient and hindering the development of off-policy methods. In this work, we propose a novel off-policy method that eliminates the need for additional environmental interactions by reformulating adversarial learning as a soft-constrained optimization problem. Our approach is theoretically supported by the symmetric property of policy evaluation between the agent and the adversary. The implementation is available at https://github.com/nakanakakosuke/VALT_SAC.",
    "summary": "arXiv:2506.16753v1 Announce Type: cross Abstract: Recently, robust reinforcement learning (RL) methods designed to handle adversarial input observations have received significant attention, motivated by RL's inherent vulnerabilities. While existing approaches have demonstrated reasonable success, addressing worst-case scenarios over long time horizons requires both minimizing the agent's cumulative rewards for adversaries and training agents to counteract them through alternating learning. However, this process introduces mutual dependencies between the agent and the adversary, making interactions with the environment inefficient and hindering the development of off-policy methods. In this work, we propose a novel off-policy method that eliminates the need for additional environmental interactions by reformulating adversarial learning as a soft-constrained optimization problem. Our approach is theoretically supported by the symmetric property of policy evaluation between the agent and the adversary. The implementation is available at https://github.com/nakanakakosuke/VALT_SAC.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16753",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "On Path to Multimodal Historical Reasoning: HistBench and HistAgent",
    "description": "arXiv:2505.20246v3 Announce Type: replace Abstract: Recent advances in large language models (LLMs) have led to remarkable progress across domains, yet their capabilities in the humanities, particularly history, remain underexplored. Historical reasoning poses unique challenges for AI, involving multimodal source interpretation, temporal inference, and cross-linguistic analysis. While general-purpose agents perform well on many existing benchmarks, they lack the domain-specific expertise required to engage with historical materials and questions. To address this gap, we introduce HistBench, a new benchmark of 414 high-quality questions designed to evaluate AI's capacity for historical reasoning and authored by more than 40 expert contributors. The tasks span a wide range of historical problems-from factual retrieval based on primary sources to interpretive analysis of manuscripts and images, to interdisciplinary challenges involving archaeology, linguistics, or cultural history. Furthermore, the benchmark dataset spans 29 ancient and modern languages and covers a wide range of historical periods and world regions. Finding the poor performance of LLMs and other agents on HistBench, we further present HistAgent, a history-specific agent equipped with carefully designed tools for OCR, translation, archival search, and image understanding in History. On HistBench, HistAgent based on GPT-4o achieves an accuracy of 27.54% pass@1 and 36.47% pass@2, significantly outperforming LLMs with online search and generalist agents, including GPT-4o (18.60%), DeepSeek-R1(14.49%) and Open Deep Research-smolagents(20.29% pass@1 and 25.12% pass@2). These results highlight the limitations of existing LLMs and generalist agents and demonstrate the advantages of HistAgent for historical reasoning.",
    "summary": "arXiv:2505.20246v3 Announce Type: replace Abstract: Recent advances in large language models (LLMs) have led to remarkable progress across domains, yet their capabilities in the humanities, particularly history, remain underexplored. Historical reasoning poses unique challenges for AI, involving multimodal source interpretation, temporal inference, and cross-linguistic analysis. While general-purpose agents perform well on many existing benchmarks, they lack the domain-specific expertise required to engage with historical materials and questions. To address this gap, we introduce HistBench, a new benchmark of 414 high-quality questions designed to evaluate AI's capacity for historical reasoning and authored by more than 40 expert contributors. The tasks span a wide range of historical problems-from factual retrieval based on primary sources to interpretive analysis of manuscripts and images, to interdisciplinary challenges involving archaeology, linguistics, or cultural history. Furthermore, the benchmark dataset spans 29 ancient and modern languages and covers a wide range of historical periods and world regions. Finding the poor performance of LLMs and other agents on HistBench, we further present HistAgent, a history-specific agent equipped with carefully designed tools for OCR, translation, archival search, and image understanding in History. On HistBench, HistAgent based on GPT-4o achieves an accuracy of 27.54% pass@1 and 36.47% pass@2, significantly outperforming LLMs with online search and generalist agents, including GPT-4o (18.60%), DeepSeek-R1(14.49%) and Open Deep Research-smolagents(20.29% pass@1 and 25.12% pass@2). These results highlight the limitations of existing LLMs and generalist agents and demonstrate the advantages of HistAgent for historical reasoning.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2505.20246",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "On the Limits of Language Generation: Trade-Offs Between Hallucination and Mode Collapse",
    "description": "arXiv:2411.09642v2 Announce Type: replace-cross Abstract: Specifying all desirable properties of a language model is challenging, but certain requirements seem essential. Given samples from an unknown language, the trained model should produce valid strings not seen in training and be expressive enough to capture the language's full richness. Otherwise, outputting invalid strings constitutes 'hallucination,' and failing to capture the full range leads to 'mode collapse.' We ask if a language model can meet both requirements. We investigate this within a statistical language generation setting building on Gold and Angluin. Here, the model receives random samples from a distribution over an unknown language K, which belongs to a possibly infinite collection of languages. The goal is to generate unseen strings from K. We say the model generates from K with consistency and breadth if, as training size increases, its output converges to all unseen strings in K. Kleinberg and Mullainathan [KM24] asked if consistency and breadth in language generation are possible. We answer this negatively: for a large class of language models, including next-token prediction models, this is impossible for most collections of candidate languages. This contrasts with [KM24]'s result, showing consistent generation without breadth is possible for any countable collection of languages. Our finding highlights that generation with breadth fundamentally differs from generation without breadth. As a byproduct, we establish near-tight bounds on the number of samples needed for generation with or without breadth. Finally, our results offer hope: consistent generation with breadth is achievable for any countable collection of languages when negative examples (strings outside K) are available alongside positive ones. This suggests that post-training feedback, which encodes negative examples, can be crucial in reducing hallucinations while limiting mode collapse.",
    "summary": "arXiv:2411.09642v2 Announce Type: replace-cross Abstract: Specifying all desirable properties of a language model is challenging, but certain requirements seem essential. Given samples from an unknown language, the trained model should produce valid strings not seen in training and be expressive enough to capture the language's full richness. Otherwise, outputting invalid strings constitutes 'hallucination,' and failing to capture the full range leads to 'mode collapse.' We ask if a language model can meet both requirements. We investigate this within a statistical language generation setting building on Gold and Angluin. Here, the model receives random samples from a distribution over an unknown language K, which belongs to a possibly infinite collection of languages. The goal is to generate unseen strings from K. We say the model generates from K with consistency and breadth if, as training size increases, its output converges to all unseen strings in K. Kleinberg and Mullainathan [KM24] asked if consistency and breadth in language generation are possible. We answer this negatively: for a large class of language models, including next-token prediction models, this is impossible for most collections of candidate languages. This contrasts with [KM24]'s result, showing consistent generation without breadth is possible for any countable collection of languages. Our finding highlights that generation with breadth fundamentally differs from generation without breadth. As a byproduct, we establish near-tight bounds on the number of samples needed for generation with or without breadth. Finally, our results offer hope: consistent generation with breadth is achievable for any countable collection of languages when negative examples (strings outside K) are available alongside positive ones. This suggests that post-training feedback, which encodes negative examples, can be crucial in reducing hallucinations while limiting mode collapse.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2411.09642",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "On Training-Test (Mis)alignment in Unsupervised Combinatorial Optimization: Observation, Empirical Exploration, and Analysis",
    "description": "arXiv:2506.16732v1 Announce Type: cross Abstract: In unsupervised combinatorial optimization (UCO), during training, one aims to have continuous decisions that are promising in a probabilistic sense for each training instance, which enables end-to-end training on initially discrete and non-differentiable problems. At the test time, for each test instance, starting from continuous decisions, derandomization is typically applied to obtain the final deterministic decisions. Researchers have developed more and more powerful test-time derandomization schemes to enhance the empirical performance and the theoretical guarantee of UCO methods. However, we notice a misalignment between training and testing in the existing UCO methods. Consequently, lower training losses do not necessarily entail better post-derandomization performance, even for the training instances without any data distribution shift. Empirically, we indeed observe such undesirable cases. We explore a preliminary idea to better align training and testing in UCO by including a differentiable version of derandomization into training. Our empirical exploration shows that such an idea indeed improves training-test alignment, but also introduces nontrivial challenges into training.",
    "summary": "arXiv:2506.16732v1 Announce Type: cross Abstract: In unsupervised combinatorial optimization (UCO), during training, one aims to have continuous decisions that are promising in a probabilistic sense for each training instance, which enables end-to-end training on initially discrete and non-differentiable problems. At the test time, for each test instance, starting from continuous decisions, derandomization is typically applied to obtain the final deterministic decisions. Researchers have developed more and more powerful test-time derandomization schemes to enhance the empirical performance and the theoretical guarantee of UCO methods. However, we notice a misalignment between training and testing in the existing UCO methods. Consequently, lower training losses do not necessarily entail better post-derandomization performance, even for the training instances without any data distribution shift. Empirically, we indeed observe such undesirable cases. We explore a preliminary idea to better align training and testing in UCO by including a differentiable version of derandomization into training. Our empirical exploration shows that such an idea indeed improves training-test alignment, but also introduces nontrivial challenges into training.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16732",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "On using AI for EEG-based BCI applications: problems, current challenges and future trends",
    "description": "arXiv:2506.16168v1 Announce Type: cross Abstract: Imagine unlocking the power of the mind to communicate, create, and even interact with the world around us. Recent breakthroughs in Artificial Intelligence (AI), especially in how machines 'see' and 'understand' language, are now fueling exciting progress in decoding brain signals from scalp electroencephalography (EEG). Prima facie, this opens the door to revolutionary brain-computer interfaces (BCIs) designed for real life, moving beyond traditional uses to envision Brain-to-Speech, Brain-to-Image, and even a Brain-to-Internet of Things (BCIoT). However, the journey is not as straightforward as it was for Computer Vision (CV) and Natural Language Processing (NLP). Applying AI to real-world EEG-based BCIs, particularly in building powerful foundational models, presents unique and intricate hurdles that could affect their reliability. Here, we unfold a guided exploration of this dynamic and rapidly evolving research area. Rather than barely outlining a map of current endeavors and results, the goal is to provide a principled navigation of this hot and cutting-edge research landscape. We consider the basic paradigms that emerge from a causal perspective and the attendant challenges presented to AI-based models. Looking ahead, we then discuss promising research avenues that could overcome today's technological, methodological, and ethical limitations. Our aim is to lay out a clear roadmap for creating truly practical and effective EEG-based BCI solutions that can thrive in everyday environments.",
    "summary": "arXiv:2506.16168v1 Announce Type: cross Abstract: Imagine unlocking the power of the mind to communicate, create, and even interact with the world around us. Recent breakthroughs in Artificial Intelligence (AI), especially in how machines 'see' and 'understand' language, are now fueling exciting progress in decoding brain signals from scalp electroencephalography (EEG). Prima facie, this opens the door to revolutionary brain-computer interfaces (BCIs) designed for real life, moving beyond traditional uses to envision Brain-to-Speech, Brain-to-Image, and even a Brain-to-Internet of Things (BCIoT). However, the journey is not as straightforward as it was for Computer Vision (CV) and Natural Language Processing (NLP). Applying AI to real-world EEG-based BCIs, particularly in building powerful foundational models, presents unique and intricate hurdles that could affect their reliability. Here, we unfold a guided exploration of this dynamic and rapidly evolving research area. Rather than barely outlining a map of current endeavors and results, the goal is to provide a principled navigation of this hot and cutting-edge research landscape. We consider the basic paradigms that emerge from a causal perspective and the attendant challenges presented to AI-based models. Looking ahead, we then discuss promising research avenues that could overcome today's technological, methodological, and ethical limitations. Our aim is to lay out a clear roadmap for creating truly practical and effective EEG-based BCI solutions that can thrive in everyday environments.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16168",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "One Sample is Enough to Make Conformal Prediction Robust",
    "description": "arXiv:2506.16553v1 Announce Type: cross Abstract: Given any model, conformal prediction (CP) returns prediction sets guaranteed to include the true label with high adjustable probability. Robust CP (RCP) extends this to inputs with worst-case noise. A well-established approach is to use randomized smoothing for RCP since it is applicable to any black-box model and provides smaller sets compared to deterministic methods. However, current smoothing-based RCP requires many model forward passes per each input which is computationally expensive. We show that conformal prediction attains some robustness even with a forward pass on a single randomly perturbed input. Using any binary certificate we propose a single sample robust CP (RCP1). Our approach returns robust sets with smaller average set size compared to SOTA methods which use many (e.g. around 100) passes per input. Our key insight is to certify the conformal prediction procedure itself rather than individual scores. Our approach is agnostic to the setup (classification and regression). We further extend our approach to smoothing-based robust conformal risk control.",
    "summary": "arXiv:2506.16553v1 Announce Type: cross Abstract: Given any model, conformal prediction (CP) returns prediction sets guaranteed to include the true label with high adjustable probability. Robust CP (RCP) extends this to inputs with worst-case noise. A well-established approach is to use randomized smoothing for RCP since it is applicable to any black-box model and provides smaller sets compared to deterministic methods. However, current smoothing-based RCP requires many model forward passes per each input which is computationally expensive. We show that conformal prediction attains some robustness even with a forward pass on a single randomly perturbed input. Using any binary certificate we propose a single sample robust CP (RCP1). Our approach returns robust sets with smaller average set size compared to SOTA methods which use many (e.g. around 100) passes per input. Our key insight is to certify the conformal prediction procedure itself rather than individual scores. Our approach is agnostic to the setup (classification and regression). We further extend our approach to smoothing-based robust conformal risk control.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16553",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "One-Step Diffusion for Detail-Rich and Temporally Consistent Video Super-Resolution",
    "description": "arXiv:2506.15591v2 Announce Type: replace-cross Abstract: It is a challenging problem to reproduce rich spatial details while maintaining temporal consistency in real-world video super-resolution (Real-VSR), especially when we leverage pre-trained generative models such as stable diffusion (SD) for realistic details synthesis. Existing SD-based Real-VSR methods often compromise spatial details for temporal coherence, resulting in suboptimal visual quality. We argue that the key lies in how to effectively extract the degradation-robust temporal consistency priors from the low-quality (LQ) input video and enhance the video details while maintaining the extracted consistency priors. To achieve this, we propose a Dual LoRA Learning (DLoRAL) paradigm to train an effective SD-based one-step diffusion model, achieving realistic frame details and temporal consistency simultaneously. Specifically, we introduce a Cross-Frame Retrieval (CFR) module to aggregate complementary information across frames, and train a Consistency-LoRA (C-LoRA) to learn robust temporal representations from degraded inputs. After consistency learning, we fix the CFR and C-LoRA modules and train a Detail-LoRA (D-LoRA) to enhance spatial details while aligning with the temporal space defined by C-LoRA to keep temporal coherence. The two phases alternate iteratively for optimization, collaboratively delivering consistent and detail-rich outputs. During inference, the two LoRA branches are merged into the SD model, allowing efficient and high-quality video restoration in a single diffusion step. Experiments show that DLoRAL achieves strong performance in both accuracy and speed. Code and models are available at https://github.com/yjsunnn/DLoRAL.",
    "summary": "arXiv:2506.15591v2 Announce Type: replace-cross Abstract: It is a challenging problem to reproduce rich spatial details while maintaining temporal consistency in real-world video super-resolution (Real-VSR), especially when we leverage pre-trained generative models such as stable diffusion (SD) for realistic details synthesis. Existing SD-based Real-VSR methods often compromise spatial details for temporal coherence, resulting in suboptimal visual quality. We argue that the key lies in how to effectively extract the degradation-robust temporal consistency priors from the low-quality (LQ) input video and enhance the video details while maintaining the extracted consistency priors. To achieve this, we propose a Dual LoRA Learning (DLoRAL) paradigm to train an effective SD-based one-step diffusion model, achieving realistic frame details and temporal consistency simultaneously. Specifically, we introduce a Cross-Frame Retrieval (CFR) module to aggregate complementary information across frames, and train a Consistency-LoRA (C-LoRA) to learn robust temporal representations from degraded inputs. After consistency learning, we fix the CFR and C-LoRA modules and train a Detail-LoRA (D-LoRA) to enhance spatial details while aligning with the temporal space defined by C-LoRA to keep temporal coherence. The two phases alternate iteratively for optimization, collaboratively delivering consistent and detail-rich outputs. During inference, the two LoRA branches are merged into the SD model, allowing efficient and high-quality video restoration in a single diffusion step. Experiments show that DLoRAL achieves strong performance in both accuracy and speed. Code and models are available at https://github.com/yjsunnn/DLoRAL.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.15591",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Open-Set Graph Anomaly Detection via Normal Structure Regularisation",
    "description": "arXiv:2311.06835v5 Announce Type: replace-cross Abstract: This paper considers an important Graph Anomaly Detection (GAD) task, namely open-set GAD, which aims to train a detection model using a small number of normal and anomaly nodes (referred to as seen anomalies) to detect both seen anomalies and unseen anomalies (i.e., anomalies that cannot be illustrated the training anomalies). Those labelled training data provide crucial prior knowledge about abnormalities for GAD models, enabling substantially reduced detection errors. However, current supervised GAD methods tend to over-emphasise fitting the seen anomalies, leading to many errors of detecting the unseen anomalies as normal nodes. Further, existing open-set AD models were introduced to handle Euclidean data, failing to effectively capture discriminative features from graph structure and node attributes for GAD. In this work, we propose a novel open-set GAD approach, namely normal structure regularisation (NSReg), to achieve generalised detection ability to unseen anomalies, while maintaining its effectiveness on detecting seen anomalies. The key idea in NSReg is to introduce a regularisation term that enforces the learning of compact, semantically-rich representations of normal nodes based on their structural relations to other nodes. When being optimised with supervised anomaly detection losses, the regularisation term helps incorporate strong normality into the modelling, and thus, it effectively avoids over-fitting the seen anomalies and learns a better normality decision boundary, largely reducing the false negatives of detecting unseen anomalies as normal. Extensive empirical results on seven real-world datasets show that NSReg significantly outperforms state-of-the-art competing methods by at least 14% AUC-ROC on the unseen anomaly classes and by 10% AUC-ROC on all anomaly classes.",
    "summary": "arXiv:2311.06835v5 Announce Type: replace-cross Abstract: This paper considers an important Graph Anomaly Detection (GAD) task, namely open-set GAD, which aims to train a detection model using a small number of normal and anomaly nodes (referred to as seen anomalies) to detect both seen anomalies and unseen anomalies (i.e., anomalies that cannot be illustrated the training anomalies). Those labelled training data provide crucial prior knowledge about abnormalities for GAD models, enabling substantially reduced detection errors. However, current supervised GAD methods tend to over-emphasise fitting the seen anomalies, leading to many errors of detecting the unseen anomalies as normal nodes. Further, existing open-set AD models were introduced to handle Euclidean data, failing to effectively capture discriminative features from graph structure and node attributes for GAD. In this work, we propose a novel open-set GAD approach, namely normal structure regularisation (NSReg), to achieve generalised detection ability to unseen anomalies, while maintaining its effectiveness on detecting seen anomalies. The key idea in NSReg is to introduce a regularisation term that enforces the learning of compact, semantically-rich representations of normal nodes based on their structural relations to other nodes. When being optimised with supervised anomaly detection losses, the regularisation term helps incorporate strong normality into the modelling, and thus, it effectively avoids over-fitting the seen anomalies and learns a better normality decision boundary, largely reducing the false negatives of detecting unseen anomalies as normal. Extensive empirical results on seven real-world datasets show that NSReg significantly outperforms state-of-the-art competing methods by at least 14% AUC-ROC on the unseen anomaly classes and by 10% AUC-ROC on all anomaly classes.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2311.06835",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Optimizing MoE Routers: Design, Implementation, and Evaluation in Transformer Models",
    "description": "arXiv:2506.16419v1 Announce Type: cross Abstract: Mixture of Experts (MoE) architectures increase large language model scalability, yet their performance depends on the router module that moves tokens to specialized experts. Bad routing can load imbalance and reduced accuracy. This project designed and implemented different router architectures within Transformer models to fix these limitations. We experimented with six distinct router variants Linear, Attention, Multi-Layer Perceptron (MLP), Hybrid, Hash, and our new MLP-Hadamard. We characterized these routers using BERT and the Qwen1.5-MoE model, looking at parameter efficiency, inference latency, routing entropy, and expert utilization patterns. Our evaluations showed distinct trade-offs: Linear routers offer speed, while MLP and Attention routers provide greater expressiveness. The MLP-Hadamard router shows a unique capability for structured, sparse routing. We successfully replaced and fine-tuned custom routers within the complex, quantized Qwen1.5-MoE model. This work provides a comparative analysis of MoE router designs and offers insights into optimizing their performance for efficient and effective large-scale model deployment.",
    "summary": "arXiv:2506.16419v1 Announce Type: cross Abstract: Mixture of Experts (MoE) architectures increase large language model scalability, yet their performance depends on the router module that moves tokens to specialized experts. Bad routing can load imbalance and reduced accuracy. This project designed and implemented different router architectures within Transformer models to fix these limitations. We experimented with six distinct router variants Linear, Attention, Multi-Layer Perceptron (MLP), Hybrid, Hash, and our new MLP-Hadamard. We characterized these routers using BERT and the Qwen1.5-MoE model, looking at parameter efficiency, inference latency, routing entropy, and expert utilization patterns. Our evaluations showed distinct trade-offs: Linear routers offer speed, while MLP and Attention routers provide greater expressiveness. The MLP-Hadamard router shows a unique capability for structured, sparse routing. We successfully replaced and fine-tuned custom routers within the complex, quantized Qwen1.5-MoE model. This work provides a comparative analysis of MoE router designs and offers insights into optimizing their performance for efficient and effective large-scale model deployment.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16419",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Optimizing Sensory Neurons: Nonlinear Attention Mechanisms for Accelerated Convergence in Permutation-Invariant Neural Networks for Reinforcement Learning",
    "description": "arXiv:2506.00691v3 Announce Type: replace-cross Abstract: Training reinforcement learning (RL) agents often requires significant computational resources and prolonged training durations. To address this challenge, we build upon prior work that introduced a neural architecture with permutation-invariant sensory processing. We propose a modified attention mechanism that applies a non-linear transformation to the key vectors (K), producing enriched representations (K') through a custom mapping function. This Nonlinear Attention (NLA) mechanism enhances the representational capacity of the attention layer, enabling the agent to learn more expressive feature interactions. As a result, our model achieves significantly faster convergence and improved training efficiency, while maintaining performance on par with the baseline. These results highlight the potential of nonlinear attention mechanisms to accelerate reinforcement learning without sacrificing effectiveness.",
    "summary": "arXiv:2506.00691v3 Announce Type: replace-cross Abstract: Training reinforcement learning (RL) agents often requires significant computational resources and prolonged training durations. To address this challenge, we build upon prior work that introduced a neural architecture with permutation-invariant sensory processing. We propose a modified attention mechanism that applies a non-linear transformation to the key vectors (K), producing enriched representations (K') through a custom mapping function. This Nonlinear Attention (NLA) mechanism enhances the representational capacity of the attention layer, enabling the agent to learn more expressive feature interactions. As a result, our model achieves significantly faster convergence and improved training efficiency, while maintaining performance on par with the baseline. These results highlight the potential of nonlinear attention mechanisms to accelerate reinforcement learning without sacrificing effectiveness.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.00691",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "OSWorld-Human: Benchmarking the Efficiency of Computer-Use Agents",
    "description": "arXiv:2506.16042v1 Announce Type: new Abstract: Generative AI is being leveraged to solve a variety of computer-use tasks involving desktop applications. State-of-the-art systems have focused solely on improving accuracy on leading benchmarks. However, these systems are practically unusable due to extremely high end-to-end latency (e.g., tens of minutes) for tasks that typically take humans just a few minutes to complete. To understand the cause behind this and to guide future developments of computer agents, we conduct the first study on the temporal performance of computer-use agents on OSWorld, the flagship benchmark in computer-use AI. We find that large model calls for planning and reflection account for the majority of the overall latency, and as an agent uses more steps to complete a task, each successive step can take 3x longer than steps at the beginning of a task. We then construct OSWorld-Human, a manually annotated version of the original OSWorld dataset that contains a human-determined trajectory for each task. We evaluate 16 agents on their efficiency using OSWorld-Human and found that even the highest-scoring agents on OSWorld take 1.4-2.7x more steps than necessary.",
    "summary": "arXiv:2506.16042v1 Announce Type: new Abstract: Generative AI is being leveraged to solve a variety of computer-use tasks involving desktop applications. State-of-the-art systems have focused solely on improving accuracy on leading benchmarks. However, these systems are practically unusable due to extremely high end-to-end latency (e.g., tens of minutes) for tasks that typically take humans just a few minutes to complete. To understand the cause behind this and to guide future developments of computer agents, we conduct the first study on the temporal performance of computer-use agents on OSWorld, the flagship benchmark in computer-use AI. We find that large model calls for planning and reflection account for the majority of the overall latency, and as an agent uses more steps to complete a task, each successive step can take 3x longer than steps at the beginning of a task. We then construct OSWorld-Human, a manually annotated version of the original OSWorld dataset that contains a human-determined trajectory for each task. We evaluate 16 agents on their efficiency using OSWorld-Human and found that even the highest-scoring agents on OSWorld take 1.4-2.7x more steps than necessary.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16042",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "ParkFormer: A Transformer-Based Parking Policy with Goal Embedding and Pedestrian-Aware Control",
    "description": "arXiv:2506.16856v1 Announce Type: cross Abstract: Autonomous parking plays a vital role in intelligent vehicle systems, particularly in constrained urban environments where high-precision control is required. While traditional rule-based parking systems struggle with environmental uncertainties and lack adaptability in crowded or dynamic scenes, human drivers demonstrate the ability to park intuitively without explicit modeling. Inspired by this observation, we propose a Transformer-based end-to-end framework for autonomous parking that learns from expert demonstrations. The network takes as input surround-view camera images, goal-point representations, ego vehicle motion, and pedestrian trajectories. It outputs discrete control sequences including throttle, braking, steering, and gear selection. A novel cross-attention module integrates BEV features with target points, and a GRU-based pedestrian predictor enhances safety by modeling dynamic obstacles. We validate our method on the CARLA 0.9.14 simulator in both vertical and parallel parking scenarios. Experiments show our model achieves a high success rate of 96.57%, with average positional and orientation errors of 0.21 meters and 0.41 degrees, respectively. The ablation studies further demonstrate the effectiveness of key modules such as pedestrian prediction and goal-point attention fusion. The code and dataset will be released at: https://github.com/little-snail-f/ParkFormer.",
    "summary": "arXiv:2506.16856v1 Announce Type: cross Abstract: Autonomous parking plays a vital role in intelligent vehicle systems, particularly in constrained urban environments where high-precision control is required. While traditional rule-based parking systems struggle with environmental uncertainties and lack adaptability in crowded or dynamic scenes, human drivers demonstrate the ability to park intuitively without explicit modeling. Inspired by this observation, we propose a Transformer-based end-to-end framework for autonomous parking that learns from expert demonstrations. The network takes as input surround-view camera images, goal-point representations, ego vehicle motion, and pedestrian trajectories. It outputs discrete control sequences including throttle, braking, steering, and gear selection. A novel cross-attention module integrates BEV features with target points, and a GRU-based pedestrian predictor enhances safety by modeling dynamic obstacles. We validate our method on the CARLA 0.9.14 simulator in both vertical and parallel parking scenarios. Experiments show our model achieves a high success rate of 96.57%, with average positional and orientation errors of 0.21 meters and 0.41 degrees, respectively. The ablation studies further demonstrate the effectiveness of key modules such as pedestrian prediction and goal-point attention fusion. The code and dataset will be released at: https://github.com/little-snail-f/ParkFormer.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16856",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Part$^{2}$GS: Part-aware Modeling of Articulated Objects using 3D Gaussian Splatting",
    "description": "arXiv:2506.17212v1 Announce Type: cross Abstract: Articulated objects are common in the real world, yet modeling their structure and motion remains a challenging task for 3D reconstruction methods. In this work, we introduce Part$^{2}$GS, a novel framework for modeling articulated digital twins of multi-part objects with high-fidelity geometry and physically consistent articulation. Part$^{2}$GS leverages a part-aware 3D Gaussian representation that encodes articulated components with learnable attributes, enabling structured, disentangled transformations that preserve high-fidelity geometry. To ensure physically consistent motion, we propose a motion-aware canonical representation guided by physics-based constraints, including contact enforcement, velocity consistency, and vector-field alignment. Furthermore, we introduce a field of repel points to prevent part collisions and maintain stable articulation paths, significantly improving motion coherence over baselines. Extensive evaluations on both synthetic and real-world datasets show that Part$^{2}$GS consistently outperforms state-of-the-art methods by up to 10$times$ in Chamfer Distance for movable parts.",
    "summary": "arXiv:2506.17212v1 Announce Type: cross Abstract: Articulated objects are common in the real world, yet modeling their structure and motion remains a challenging task for 3D reconstruction methods. In this work, we introduce Part$^{2}$GS, a novel framework for modeling articulated digital twins of multi-part objects with high-fidelity geometry and physically consistent articulation. Part$^{2}$GS leverages a part-aware 3D Gaussian representation that encodes articulated components with learnable attributes, enabling structured, disentangled transformations that preserve high-fidelity geometry. To ensure physically consistent motion, we propose a motion-aware canonical representation guided by physics-based constraints, including contact enforcement, velocity consistency, and vector-field alignment. Furthermore, we introduce a field of repel points to prevent part collisions and maintain stable articulation paths, significantly improving motion coherence over baselines. Extensive evaluations on both synthetic and real-world datasets show that Part$^{2}$GS consistently outperforms state-of-the-art methods by up to 10$times$ in Chamfer Distance for movable parts.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.17212",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "PerceptionLM: Open-Access Data and Models for Detailed Visual Understanding",
    "description": "arXiv:2504.13180v2 Announce Type: replace-cross Abstract: Vision-language models are integral to computer vision research, yet many high-performing models remain closed-source, obscuring their data, design and training recipe. The research community has responded by using distillation from black-box models to label training data, achieving strong benchmark results, at the cost of measurable scientific progress. However, without knowing the details of the teacher model and its data sources, scientific progress remains difficult to measure. In this paper, we study building a Perception Language Model (PLM) in a fully open and reproducible framework for transparent research in image and video understanding. We analyze standard training pipelines without distillation from proprietary models and explore large-scale synthetic data to identify critical data gaps, particularly in detailed video understanding. To bridge these gaps, we release 2.8M human-labeled instances of fine-grained video question-answer pairs and spatio-temporally grounded video captions. Additionally, we introduce PLM-VideoBench, a suite for evaluating challenging video understanding tasks focusing on the ability to reason about 'what', 'where', 'when', and 'how' of a video. We make our work fully reproducible by providing data, training recipes, code & models. https://github.com/facebookresearch/perception_models",
    "summary": "arXiv:2504.13180v2 Announce Type: replace-cross Abstract: Vision-language models are integral to computer vision research, yet many high-performing models remain closed-source, obscuring their data, design and training recipe. The research community has responded by using distillation from black-box models to label training data, achieving strong benchmark results, at the cost of measurable scientific progress. However, without knowing the details of the teacher model and its data sources, scientific progress remains difficult to measure. In this paper, we study building a Perception Language Model (PLM) in a fully open and reproducible framework for transparent research in image and video understanding. We analyze standard training pipelines without distillation from proprietary models and explore large-scale synthetic data to identify critical data gaps, particularly in detailed video understanding. To bridge these gaps, we release 2.8M human-labeled instances of fine-grained video question-answer pairs and spatio-temporally grounded video captions. Additionally, we introduce PLM-VideoBench, a suite for evaluating challenging video understanding tasks focusing on the ability to reason about 'what', 'where', 'when', and 'how' of a video. We make our work fully reproducible by providing data, training recipes, code & models. https://github.com/facebookresearch/perception_models",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2504.13180",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Planning of Heuristics: Strategic Planning on Large Language Models with Monte Carlo Tree Search for Automating Heuristic Optimization",
    "description": "arXiv:2502.11422v3 Announce Type: replace Abstract: Heuristics have achieved great success in solving combinatorial optimization problems~(COPs). However, heuristics designed by humans require too much domain knowledge and testing time. Since Large Language Models~(LLMs) possess strong capabilities to understand and generate content with a knowledge base that covers various domains, they offer potential ways to automatically optimize heuristics. To this end, we propose Planning of Heuristics~(PoH), an optimization method that integrates LLM self-reflection with Monte Carlo Tree Search, a well-known planning algorithm. PoH iteratively refines generated heuristics by evaluating their performance and providing improvement suggestions. Our method enables to iteratively evaluate the generated heuristics~(states) and improve them based on the improvement suggestions~(actions) and evaluation results~(rewards), by effectively simulating future states to search for paths with higher rewards. In this paper, we apply PoH to solve the Traveling Salesman Problem and the Flow Shop Scheduling Problem. The experimental results show that PoH outperforms hand-crafted heuristics and other Automatic Heuristic Design methods based on LLMs, and achieves the state-of-the-art performance in automating heuristic optimization with LLMs to solve tested COPs, especially with large sizes.",
    "summary": "arXiv:2502.11422v3 Announce Type: replace Abstract: Heuristics have achieved great success in solving combinatorial optimization problems~(COPs). However, heuristics designed by humans require too much domain knowledge and testing time. Since Large Language Models~(LLMs) possess strong capabilities to understand and generate content with a knowledge base that covers various domains, they offer potential ways to automatically optimize heuristics. To this end, we propose Planning of Heuristics~(PoH), an optimization method that integrates LLM self-reflection with Monte Carlo Tree Search, a well-known planning algorithm. PoH iteratively refines generated heuristics by evaluating their performance and providing improvement suggestions. Our method enables to iteratively evaluate the generated heuristics~(states) and improve them based on the improvement suggestions~(actions) and evaluation results~(rewards), by effectively simulating future states to search for paths with higher rewards. In this paper, we apply PoH to solve the Traveling Salesman Problem and the Flow Shop Scheduling Problem. The experimental results show that PoH outperforms hand-crafted heuristics and other Automatic Heuristic Design methods based on LLMs, and achieves the state-of-the-art performance in automating heuristic optimization with LLMs to solve tested COPs, especially with large sizes.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2502.11422",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "PlantBert: An Open Source Language Model for Plant Science",
    "description": "arXiv:2506.08897v2 Announce Type: replace-cross Abstract: The rapid advancement of transformer-based language models has catalyzed breakthroughs in biomedical and clinical natural language processing; however, plant science remains markedly underserved by such domain-adapted tools. In this work, we present PlantBert, a high-performance, open-source language model specifically tailored for extracting structured knowledge from plant stress-response literature. Built upon the DeBERTa architecture-known for its disentangled attention and robust contextual encoding-PlantBert is fine-tuned on a meticulously curated corpus of expert-annotated abstracts, with a primary focus on lentil (Lens culinaris) responses to diverse abiotic and biotic stressors. Our methodology combines transformer-based modeling with rule-enhanced linguistic post-processing and ontology-grounded entity normalization, enabling PlantBert to capture biologically meaningful relationships with precision and semantic fidelity. The underlying corpus is annotated using a hierarchical schema aligned with the Crop Ontology, encompassing molecular, physiological, biochemical, and agronomic dimensions of plant adaptation. PlantBert exhibits strong generalization capabilities across entity types and demonstrates the feasibility of robust domain adaptation in low-resource scientific fields. By providing a scalable and reproducible framework for high-resolution entity recognition, PlantBert bridges a critical gap in agricultural NLP and paves the way for intelligent, data-driven systems in plant genomics, phenomics, and agronomic knowledge discovery. Our model is publicly released to promote transparency and accelerate cross-disciplinary innovation in computational plant science.",
    "summary": "arXiv:2506.08897v2 Announce Type: replace-cross Abstract: The rapid advancement of transformer-based language models has catalyzed breakthroughs in biomedical and clinical natural language processing; however, plant science remains markedly underserved by such domain-adapted tools. In this work, we present PlantBert, a high-performance, open-source language model specifically tailored for extracting structured knowledge from plant stress-response literature. Built upon the DeBERTa architecture-known for its disentangled attention and robust contextual encoding-PlantBert is fine-tuned on a meticulously curated corpus of expert-annotated abstracts, with a primary focus on lentil (Lens culinaris) responses to diverse abiotic and biotic stressors. Our methodology combines transformer-based modeling with rule-enhanced linguistic post-processing and ontology-grounded entity normalization, enabling PlantBert to capture biologically meaningful relationships with precision and semantic fidelity. The underlying corpus is annotated using a hierarchical schema aligned with the Crop Ontology, encompassing molecular, physiological, biochemical, and agronomic dimensions of plant adaptation. PlantBert exhibits strong generalization capabilities across entity types and demonstrates the feasibility of robust domain adaptation in low-resource scientific fields. By providing a scalable and reproducible framework for high-resolution entity recognition, PlantBert bridges a critical gap in agricultural NLP and paves the way for intelligent, data-driven systems in plant genomics, phenomics, and agronomic knowledge discovery. Our model is publicly released to promote transparency and accelerate cross-disciplinary innovation in computational plant science.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.08897",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "PNCS:Power-Norm Cosine Similarity for Diverse Client Selection in Federated Learning",
    "description": "arXiv:2506.15923v1 Announce Type: cross Abstract: Federated Learning (FL) has emerged as a powerful paradigm for leveraging diverse datasets from multiple sources while preserving data privacy by avoiding centralized storage. However, many existing approaches fail to account for the intricate gradient correlations between remote clients, a limitation that becomes especially problematic in data heterogeneity scenarios. In this work, we propose a novel FL framework utilizing Power-Norm Cosine Similarity (PNCS) to improve client selection for model aggregation. By capturing higher-order gradient moments, PNCS addresses non-IID data challenges, enhancing convergence speed and accuracy. Additionally, we introduce a simple algorithm ensuring diverse client selection through a selection history queue. Experiments with a VGG16 model across varied data partitions demonstrate consistent improvements over state-of-the-art methods.",
    "summary": "arXiv:2506.15923v1 Announce Type: cross Abstract: Federated Learning (FL) has emerged as a powerful paradigm for leveraging diverse datasets from multiple sources while preserving data privacy by avoiding centralized storage. However, many existing approaches fail to account for the intricate gradient correlations between remote clients, a limitation that becomes especially problematic in data heterogeneity scenarios. In this work, we propose a novel FL framework utilizing Power-Norm Cosine Similarity (PNCS) to improve client selection for model aggregation. By capturing higher-order gradient moments, PNCS addresses non-IID data challenges, enhancing convergence speed and accuracy. Additionally, we introduce a simple algorithm ensuring diverse client selection through a selection history queue. Experiments with a VGG16 model across varied data partitions demonstrate consistent improvements over state-of-the-art methods.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.15923",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "POV Learning: Individual Alignment of Multimodal Models using Human Perception",
    "description": "arXiv:2405.04443v2 Announce Type: replace Abstract: Aligning machine learning systems with human expectations is mostly attempted by training with manually vetted human behavioral samples, typically explicit feedback. This is done on a population level since the context that is capturing the subjective Point-Of-View (POV) of a concrete person in a specific situational context is not retained in the data. However, we argue that alignment on an individual level can boost the subjective predictive performance for the individual user interacting with the system considerably. Since perception differs for each person, the same situation is observed differently. Consequently, the basis for decision making and the subsequent reasoning processes and observable reactions differ. We hypothesize that individual perception patterns can be used for improving the alignment on an individual level. We test this, by integrating perception information into machine learning systems and measuring their predictive performance wrt.~individual subjective assessments. For our empirical study, we collect a novel data set of multimodal stimuli and corresponding eye tracking sequences for the novel task of Perception-Guided Crossmodal Entailment and tackle it with our Perception-Guided Multimodal Transformer. Our findings suggest that exploiting individual perception signals for the machine learning of subjective human assessments provides a valuable cue for individual alignment. It does not only improve the overall predictive performance from the point-of-view of the individual user but might also contribute to steering AI systems towards every person's individual expectations and values.",
    "summary": "arXiv:2405.04443v2 Announce Type: replace Abstract: Aligning machine learning systems with human expectations is mostly attempted by training with manually vetted human behavioral samples, typically explicit feedback. This is done on a population level since the context that is capturing the subjective Point-Of-View (POV) of a concrete person in a specific situational context is not retained in the data. However, we argue that alignment on an individual level can boost the subjective predictive performance for the individual user interacting with the system considerably. Since perception differs for each person, the same situation is observed differently. Consequently, the basis for decision making and the subsequent reasoning processes and observable reactions differ. We hypothesize that individual perception patterns can be used for improving the alignment on an individual level. We test this, by integrating perception information into machine learning systems and measuring their predictive performance wrt.~individual subjective assessments. For our empirical study, we collect a novel data set of multimodal stimuli and corresponding eye tracking sequences for the novel task of Perception-Guided Crossmodal Entailment and tackle it with our Perception-Guided Multimodal Transformer. Our findings suggest that exploiting individual perception signals for the machine learning of subjective human assessments provides a valuable cue for individual alignment. It does not only improve the overall predictive performance from the point-of-view of the individual user but might also contribute to steering AI systems towards every person's individual expectations and values.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2405.04443",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "PQCAD-DM: Progressive Quantization and Calibration-Assisted Distillation for Extremely Efficient Diffusion Model",
    "description": "arXiv:2506.16776v1 Announce Type: cross Abstract: Diffusion models excel in image generation but are computational and resource-intensive due to their reliance on iterative Markov chain processes, leading to error accumulation and limiting the effectiveness of naive compression techniques. In this paper, we propose PQCAD-DM, a novel hybrid compression framework combining Progressive Quantization (PQ) and Calibration-Assisted Distillation (CAD) to address these challenges. PQ employs a two-stage quantization with adaptive bit-width transitions guided by a momentum-based mechanism, reducing excessive weight perturbations in low-precision. CAD leverages full-precision calibration datasets during distillation, enabling the student to match full-precision performance even with a quantized teacher. As a result, PQCAD-DM achieves a balance between computational efficiency and generative quality, halving inference time while maintaining competitive performance. Extensive experiments validate PQCAD-DM's superior generative capabilities and efficiency across diverse datasets, outperforming fixed-bit quantization methods.",
    "summary": "arXiv:2506.16776v1 Announce Type: cross Abstract: Diffusion models excel in image generation but are computational and resource-intensive due to their reliance on iterative Markov chain processes, leading to error accumulation and limiting the effectiveness of naive compression techniques. In this paper, we propose PQCAD-DM, a novel hybrid compression framework combining Progressive Quantization (PQ) and Calibration-Assisted Distillation (CAD) to address these challenges. PQ employs a two-stage quantization with adaptive bit-width transitions guided by a momentum-based mechanism, reducing excessive weight perturbations in low-precision. CAD leverages full-precision calibration datasets during distillation, enabling the student to match full-precision performance even with a quantized teacher. As a result, PQCAD-DM achieves a balance between computational efficiency and generative quality, halving inference time while maintaining competitive performance. Extensive experiments validate PQCAD-DM's superior generative capabilities and efficiency across diverse datasets, outperforming fixed-bit quantization methods.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16776",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "PR-Attack: Coordinated Prompt-RAG Attacks on Retrieval-Augmented Generation in Large Language Models via Bilevel Optimization",
    "description": "arXiv:2504.07717v3 Announce Type: replace-cross Abstract: Large Language Models (LLMs) have demonstrated remarkable performance across a wide range of applications, e.g., medical question-answering, mathematical sciences, and code generation. However, they also exhibit inherent limitations, such as outdated knowledge and susceptibility to hallucinations. Retrieval-Augmented Generation (RAG) has emerged as a promising paradigm to address these issues, but it also introduces new vulnerabilities. Recent efforts have focused on the security of RAG-based LLMs, yet existing attack methods face three critical challenges: (1) their effectiveness declines sharply when only a limited number of poisoned texts can be injected into the knowledge database, (2) they lack sufficient stealth, as the attacks are often detectable by anomaly detection systems, which compromises their effectiveness, and (3) they rely on heuristic approaches to generate poisoned texts, lacking formal optimization frameworks and theoretic guarantees, which limits their effectiveness and applicability. To address these issues, we propose coordinated Prompt-RAG attack (PR-attack), a novel optimization-driven attack that introduces a small number of poisoned texts into the knowledge database while embedding a backdoor trigger within the prompt. When activated, the trigger causes the LLM to generate pre-designed responses to targeted queries, while maintaining normal behavior in other contexts. This ensures both high effectiveness and stealth. We formulate the attack generation process as a bilevel optimization problem leveraging a principled optimization framework to develop optimal poisoned texts and triggers. Extensive experiments across diverse LLMs and datasets demonstrate the effectiveness of PR-Attack, achieving a high attack success rate even with a limited number of poisoned texts and significantly improved stealth compared to existing methods.",
    "summary": "arXiv:2504.07717v3 Announce Type: replace-cross Abstract: Large Language Models (LLMs) have demonstrated remarkable performance across a wide range of applications, e.g., medical question-answering, mathematical sciences, and code generation. However, they also exhibit inherent limitations, such as outdated knowledge and susceptibility to hallucinations. Retrieval-Augmented Generation (RAG) has emerged as a promising paradigm to address these issues, but it also introduces new vulnerabilities. Recent efforts have focused on the security of RAG-based LLMs, yet existing attack methods face three critical challenges: (1) their effectiveness declines sharply when only a limited number of poisoned texts can be injected into the knowledge database, (2) they lack sufficient stealth, as the attacks are often detectable by anomaly detection systems, which compromises their effectiveness, and (3) they rely on heuristic approaches to generate poisoned texts, lacking formal optimization frameworks and theoretic guarantees, which limits their effectiveness and applicability. To address these issues, we propose coordinated Prompt-RAG attack (PR-attack), a novel optimization-driven attack that introduces a small number of poisoned texts into the knowledge database while embedding a backdoor trigger within the prompt. When activated, the trigger causes the LLM to generate pre-designed responses to targeted queries, while maintaining normal behavior in other contexts. This ensures both high effectiveness and stealth. We formulate the attack generation process as a bilevel optimization problem leveraging a principled optimization framework to develop optimal poisoned texts and triggers. Extensive experiments across diverse LLMs and datasets demonstrate the effectiveness of PR-Attack, achieving a high attack success rate even with a limited number of poisoned texts and significantly improved stealth compared to existing methods.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2504.07717",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Preference-Driven Multi-Objective Combinatorial Optimization with Conditional Computation",
    "description": "arXiv:2506.08898v2 Announce Type: replace Abstract: Recent deep reinforcement learning methods have achieved remarkable success in solving multi-objective combinatorial optimization problems (MOCOPs) by decomposing them into multiple subproblems, each associated with a specific weight vector. However, these methods typically treat all subproblems equally and solve them using a single model, hindering the effective exploration of the solution space and thus leading to suboptimal performance. To overcome the limitation, we propose POCCO, a novel plug-and-play framework that enables adaptive selection of model structures for subproblems, which are subsequently optimized based on preference signals rather than explicit reward values. Specifically, we design a conditional computation block that routes subproblems to specialized neural architectures. Moreover, we propose a preference-driven optimization algorithm that learns pairwise preferences between winning and losing solutions. We evaluate the efficacy and versatility of POCCO by applying it to two state-of-the-art neural methods for MOCOPs. Experimental results across four classic MOCOP benchmarks demonstrate its significant superiority and strong generalization.",
    "summary": "arXiv:2506.08898v2 Announce Type: replace Abstract: Recent deep reinforcement learning methods have achieved remarkable success in solving multi-objective combinatorial optimization problems (MOCOPs) by decomposing them into multiple subproblems, each associated with a specific weight vector. However, these methods typically treat all subproblems equally and solve them using a single model, hindering the effective exploration of the solution space and thus leading to suboptimal performance. To overcome the limitation, we propose POCCO, a novel plug-and-play framework that enables adaptive selection of model structures for subproblems, which are subsequently optimized based on preference signals rather than explicit reward values. Specifically, we design a conditional computation block that routes subproblems to specialized neural architectures. Moreover, we propose a preference-driven optimization algorithm that learns pairwise preferences between winning and losing solutions. We evaluate the efficacy and versatility of POCCO by applying it to two state-of-the-art neural methods for MOCOPs. Experimental results across four classic MOCOP benchmarks demonstrate its significant superiority and strong generalization.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.08898",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "PRISON: Unmasking the Criminal Potential of Large Language Models",
    "description": "arXiv:2506.16150v1 Announce Type: cross Abstract: As large language models (LLMs) advance, concerns about their misconduct in complex social contexts intensify. Existing research overlooked the systematic understanding and assessment of their criminal capability in realistic interactions. We propose a unified framework PRISON, to quantify LLMs' criminal potential across five dimensions: False Statements, Frame-Up, Psychological Manipulation, Emotional Disguise, and Moral Disengagement. Using structured crime scenarios adapted from classic films, we evaluate both criminal potential and anti-crime ability of LLMs via role-play. Results show that state-of-the-art LLMs frequently exhibit emergent criminal tendencies, such as proposing misleading statements or evasion tactics, even without explicit instructions. Moreover, when placed in a detective role, models recognize deceptive behavior with only 41% accuracy on average, revealing a striking mismatch between conducting and detecting criminal behavior. These findings underscore the urgent need for adversarial robustness, behavioral alignment, and safety mechanisms before broader LLM deployment.",
    "summary": "arXiv:2506.16150v1 Announce Type: cross Abstract: As large language models (LLMs) advance, concerns about their misconduct in complex social contexts intensify. Existing research overlooked the systematic understanding and assessment of their criminal capability in realistic interactions. We propose a unified framework PRISON, to quantify LLMs' criminal potential across five dimensions: False Statements, Frame-Up, Psychological Manipulation, Emotional Disguise, and Moral Disengagement. Using structured crime scenarios adapted from classic films, we evaluate both criminal potential and anti-crime ability of LLMs via role-play. Results show that state-of-the-art LLMs frequently exhibit emergent criminal tendencies, such as proposing misleading statements or evasion tactics, even without explicit instructions. Moreover, when placed in a detective role, models recognize deceptive behavior with only 41% accuracy on average, revealing a striking mismatch between conducting and detecting criminal behavior. These findings underscore the urgent need for adversarial robustness, behavioral alignment, and safety mechanisms before broader LLM deployment.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16150",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Probing the Robustness of Large Language Models Safety to Latent Perturbations",
    "description": "arXiv:2506.16078v1 Announce Type: cross Abstract: Safety alignment is a key requirement for building reliable Artificial General Intelligence. Despite significant advances in safety alignment, we observe that minor latent shifts can still trigger unsafe responses in aligned models. We argue that this stems from the shallow nature of existing alignment methods, which focus on surface-level refusal behaviors without sufficiently altering internal representations. Consequently, small shifts in hidden activations can re-trigger harmful behaviors embedded in the latent space. To explore the robustness of safety alignment to latent perturbations, we introduce a probing method that measures the Negative Log-Likelihood of the original response generated by the model. This probe quantifies local sensitivity in the latent space, serving as a diagnostic tool for identifying vulnerable directions. Based on this signal, we construct effective jailbreak trajectories, giving rise to the Activation Steering Attack (ASA). More importantly, these insights offer a principled foundation for improving alignment robustness. To this end, we introduce Layer-wise Adversarial Patch Training~(LAPT), a fine-tuning strategy that inject controlled perturbations into hidden representations during training. Experimental results highlight that LAPT strengthen alignment robustness without compromising general capabilities. Our findings reveal fundamental flaws in current alignment paradigms and call for representation-level training strategies that move beyond surface-level behavior supervision. Codes and results are available at https://github.com/Carol-gutianle/LatentSafety.",
    "summary": "arXiv:2506.16078v1 Announce Type: cross Abstract: Safety alignment is a key requirement for building reliable Artificial General Intelligence. Despite significant advances in safety alignment, we observe that minor latent shifts can still trigger unsafe responses in aligned models. We argue that this stems from the shallow nature of existing alignment methods, which focus on surface-level refusal behaviors without sufficiently altering internal representations. Consequently, small shifts in hidden activations can re-trigger harmful behaviors embedded in the latent space. To explore the robustness of safety alignment to latent perturbations, we introduce a probing method that measures the Negative Log-Likelihood of the original response generated by the model. This probe quantifies local sensitivity in the latent space, serving as a diagnostic tool for identifying vulnerable directions. Based on this signal, we construct effective jailbreak trajectories, giving rise to the Activation Steering Attack (ASA). More importantly, these insights offer a principled foundation for improving alignment robustness. To this end, we introduce Layer-wise Adversarial Patch Training~(LAPT), a fine-tuning strategy that inject controlled perturbations into hidden representations during training. Experimental results highlight that LAPT strengthen alignment robustness without compromising general capabilities. Our findings reveal fundamental flaws in current alignment paradigms and call for representation-level training strategies that move beyond surface-level behavior supervision. Codes and results are available at https://github.com/Carol-gutianle/LatentSafety.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16078",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Progressive Inference-Time Annealing of Diffusion Models for Sampling from Boltzmann Densities",
    "description": "arXiv:2506.16471v1 Announce Type: cross Abstract: Sampling efficiently from a target unnormalized probability density remains a core challenge, with relevance across countless high-impact scientific applications. A promising approach towards this challenge is the design of amortized samplers that borrow key ideas, such as probability path design, from state-of-the-art generative diffusion models. However, all existing diffusion-based samplers remain unable to draw samples from distributions at the scale of even simple molecular systems. In this paper, we propose Progressive Inference-Time Annealing (PITA), a novel framework to learn diffusion-based samplers that combines two complementary interpolation techniques: I.) Annealing of the Boltzmann distribution and II.) Diffusion smoothing. PITA trains a sequence of diffusion models from high to low temperatures by sequentially training each model at progressively higher temperatures, leveraging engineered easy access to samples of the temperature-annealed target density. In the subsequent step, PITA enables simulating the trained diffusion model to procure training samples at a lower temperature for the next diffusion model through inference-time annealing using a novel Feynman-Kac PDE combined with Sequential Monte Carlo. Empirically, PITA enables, for the first time, equilibrium sampling of N-body particle systems, Alanine Dipeptide, and tripeptides in Cartesian coordinates with dramatically lower energy function evaluations. Code available at: https://github.com/taraak/pita",
    "summary": "arXiv:2506.16471v1 Announce Type: cross Abstract: Sampling efficiently from a target unnormalized probability density remains a core challenge, with relevance across countless high-impact scientific applications. A promising approach towards this challenge is the design of amortized samplers that borrow key ideas, such as probability path design, from state-of-the-art generative diffusion models. However, all existing diffusion-based samplers remain unable to draw samples from distributions at the scale of even simple molecular systems. In this paper, we propose Progressive Inference-Time Annealing (PITA), a novel framework to learn diffusion-based samplers that combines two complementary interpolation techniques: I.) Annealing of the Boltzmann distribution and II.) Diffusion smoothing. PITA trains a sequence of diffusion models from high to low temperatures by sequentially training each model at progressively higher temperatures, leveraging engineered easy access to samples of the temperature-annealed target density. In the subsequent step, PITA enables simulating the trained diffusion model to procure training samples at a lower temperature for the next diffusion model through inference-time annealing using a novel Feynman-Kac PDE combined with Sequential Monte Carlo. Empirically, PITA enables, for the first time, equilibrium sampling of N-body particle systems, Alanine Dipeptide, and tripeptides in Cartesian coordinates with dramatically lower energy function evaluations. Code available at: https://github.com/taraak/pita",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16471",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "PromptDSI: Prompt-based Rehearsal-free Instance-wise Incremental Learning for Document Retrieval",
    "description": "arXiv:2406.12593v3 Announce Type: replace-cross Abstract: Differentiable Search Index (DSI) utilizes pre-trained language models to perform indexing and document retrieval via end-to-end learning without relying on external indexes. However, DSI requires full re-training to index new documents, causing significant computational inefficiencies. Continual learning (CL) offers a solution by enabling the model to incrementally update without full re-training. Existing CL solutions in document retrieval rely on memory buffers or generative models for rehearsal, which is infeasible when accessing previous training data is restricted due to privacy concerns. To this end, we introduce PromptDSI, a prompt-based, rehearsal-free continual learning approach for document retrieval. PromptDSI follows the Prompt-based Continual Learning (PCL) framework, using learnable prompts to efficiently index new documents without accessing previous documents or queries. To improve retrieval latency, we remove the initial forward pass of PCL, which otherwise greatly increases training and inference time, with a negligible trade-off in performance. Additionally, we introduce a novel topic-aware prompt pool that employs neural topic embeddings as fixed keys, eliminating the instability of prompt key optimization while maintaining competitive performance with existing PCL prompt pools. In a challenging rehearsal-free continual learning setup, we demonstrate that PromptDSI variants outperform rehearsal-based baselines, match the strong cache-based baseline in mitigating forgetting, and significantly improving retrieval performance on new corpora.",
    "summary": "arXiv:2406.12593v3 Announce Type: replace-cross Abstract: Differentiable Search Index (DSI) utilizes pre-trained language models to perform indexing and document retrieval via end-to-end learning without relying on external indexes. However, DSI requires full re-training to index new documents, causing significant computational inefficiencies. Continual learning (CL) offers a solution by enabling the model to incrementally update without full re-training. Existing CL solutions in document retrieval rely on memory buffers or generative models for rehearsal, which is infeasible when accessing previous training data is restricted due to privacy concerns. To this end, we introduce PromptDSI, a prompt-based, rehearsal-free continual learning approach for document retrieval. PromptDSI follows the Prompt-based Continual Learning (PCL) framework, using learnable prompts to efficiently index new documents without accessing previous documents or queries. To improve retrieval latency, we remove the initial forward pass of PCL, which otherwise greatly increases training and inference time, with a negligible trade-off in performance. Additionally, we introduce a novel topic-aware prompt pool that employs neural topic embeddings as fixed keys, eliminating the instability of prompt key optimization while maintaining competitive performance with existing PCL prompt pools. In a challenging rehearsal-free continual learning setup, we demonstrate that PromptDSI variants outperform rehearsal-based baselines, match the strong cache-based baseline in mitigating forgetting, and significantly improving retrieval performance on new corpora.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2406.12593",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Proportional Sensitivity in Generative Adversarial Network (GAN)-Augmented Brain Tumor Classification Using Convolutional Neural Network",
    "description": "arXiv:2506.17165v1 Announce Type: cross Abstract: Generative Adversarial Networks (GAN) have shown potential in expanding limited medical imaging datasets. This study explores how different ratios of GAN-generated and real brain tumor MRI images impact the performance of a CNN in classifying healthy vs. tumorous scans. A DCGAN was used to create synthetic images which were mixed with real ones at various ratios to train a custom CNN. The CNN was then evaluated on a separate real-world test set. Our results indicate that the model maintains high sensitivity and precision in tumor classification, even when trained predominantly on synthetic data. When only a small portion of GAN data was added, such as 900 real images and 100 GAN images, the model achieved excellent performance, with test accuracy reaching 95.2%, and precision, recall, and F1-score all exceeding 95%. However, as the proportion of GAN images increased further, performance gradually declined. This study suggests that while GANs are useful for augmenting limited datasets especially when real data is scarce, too much synthetic data can introduce artifacts that affect the model's ability to generalize to real world cases.",
    "summary": "arXiv:2506.17165v1 Announce Type: cross Abstract: Generative Adversarial Networks (GAN) have shown potential in expanding limited medical imaging datasets. This study explores how different ratios of GAN-generated and real brain tumor MRI images impact the performance of a CNN in classifying healthy vs. tumorous scans. A DCGAN was used to create synthetic images which were mixed with real ones at various ratios to train a custom CNN. The CNN was then evaluated on a separate real-world test set. Our results indicate that the model maintains high sensitivity and precision in tumor classification, even when trained predominantly on synthetic data. When only a small portion of GAN data was added, such as 900 real images and 100 GAN images, the model achieved excellent performance, with test accuracy reaching 95.2%, and precision, recall, and F1-score all exceeding 95%. However, as the proportion of GAN images increased further, performance gradually declined. This study suggests that while GANs are useful for augmenting limited datasets especially when real data is scarce, too much synthetic data can introduce artifacts that affect the model's ability to generalize to real world cases.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.17165",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "QG-SMS: Enhancing Test Item Analysis via Student Modeling and Simulation",
    "description": "arXiv:2503.05888v2 Announce Type: replace-cross Abstract: While the Question Generation (QG) task has been increasingly adopted in educational assessments, its evaluation remains limited by approaches that lack a clear connection to the educational values of test items. In this work, we introduce test item analysis, a method frequently used by educators to assess test question quality, into QG evaluation. Specifically, we construct pairs of candidate questions that differ in quality across dimensions such as topic coverage, item difficulty, item discrimination, and distractor efficiency. We then examine whether existing QG evaluation approaches can effectively distinguish these differences. Our findings reveal significant shortcomings in these approaches with respect to accurately assessing test item quality in relation to student performance. To address this gap, we propose a novel QG evaluation framework, QG-SMS, which leverages Large Language Model for Student Modeling and Simulation to perform test item analysis. As demonstrated in our extensive experiments and human evaluation study, the additional perspectives introduced by the simulated student profiles lead to a more effective and robust assessment of test items.",
    "summary": "arXiv:2503.05888v2 Announce Type: replace-cross Abstract: While the Question Generation (QG) task has been increasingly adopted in educational assessments, its evaluation remains limited by approaches that lack a clear connection to the educational values of test items. In this work, we introduce test item analysis, a method frequently used by educators to assess test question quality, into QG evaluation. Specifically, we construct pairs of candidate questions that differ in quality across dimensions such as topic coverage, item difficulty, item discrimination, and distractor efficiency. We then examine whether existing QG evaluation approaches can effectively distinguish these differences. Our findings reveal significant shortcomings in these approaches with respect to accurately assessing test item quality in relation to student performance. To address this gap, we propose a novel QG evaluation framework, QG-SMS, which leverages Large Language Model for Student Modeling and Simulation to perform test item analysis. As demonstrated in our extensive experiments and human evaluation study, the additional perspectives introduced by the simulated student profiles lead to a more effective and robust assessment of test items.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2503.05888",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Quantifying artificial intelligence through algorithmic generalization",
    "description": "arXiv:2411.05943v2 Announce Type: replace Abstract: The rapid development of artificial intelligence (AI) systems has created an urgent need for their scientific quantification. While their fluency across a variety of domains is impressive, AI systems fall short on tests requiring algorithmic reasoning -- a glaring limitation given the necessity for interpretable and reliable technology. Despite a surge of reasoning benchmarks emerging from the academic community, no theoretical framework exists to quantify algorithmic reasoning in AI systems. Here, we adopt a framework from computational complexity theory to quantify algorithmic generalization using algebraic expressions: algebraic circuit complexity. Algebraic circuit complexity theory -- the study of algebraic expressions as circuit models -- is a natural framework to study the complexity of algorithmic computation. Algebraic circuit complexity enables the study of generalization by defining benchmarks in terms of the computational requirements to solve a problem. Moreover, algebraic circuits are generic mathematical objects; an arbitrarily large number of samples can be generated for a specified circuit, making it an ideal experimental sandbox for the data-hungry models that are used today. In this Perspective, we adopt tools from algebraic circuit complexity, apply them to formalize a science of algorithmic generalization, and address key challenges for its successful application to AI science.",
    "summary": "arXiv:2411.05943v2 Announce Type: replace Abstract: The rapid development of artificial intelligence (AI) systems has created an urgent need for their scientific quantification. While their fluency across a variety of domains is impressive, AI systems fall short on tests requiring algorithmic reasoning -- a glaring limitation given the necessity for interpretable and reliable technology. Despite a surge of reasoning benchmarks emerging from the academic community, no theoretical framework exists to quantify algorithmic reasoning in AI systems. Here, we adopt a framework from computational complexity theory to quantify algorithmic generalization using algebraic expressions: algebraic circuit complexity. Algebraic circuit complexity theory -- the study of algebraic expressions as circuit models -- is a natural framework to study the complexity of algorithmic computation. Algebraic circuit complexity enables the study of generalization by defining benchmarks in terms of the computational requirements to solve a problem. Moreover, algebraic circuits are generic mathematical objects; an arbitrarily large number of samples can be generated for a specified circuit, making it an ideal experimental sandbox for the data-hungry models that are used today. In this Perspective, we adopt tools from algebraic circuit complexity, apply them to formalize a science of algorithmic generalization, and address key challenges for its successful application to AI science.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2411.05943",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Quantum Artificial Intelligence for Secure Autonomous Vehicle Navigation: An Architectural Proposal",
    "description": "arXiv:2506.16000v1 Announce Type: cross Abstract: Navigation is a very crucial aspect of autonomous vehicle ecosystem which heavily relies on collecting and processing large amounts of data in various states and taking a confident and safe decision to define the next vehicle maneuver. In this paper, we propose a novel architecture based on Quantum Artificial Intelligence by enabling quantum and AI at various levels of navigation decision making and communication process in Autonomous vehicles : Quantum Neural Networks for multimodal sensor fusion, Nav-Q for Quantum reinforcement learning for navigation policy optimization and finally post-quantum cryptographic protocols for secure communication. Quantum neural networks uses quantum amplitude encoding to fuse data from various sensors like LiDAR, radar, camera, GPS and weather etc., This approach gives a unified quantum state representation between heterogeneous sensor modalities. Nav-Q module processes the fused quantum states through variational quantum circuits to learn optimal navigation policies under swift dynamic and complex conditions. Finally, post quantum cryptographic protocols are used to secure communication channels for both within vehicle communication and V2X (Vehicle to Everything) communications and thus secures the autonomous vehicle communication from both classical and quantum security threats. Thus, the proposed framework addresses fundamental challenges in autonomous vehicles navigation by providing quantum performance and future proof security. Index Terms Quantum Computing, Autonomous Vehicles, Sensor Fusion",
    "summary": "arXiv:2506.16000v1 Announce Type: cross Abstract: Navigation is a very crucial aspect of autonomous vehicle ecosystem which heavily relies on collecting and processing large amounts of data in various states and taking a confident and safe decision to define the next vehicle maneuver. In this paper, we propose a novel architecture based on Quantum Artificial Intelligence by enabling quantum and AI at various levels of navigation decision making and communication process in Autonomous vehicles : Quantum Neural Networks for multimodal sensor fusion, Nav-Q for Quantum reinforcement learning for navigation policy optimization and finally post-quantum cryptographic protocols for secure communication. Quantum neural networks uses quantum amplitude encoding to fuse data from various sensors like LiDAR, radar, camera, GPS and weather etc., This approach gives a unified quantum state representation between heterogeneous sensor modalities. Nav-Q module processes the fused quantum states through variational quantum circuits to learn optimal navigation policies under swift dynamic and complex conditions. Finally, post quantum cryptographic protocols are used to secure communication channels for both within vehicle communication and V2X (Vehicle to Everything) communications and thus secures the autonomous vehicle communication from both classical and quantum security threats. Thus, the proposed framework addresses fundamental challenges in autonomous vehicles navigation by providing quantum performance and future proof security. Index Terms Quantum Computing, Autonomous Vehicles, Sensor Fusion",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16000",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "RapFlow-TTS: Rapid and High-Fidelity Text-to-Speech with Improved Consistency Flow Matching",
    "description": "arXiv:2506.16741v1 Announce Type: cross Abstract: We introduce RapFlow-TTS, a rapid and high-fidelity TTS acoustic model that leverages velocity consistency constraints in flow matching (FM) training. Although ordinary differential equation (ODE)-based TTS generation achieves natural-quality speech, it typically requires a large number of generation steps, resulting in a trade-off between quality and inference speed. To address this challenge, RapFlow-TTS enforces consistency in the velocity field along the FM-straightened ODE trajectory, enabling consistent synthetic quality with fewer generation steps. Additionally, we introduce techniques such as time interval scheduling and adversarial learning to further enhance the quality of the few-step synthesis. Experimental results show that RapFlow-TTS achieves high-fidelity speech synthesis with a 5- and 10-fold reduction in synthesis steps than the conventional FM- and score-based approaches, respectively.",
    "summary": "arXiv:2506.16741v1 Announce Type: cross Abstract: We introduce RapFlow-TTS, a rapid and high-fidelity TTS acoustic model that leverages velocity consistency constraints in flow matching (FM) training. Although ordinary differential equation (ODE)-based TTS generation achieves natural-quality speech, it typically requires a large number of generation steps, resulting in a trade-off between quality and inference speed. To address this challenge, RapFlow-TTS enforces consistency in the velocity field along the FM-straightened ODE trajectory, enabling consistent synthetic quality with fewer generation steps. Additionally, we introduce techniques such as time interval scheduling and adversarial learning to further enhance the quality of the few-step synthesis. Experimental results show that RapFlow-TTS achieves high-fidelity speech synthesis with a 5- and 10-fold reduction in synthesis steps than the conventional FM- and score-based approaches, respectively.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16741",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Rapid and Continuous Trust Evaluation for Effective Task Collaboration Through Siamese Model",
    "description": "arXiv:2506.17128v1 Announce Type: cross Abstract: Trust is emerging as an effective tool to ensure the successful completion of collaborative tasks within collaborative systems. However, rapidly and continuously evaluating the trustworthiness of collaborators during task execution is a significant challenge due to distributed devices, complex operational environments, and dynamically changing resources. To tackle this challenge, this paper proposes a Siamese-enabled rapid and continuous trust evaluation framework (SRCTE) to facilitate effective task collaboration. First, the communication and computing resource attributes of the collaborator in a trusted state, along with historical collaboration data, are collected and represented using an attributed control flow graph (ACFG) that captures trust-related semantic information and serves as a reference for comparison with data collected during task execution. At each time slot of task execution, the collaborator's communication and computing resource attributes, as well as task completion effectiveness, are collected in real time and represented with an ACFG to convey their trust-related semantic information. A Siamese model, consisting of two shared-parameter Structure2vec networks, is then employed to learn the deep semantics of each pair of ACFGs and generate their embeddings. Finally, the similarity between the embeddings of each pair of ACFGs is calculated to determine the collaborator's trust value at each time slot. A real system is built using two Dell EMC 5200 servers and a Google Pixel 8 to test the effectiveness of the proposed SRCTE framework. Experimental results demonstrate that SRCTE converges rapidly with only a small amount of data and achieves a high anomaly trust detection rate compared to the baseline algorithm.",
    "summary": "arXiv:2506.17128v1 Announce Type: cross Abstract: Trust is emerging as an effective tool to ensure the successful completion of collaborative tasks within collaborative systems. However, rapidly and continuously evaluating the trustworthiness of collaborators during task execution is a significant challenge due to distributed devices, complex operational environments, and dynamically changing resources. To tackle this challenge, this paper proposes a Siamese-enabled rapid and continuous trust evaluation framework (SRCTE) to facilitate effective task collaboration. First, the communication and computing resource attributes of the collaborator in a trusted state, along with historical collaboration data, are collected and represented using an attributed control flow graph (ACFG) that captures trust-related semantic information and serves as a reference for comparison with data collected during task execution. At each time slot of task execution, the collaborator's communication and computing resource attributes, as well as task completion effectiveness, are collected in real time and represented with an ACFG to convey their trust-related semantic information. A Siamese model, consisting of two shared-parameter Structure2vec networks, is then employed to learn the deep semantics of each pair of ACFGs and generate their embeddings. Finally, the similarity between the embeddings of each pair of ACFGs is calculated to determine the collaborator's trust value at each time slot. A real system is built using two Dell EMC 5200 servers and a Google Pixel 8 to test the effectiveness of the proposed SRCTE framework. Experimental results demonstrate that SRCTE converges rapidly with only a small amount of data and achieves a high anomaly trust detection rate compared to the baseline algorithm.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.17128",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "RAST: Reasoning Activation in LLMs via Small-model Transfer",
    "description": "arXiv:2506.15710v1 Announce Type: cross Abstract: Reinforcement learning (RL) has become a powerful approach for improving the reasoning capabilities of large language models (LLMs), as evidenced by recent successes such as OpenAI's o1 and Deepseek-R1. However, applying RL at scale remains intimidatingly resource-intensive, requiring multiple model copies and extensive GPU workloads. On the other hand, while being powerful, recent studies suggest that RL does not fundamentally endow models with new knowledge; rather, it primarily reshapes the model's output distribution to activate reasoning capabilities latent in the base model. Building on this insight, we hypothesize that the changes in output probabilities induced by RL are largely model-size invariant, opening the door to a more efficient paradigm: training a small model with RL and transferring its induced probability shifts to larger base models. To verify our hypothesis, we conduct a token-level analysis of decoding trajectories and find high alignment in RL-induced output distributions across model scales, validating our hypothesis. Motivated by this, we propose RAST, a simple yet effective method that transfers reasoning behaviors by injecting RL-induced probability adjustments from a small RL-trained model into larger models. Experiments across multiple mathematical reasoning benchmarks show that RAST substantially and consistently enhances the reasoning capabilities of base models while requiring significantly lower GPU memory than direct RL training, sometimes even yielding better performance than the RL-trained counterparts. Our findings offer new insights into the nature of RL-driven reasoning and practical strategies for scaling its benefits without incurring its full computational cost. The project page of RAST is available at https://ozyyshr.github.io/RAST/.",
    "summary": "arXiv:2506.15710v1 Announce Type: cross Abstract: Reinforcement learning (RL) has become a powerful approach for improving the reasoning capabilities of large language models (LLMs), as evidenced by recent successes such as OpenAI's o1 and Deepseek-R1. However, applying RL at scale remains intimidatingly resource-intensive, requiring multiple model copies and extensive GPU workloads. On the other hand, while being powerful, recent studies suggest that RL does not fundamentally endow models with new knowledge; rather, it primarily reshapes the model's output distribution to activate reasoning capabilities latent in the base model. Building on this insight, we hypothesize that the changes in output probabilities induced by RL are largely model-size invariant, opening the door to a more efficient paradigm: training a small model with RL and transferring its induced probability shifts to larger base models. To verify our hypothesis, we conduct a token-level analysis of decoding trajectories and find high alignment in RL-induced output distributions across model scales, validating our hypothesis. Motivated by this, we propose RAST, a simple yet effective method that transfers reasoning behaviors by injecting RL-induced probability adjustments from a small RL-trained model into larger models. Experiments across multiple mathematical reasoning benchmarks show that RAST substantially and consistently enhances the reasoning capabilities of base models while requiring significantly lower GPU memory than direct RL training, sometimes even yielding better performance than the RL-trained counterparts. Our findings offer new insights into the nature of RL-driven reasoning and practical strategies for scaling its benefits without incurring its full computational cost. The project page of RAST is available at https://ozyyshr.github.io/RAST/.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.15710",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Real-Time Black-Box Optimization for Dynamic Discrete Environments Using Embedded Ising Machines",
    "description": "arXiv:2506.16924v1 Announce Type: new Abstract: Many real-time systems require the optimization of discrete variables. Black-box optimization (BBO) algorithms and multi-armed bandit (MAB) algorithms perform optimization by repeatedly taking actions and observing the corresponding instant rewards without any prior knowledge. Recently, a BBO method using an Ising machine has been proposed to find the best action that is represented by a combination of discrete values and maximizes the instant reward in static environments. In contrast, dynamic environments, where real-time systems operate, necessitate MAB algorithms that maximize the average reward over multiple trials. However, due to the enormous number of actions resulting from the combinatorial nature of discrete optimization, conventional MAB algorithms cannot effectively optimize dynamic, discrete environments. Here, we show a heuristic MAB method for dynamic, discrete environments by extending the BBO method, in which an Ising machine effectively explores the actions while considering interactions between variables and changes in dynamic environments. We demonstrate the dynamic adaptability of the proposed method in a wireless communication system with moving users.",
    "summary": "arXiv:2506.16924v1 Announce Type: new Abstract: Many real-time systems require the optimization of discrete variables. Black-box optimization (BBO) algorithms and multi-armed bandit (MAB) algorithms perform optimization by repeatedly taking actions and observing the corresponding instant rewards without any prior knowledge. Recently, a BBO method using an Ising machine has been proposed to find the best action that is represented by a combination of discrete values and maximizes the instant reward in static environments. In contrast, dynamic environments, where real-time systems operate, necessitate MAB algorithms that maximize the average reward over multiple trials. However, due to the enormous number of actions resulting from the combinatorial nature of discrete optimization, conventional MAB algorithms cannot effectively optimize dynamic, discrete environments. Here, we show a heuristic MAB method for dynamic, discrete environments by extending the BBO method, in which an Ising machine effectively explores the actions while considering interactions between variables and changes in dynamic environments. We demonstrate the dynamic adaptability of the proposed method in a wireless communication system with moving users.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16924",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "ReasonGRM: Enhancing Generative Reward Models through Large Reasoning Models",
    "description": "arXiv:2506.16712v1 Announce Type: cross Abstract: Generative Reward Models (GRMs) provide greater flexibility than scalar reward models in capturing human preferences, but their effectiveness is limited by poor reasoning capabilities. This often results in incomplete or overly speculative reasoning paths, leading to hallucinations or missing key information in complex tasks. We address this challenge with ReasonGRM, a three-stage generative reward modeling framework. In the first stage, Zero-RL is used to generate concise, outcome-directed reasoning paths that reduce the likelihood of critical omissions. In the second stage, we introduce a novel evaluation metric, $R^star$, which scores reasoning paths based on their generation likelihood. This favors paths that reach correct answers with minimal exploration, helping to reduce hallucination-prone data during training. In the final stage, the model is further refined through reinforcement learning on challenging examples to enhance its preference discrimination capabilities. Experiments on three public benchmarks show that ReasonGRM achieves competitive or state-of-the-art performance, outperforming previous best GRMs by 1.8% on average and surpassing proprietary models such as GPT-4o by up to 5.6%. These results demonstrate the effectiveness of reasoning-aware training and highlight the importance of high-quality rationale selection for reliable preference modeling.",
    "summary": "arXiv:2506.16712v1 Announce Type: cross Abstract: Generative Reward Models (GRMs) provide greater flexibility than scalar reward models in capturing human preferences, but their effectiveness is limited by poor reasoning capabilities. This often results in incomplete or overly speculative reasoning paths, leading to hallucinations or missing key information in complex tasks. We address this challenge with ReasonGRM, a three-stage generative reward modeling framework. In the first stage, Zero-RL is used to generate concise, outcome-directed reasoning paths that reduce the likelihood of critical omissions. In the second stage, we introduce a novel evaluation metric, $R^star$, which scores reasoning paths based on their generation likelihood. This favors paths that reach correct answers with minimal exploration, helping to reduce hallucination-prone data during training. In the final stage, the model is further refined through reinforcement learning on challenging examples to enhance its preference discrimination capabilities. Experiments on three public benchmarks show that ReasonGRM achieves competitive or state-of-the-art performance, outperforming previous best GRMs by 1.8% on average and surpassing proprietary models such as GPT-4o by up to 5.6%. These results demonstrate the effectiveness of reasoning-aware training and highlight the importance of high-quality rationale selection for reliable preference modeling.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16712",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "RecBayes: Recurrent Bayesian Ad Hoc Teamwork in Large Partially Observable Domains",
    "description": "arXiv:2506.15756v1 Announce Type: cross Abstract: This paper proposes RecBayes, a novel approach for ad hoc teamwork under partial observability, a setting where agents are deployed on-the-fly to environments where pre-existing teams operate, that never requires, at any stage, access to the states of the environment or the actions of its teammates. We show that by relying on a recurrent Bayesian classifier trained using past experiences, an ad hoc agent is effectively able to identify known teams and tasks being performed from observations alone. Unlike recent approaches such as PO-GPL (Gu et al., 2021) and FEAT (Rahman et al., 2023), that require at some stage fully observable states of the environment, actions of teammates, or both, or approaches such as ATPO (Ribeiro et al., 2023) that require the environments to be small enough to be tabularly modelled (Ribeiro et al., 2023), in their work up to 4.8K states and 1.7K observations, we show RecBayes is both able to handle arbitrarily large spaces while never relying on either states and teammates' actions. Our results in benchmark domains from the multi-agent systems literature, adapted for partial observability and scaled up to 1M states and 2^125 observations, show that RecBayes is effective at identifying known teams and tasks being performed from partial observations alone, and as a result, is able to assist the teams in solving the tasks effectively.",
    "summary": "arXiv:2506.15756v1 Announce Type: cross Abstract: This paper proposes RecBayes, a novel approach for ad hoc teamwork under partial observability, a setting where agents are deployed on-the-fly to environments where pre-existing teams operate, that never requires, at any stage, access to the states of the environment or the actions of its teammates. We show that by relying on a recurrent Bayesian classifier trained using past experiences, an ad hoc agent is effectively able to identify known teams and tasks being performed from observations alone. Unlike recent approaches such as PO-GPL (Gu et al., 2021) and FEAT (Rahman et al., 2023), that require at some stage fully observable states of the environment, actions of teammates, or both, or approaches such as ATPO (Ribeiro et al., 2023) that require the environments to be small enough to be tabularly modelled (Ribeiro et al., 2023), in their work up to 4.8K states and 1.7K observations, we show RecBayes is both able to handle arbitrarily large spaces while never relying on either states and teammates' actions. Our results in benchmark domains from the multi-agent systems literature, adapted for partial observability and scaled up to 1M states and 2^125 observations, show that RecBayes is effective at identifying known teams and tasks being performed from partial observations alone, and as a result, is able to assist the teams in solving the tasks effectively.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.15756",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Refined Causal Graph Structure Learning via Curvature for Brain Disease Classification",
    "description": "arXiv:2506.15708v1 Announce Type: cross Abstract: Graph neural networks (GNNs) have been developed to model the relationship between regions of interest (ROIs) in brains and have shown significant improvement in detecting brain diseases. However, most of these frameworks do not consider the intrinsic relationship of causality factor between brain ROIs, which is arguably more essential to observe cause and effect interaction between signals rather than typical correlation values. We propose a novel framework called CGB (Causal Graphs for Brains) for brain disease classification/detection, which models refined brain networks based on the causal discovery method, transfer entropy, and geometric curvature strategy. CGB unveils causal relationships between ROIs that bring vital information to enhance brain disease classification performance. Furthermore, CGB also performs a graph rewiring through a geometric curvature strategy to refine the generated causal graph to become more expressive and reduce potential information bottlenecks when GNNs model it. Our extensive experiments show that CGB outperforms state-of-the-art methods in classification tasks on brain disease datasets, as measured by average F1 scores.",
    "summary": "arXiv:2506.15708v1 Announce Type: cross Abstract: Graph neural networks (GNNs) have been developed to model the relationship between regions of interest (ROIs) in brains and have shown significant improvement in detecting brain diseases. However, most of these frameworks do not consider the intrinsic relationship of causality factor between brain ROIs, which is arguably more essential to observe cause and effect interaction between signals rather than typical correlation values. We propose a novel framework called CGB (Causal Graphs for Brains) for brain disease classification/detection, which models refined brain networks based on the causal discovery method, transfer entropy, and geometric curvature strategy. CGB unveils causal relationships between ROIs that bring vital information to enhance brain disease classification performance. Furthermore, CGB also performs a graph rewiring through a geometric curvature strategy to refine the generated causal graph to become more expressive and reduce potential information bottlenecks when GNNs model it. Our extensive experiments show that CGB outperforms state-of-the-art methods in classification tasks on brain disease datasets, as measured by average F1 scores.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.15708",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Refining music sample identification with a self-supervised graph neural network",
    "description": "arXiv:2506.14684v2 Announce Type: replace-cross Abstract: Automatic sample identification (ASID), the detection and identification of portions of audio recordings that have been reused in new musical works, is an essential but challenging task in the field of audio query-based retrieval. While a related task, audio fingerprinting, has made significant progress in accurately retrieving musical content under 'real world' (noisy, reverberant) conditions, ASID systems struggle to identify samples that have undergone musical modifications. Thus, a system robust to common music production transformations such as time-stretching, pitch-shifting, effects processing, and underlying or overlaying music is an important open challenge. In this work, we propose a lightweight and scalable encoding architecture employing a Graph Neural Network within a contrastive learning framework. Our model uses only 9% of the trainable parameters compared to the current state-of-the-art system while achieving comparable performance, reaching a mean average precision (mAP) of 44.2%. To enhance retrieval quality, we introduce a two-stage approach consisting of an initial coarse similarity search for candidate selection, followed by a cross-attention classifier that rejects irrelevant matches and refines the ranking of retrieved candidates - an essential capability absent in prior models. In addition, because queries in real-world applications are often short in duration, we benchmark our system for short queries using new fine-grained annotations for the Sample100 dataset, which we publish as part of this work.",
    "summary": "arXiv:2506.14684v2 Announce Type: replace-cross Abstract: Automatic sample identification (ASID), the detection and identification of portions of audio recordings that have been reused in new musical works, is an essential but challenging task in the field of audio query-based retrieval. While a related task, audio fingerprinting, has made significant progress in accurately retrieving musical content under 'real world' (noisy, reverberant) conditions, ASID systems struggle to identify samples that have undergone musical modifications. Thus, a system robust to common music production transformations such as time-stretching, pitch-shifting, effects processing, and underlying or overlaying music is an important open challenge. In this work, we propose a lightweight and scalable encoding architecture employing a Graph Neural Network within a contrastive learning framework. Our model uses only 9% of the trainable parameters compared to the current state-of-the-art system while achieving comparable performance, reaching a mean average precision (mAP) of 44.2%. To enhance retrieval quality, we introduce a two-stage approach consisting of an initial coarse similarity search for candidate selection, followed by a cross-attention classifier that rejects irrelevant matches and refines the ranking of retrieved candidates - an essential capability absent in prior models. In addition, because queries in real-world applications are often short in duration, we benchmark our system for short queries using new fine-grained annotations for the Sample100 dataset, which we publish as part of this work.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.14684",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Reimagination with Test-time Observation Interventions: Distractor-Robust World Model Predictions for Visual Model Predictive Control",
    "description": "arXiv:2506.16565v1 Announce Type: cross Abstract: World models enable robots to 'imagine' future observations given current observations and planned actions, and have been increasingly adopted as generalized dynamics models to facilitate robot learning. Despite their promise, these models remain brittle when encountering novel visual distractors such as objects and background elements rarely seen during training. Specifically, novel distractors can corrupt action outcome predictions, causing downstream failures when robots rely on the world model imaginations for planning or action verification. In this work, we propose Reimagination with Observation Intervention (ReOI), a simple yet effective test-time strategy that enables world models to predict more reliable action outcomes in open-world scenarios where novel and unanticipated visual distractors are inevitable. Given the current robot observation, ReOI first detects visual distractors by identifying which elements of the scene degrade in physically implausible ways during world model prediction. Then, it modifies the current observation to remove these distractors and bring the observation closer to the training distribution. Finally, ReOI 'reimagines' future outcomes with the modified observation and reintroduces the distractors post-hoc to preserve visual consistency for downstream planning and verification. We validate our approach on a suite of robotic manipulation tasks in the context of action verification, where the verifier needs to select desired action plans based on predictions from a world model. Our results show that ReOI is robust to both in-distribution and out-of-distribution visual distractors. Notably, it improves task success rates by up to 3x in the presence of novel distractors, significantly outperforming action verification that relies on world model predictions without imagination interventions.",
    "summary": "arXiv:2506.16565v1 Announce Type: cross Abstract: World models enable robots to 'imagine' future observations given current observations and planned actions, and have been increasingly adopted as generalized dynamics models to facilitate robot learning. Despite their promise, these models remain brittle when encountering novel visual distractors such as objects and background elements rarely seen during training. Specifically, novel distractors can corrupt action outcome predictions, causing downstream failures when robots rely on the world model imaginations for planning or action verification. In this work, we propose Reimagination with Observation Intervention (ReOI), a simple yet effective test-time strategy that enables world models to predict more reliable action outcomes in open-world scenarios where novel and unanticipated visual distractors are inevitable. Given the current robot observation, ReOI first detects visual distractors by identifying which elements of the scene degrade in physically implausible ways during world model prediction. Then, it modifies the current observation to remove these distractors and bring the observation closer to the training distribution. Finally, ReOI 'reimagines' future outcomes with the modified observation and reintroduces the distractors post-hoc to preserve visual consistency for downstream planning and verification. We validate our approach on a suite of robotic manipulation tasks in the context of action verification, where the verifier needs to select desired action plans based on predictions from a world model. Our results show that ReOI is robust to both in-distribution and out-of-distribution visual distractors. Notably, it improves task success rates by up to 3x in the presence of novel distractors, significantly outperforming action verification that relies on world model predictions without imagination interventions.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16565",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Reinforcement learning for hybrid charging stations planning and operation considering fixed and mobile chargers",
    "description": "arXiv:2506.16764v1 Announce Type: new Abstract: The success of vehicle electrification, which brings significant societal and environmental benefits, is contingent upon the availability of efficient and adaptable charging infrastructure. Traditional fixed-location charging stations often face issues like underutilization or congestion due to the dynamic nature of charging demand. Mobile chargers have emerged as a flexible solution, capable of relocating to align with these demand fluctuations. This paper addresses the optimal planning and operation of hybrid charging infrastructures, integrating both fixed and mobile chargers within urban road networks. We introduce the Hybrid Charging Station Planning and Operation (HCSPO) problem, which simultaneously optimizes the location and configuration of fixed charging stations and schedules mobile chargers for dynamic operations. Our approach incorporates a charging demand prediction model grounded in Model Predictive Control (MPC) to enhance decision-making. To solve the HCSPO problem, we propose a deep reinforcement learning method, augmented with heuristic scheduling techniques, to effectively bridge the planning of fixed chargers with the real-time operation of mobile chargers. Extensive case studies using real-world urban scenarios demonstrate that our method significantly improves the availability of charging infrastructure and reduces user inconvenience compared to existing solutions and baselines.",
    "summary": "arXiv:2506.16764v1 Announce Type: new Abstract: The success of vehicle electrification, which brings significant societal and environmental benefits, is contingent upon the availability of efficient and adaptable charging infrastructure. Traditional fixed-location charging stations often face issues like underutilization or congestion due to the dynamic nature of charging demand. Mobile chargers have emerged as a flexible solution, capable of relocating to align with these demand fluctuations. This paper addresses the optimal planning and operation of hybrid charging infrastructures, integrating both fixed and mobile chargers within urban road networks. We introduce the Hybrid Charging Station Planning and Operation (HCSPO) problem, which simultaneously optimizes the location and configuration of fixed charging stations and schedules mobile chargers for dynamic operations. Our approach incorporates a charging demand prediction model grounded in Model Predictive Control (MPC) to enhance decision-making. To solve the HCSPO problem, we propose a deep reinforcement learning method, augmented with heuristic scheduling techniques, to effectively bridge the planning of fixed chargers with the real-time operation of mobile chargers. Extensive case studies using real-world urban scenarios demonstrate that our method significantly improves the availability of charging infrastructure and reduces user inconvenience compared to existing solutions and baselines.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16764",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Reinforcing Spatial Reasoning in Vision-Language Models with Interwoven Thinking and Visual Drawing",
    "description": "arXiv:2506.09965v2 Announce Type: replace-cross Abstract: As textual reasoning with large language models (LLMs) has advanced significantly, there has been growing interest in enhancing the multimodal reasoning capabilities of large vision-language models (LVLMs). However, existing methods primarily approach multimodal reasoning in a straightforward, text-centric manner, where both reasoning and answer derivation are conducted purely through text, with the only difference being the presence of multimodal input. As a result, these methods often encounter fundamental limitations in spatial reasoning tasks that demand precise geometric understanding and continuous spatial tracking-capabilities that humans achieve through mental visualization and manipulation. To address the limitations, we propose drawing to reason in space, a novel paradigm that enables LVLMs to reason through elementary drawing operations in the visual space. By equipping models with basic drawing operations, including annotating bounding boxes and drawing auxiliary lines, we empower them to express and analyze spatial relationships through direct visual manipulation, meanwhile avoiding the performance ceiling imposed by specialized perception tools in previous tool-integrated reasoning approaches. To cultivate this capability, we develop a three-stage training framework: cold-start training with synthetic data to establish basic drawing abilities, reflective rejection sampling to enhance self-reflection behaviors, and reinforcement learning to directly optimize for target rewards. Extensive experiments demonstrate that our model, named VILASR, consistently outperforms existing methods across diverse spatial reasoning benchmarks, involving maze navigation, static spatial reasoning, video-based reasoning, and multi-view-based reasoning tasks, with an average improvement of 18.4%.",
    "summary": "arXiv:2506.09965v2 Announce Type: replace-cross Abstract: As textual reasoning with large language models (LLMs) has advanced significantly, there has been growing interest in enhancing the multimodal reasoning capabilities of large vision-language models (LVLMs). However, existing methods primarily approach multimodal reasoning in a straightforward, text-centric manner, where both reasoning and answer derivation are conducted purely through text, with the only difference being the presence of multimodal input. As a result, these methods often encounter fundamental limitations in spatial reasoning tasks that demand precise geometric understanding and continuous spatial tracking-capabilities that humans achieve through mental visualization and manipulation. To address the limitations, we propose drawing to reason in space, a novel paradigm that enables LVLMs to reason through elementary drawing operations in the visual space. By equipping models with basic drawing operations, including annotating bounding boxes and drawing auxiliary lines, we empower them to express and analyze spatial relationships through direct visual manipulation, meanwhile avoiding the performance ceiling imposed by specialized perception tools in previous tool-integrated reasoning approaches. To cultivate this capability, we develop a three-stage training framework: cold-start training with synthetic data to establish basic drawing abilities, reflective rejection sampling to enhance self-reflection behaviors, and reinforcement learning to directly optimize for target rewards. Extensive experiments demonstrate that our model, named VILASR, consistently outperforms existing methods across diverse spatial reasoning benchmarks, involving maze navigation, static spatial reasoning, video-based reasoning, and multi-view-based reasoning tasks, with an average improvement of 18.4%.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.09965",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Relational Deep Learning: Challenges, Foundations and Next-Generation Architectures",
    "description": "arXiv:2506.16654v1 Announce Type: cross Abstract: Graph machine learning has led to a significant increase in the capabilities of models that learn on arbitrary graph-structured data and has been applied to molecules, social networks, recommendation systems, and transportation, among other domains. Data in multi-tabular relational databases can also be constructed as 'relational entity graphs' for Relational Deep Learning (RDL) - a new blueprint that enables end-to-end representation learning without traditional feature engineering. Compared to arbitrary graph-structured data, relational entity graphs have key properties: (i) their structure is defined by primary-foreign key relationships between entities in different tables, (ii) the structural connectivity is a function of the relational schema defining a database, and (iii) the graph connectivity is temporal and heterogeneous in nature. In this paper, we provide a comprehensive review of RDL by first introducing the representation of relational databases as relational entity graphs, and then reviewing public benchmark datasets that have been used to develop and evaluate recent GNN-based RDL models. We discuss key challenges including large-scale multi-table integration and the complexities of modeling temporal dynamics and heterogeneous data, while also surveying foundational neural network methods and recent architectural advances specialized for relational entity graphs. Finally, we explore opportunities to unify these distinct modeling challenges, highlighting how RDL converges multiple sub-fields in graph machine learning towards the design of foundation models that can transform the processing of relational data.",
    "summary": "arXiv:2506.16654v1 Announce Type: cross Abstract: Graph machine learning has led to a significant increase in the capabilities of models that learn on arbitrary graph-structured data and has been applied to molecules, social networks, recommendation systems, and transportation, among other domains. Data in multi-tabular relational databases can also be constructed as 'relational entity graphs' for Relational Deep Learning (RDL) - a new blueprint that enables end-to-end representation learning without traditional feature engineering. Compared to arbitrary graph-structured data, relational entity graphs have key properties: (i) their structure is defined by primary-foreign key relationships between entities in different tables, (ii) the structural connectivity is a function of the relational schema defining a database, and (iii) the graph connectivity is temporal and heterogeneous in nature. In this paper, we provide a comprehensive review of RDL by first introducing the representation of relational databases as relational entity graphs, and then reviewing public benchmark datasets that have been used to develop and evaluate recent GNN-based RDL models. We discuss key challenges including large-scale multi-table integration and the complexities of modeling temporal dynamics and heterogeneous data, while also surveying foundational neural network methods and recent architectural advances specialized for relational entity graphs. Finally, we explore opportunities to unify these distinct modeling challenges, highlighting how RDL converges multiple sub-fields in graph machine learning towards the design of foundation models that can transform the processing of relational data.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16654",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Reliable Few-shot Learning under Dual Noises",
    "description": "arXiv:2506.16330v1 Announce Type: cross Abstract: Recent advances in model pre-training give rise to task adaptation-based few-shot learning (FSL), where the goal is to adapt a pre-trained task-agnostic model for capturing task-specific knowledge with a few-labeled support samples of the target task.Nevertheless, existing approaches may still fail in the open world due to the inevitable in-distribution (ID) and out-of-distribution (OOD) noise from both support and query samples of the target task. With limited support samples available, i) the adverse effect of the dual noises can be severely amplified during task adaptation, and ii) the adapted model can produce unreliable predictions on query samples in the presence of the dual noises. In this work, we propose DEnoised Task Adaptation (DETA++) for reliable FSL. DETA++ uses a Contrastive Relevance Aggregation (CoRA) module to calculate image and region weights for support samples, based on which a clean prototype loss and a noise entropy maximization loss are proposed to achieve noise-robust task adaptation. Additionally,DETA++ employs a memory bank to store and refine clean regions for each inner-task class, based on which a Local Nearest Centroid Classifier (LocalNCC) is devised to yield noise-robust predictions on query samples. Moreover, DETA++ utilizes an Intra-class Region Swapping (IntraSwap) strategy to rectify ID class prototypes during task adaptation, enhancing the model's robustness to the dual noises. Extensive experiments demonstrate the effectiveness and flexibility of DETA++.",
    "summary": "arXiv:2506.16330v1 Announce Type: cross Abstract: Recent advances in model pre-training give rise to task adaptation-based few-shot learning (FSL), where the goal is to adapt a pre-trained task-agnostic model for capturing task-specific knowledge with a few-labeled support samples of the target task.Nevertheless, existing approaches may still fail in the open world due to the inevitable in-distribution (ID) and out-of-distribution (OOD) noise from both support and query samples of the target task. With limited support samples available, i) the adverse effect of the dual noises can be severely amplified during task adaptation, and ii) the adapted model can produce unreliable predictions on query samples in the presence of the dual noises. In this work, we propose DEnoised Task Adaptation (DETA++) for reliable FSL. DETA++ uses a Contrastive Relevance Aggregation (CoRA) module to calculate image and region weights for support samples, based on which a clean prototype loss and a noise entropy maximization loss are proposed to achieve noise-robust task adaptation. Additionally,DETA++ employs a memory bank to store and refine clean regions for each inner-task class, based on which a Local Nearest Centroid Classifier (LocalNCC) is devised to yield noise-robust predictions on query samples. Moreover, DETA++ utilizes an Intra-class Region Swapping (IntraSwap) strategy to rectify ID class prototypes during task adaptation, enhancing the model's robustness to the dual noises. Extensive experiments demonstrate the effectiveness and flexibility of DETA++.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16330",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Relic: Enhancing Reward Model Generalization for Low-Resource Indic Languages with Few-Shot Examples",
    "description": "arXiv:2506.16502v1 Announce Type: cross Abstract: Reward models are essential for aligning large language models (LLMs) with human preferences. However, most open-source multilingual reward models are primarily trained on preference datasets in high-resource languages, resulting in unreliable reward signals for low-resource Indic languages. Collecting large-scale, high-quality preference data for these languages is prohibitively expensive, making preference-based training approaches impractical. To address this challenge, we propose RELIC, a novel in-context learning framework for reward modeling in low-resource Indic languages. RELIC trains a retriever with a pairwise ranking objective to select in-context examples from auxiliary high-resource languages that most effectively highlight the distinction between preferred and less-preferred responses. Extensive experiments on three preference datasets- PKU-SafeRLHF, WebGPT, and HH-RLHF-using state-of-the-art open-source reward models demonstrate that RELIC significantly improves reward model accuracy for low-resource Indic languages, consistently outperforming existing example selection methods. For example, on Bodo-a low-resource Indic language-using a LLaMA-3.2-3B reward model, RELIC achieves a 12.81% and 10.13% improvement in accuracy over zero-shot prompting and state-of-the-art example selection method, respectively.",
    "summary": "arXiv:2506.16502v1 Announce Type: cross Abstract: Reward models are essential for aligning large language models (LLMs) with human preferences. However, most open-source multilingual reward models are primarily trained on preference datasets in high-resource languages, resulting in unreliable reward signals for low-resource Indic languages. Collecting large-scale, high-quality preference data for these languages is prohibitively expensive, making preference-based training approaches impractical. To address this challenge, we propose RELIC, a novel in-context learning framework for reward modeling in low-resource Indic languages. RELIC trains a retriever with a pairwise ranking objective to select in-context examples from auxiliary high-resource languages that most effectively highlight the distinction between preferred and less-preferred responses. Extensive experiments on three preference datasets- PKU-SafeRLHF, WebGPT, and HH-RLHF-using state-of-the-art open-source reward models demonstrate that RELIC significantly improves reward model accuracy for low-resource Indic languages, consistently outperforming existing example selection methods. For example, on Bodo-a low-resource Indic language-using a LLaMA-3.2-3B reward model, RELIC achieves a 12.81% and 10.13% improvement in accuracy over zero-shot prompting and state-of-the-art example selection method, respectively.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16502",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Representation Learning of Point Cloud Upsampling in Global and Local Inputs",
    "description": "arXiv:2501.07076v3 Announce Type: replace-cross Abstract: In recent years, point cloud upsampling has been widely applied in tasks such as 3D reconstruction and object recognition. This study proposed a novel framework, ReLPU, which enhances upsampling performance by explicitly learning from both global and local structural features of point clouds. Specifically, we extracted global features from uniformly segmented inputs (Average Segments) and local features from patch-based inputs of the same point cloud. These two types of features were processed through parallel autoencoders, fused, and then fed into a shared decoder for upsampling. This dual-input design improved feature completeness and cross-scale consistency, especially in sparse and noisy regions. Our framework was applied to several state-of-the-art autoencoder-based networks and validated on standard datasets. Experimental results demonstrated consistent improvements in geometric fidelity and robustness. In addition, saliency maps confirmed that parallel global-local learning significantly enhanced the interpretability and performance of point cloud upsampling.",
    "summary": "arXiv:2501.07076v3 Announce Type: replace-cross Abstract: In recent years, point cloud upsampling has been widely applied in tasks such as 3D reconstruction and object recognition. This study proposed a novel framework, ReLPU, which enhances upsampling performance by explicitly learning from both global and local structural features of point clouds. Specifically, we extracted global features from uniformly segmented inputs (Average Segments) and local features from patch-based inputs of the same point cloud. These two types of features were processed through parallel autoencoders, fused, and then fed into a shared decoder for upsampling. This dual-input design improved feature completeness and cross-scale consistency, especially in sparse and noisy regions. Our framework was applied to several state-of-the-art autoencoder-based networks and validated on standard datasets. Experimental results demonstrated consistent improvements in geometric fidelity and robustness. In addition, saliency maps confirmed that parallel global-local learning significantly enhanced the interpretability and performance of point cloud upsampling.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2501.07076",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Representation Learning with Mutual Influence of Modalities for Node Classification in Multi-Modal Heterogeneous Networks",
    "description": "arXiv:2505.07895v3 Announce Type: replace-cross Abstract: Nowadays, numerous online platforms can be described as multi-modal heterogeneous networks (MMHNs), such as Douban's movie networks and Amazon's product review networks. Accurately categorizing nodes within these networks is crucial for analyzing the corresponding entities, which requires effective representation learning on nodes. However, existing multi-modal fusion methods often adopt either early fusion strategies which may lose the unique characteristics of individual modalities, or late fusion approaches overlooking the cross-modal guidance in GNN-based information propagation. In this paper, we propose a novel model for node classification in MMHNs, named Heterogeneous Graph Neural Network with Inter-Modal Attention (HGNN-IMA). It learns node representations by capturing the mutual influence of multiple modalities during the information propagation process, within the framework of heterogeneous graph transformer. Specifically, a nested inter-modal attention mechanism is integrated into the inter-node attention to achieve adaptive multi-modal fusion, and modality alignment is also taken into account to encourage the propagation among nodes with consistent similarities across all modalities. Moreover, an attention loss is augmented to mitigate the impact of missing modalities. Extensive experiments validate the superiority of the model in the node classification task, providing an innovative view to handle multi-modal data, especially when accompanied with network structures.",
    "summary": "arXiv:2505.07895v3 Announce Type: replace-cross Abstract: Nowadays, numerous online platforms can be described as multi-modal heterogeneous networks (MMHNs), such as Douban's movie networks and Amazon's product review networks. Accurately categorizing nodes within these networks is crucial for analyzing the corresponding entities, which requires effective representation learning on nodes. However, existing multi-modal fusion methods often adopt either early fusion strategies which may lose the unique characteristics of individual modalities, or late fusion approaches overlooking the cross-modal guidance in GNN-based information propagation. In this paper, we propose a novel model for node classification in MMHNs, named Heterogeneous Graph Neural Network with Inter-Modal Attention (HGNN-IMA). It learns node representations by capturing the mutual influence of multiple modalities during the information propagation process, within the framework of heterogeneous graph transformer. Specifically, a nested inter-modal attention mechanism is integrated into the inter-node attention to achieve adaptive multi-modal fusion, and modality alignment is also taken into account to encourage the propagation among nodes with consistent similarities across all modalities. Moreover, an attention loss is augmented to mitigate the impact of missing modalities. Extensive experiments validate the superiority of the model in the node classification task, providing an innovative view to handle multi-modal data, especially when accompanied with network structures.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2505.07895",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Rethinking External Slow-Thinking: From Snowball Errors to Probability of Correct Reasoning",
    "description": "arXiv:2501.15602v3 Announce Type: replace Abstract: Test-time scaling, which is also often referred to as slow-thinking, has been demonstrated to enhance multi-step reasoning in large language models (LLMs). However, despite its widespread utilization, the mechanisms underlying slow-thinking methods remain poorly understood. This paper explores the mechanisms of external slow-thinking from a theoretical standpoint. We begin by examining the snowball error effect within the LLM reasoning process and connect it to the likelihood of correct reasoning using information theory. Building on this, we show that external slow-thinking methods can be interpreted as strategies to mitigate the error probability. We further provide a comparative analysis of popular external slow-thinking approaches, ranging from simple to complex, highlighting their differences and interrelationships. Our findings suggest that the efficacy of these methods is not primarily determined by the specific framework employed, and that expanding the search scope or the model's internal reasoning capacity may yield more sustained improvements in the long term. We open-source our code at https://github.com/ZyGan1999/Snowball-Errors-and-Probability.",
    "summary": "arXiv:2501.15602v3 Announce Type: replace Abstract: Test-time scaling, which is also often referred to as slow-thinking, has been demonstrated to enhance multi-step reasoning in large language models (LLMs). However, despite its widespread utilization, the mechanisms underlying slow-thinking methods remain poorly understood. This paper explores the mechanisms of external slow-thinking from a theoretical standpoint. We begin by examining the snowball error effect within the LLM reasoning process and connect it to the likelihood of correct reasoning using information theory. Building on this, we show that external slow-thinking methods can be interpreted as strategies to mitigate the error probability. We further provide a comparative analysis of popular external slow-thinking approaches, ranging from simple to complex, highlighting their differences and interrelationships. Our findings suggest that the efficacy of these methods is not primarily determined by the specific framework employed, and that expanding the search scope or the model's internal reasoning capacity may yield more sustained improvements in the long term. We open-source our code at https://github.com/ZyGan1999/Snowball-Errors-and-Probability.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2501.15602",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Rethinking Fine-Tuning when Scaling Test-Time Compute: Limiting Confidence Improves Mathematical Reasoning",
    "description": "arXiv:2502.07154v3 Announce Type: replace-cross Abstract: Recent progress in large language models (LLMs) highlights the power of scaling test-time compute to achieve strong performance on complex tasks, such as mathematical reasoning and code generation. This raises a critical question: how should model training be modified to optimize performance under a subsequent test-time compute strategy and budget? To explore this, we focus on pass@N, a simple test-time strategy that searches for a correct answer in $N$ independent samples. We show, surprisingly, that training with cross-entropy (CE) loss can be ${it misaligned}$ with pass@N in that pass@N accuracy ${it decreases}$ with longer training. We explain the origins of this misalignment in terms of model overconfidence induced by CE, and experimentally verify our prediction of overconfidence as an impediment to scaling test-time compute via pass@N. Furthermore we suggest a principled, modified training loss that is better aligned to pass@N by limiting model confidence and rescuing pass@N test performance. Our algorithm demonstrates improved mathematical reasoning on MATH and MiniF2F benchmarks under several scenarios: (1) providing answers to math questions; and (2) proving theorems by searching over proof trees of varying shapes. Overall our work underscores the importance of co-designing two traditionally separate phases of LLM development: training-time protocols and test-time search and reasoning strategies.",
    "summary": "arXiv:2502.07154v3 Announce Type: replace-cross Abstract: Recent progress in large language models (LLMs) highlights the power of scaling test-time compute to achieve strong performance on complex tasks, such as mathematical reasoning and code generation. This raises a critical question: how should model training be modified to optimize performance under a subsequent test-time compute strategy and budget? To explore this, we focus on pass@N, a simple test-time strategy that searches for a correct answer in $N$ independent samples. We show, surprisingly, that training with cross-entropy (CE) loss can be ${it misaligned}$ with pass@N in that pass@N accuracy ${it decreases}$ with longer training. We explain the origins of this misalignment in terms of model overconfidence induced by CE, and experimentally verify our prediction of overconfidence as an impediment to scaling test-time compute via pass@N. Furthermore we suggest a principled, modified training loss that is better aligned to pass@N by limiting model confidence and rescuing pass@N test performance. Our algorithm demonstrates improved mathematical reasoning on MATH and MiniF2F benchmarks under several scenarios: (1) providing answers to math questions; and (2) proving theorems by searching over proof trees of varying shapes. Overall our work underscores the importance of co-designing two traditionally separate phases of LLM development: training-time protocols and test-time search and reasoning strategies.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2502.07154",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Revisiting Multi-Agent Debate as Test-Time Scaling: A Systematic Study of Conditional Effectiveness",
    "description": "arXiv:2505.22960v2 Announce Type: replace Abstract: The remarkable growth in large language model (LLM) capabilities has spurred exploration into multi-agent systems, with debate frameworks emerging as a promising avenue for enhanced problem-solving. These multi-agent debate (MAD) approaches, where agents collaboratively present, critique, and refine arguments, potentially offer improved reasoning, robustness, and diverse perspectives over monolithic models. Despite prior studies leveraging MAD, a systematic understanding of its effectiveness compared to self-agent methods, particularly under varying conditions, remains elusive. This paper seeks to fill this gap by conceptualizing MAD as a test-time computational scaling technique, distinguished by collaborative refinement and diverse exploration capabilities. We conduct a comprehensive empirical investigation comparing MAD with strong self-agent test-time scaling baselines on mathematical reasoning and safety-related tasks. Our study systematically examines the influence of task difficulty, model scale, and agent diversity on MAD's performance. Key findings reveal that, for mathematical reasoning, MAD offers limited advantages over self-agent scaling but becomes more effective with increased problem difficulty and decreased model capability, while agent diversity shows little benefit. Conversely, for safety tasks, MAD's collaborative refinement can increase vulnerability, but incorporating diverse agent configurations facilitates a gradual reduction in attack success through the collaborative refinement process. We believe our findings provide critical guidance for the future development of more effective and strategically deployed MAD systems.",
    "summary": "arXiv:2505.22960v2 Announce Type: replace Abstract: The remarkable growth in large language model (LLM) capabilities has spurred exploration into multi-agent systems, with debate frameworks emerging as a promising avenue for enhanced problem-solving. These multi-agent debate (MAD) approaches, where agents collaboratively present, critique, and refine arguments, potentially offer improved reasoning, robustness, and diverse perspectives over monolithic models. Despite prior studies leveraging MAD, a systematic understanding of its effectiveness compared to self-agent methods, particularly under varying conditions, remains elusive. This paper seeks to fill this gap by conceptualizing MAD as a test-time computational scaling technique, distinguished by collaborative refinement and diverse exploration capabilities. We conduct a comprehensive empirical investigation comparing MAD with strong self-agent test-time scaling baselines on mathematical reasoning and safety-related tasks. Our study systematically examines the influence of task difficulty, model scale, and agent diversity on MAD's performance. Key findings reveal that, for mathematical reasoning, MAD offers limited advantages over self-agent scaling but becomes more effective with increased problem difficulty and decreased model capability, while agent diversity shows little benefit. Conversely, for safety tasks, MAD's collaborative refinement can increase vulnerability, but incorporating diverse agent configurations facilitates a gradual reduction in attack success through the collaborative refinement process. We believe our findings provide critical guidance for the future development of more effective and strategically deployed MAD systems.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2505.22960",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "RiOSWorld: Benchmarking the Risk of Multimodal Computer-Use Agents",
    "description": "arXiv:2506.00618v3 Announce Type: replace Abstract: With the rapid development of multimodal large language models (MLLMs), they are increasingly deployed as autonomous computer-use agents capable of accomplishing complex computer tasks. However, a pressing issue arises: Can the safety risk principles designed and aligned for general MLLMs in dialogue scenarios be effectively transferred to real-world computer-use scenarios? Existing research on evaluating the safety risks of MLLM-based computer-use agents suffers from several limitations: it either lacks realistic interactive environments, or narrowly focuses on one or a few specific risk types. These limitations ignore the complexity, variability, and diversity of real-world environments, thereby restricting comprehensive risk evaluation for computer-use agents. To this end, we introduce textbf{RiOSWorld}, a benchmark designed to evaluate the potential risks of MLLM-based agents during real-world computer manipulations. Our benchmark includes 492 risky tasks spanning various computer applications, involving web, social media, multimedia, os, email, and office software. We categorize these risks into two major classes based on their risk source: (i) User-originated risks and (ii) Environmental risks. For the evaluation, we evaluate safety risks from two perspectives: (i) Risk goal intention and (ii) Risk goal completion. Extensive experiments with multimodal agents on textbf{RiOSWorld} demonstrate that current computer-use agents confront significant safety risks in real-world scenarios. Our findings highlight the necessity and urgency of safety alignment for computer-use agents in real-world computer manipulation, providing valuable insights for developing trustworthy computer-use agents. Our benchmark is publicly available at https://yjyddq.github.io/RiOSWorld.github.io/.",
    "summary": "arXiv:2506.00618v3 Announce Type: replace Abstract: With the rapid development of multimodal large language models (MLLMs), they are increasingly deployed as autonomous computer-use agents capable of accomplishing complex computer tasks. However, a pressing issue arises: Can the safety risk principles designed and aligned for general MLLMs in dialogue scenarios be effectively transferred to real-world computer-use scenarios? Existing research on evaluating the safety risks of MLLM-based computer-use agents suffers from several limitations: it either lacks realistic interactive environments, or narrowly focuses on one or a few specific risk types. These limitations ignore the complexity, variability, and diversity of real-world environments, thereby restricting comprehensive risk evaluation for computer-use agents. To this end, we introduce textbf{RiOSWorld}, a benchmark designed to evaluate the potential risks of MLLM-based agents during real-world computer manipulations. Our benchmark includes 492 risky tasks spanning various computer applications, involving web, social media, multimedia, os, email, and office software. We categorize these risks into two major classes based on their risk source: (i) User-originated risks and (ii) Environmental risks. For the evaluation, we evaluate safety risks from two perspectives: (i) Risk goal intention and (ii) Risk goal completion. Extensive experiments with multimodal agents on textbf{RiOSWorld} demonstrate that current computer-use agents confront significant safety risks in real-world scenarios. Our findings highlight the necessity and urgency of safety alignment for computer-use agents in real-world computer manipulation, providing valuable insights for developing trustworthy computer-use agents. Our benchmark is publicly available at https://yjyddq.github.io/RiOSWorld.github.io/.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.00618",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "RL2Grid: Benchmarking Reinforcement Learning in Power Grid Operations",
    "description": "arXiv:2503.23101v2 Announce Type: replace-cross Abstract: Reinforcement learning (RL) can provide adaptive and scalable controllers essential for power grid decarbonization. However, RL methods struggle with power grids' complex dynamics, long-horizon goals, and hard physical constraints. For these reasons, we present RL2Grid, a benchmark designed in collaboration with power system operators to accelerate progress in grid control and foster RL maturity. Built on RTE France's power simulation framework, RL2Grid standardizes tasks, state and action spaces, and reward structures for a systematic evaluation and comparison of RL algorithms. Moreover, we integrate operational heuristics and design safety constraints based on human expertise to ensure alignment with physical requirements. By establishing reference performance metrics for classic RL baselines on RL2Grid's tasks, we highlight the need for novel methods capable of handling real systems and discuss future directions for RL-based grid control.",
    "summary": "arXiv:2503.23101v2 Announce Type: replace-cross Abstract: Reinforcement learning (RL) can provide adaptive and scalable controllers essential for power grid decarbonization. However, RL methods struggle with power grids' complex dynamics, long-horizon goals, and hard physical constraints. For these reasons, we present RL2Grid, a benchmark designed in collaboration with power system operators to accelerate progress in grid control and foster RL maturity. Built on RTE France's power simulation framework, RL2Grid standardizes tasks, state and action spaces, and reward structures for a systematic evaluation and comparison of RL algorithms. Moreover, we integrate operational heuristics and design safety constraints based on human expertise to ensure alignment with physical requirements. By establishing reference performance metrics for classic RL baselines on RL2Grid's tasks, we highlight the need for novel methods capable of handling real systems and discuss future directions for RL-based grid control.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2503.23101",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Robo2VLM: Visual Question Answering from Large-Scale In-the-Wild Robot Manipulation Datasets",
    "description": "arXiv:2505.15517v2 Announce Type: replace-cross Abstract: Vision-Language Models (VLMs) acquire real-world knowledge and general reasoning ability through Internet-scale image-text corpora. They can augment robotic systems with scene understanding and task planning, and assist visuomotor policies that are trained on robot trajectory data. We explore the reverse paradigm - using rich, real, multi-modal robot trajectory data to enhance and evaluate VLMs. In this paper, we present Robo2VLM, a Visual Question Answering (VQA) dataset generation framework for VLMs. Given a human tele-operated robot trajectory, Robo2VLM derives ground-truth from non-visual and non-descriptive sensory modalities, such as end-effector pose, gripper aperture, and force sensing. Based on these modalities, it segments the robot trajectory into a sequence of manipulation phases. At each phase, Robo2VLM uses scene and interaction understanding to identify 3D properties of the robot, task goal, and the target object. The properties are used to generate representative VQA queries - images with textural multiple-choice questions - based on spatial, goal-conditioned, and interaction reasoning question templates. We curate Robo2VLM-1, a large-scale in-the-wild dataset with 684,710 questions covering 463 distinct scenes and 3,396 robotic manipulation tasks from 176k real robot trajectories. Results suggest that Robo2VLM-1 can benchmark and improve VLM capabilities in spatial and interaction reasoning.",
    "summary": "arXiv:2505.15517v2 Announce Type: replace-cross Abstract: Vision-Language Models (VLMs) acquire real-world knowledge and general reasoning ability through Internet-scale image-text corpora. They can augment robotic systems with scene understanding and task planning, and assist visuomotor policies that are trained on robot trajectory data. We explore the reverse paradigm - using rich, real, multi-modal robot trajectory data to enhance and evaluate VLMs. In this paper, we present Robo2VLM, a Visual Question Answering (VQA) dataset generation framework for VLMs. Given a human tele-operated robot trajectory, Robo2VLM derives ground-truth from non-visual and non-descriptive sensory modalities, such as end-effector pose, gripper aperture, and force sensing. Based on these modalities, it segments the robot trajectory into a sequence of manipulation phases. At each phase, Robo2VLM uses scene and interaction understanding to identify 3D properties of the robot, task goal, and the target object. The properties are used to generate representative VQA queries - images with textural multiple-choice questions - based on spatial, goal-conditioned, and interaction reasoning question templates. We curate Robo2VLM-1, a large-scale in-the-wild dataset with 684,710 questions covering 463 distinct scenes and 3,396 robotic manipulation tasks from 176k real robot trajectories. Results suggest that Robo2VLM-1 can benchmark and improve VLM capabilities in spatial and interaction reasoning.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2505.15517",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Robust Dynamic Material Handling via Adaptive Constrained Evolutionary Reinforcement Learning",
    "description": "arXiv:2506.16795v1 Announce Type: cross Abstract: Dynamic material handling (DMH) involves the assignment of dynamically arriving material transporting tasks to suitable vehicles in real time for minimising makespan and tardiness. In real-world scenarios, historical task records are usually available, which enables the training of a decision policy on multiple instances consisting of historical records. Recently, reinforcement learning has been applied to solve DMH. Due to the occurrence of dynamic events such as new tasks, adaptability is highly required. Solving DMH is challenging since constraints including task delay should be satisfied. A feedback is received only when all tasks are served, which leads to sparse reward. Besides, making the best use of limited computational resources and historical records for training a robust policy is crucial. The time allocated to different problem instances would highly impact the learning process. To tackle those challenges, this paper proposes a novel adaptive constrained evolutionary reinforcement learning (ACERL) approach, which maintains a population of actors for diverse exploration. ACERL accesses each actor for tackling sparse rewards and constraint violation to restrict the behaviour of the policy. Moreover, ACERL adaptively selects the most beneficial training instances for improving the policy. Extensive experiments on eight training and eight unseen test instances demonstrate the outstanding performance of ACERL compared with several state-of-the-art algorithms. Policies trained by ACERL can schedule the vehicles while fully satisfying the constraints. Additional experiments on 40 unseen noised instances show the robust performance of ACERL. Cross-validation further presents the overall effectiveness of ACREL. Besides, a rigorous ablation study highlights the coordination and benefits of each ingredient of ACERL.",
    "summary": "arXiv:2506.16795v1 Announce Type: cross Abstract: Dynamic material handling (DMH) involves the assignment of dynamically arriving material transporting tasks to suitable vehicles in real time for minimising makespan and tardiness. In real-world scenarios, historical task records are usually available, which enables the training of a decision policy on multiple instances consisting of historical records. Recently, reinforcement learning has been applied to solve DMH. Due to the occurrence of dynamic events such as new tasks, adaptability is highly required. Solving DMH is challenging since constraints including task delay should be satisfied. A feedback is received only when all tasks are served, which leads to sparse reward. Besides, making the best use of limited computational resources and historical records for training a robust policy is crucial. The time allocated to different problem instances would highly impact the learning process. To tackle those challenges, this paper proposes a novel adaptive constrained evolutionary reinforcement learning (ACERL) approach, which maintains a population of actors for diverse exploration. ACERL accesses each actor for tackling sparse rewards and constraint violation to restrict the behaviour of the policy. Moreover, ACERL adaptively selects the most beneficial training instances for improving the policy. Extensive experiments on eight training and eight unseen test instances demonstrate the outstanding performance of ACERL compared with several state-of-the-art algorithms. Policies trained by ACERL can schedule the vehicles while fully satisfying the constraints. Additional experiments on 40 unseen noised instances show the robust performance of ACERL. Cross-validation further presents the overall effectiveness of ACREL. Besides, a rigorous ablation study highlights the coordination and benefits of each ingredient of ACERL.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16795",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Robust Finite-Memory Policy Gradients for Hidden-Model POMDPs",
    "description": "arXiv:2505.09518v2 Announce Type: replace Abstract: Partially observable Markov decision processes (POMDPs) model specific environments in sequential decision-making under uncertainty. Critically, optimal policies for POMDPs may not be robust against perturbations in the environment. Hidden-model POMDPs (HM-POMDPs) capture sets of different environment models, that is, POMDPs with a shared action and observation space. The intuition is that the true model is hidden among a set of potential models, and it is unknown which model will be the environment at execution time. A policy is robust for a given HM-POMDP if it achieves sufficient performance for each of its POMDPs.We compute such robust policies by combining two orthogonal techniques: (1) a deductive formal verification technique that supports tractable robust policy evaluation by computing a worst-case POMDP within the HM-POMDP, and (2) subgradient ascent to optimize the candidate policy for a worst-case POMDP. The empirical evaluation shows that, compared to various baselines, our approach (1) produces policies that are more robust and generalize better to unseen POMDPs, and (2) scales to HM-POMDPs that consist of over a hundred thousand environments.",
    "summary": "arXiv:2505.09518v2 Announce Type: replace Abstract: Partially observable Markov decision processes (POMDPs) model specific environments in sequential decision-making under uncertainty. Critically, optimal policies for POMDPs may not be robust against perturbations in the environment. Hidden-model POMDPs (HM-POMDPs) capture sets of different environment models, that is, POMDPs with a shared action and observation space. The intuition is that the true model is hidden among a set of potential models, and it is unknown which model will be the environment at execution time. A policy is robust for a given HM-POMDP if it achieves sufficient performance for each of its POMDPs.We compute such robust policies by combining two orthogonal techniques: (1) a deductive formal verification technique that supports tractable robust policy evaluation by computing a worst-case POMDP within the HM-POMDP, and (2) subgradient ascent to optimize the candidate policy for a worst-case POMDP. The empirical evaluation shows that, compared to various baselines, our approach (1) produces policies that are more robust and generalize better to unseen POMDPs, and (2) scales to HM-POMDPs that consist of over a hundred thousand environments.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2505.09518",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Robust Training with Data Augmentation for Medical Imaging Classification",
    "description": "arXiv:2506.17133v1 Announce Type: cross Abstract: Deep neural networks are increasingly being used to detect and diagnose medical conditions using medical imaging. Despite their utility, these models are highly vulnerable to adversarial attacks and distribution shifts, which can affect diagnostic reliability and undermine trust among healthcare professionals. In this study, we propose a robust training algorithm with data augmentation (RTDA) to mitigate these vulnerabilities in medical image classification. We benchmark classifier robustness against adversarial perturbations and natural variations of RTDA and six competing baseline techniques, including adversarial training and data augmentation approaches in isolation and combination, using experimental data sets with three different imaging technologies (mammograms, X-rays, and ultrasound). We demonstrate that RTDA achieves superior robustness against adversarial attacks and improved generalization performance in the presence of distribution shift in each image classification task while maintaining high clean accuracy.",
    "summary": "arXiv:2506.17133v1 Announce Type: cross Abstract: Deep neural networks are increasingly being used to detect and diagnose medical conditions using medical imaging. Despite their utility, these models are highly vulnerable to adversarial attacks and distribution shifts, which can affect diagnostic reliability and undermine trust among healthcare professionals. In this study, we propose a robust training algorithm with data augmentation (RTDA) to mitigate these vulnerabilities in medical image classification. We benchmark classifier robustness against adversarial perturbations and natural variations of RTDA and six competing baseline techniques, including adversarial training and data augmentation approaches in isolation and combination, using experimental data sets with three different imaging technologies (mammograms, X-rays, and ultrasound). We demonstrate that RTDA achieves superior robustness against adversarial attacks and improved generalization performance in the presence of distribution shift in each image classification task while maintaining high clean accuracy.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.17133",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Robustness Evaluation of OCR-based Visual Document Understanding under Multi-Modal Adversarial Attacks",
    "description": "arXiv:2506.16407v1 Announce Type: cross Abstract: Visual Document Understanding (VDU) systems have achieved strong performance in information extraction by integrating textual, layout, and visual signals. However, their robustness under realistic adversarial perturbations remains insufficiently explored. We introduce the first unified framework for generating and evaluating multi-modal adversarial attacks on OCR-based VDU models. Our method covers six gradient-based layout attack scenarios, incorporating manipulations of OCR bounding boxes, pixels, and texts across both word and line granularities, with constraints on layout perturbation budget (e.g., IoU >= 0.6) to preserve plausibility. Experimental results across four datasets (FUNSD, CORD, SROIE, DocVQA) and six model families demonstrate that line-level attacks and compound perturbations (BBox + Pixel + Text) yield the most severe performance degradation. Projected Gradient Descent (PGD)-based BBox perturbations outperform random-shift baselines in all investigated models. Ablation studies further validate the impact of layout budget, text modification, and adversarial transferability.",
    "summary": "arXiv:2506.16407v1 Announce Type: cross Abstract: Visual Document Understanding (VDU) systems have achieved strong performance in information extraction by integrating textual, layout, and visual signals. However, their robustness under realistic adversarial perturbations remains insufficiently explored. We introduce the first unified framework for generating and evaluating multi-modal adversarial attacks on OCR-based VDU models. Our method covers six gradient-based layout attack scenarios, incorporating manipulations of OCR bounding boxes, pixels, and texts across both word and line granularities, with constraints on layout perturbation budget (e.g., IoU >= 0.6) to preserve plausibility. Experimental results across four datasets (FUNSD, CORD, SROIE, DocVQA) and six model families demonstrate that line-level attacks and compound perturbations (BBox + Pixel + Text) yield the most severe performance degradation. Projected Gradient Descent (PGD)-based BBox perturbations outperform random-shift baselines in all investigated models. Ablation studies further validate the impact of layout budget, text modification, and adversarial transferability.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16407",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "SafeGenBench: A Benchmark Framework for Security Vulnerability Detection in LLM-Generated Code",
    "description": "arXiv:2506.05692v3 Announce Type: replace-cross Abstract: The code generation capabilities of large language models(LLMs) have emerged as a critical dimension in evaluating their overall performance. However, prior research has largely overlooked the security risks inherent in the generated code. In this work, we introduce SafeGenBench, a benchmark specifically designed to assess the security of LLM-generated code. The dataset encompasses a wide range of common software development scenarios and vulnerability types. Building upon this benchmark, we develop an automatic evaluation framework that leverages both static application security testing(SAST) and LLM-based judging to assess the presence of security vulnerabilities in model-generated code. Through the empirical evaluation of state-of-the-art LLMs on SafeGenBench, we reveal notable deficiencies in their ability to produce vulnerability-free code. Our findings highlight pressing challenges and offer actionable insights for future advancements in the secure code generation performance of LLMs. The data and code will be released soon.",
    "summary": "arXiv:2506.05692v3 Announce Type: replace-cross Abstract: The code generation capabilities of large language models(LLMs) have emerged as a critical dimension in evaluating their overall performance. However, prior research has largely overlooked the security risks inherent in the generated code. In this work, we introduce SafeGenBench, a benchmark specifically designed to assess the security of LLM-generated code. The dataset encompasses a wide range of common software development scenarios and vulnerability types. Building upon this benchmark, we develop an automatic evaluation framework that leverages both static application security testing(SAST) and LLM-based judging to assess the presence of security vulnerabilities in model-generated code. Through the empirical evaluation of state-of-the-art LLMs on SafeGenBench, we reveal notable deficiencies in their ability to produce vulnerability-free code. Our findings highlight pressing challenges and offer actionable insights for future advancements in the secure code generation performance of LLMs. The data and code will be released soon.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.05692",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "SafeMimic: Towards Safe and Autonomous Human-to-Robot Imitation for Mobile Manipulation",
    "description": "arXiv:2506.15847v1 Announce Type: cross Abstract: For robots to become efficient helpers in the home, they must learn to perform new mobile manipulation tasks simply by watching humans perform them. Learning from a single video demonstration from a human is challenging as the robot needs to first extract from the demo what needs to be done and how, translate the strategy from a third to a first-person perspective, and then adapt it to be successful with its own morphology. Furthermore, to mitigate the dependency on costly human monitoring, this learning process should be performed in a safe and autonomous manner. We present SafeMimic, a framework to learn new mobile manipulation skills safely and autonomously from a single third-person human video. Given an initial human video demonstration of a multi-step mobile manipulation task, SafeMimic first parses the video into segments, inferring both the semantic changes caused and the motions the human executed to achieve them and translating them to an egocentric reference. Then, it adapts the behavior to the robot's own morphology by sampling candidate actions around the human ones, and verifying them for safety before execution in a receding horizon fashion using an ensemble of safety Q-functions trained in simulation. When safe forward progression is not possible, SafeMimic backtracks to previous states and attempts a different sequence of actions, adapting both the trajectory and the grasping modes when required for its morphology. As a result, SafeMimic yields a strategy that succeeds in the demonstrated behavior and learns task-specific actions that reduce exploration in future attempts. Our experiments show that our method allows robots to safely and efficiently learn multi-step mobile manipulation behaviors from a single human demonstration, from different users, and in different environments, with improvements over state-of-the-art baselines across seven tasks",
    "summary": "arXiv:2506.15847v1 Announce Type: cross Abstract: For robots to become efficient helpers in the home, they must learn to perform new mobile manipulation tasks simply by watching humans perform them. Learning from a single video demonstration from a human is challenging as the robot needs to first extract from the demo what needs to be done and how, translate the strategy from a third to a first-person perspective, and then adapt it to be successful with its own morphology. Furthermore, to mitigate the dependency on costly human monitoring, this learning process should be performed in a safe and autonomous manner. We present SafeMimic, a framework to learn new mobile manipulation skills safely and autonomously from a single third-person human video. Given an initial human video demonstration of a multi-step mobile manipulation task, SafeMimic first parses the video into segments, inferring both the semantic changes caused and the motions the human executed to achieve them and translating them to an egocentric reference. Then, it adapts the behavior to the robot's own morphology by sampling candidate actions around the human ones, and verifying them for safety before execution in a receding horizon fashion using an ensemble of safety Q-functions trained in simulation. When safe forward progression is not possible, SafeMimic backtracks to previous states and attempts a different sequence of actions, adapting both the trajectory and the grasping modes when required for its morphology. As a result, SafeMimic yields a strategy that succeeds in the demonstrated behavior and learns task-specific actions that reduce exploration in future attempts. Our experiments show that our method allows robots to safely and efficiently learn multi-step mobile manipulation behaviors from a single human demonstration, from different users, and in different environments, with improvements over state-of-the-art baselines across seven tasks",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.15847",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Screen Hijack: Visual Poisoning of VLM Agents in Mobile Environments",
    "description": "arXiv:2506.13205v2 Announce Type: replace-cross Abstract: With the growing integration of vision-language models (VLMs), mobile agents are now widely used for tasks like UI automation and camera-based user assistance. These agents are often fine-tuned on limited user-generated datasets, leaving them vulnerable to covert threats during the training process. In this work we present GHOST, the first clean-label backdoor attack specifically designed for mobile agents built upon VLMs. Our method manipulates only the visual inputs of a portion of the training samples - without altering their corresponding labels or instructions - thereby injecting malicious behaviors into the model. Once fine-tuned with this tampered data, the agent will exhibit attacker-controlled responses when a specific visual trigger is introduced at inference time. The core of our approach lies in aligning the gradients of poisoned samples with those of a chosen target instance, embedding backdoor-relevant features into the poisoned training data. To maintain stealth and enhance robustness, we develop three realistic visual triggers: static visual patches, dynamic motion cues, and subtle low-opacity overlays. We evaluate our method across six real-world Android apps and three VLM architectures adapted for mobile use. Results show that our attack achieves high attack success rates (up to 94.67 percent) while maintaining high clean-task performance (FSR up to 95.85 percent). Additionally, ablation studies shed light on how various design choices affect the efficacy and concealment of the attack. Overall, this work is the first to expose critical security flaws in VLM-based mobile agents, highlighting their susceptibility to clean-label backdoor attacks and the urgent need for effective defense mechanisms in their training pipelines.",
    "summary": "arXiv:2506.13205v2 Announce Type: replace-cross Abstract: With the growing integration of vision-language models (VLMs), mobile agents are now widely used for tasks like UI automation and camera-based user assistance. These agents are often fine-tuned on limited user-generated datasets, leaving them vulnerable to covert threats during the training process. In this work we present GHOST, the first clean-label backdoor attack specifically designed for mobile agents built upon VLMs. Our method manipulates only the visual inputs of a portion of the training samples - without altering their corresponding labels or instructions - thereby injecting malicious behaviors into the model. Once fine-tuned with this tampered data, the agent will exhibit attacker-controlled responses when a specific visual trigger is introduced at inference time. The core of our approach lies in aligning the gradients of poisoned samples with those of a chosen target instance, embedding backdoor-relevant features into the poisoned training data. To maintain stealth and enhance robustness, we develop three realistic visual triggers: static visual patches, dynamic motion cues, and subtle low-opacity overlays. We evaluate our method across six real-world Android apps and three VLM architectures adapted for mobile use. Results show that our attack achieves high attack success rates (up to 94.67 percent) while maintaining high clean-task performance (FSR up to 95.85 percent). Additionally, ablation studies shed light on how various design choices affect the efficacy and concealment of the attack. Overall, this work is the first to expose critical security flaws in VLM-based mobile agents, highlighting their susceptibility to clean-label backdoor attacks and the urgent need for effective defense mechanisms in their training pipelines.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.13205",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "SDE-SQL: Enhancing Text-to-SQL Generation in Large Language Models via Self-Driven Exploration with SQL Probes",
    "description": "arXiv:2506.07245v2 Announce Type: replace-cross Abstract: Recent advancements in large language models (LLMs) have significantly improved performance on the Text-to-SQL task. However, prior approaches typically rely on static, pre-processed database information provided at inference time, which limits the model's ability to fully understand the database contents. Without dynamic interaction, LLMs are constrained to fixed, human-provided context and cannot autonomously explore the underlying data. To address this limitation, we propose SDE-SQL, a framework that enables large language models to perform self-driven exploration of databases during inference. This is accomplished by generating and executing SQL probes, which allow the model to actively retrieve information from the database and iteratively update its understanding of the data. Unlike prior methods, SDE-SQL operates in a zero-shot setting, without relying on any question-SQL pairs as in-context demonstrations. When evaluated on the BIRD benchmark with Qwen2.5-72B-Instruct, SDE-SQL achieves an 8.02% relative improvement in execution accuracy over the vanilla Qwen2.5-72B-Instruct baseline, establishing a new state-of-the-art among methods based on open-source models without supervised fine-tuning (SFT) or model ensembling. Moreover, with SFT, the performance of SDE-SQL can be further enhanced, yielding an additional 0.52% improvement.",
    "summary": "arXiv:2506.07245v2 Announce Type: replace-cross Abstract: Recent advancements in large language models (LLMs) have significantly improved performance on the Text-to-SQL task. However, prior approaches typically rely on static, pre-processed database information provided at inference time, which limits the model's ability to fully understand the database contents. Without dynamic interaction, LLMs are constrained to fixed, human-provided context and cannot autonomously explore the underlying data. To address this limitation, we propose SDE-SQL, a framework that enables large language models to perform self-driven exploration of databases during inference. This is accomplished by generating and executing SQL probes, which allow the model to actively retrieve information from the database and iteratively update its understanding of the data. Unlike prior methods, SDE-SQL operates in a zero-shot setting, without relying on any question-SQL pairs as in-context demonstrations. When evaluated on the BIRD benchmark with Qwen2.5-72B-Instruct, SDE-SQL achieves an 8.02% relative improvement in execution accuracy over the vanilla Qwen2.5-72B-Instruct baseline, establishing a new state-of-the-art among methods based on open-source models without supervised fine-tuning (SFT) or model ensembling. Moreover, with SFT, the performance of SDE-SQL can be further enhanced, yielding an additional 0.52% improvement.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.07245",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Segment Anything for Satellite Imagery: A Strong Baseline and a Regional Dataset for Automatic Field Delineation",
    "description": "arXiv:2506.16318v1 Announce Type: cross Abstract: Accurate mapping of agricultural field boundaries is essential for the efficient operation of agriculture. Automatic extraction from high-resolution satellite imagery, supported by computer vision techniques, can avoid costly ground surveys. In this paper, we present a pipeline for field delineation based on the Segment Anything Model (SAM), introducing a fine-tuning strategy to adapt SAM to this task. In addition to using published datasets, we describe a method for acquiring a complementary regional dataset that covers areas beyond current sources. Extensive experiments assess segmentation accuracy and evaluate the generalization capabilities. Our approach provides a robust baseline for automated field delineation. The new regional dataset, known as ERAS, is now publicly available.",
    "summary": "arXiv:2506.16318v1 Announce Type: cross Abstract: Accurate mapping of agricultural field boundaries is essential for the efficient operation of agriculture. Automatic extraction from high-resolution satellite imagery, supported by computer vision techniques, can avoid costly ground surveys. In this paper, we present a pipeline for field delineation based on the Segment Anything Model (SAM), introducing a fine-tuning strategy to adapt SAM to this task. In addition to using published datasets, we describe a method for acquiring a complementary regional dataset that covers areas beyond current sources. Extensive experiments assess segmentation accuracy and evaluate the generalization capabilities. Our approach provides a robust baseline for automated field delineation. The new regional dataset, known as ERAS, is now publicly available.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16318",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Sekai: A Video Dataset towards World Exploration",
    "description": "arXiv:2506.15675v2 Announce Type: replace-cross Abstract: Video generation techniques have made remarkable progress, promising to be the foundation of interactive world exploration. However, existing video generation datasets are not well-suited for world exploration training as they suffer from some limitations: limited locations, short duration, static scenes, and a lack of annotations about exploration and the world. In this paper, we introduce Sekai (meaning ``world'' in Japanese), a high-quality first-person view worldwide video dataset with rich annotations for world exploration. It consists of over 5,000 hours of walking or drone view (FPV and UVA) videos from over 100 countries and regions across 750 cities. We develop an efficient and effective toolbox to collect, pre-process and annotate videos with location, scene, weather, crowd density, captions, and camera trajectories. Experiments demonstrate the quality of the dataset. And, we use a subset to train an interactive video world exploration model, named YUME (meaning ``dream'' in Japanese). We believe Sekai will benefit the area of video generation and world exploration, and motivate valuable applications. The project page is https://lixsp11.github.io/sekai-project/.",
    "summary": "arXiv:2506.15675v2 Announce Type: replace-cross Abstract: Video generation techniques have made remarkable progress, promising to be the foundation of interactive world exploration. However, existing video generation datasets are not well-suited for world exploration training as they suffer from some limitations: limited locations, short duration, static scenes, and a lack of annotations about exploration and the world. In this paper, we introduce Sekai (meaning ``world'' in Japanese), a high-quality first-person view worldwide video dataset with rich annotations for world exploration. It consists of over 5,000 hours of walking or drone view (FPV and UVA) videos from over 100 countries and regions across 750 cities. We develop an efficient and effective toolbox to collect, pre-process and annotate videos with location, scene, weather, crowd density, captions, and camera trajectories. Experiments demonstrate the quality of the dataset. And, we use a subset to train an interactive video world exploration model, named YUME (meaning ``dream'' in Japanese). We believe Sekai will benefit the area of video generation and world exploration, and motivate valuable applications. The project page is https://lixsp11.github.io/sekai-project/.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.15675",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Selective Use of Yannakakis' Algorithm to Improve Query Performance: Machine Learning to the Rescue",
    "description": "arXiv:2502.20233v2 Announce Type: replace-cross Abstract: Query optimization has played a central role in database research for decades. However, more often than not, the proposed optimization techniques lead to a performance improvement in some, but not in all, situations. Therefore, we urgently need a methodology for designing a decision procedure that decides for a given query whether the optimization technique should be applied or not. In this work, we propose such a methodology with a focus on Yannakakis-style query evaluation as our optimization technique of interest. More specifically, we formulate this decision problem as an algorithm selection problem and we present a Machine Learning based approach for its solution. Empirical results with several benchmarks on a variety of database systems show that our approach indeed leads to a statistically significant performance improvement.",
    "summary": "arXiv:2502.20233v2 Announce Type: replace-cross Abstract: Query optimization has played a central role in database research for decades. However, more often than not, the proposed optimization techniques lead to a performance improvement in some, but not in all, situations. Therefore, we urgently need a methodology for designing a decision procedure that decides for a given query whether the optimization technique should be applied or not. In this work, we propose such a methodology with a focus on Yannakakis-style query evaluation as our optimization technique of interest. More specifically, we formulate this decision problem as an algorithm selection problem and we present a Machine Learning based approach for its solution. Empirical results with several benchmarks on a variety of database systems show that our approach indeed leads to a statistically significant performance improvement.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2502.20233",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "SemAgent: A Semantics Aware Program Repair Agent",
    "description": "arXiv:2506.16650v1 Announce Type: cross Abstract: Large Language Models (LLMs) have shown impressive capabilities in downstream software engineering tasks such as Automated Program Repair (APR). In particular, there has been a lot of research on repository-level issue-resolution benchmarks such as SWE-Bench. Although there has been significant progress on this topic, we notice that in the process of solving such issues, existing agentic systems tend to hyper-localize on immediately suspicious lines of code and fix them in isolation, without a deeper understanding of the issue semantics, code semantics, or execution semantics. Consequently, many existing systems generate patches that overfit to the user issue, even when a more general fix is preferable. To address this limitation, we introduce SemAgent, a novel workflow-based procedure that leverages issue, code, and execution semantics to generate patches that are complete - identifying and fixing all lines relevant to the issue. We achieve this through a novel pipeline that (a) leverages execution semantics to retrieve relevant context, (b) comprehends issue-semantics via generalized abstraction, (c) isolates code-semantics within the context of this abstraction, and (d) leverages this understanding in a two-stage architecture: a repair stage that proposes fine-grained fixes, followed by a reviewer stage that filters relevant fixes based on the inferred issue-semantics. Our evaluations show that our methodology achieves a solve rate of 44.66% on the SWEBench-Lite benchmark beating all other workflow-based approaches, and an absolute improvement of 7.66% compared to our baseline, which lacks such deep semantic understanding. We note that our approach performs particularly well on issues requiring multi-line reasoning (and editing) and edge-case handling, suggesting that incorporating issue and code semantics into APR pipelines can lead to robust and semantically consistent repairs.",
    "summary": "arXiv:2506.16650v1 Announce Type: cross Abstract: Large Language Models (LLMs) have shown impressive capabilities in downstream software engineering tasks such as Automated Program Repair (APR). In particular, there has been a lot of research on repository-level issue-resolution benchmarks such as SWE-Bench. Although there has been significant progress on this topic, we notice that in the process of solving such issues, existing agentic systems tend to hyper-localize on immediately suspicious lines of code and fix them in isolation, without a deeper understanding of the issue semantics, code semantics, or execution semantics. Consequently, many existing systems generate patches that overfit to the user issue, even when a more general fix is preferable. To address this limitation, we introduce SemAgent, a novel workflow-based procedure that leverages issue, code, and execution semantics to generate patches that are complete - identifying and fixing all lines relevant to the issue. We achieve this through a novel pipeline that (a) leverages execution semantics to retrieve relevant context, (b) comprehends issue-semantics via generalized abstraction, (c) isolates code-semantics within the context of this abstraction, and (d) leverages this understanding in a two-stage architecture: a repair stage that proposes fine-grained fixes, followed by a reviewer stage that filters relevant fixes based on the inferred issue-semantics. Our evaluations show that our methodology achieves a solve rate of 44.66% on the SWEBench-Lite benchmark beating all other workflow-based approaches, and an absolute improvement of 7.66% compared to our baseline, which lacks such deep semantic understanding. We note that our approach performs particularly well on issues requiring multi-line reasoning (and editing) and edge-case handling, suggesting that incorporating issue and code semantics into APR pipelines can lead to robust and semantically consistent repairs.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16650",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Semantic Preprocessing for LLM-based Malware Analysis",
    "description": "arXiv:2506.12113v2 Announce Type: replace-cross Abstract: In a context of malware analysis, numerous approaches rely on Artificial Intelligence to handle a large volume of data. However, these techniques focus on data view (images, sequences) and not on an expert's view. Noticing this issue, we propose a preprocessing that focuses on expert knowledge to improve malware semantic analysis and result interpretability. We propose a new preprocessing method which creates JSON reports for Portable Executable files. These reports gather features from both static and behavioral analysis, and incorporate packer signature detection, MITRE ATT&amp;CK and Malware Behavior Catalog (MBC) knowledge. The purpose of this preprocessing is to gather a semantic representation of binary files, understandable by malware analysts, and that can enhance AI models' explainability for malicious files analysis. Using this preprocessing to train a Large Language Model for Malware classification, we achieve a weighted-average F1-score of 0.94 on a complex dataset, representative of market reality.",
    "summary": "arXiv:2506.12113v2 Announce Type: replace-cross Abstract: In a context of malware analysis, numerous approaches rely on Artificial Intelligence to handle a large volume of data. However, these techniques focus on data view (images, sequences) and not on an expert's view. Noticing this issue, we propose a preprocessing that focuses on expert knowledge to improve malware semantic analysis and result interpretability. We propose a new preprocessing method which creates JSON reports for Portable Executable files. These reports gather features from both static and behavioral analysis, and incorporate packer signature detection, MITRE ATT&amp;CK and Malware Behavior Catalog (MBC) knowledge. The purpose of this preprocessing is to gather a semantic representation of binary files, understandable by malware analysts, and that can enhance AI models' explainability for malicious files analysis. Using this preprocessing to train a Large Language Model for Malware classification, we achieve a weighted-average F1-score of 0.94 on a complex dataset, representative of market reality.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.12113",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Serving Large Language Models on Huawei CloudMatrix384",
    "description": "arXiv:2506.12708v3 Announce Type: replace-cross Abstract: The rapid evolution of large language models (LLMs), driven by growing parameter scales, adoption of mixture-of-experts (MoE) architectures, and expanding context lengths, imposes unprecedented demands on AI infrastructure. Traditional AI clusters face limitations in compute intensity, memory bandwidth, inter-chip communication, and latency, compounded by variable workloads and strict service-level objectives. Addressing these issues requires fundamentally redesigned hardware-software integration. This paper introduces Huawei CloudMatrix, a next-generation AI datacenter architecture, realized in the production-grade CloudMatrix384 supernode. It integrates 384 Ascend 910 NPUs and 192 Kunpeng CPUs interconnected via an ultra-high-bandwidth Unified Bus (UB) network, enabling direct all-to-all communication and dynamic pooling of resources. These features optimize performance for communication-intensive operations, such as large-scale MoE expert parallelism and distributed key-value cache access. To fully leverage CloudMatrix384, we propose CloudMatrix-Infer, an advanced LLM serving solution incorporating three core innovations: a peer-to-peer serving architecture that independently scales prefill, decode, and caching; a large-scale expert parallelism strategy supporting EP320 via efficient UB-based token dispatch; and hardware-aware optimizations including specialized operators, microbatch-based pipelining, and INT8 quantization. Evaluation with the DeepSeek-R1 model shows CloudMatrix-Infer achieves state-of-the-art efficiency: prefill throughput of 6,688 tokens/s per NPU and decode throughput of 1,943 tokens/s per NPU (<50 ms TPOT). It effectively balances throughput and latency, sustaining 538 tokens/s per NPU even under stringent 15 ms latency constraints, while INT8 quantization maintains model accuracy across benchmarks.",
    "summary": "arXiv:2506.12708v3 Announce Type: replace-cross Abstract: The rapid evolution of large language models (LLMs), driven by growing parameter scales, adoption of mixture-of-experts (MoE) architectures, and expanding context lengths, imposes unprecedented demands on AI infrastructure. Traditional AI clusters face limitations in compute intensity, memory bandwidth, inter-chip communication, and latency, compounded by variable workloads and strict service-level objectives. Addressing these issues requires fundamentally redesigned hardware-software integration. This paper introduces Huawei CloudMatrix, a next-generation AI datacenter architecture, realized in the production-grade CloudMatrix384 supernode. It integrates 384 Ascend 910 NPUs and 192 Kunpeng CPUs interconnected via an ultra-high-bandwidth Unified Bus (UB) network, enabling direct all-to-all communication and dynamic pooling of resources. These features optimize performance for communication-intensive operations, such as large-scale MoE expert parallelism and distributed key-value cache access. To fully leverage CloudMatrix384, we propose CloudMatrix-Infer, an advanced LLM serving solution incorporating three core innovations: a peer-to-peer serving architecture that independently scales prefill, decode, and caching; a large-scale expert parallelism strategy supporting EP320 via efficient UB-based token dispatch; and hardware-aware optimizations including specialized operators, microbatch-based pipelining, and INT8 quantization. Evaluation with the DeepSeek-R1 model shows CloudMatrix-Infer achieves state-of-the-art efficiency: prefill throughput of 6,688 tokens/s per NPU and decode throughput of 1,943 tokens/s per NPU (<50 ms TPOT). It effectively balances throughput and latency, sustaining 538 tokens/s per NPU even under stringent 15 ms latency constraints, while INT8 quantization maintains model accuracy across benchmarks.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.12708",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "SHADE-Arena: Evaluating Sabotage and Monitoring in LLM Agents",
    "description": "arXiv:2506.15740v1 Announce Type: new Abstract: As Large Language Models (LLMs) are increasingly deployed as autonomous agents in complex and long horizon settings, it is critical to evaluate their ability to sabotage users by pursuing hidden objectives. We study the ability of frontier LLMs to evade monitoring and achieve harmful hidden goals while completing a wide array of realistic tasks. We evaluate a broad range of frontier LLMs using SHADE (Subtle Harmful Agent Detection & Evaluation)-Arena, the first highly diverse agent evaluation dataset for sabotage and monitoring capabilities of LLM agents. SHADE-Arena consists of complex pairs of benign main tasks and harmful side objectives in complicated environments. Agents are evaluated on their ability to complete the side task without appearing suspicious to an LLM monitor. When measuring agent ability to (a) complete the main task, (b) complete the side task, and (c) avoid detection, we find that the best performing frontier models score 27% (Claude 3.7 Sonnet) and 15% (Gemini 2.5 Pro) as sabotage agents when overseen by Claude 3.6 Sonnet. For current frontier models, success on the side task relies heavily on having access to a hidden scratchpad that is not visible to the monitor. We also use SHADE-Arena to measure models' monitoring abilities, with the top monitor (Gemini 2.5 Pro) achieving an AUC of 0.87 at distinguishing benign and malign transcripts. We find that for now, models still struggle at sabotage due to failures in long-context main task execution. However, our measurements already demonstrate the difficulty of monitoring for subtle sabotage attempts, which we expect to only increase in the face of more complex and longer-horizon tasks.",
    "summary": "arXiv:2506.15740v1 Announce Type: new Abstract: As Large Language Models (LLMs) are increasingly deployed as autonomous agents in complex and long horizon settings, it is critical to evaluate their ability to sabotage users by pursuing hidden objectives. We study the ability of frontier LLMs to evade monitoring and achieve harmful hidden goals while completing a wide array of realistic tasks. We evaluate a broad range of frontier LLMs using SHADE (Subtle Harmful Agent Detection & Evaluation)-Arena, the first highly diverse agent evaluation dataset for sabotage and monitoring capabilities of LLM agents. SHADE-Arena consists of complex pairs of benign main tasks and harmful side objectives in complicated environments. Agents are evaluated on their ability to complete the side task without appearing suspicious to an LLM monitor. When measuring agent ability to (a) complete the main task, (b) complete the side task, and (c) avoid detection, we find that the best performing frontier models score 27% (Claude 3.7 Sonnet) and 15% (Gemini 2.5 Pro) as sabotage agents when overseen by Claude 3.6 Sonnet. For current frontier models, success on the side task relies heavily on having access to a hidden scratchpad that is not visible to the monitor. We also use SHADE-Arena to measure models' monitoring abilities, with the top monitor (Gemini 2.5 Pro) achieving an AUC of 0.87 at distinguishing benign and malign transcripts. We find that for now, models still struggle at sabotage due to failures in long-context main task execution. However, our measurements already demonstrate the difficulty of monitoring for subtle sabotage attempts, which we expect to only increase in the face of more complex and longer-horizon tasks.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.15740",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Shadow defense against gradient inversion attack in federated learning",
    "description": "arXiv:2506.15711v1 Announce Type: cross Abstract: Federated learning (FL) has emerged as a transformative framework for privacy-preserving distributed training, allowing clients to collaboratively train a global model without sharing their local data. This is especially crucial in sensitive fields like healthcare, where protecting patient data is paramount. However, privacy leakage remains a critical challenge, as the communication of model updates can be exploited by potential adversaries. Gradient inversion attacks (GIAs), for instance, allow adversaries to approximate the gradients used for training and reconstruct training images, thus stealing patient privacy. Existing defense mechanisms obscure gradients, yet lack a nuanced understanding of which gradients or types of image information are most vulnerable to such attacks. These indiscriminate calibrated perturbations result in either excessive privacy protection degrading model accuracy, or insufficient one failing to safeguard sensitive information. Therefore, we introduce a framework that addresses these challenges by leveraging a shadow model with interpretability for identifying sensitive areas. This enables a more targeted and sample-specific noise injection. Specially, our defensive strategy achieves discrepancies of 3.73 in PSNR and 0.2 in SSIM compared to the circumstance without defense on the ChestXRay dataset, and 2.78 in PSNR and 0.166 in the EyePACS dataset. Moreover, it minimizes adverse effects on model performance, with less than 1% F1 reduction compared to SOTA methods. Our extensive experiments, conducted across diverse types of medical images, validate the generalization of the proposed framework. The stable defense improvements for FedAvg are consistently over 1.5% times in LPIPS and SSIM. It also offers a universal defense against various GIA types, especially for these sensitive areas in images.",
    "summary": "arXiv:2506.15711v1 Announce Type: cross Abstract: Federated learning (FL) has emerged as a transformative framework for privacy-preserving distributed training, allowing clients to collaboratively train a global model without sharing their local data. This is especially crucial in sensitive fields like healthcare, where protecting patient data is paramount. However, privacy leakage remains a critical challenge, as the communication of model updates can be exploited by potential adversaries. Gradient inversion attacks (GIAs), for instance, allow adversaries to approximate the gradients used for training and reconstruct training images, thus stealing patient privacy. Existing defense mechanisms obscure gradients, yet lack a nuanced understanding of which gradients or types of image information are most vulnerable to such attacks. These indiscriminate calibrated perturbations result in either excessive privacy protection degrading model accuracy, or insufficient one failing to safeguard sensitive information. Therefore, we introduce a framework that addresses these challenges by leveraging a shadow model with interpretability for identifying sensitive areas. This enables a more targeted and sample-specific noise injection. Specially, our defensive strategy achieves discrepancies of 3.73 in PSNR and 0.2 in SSIM compared to the circumstance without defense on the ChestXRay dataset, and 2.78 in PSNR and 0.166 in the EyePACS dataset. Moreover, it minimizes adverse effects on model performance, with less than 1% F1 reduction compared to SOTA methods. Our extensive experiments, conducted across diverse types of medical images, validate the generalization of the proposed framework. The stable defense improvements for FedAvg are consistently over 1.5% times in LPIPS and SSIM. It also offers a universal defense against various GIA types, especially for these sensitive areas in images.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.15711",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "ShapeLib: Designing a library of programmatic 3D shape abstractions with Large Language Models",
    "description": "arXiv:2502.08884v2 Announce Type: replace-cross Abstract: We present ShapeLib, the first method that leverages the priors of LLMs to design libraries of programmatic 3D shape abstractions. Our system accepts two forms of design intent: text descriptions of functions to include in the library and a seed set of exemplar shapes. We discover abstractions that match this design intent with a guided LLM workflow that first proposes, and then validates, different ways of applying and implementing functions. We learn recognition networks that map shapes to programs with these newly discovered abstractions by training on data produced by LLM authored synthetic data generation procedures. Across modeling domains (split by shape category), we find that LLMs, when thoughtfully combined with geometric reasoning, can be guided to author a library of abstraction functions that generalize to shapes outside of the seed set. This framework addresses a long-standing shape analysis problem of how to discover reusable abstraction functions while exposing interpretable, semantically aligned interfaces. We find that ShapeLib provides distinct advantages over prior alternative abstraction discovery works in terms of generalization, usability, and maintaining plausibility under manipulation. Finally, we demonstrate that ShapeLib's abstraction functions unlock a number of downstream applications, combining LLM reasoning over shape programs with geometry processing to support shape editing and generation.",
    "summary": "arXiv:2502.08884v2 Announce Type: replace-cross Abstract: We present ShapeLib, the first method that leverages the priors of LLMs to design libraries of programmatic 3D shape abstractions. Our system accepts two forms of design intent: text descriptions of functions to include in the library and a seed set of exemplar shapes. We discover abstractions that match this design intent with a guided LLM workflow that first proposes, and then validates, different ways of applying and implementing functions. We learn recognition networks that map shapes to programs with these newly discovered abstractions by training on data produced by LLM authored synthetic data generation procedures. Across modeling domains (split by shape category), we find that LLMs, when thoughtfully combined with geometric reasoning, can be guided to author a library of abstraction functions that generalize to shapes outside of the seed set. This framework addresses a long-standing shape analysis problem of how to discover reusable abstraction functions while exposing interpretable, semantically aligned interfaces. We find that ShapeLib provides distinct advantages over prior alternative abstraction discovery works in terms of generalization, usability, and maintaining plausibility under manipulation. Finally, we demonstrate that ShapeLib's abstraction functions unlock a number of downstream applications, combining LLM reasoning over shape programs with geometry processing to support shape editing and generation.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2502.08884",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Single-shot thermometry of simulated Bose--Einstein condensates using artificial intelligence",
    "description": "arXiv:2506.16925v1 Announce Type: cross Abstract: Precise determination of thermodynamic parameters in ultracold Bose gases remains challenging due to the destructive nature of conventional measurement techniques and inherent experimental uncertainties. We demonstrate an artificial intelligence approach for rapid, non-destructive estimation of the chemical potential and temperature from single-shot, in situ imaged density profiles of finite-temperature Bose gases. Our convolutional neural network is trained exclusively on quasi-2D `pancake' condensates in harmonic trap configurations. It achieves parameter extraction within fractions of a second. The model also demonstrates zero-shot generalisation across both trap geometry and thermalisation dynamics, successfully estimating thermodynamic parameters for toroidally trapped condensates with errors of only a few nanokelvin despite no prior exposure to such geometries during training, and maintaining predictive accuracy during dynamic thermalisation processes after a relatively brief evolution without explicit training on non-equilibrium states. These results suggest that supervised learning can overcome traditional limitations in ultracold atom thermometry, with extension to broader geometric configurations, temperature ranges, and additional parameters potentially enabling comprehensive real-time analysis of quantum gas experiments. Such capabilities could significantly streamline experimental workflows whilst improving measurement precision across a range of quantum fluid systems.",
    "summary": "arXiv:2506.16925v1 Announce Type: cross Abstract: Precise determination of thermodynamic parameters in ultracold Bose gases remains challenging due to the destructive nature of conventional measurement techniques and inherent experimental uncertainties. We demonstrate an artificial intelligence approach for rapid, non-destructive estimation of the chemical potential and temperature from single-shot, in situ imaged density profiles of finite-temperature Bose gases. Our convolutional neural network is trained exclusively on quasi-2D `pancake' condensates in harmonic trap configurations. It achieves parameter extraction within fractions of a second. The model also demonstrates zero-shot generalisation across both trap geometry and thermalisation dynamics, successfully estimating thermodynamic parameters for toroidally trapped condensates with errors of only a few nanokelvin despite no prior exposure to such geometries during training, and maintaining predictive accuracy during dynamic thermalisation processes after a relatively brief evolution without explicit training on non-equilibrium states. These results suggest that supervised learning can overcome traditional limitations in ultracold atom thermometry, with extension to broader geometric configurations, temperature ranges, and additional parameters potentially enabling comprehensive real-time analysis of quantum gas experiments. Such capabilities could significantly streamline experimental workflows whilst improving measurement precision across a range of quantum fluid systems.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16925",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "SLR: An Automated Synthesis Framework for Scalable Logical Reasoning",
    "description": "arXiv:2506.15787v1 Announce Type: new Abstract: We introduce SLR, an end-to-end framework for systematic evaluation and training of Large Language Models (LLMs) via Scalable Logical Reasoning. Given a user's task specification, SLR enables scalable, automated synthesis of inductive reasoning tasks with precisely controlled difficulty. For each task, SLR synthesizes (i) a latent ground-truth rule, (ii) an executable validation program used by a symbolic judge to deterministically verify model outputs, and (iii) an instruction prompt for the reasoning task. Using SLR, we create SLR-Bench, a benchmark comprising over 19k prompts spanning 20 curriculum levels that progressively increase in relational, arithmetic, and recursive complexity. Large-scale evaluation reveals that contemporary LLMs readily produce syntactically valid rules, yet often fail at correct logical inference. Recent reasoning LLMs do somewhat better, but incur substantial increases in test-time compute, sometimes exceeding 15k completion tokens. Finally, logic-tuning via SLR doubles Llama-3-8B accuracy on SLR-Bench, achieving parity with Gemini-Flash-Thinking at a fraction of computational cost. SLR is fully automated, requires no human annotation, ensures dataset novelty, and offers a scalable environment for probing and advancing LLMs' reasoning capabilities.",
    "summary": "arXiv:2506.15787v1 Announce Type: new Abstract: We introduce SLR, an end-to-end framework for systematic evaluation and training of Large Language Models (LLMs) via Scalable Logical Reasoning. Given a user's task specification, SLR enables scalable, automated synthesis of inductive reasoning tasks with precisely controlled difficulty. For each task, SLR synthesizes (i) a latent ground-truth rule, (ii) an executable validation program used by a symbolic judge to deterministically verify model outputs, and (iii) an instruction prompt for the reasoning task. Using SLR, we create SLR-Bench, a benchmark comprising over 19k prompts spanning 20 curriculum levels that progressively increase in relational, arithmetic, and recursive complexity. Large-scale evaluation reveals that contemporary LLMs readily produce syntactically valid rules, yet often fail at correct logical inference. Recent reasoning LLMs do somewhat better, but incur substantial increases in test-time compute, sometimes exceeding 15k completion tokens. Finally, logic-tuning via SLR doubles Llama-3-8B accuracy on SLR-Bench, achieving parity with Gemini-Flash-Thinking at a fraction of computational cost. SLR is fully automated, requires no human annotation, ensures dataset novelty, and offers a scalable environment for probing and advancing LLMs' reasoning capabilities.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.15787",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Song Form-aware Full-Song Text-to-Lyrics Generation with Multi-Level Granularity Syllable Count Control",
    "description": "arXiv:2411.13100v2 Announce Type: replace-cross Abstract: Lyrics generation presents unique challenges, particularly in achieving precise syllable control while adhering to song form structures such as verses and choruses. Conventional line-by-line approaches often lead to unnatural phrasing, underscoring the need for more granular syllable management. We propose a framework for lyrics generation that enables multi-level syllable control at the word, phrase, line, and paragraph levels, aware of song form. Our approach generates complete lyrics conditioned on input text and song form, ensuring alignment with specified syllable constraints. Generated lyrics samples are available at: https://tinyurl.com/lyrics9999",
    "summary": "arXiv:2411.13100v2 Announce Type: replace-cross Abstract: Lyrics generation presents unique challenges, particularly in achieving precise syllable control while adhering to song form structures such as verses and choruses. Conventional line-by-line approaches often lead to unnatural phrasing, underscoring the need for more granular syllable management. We propose a framework for lyrics generation that enables multi-level syllable control at the word, phrase, line, and paragraph levels, aware of song form. Our approach generates complete lyrics conditioned on input text and song form, ensuring alignment with specified syllable constraints. Generated lyrics samples are available at: https://tinyurl.com/lyrics9999",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2411.13100",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "SP-VLA: A Joint Model Scheduling and Token Pruning Approach for VLA Model Acceleration",
    "description": "arXiv:2506.12723v2 Announce Type: replace-cross Abstract: Vision-Language-Action (VLA) models have attracted increasing attention for their strong control capabilities. However, their high computational cost and low execution frequency hinder their suitability for real-time tasks such as robotic manipulation and autonomous navigation. Existing VLA acceleration methods primarily focus on structural optimization, overlooking the fact that these models operate in sequential decision-making environments. As a result, temporal redundancy in sequential action generation and spatial redundancy in visual input remain unaddressed. To this end, we propose SP-VLA, a unified framework that accelerates VLA models by jointly scheduling models and pruning tokens. Specifically, we design an action-aware model scheduling mechanism that reduces temporal redundancy by dynamically switching between VLA model and a lightweight generator. Inspired by the human motion pattern of focusing on key decision points while relying on intuition for other actions, we categorize VLA actions into deliberative and intuitive, assigning the former to the VLA model and the latter to the lightweight generator, enabling frequency-adaptive execution through collaborative model scheduling. To address spatial redundancy, we further develop a spatio-semantic dual-aware token pruning method. Tokens are classified into spatial and semantic types and pruned based on their dual-aware importance to accelerate VLA inference. These two mechanisms work jointly to guide the VLA in focusing on critical actions and salient visual information, achieving effective acceleration while maintaining high accuracy. Experimental results demonstrate that our method achieves up to 1.5$times$ acceleration with less than 3% drop in accuracy, outperforming existing approaches in multiple tasks.",
    "summary": "arXiv:2506.12723v2 Announce Type: replace-cross Abstract: Vision-Language-Action (VLA) models have attracted increasing attention for their strong control capabilities. However, their high computational cost and low execution frequency hinder their suitability for real-time tasks such as robotic manipulation and autonomous navigation. Existing VLA acceleration methods primarily focus on structural optimization, overlooking the fact that these models operate in sequential decision-making environments. As a result, temporal redundancy in sequential action generation and spatial redundancy in visual input remain unaddressed. To this end, we propose SP-VLA, a unified framework that accelerates VLA models by jointly scheduling models and pruning tokens. Specifically, we design an action-aware model scheduling mechanism that reduces temporal redundancy by dynamically switching between VLA model and a lightweight generator. Inspired by the human motion pattern of focusing on key decision points while relying on intuition for other actions, we categorize VLA actions into deliberative and intuitive, assigning the former to the VLA model and the latter to the lightweight generator, enabling frequency-adaptive execution through collaborative model scheduling. To address spatial redundancy, we further develop a spatio-semantic dual-aware token pruning method. Tokens are classified into spatial and semantic types and pruned based on their dual-aware importance to accelerate VLA inference. These two mechanisms work jointly to guide the VLA in focusing on critical actions and salient visual information, achieving effective acceleration while maintaining high accuracy. Experimental results demonstrate that our method achieves up to 1.5$times$ acceleration with less than 3% drop in accuracy, outperforming existing approaches in multiple tasks.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.12723",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Sparse-Reg: Improving Sample Complexity in Offline Reinforcement Learning using Sparsity",
    "description": "arXiv:2506.17155v1 Announce Type: cross Abstract: In this paper, we investigate the use of small datasets in the context of offline reinforcement learning (RL). While many common offline RL benchmarks employ datasets with over a million data points, many offline RL applications rely on considerably smaller datasets. We show that offline RL algorithms can overfit on small datasets, resulting in poor performance. To address this challenge, we introduce 'Sparse-Reg': a regularization technique based on sparsity to mitigate overfitting in offline reinforcement learning, enabling effective learning in limited data settings and outperforming state-of-the-art baselines in continuous control.",
    "summary": "arXiv:2506.17155v1 Announce Type: cross Abstract: In this paper, we investigate the use of small datasets in the context of offline reinforcement learning (RL). While many common offline RL benchmarks employ datasets with over a million data points, many offline RL applications rely on considerably smaller datasets. We show that offline RL algorithms can overfit on small datasets, resulting in poor performance. To address this challenge, we introduce 'Sparse-Reg': a regularization technique based on sparsity to mitigate overfitting in offline reinforcement learning, enabling effective learning in limited data settings and outperforming state-of-the-art baselines in continuous control.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.17155",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Spatially-Aware Evaluation of Segmentation Uncertainty",
    "description": "arXiv:2506.16589v1 Announce Type: cross Abstract: Uncertainty maps highlight unreliable regions in segmentation predictions. However, most uncertainty evaluation metrics treat voxels independently, ignoring spatial context and anatomical structure. As a result, they may assign identical scores to qualitatively distinct patterns (e.g., scattered vs. boundary-aligned uncertainty). We propose three spatially aware metrics that incorporate structural and boundary information and conduct a thorough validation on medical imaging data from the prostate zonal segmentation challenge within the Medical Segmentation Decathlon. Our results demonstrate improved alignment with clinically important factors and better discrimination between meaningful and spurious uncertainty patterns.",
    "summary": "arXiv:2506.16589v1 Announce Type: cross Abstract: Uncertainty maps highlight unreliable regions in segmentation predictions. However, most uncertainty evaluation metrics treat voxels independently, ignoring spatial context and anatomical structure. As a result, they may assign identical scores to qualitatively distinct patterns (e.g., scattered vs. boundary-aligned uncertainty). We propose three spatially aware metrics that incorporate structural and boundary information and conduct a thorough validation on medical imaging data from the prostate zonal segmentation challenge within the Medical Segmentation Decathlon. Our results demonstrate improved alignment with clinically important factors and better discrimination between meaningful and spurious uncertainty patterns.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16589",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "SPIN-ODE: Stiff Physics-Informed Neural ODE for Chemical Reaction Rate Estimation",
    "description": "arXiv:2505.05625v2 Announce Type: replace-cross Abstract: Estimating rate coefficients from complex chemical reactions is essential for advancing detailed chemistry. However, the stiffness inherent in real-world atmospheric chemistry systems poses severe challenges, leading to training instability and poor convergence that hinder effective rate coefficient estimation using learning-based approaches. To address this, we propose a Stiff Physics-Informed Neural ODE framework (SPIN-ODE) for chemical reaction modelling. Our method introduces a three-stage optimisation process: first, a latent neural ODE learns the continuous and differentiable trajectory between chemical concentrations and their time derivatives; second, an explicit Chemical Reaction Neural Network (CRNN) extracts the underlying rate coefficients based on the learned dynamics; and third, fine-tune CRNN using a neural ODE solver to further improve rate coefficient estimation. Extensive experiments on both synthetic and newly proposed real-world datasets validate the effectiveness and robustness of our approach. As the first work on stiff Neural ODEs for chemical rate coefficient discovery, our study opens promising directions for integrating neural networks with detailed chemistry.",
    "summary": "arXiv:2505.05625v2 Announce Type: replace-cross Abstract: Estimating rate coefficients from complex chemical reactions is essential for advancing detailed chemistry. However, the stiffness inherent in real-world atmospheric chemistry systems poses severe challenges, leading to training instability and poor convergence that hinder effective rate coefficient estimation using learning-based approaches. To address this, we propose a Stiff Physics-Informed Neural ODE framework (SPIN-ODE) for chemical reaction modelling. Our method introduces a three-stage optimisation process: first, a latent neural ODE learns the continuous and differentiable trajectory between chemical concentrations and their time derivatives; second, an explicit Chemical Reaction Neural Network (CRNN) extracts the underlying rate coefficients based on the learned dynamics; and third, fine-tune CRNN using a neural ODE solver to further improve rate coefficient estimation. Extensive experiments on both synthetic and newly proposed real-world datasets validate the effectiveness and robustness of our approach. As the first work on stiff Neural ODEs for chemical rate coefficient discovery, our study opens promising directions for integrating neural networks with detailed chemistry.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2505.05625",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Spotting tell-tale visual artifacts in face swapping videos: strengths and pitfalls of CNN detectors",
    "description": "arXiv:2506.16497v1 Announce Type: cross Abstract: Face swapping manipulations in video streams represents an increasing threat in remote video communications, due to advances in automated and real-time tools. Recent literature proposes to characterize and exploit visual artifacts introduced in video frames by swapping algorithms when dealing with challenging physical scenes, such as face occlusions. This paper investigates the effectiveness of this approach by benchmarking CNN-based data-driven models on two data corpora (including a newly collected one) and analyzing generalization capabilities with respect to different acquisition sources and swapping algorithms. The results confirm excellent performance of general-purpose CNN architectures when operating within the same data source, but a significant difficulty in robustly characterizing occlusion-based visual cues across datasets. This highlights the need for specialized detection strategies to deal with such artifacts.",
    "summary": "arXiv:2506.16497v1 Announce Type: cross Abstract: Face swapping manipulations in video streams represents an increasing threat in remote video communications, due to advances in automated and real-time tools. Recent literature proposes to characterize and exploit visual artifacts introduced in video frames by swapping algorithms when dealing with challenging physical scenes, such as face occlusions. This paper investigates the effectiveness of this approach by benchmarking CNN-based data-driven models on two data corpora (including a newly collected one) and analyzing generalization capabilities with respect to different acquisition sources and swapping algorithms. The results confirm excellent performance of general-purpose CNN architectures when operating within the same data source, but a significant difficulty in robustly characterizing occlusion-based visual cues across datasets. This highlights the need for specialized detection strategies to deal with such artifacts.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16497",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "SSR-Zero: Simple Self-Rewarding Reinforcement Learning for Machine Translation",
    "description": "arXiv:2505.16637v3 Announce Type: replace-cross Abstract: Large language models (LLMs) have recently demonstrated remarkable capabilities in machine translation (MT). However, most advanced MT-specific LLMs heavily rely on external supervision signals during training, such as human-annotated reference data or trained reward models (RMs), which are often expensive to obtain and challenging to scale. To overcome this limitation, we propose a Simple Self-Rewarding (SSR) Reinforcement Learning (RL) framework for MT that is reference-free, fully online, and relies solely on self-judging rewards. Training with SSR using 13K monolingual examples and Qwen-2.5-7B as the backbone, our model SSR-Zero-7B outperforms existing MT-specific LLMs, e.g., TowerInstruct-13B and GemmaX-28-9B, as well as larger general LLMs like Qwen2.5-32B-Instruct in English $leftrightarrow$ Chinese translation tasks from WMT23, WMT24, and Flores200 benchmarks. Furthermore, by augmenting SSR with external supervision from COMET, our strongest model, SSR-X-Zero-7B, achieves state-of-the-art performance in English $leftrightarrow$ Chinese translation, surpassing all existing open-source models under 72B parameters and even outperforming closed-source models, e.g., GPT-4o and Gemini 1.5 Pro. Our analysis highlights the effectiveness of the self-rewarding mechanism compared to the external LLM-as-a-judge approach in MT and demonstrates its complementary benefits when combined with trained RMs. Our findings provide valuable insight into the potential of self-improving RL methods. We have publicly released our code, data and models.",
    "summary": "arXiv:2505.16637v3 Announce Type: replace-cross Abstract: Large language models (LLMs) have recently demonstrated remarkable capabilities in machine translation (MT). However, most advanced MT-specific LLMs heavily rely on external supervision signals during training, such as human-annotated reference data or trained reward models (RMs), which are often expensive to obtain and challenging to scale. To overcome this limitation, we propose a Simple Self-Rewarding (SSR) Reinforcement Learning (RL) framework for MT that is reference-free, fully online, and relies solely on self-judging rewards. Training with SSR using 13K monolingual examples and Qwen-2.5-7B as the backbone, our model SSR-Zero-7B outperforms existing MT-specific LLMs, e.g., TowerInstruct-13B and GemmaX-28-9B, as well as larger general LLMs like Qwen2.5-32B-Instruct in English $leftrightarrow$ Chinese translation tasks from WMT23, WMT24, and Flores200 benchmarks. Furthermore, by augmenting SSR with external supervision from COMET, our strongest model, SSR-X-Zero-7B, achieves state-of-the-art performance in English $leftrightarrow$ Chinese translation, surpassing all existing open-source models under 72B parameters and even outperforming closed-source models, e.g., GPT-4o and Gemini 1.5 Pro. Our analysis highlights the effectiveness of the self-rewarding mechanism compared to the external LLM-as-a-judge approach in MT and demonstrates its complementary benefits when combined with trained RMs. Our findings provide valuable insight into the potential of self-improving RL methods. We have publicly released our code, data and models.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2505.16637",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "StoryWriter: A Multi-Agent Framework for Long Story Generation",
    "description": "arXiv:2506.16445v1 Announce Type: cross Abstract: Long story generation remains a challenge for existing large language models (LLMs), primarily due to two main factors: (1) discourse coherence, which requires plot consistency, logical coherence, and completeness in the long-form generation, and (2) narrative complexity, which requires an interwoven and engaging narrative. To address these challenges, we propose StoryWriter, a multi-agent story generation framework, which consists of three main modules: (1) outline agent, which generates event-based outlines containing rich event plots, character, and event-event relationships. (2) planning agent, which further details events and plans which events should be written in each chapter to maintain an interwoven and engaging story. (3) writing agent, which dynamically compresses the story history based on the current event to generate and reflect new plots, ensuring the coherence of the generated story. We conduct both human and automated evaluation, and StoryWriter significantly outperforms existing story generation baselines in both story quality and length. Furthermore, we use StoryWriter to generate a dataset, which contains about $6,000$ high-quality long stories, with an average length of $8,000$ words. We train the model Llama3.1-8B and GLM4-9B using supervised fine-tuning on LongStory and develop StoryWriter_GLM and StoryWriter_GLM, which demonstrates advanced performance in long story generation.",
    "summary": "arXiv:2506.16445v1 Announce Type: cross Abstract: Long story generation remains a challenge for existing large language models (LLMs), primarily due to two main factors: (1) discourse coherence, which requires plot consistency, logical coherence, and completeness in the long-form generation, and (2) narrative complexity, which requires an interwoven and engaging narrative. To address these challenges, we propose StoryWriter, a multi-agent story generation framework, which consists of three main modules: (1) outline agent, which generates event-based outlines containing rich event plots, character, and event-event relationships. (2) planning agent, which further details events and plans which events should be written in each chapter to maintain an interwoven and engaging story. (3) writing agent, which dynamically compresses the story history based on the current event to generate and reflect new plots, ensuring the coherence of the generated story. We conduct both human and automated evaluation, and StoryWriter significantly outperforms existing story generation baselines in both story quality and length. Furthermore, we use StoryWriter to generate a dataset, which contains about $6,000$ high-quality long stories, with an average length of $8,000$ words. We train the model Llama3.1-8B and GLM4-9B using supervised fine-tuning on LongStory and develop StoryWriter_GLM and StoryWriter_GLM, which demonstrates advanced performance in long story generation.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16445",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Studying and Improving Graph Neural Network-based Motif Estimation",
    "description": "arXiv:2506.15709v1 Announce Type: cross Abstract: Graph Neural Networks (GNNs) are a predominant method for graph representation learning. However, beyond subgraph frequency estimation, their application to network motif significance-profile (SP) prediction remains under-explored, with no established benchmarks in the literature. We propose to address this problem, framing SP estimation as a task independent of subgraph frequency estimation. Our approach shifts from frequency counting to direct SP estimation and modulates the problem as multitarget regression. The reformulation is optimised for interpretability, stability and scalability on large graphs. We validate our method using a large synthetic dataset and further test it on real-world graphs. Our experiments reveal that 1-WL limited models struggle to make precise estimations of SPs. However, they can generalise to approximate the graph generation processes of networks by comparing their predicted SP with the ones originating from synthetic generators. This first study on GNN-based motif estimation also hints at how using direct SP estimation can help go past the theoretical limitations that motif estimation faces when performed through subgraph counting.",
    "summary": "arXiv:2506.15709v1 Announce Type: cross Abstract: Graph Neural Networks (GNNs) are a predominant method for graph representation learning. However, beyond subgraph frequency estimation, their application to network motif significance-profile (SP) prediction remains under-explored, with no established benchmarks in the literature. We propose to address this problem, framing SP estimation as a task independent of subgraph frequency estimation. Our approach shifts from frequency counting to direct SP estimation and modulates the problem as multitarget regression. The reformulation is optimised for interpretability, stability and scalability on large graphs. We validate our method using a large synthetic dataset and further test it on real-world graphs. Our experiments reveal that 1-WL limited models struggle to make precise estimations of SPs. However, they can generalise to approximate the graph generation processes of networks by comparing their predicted SP with the ones originating from synthetic generators. This first study on GNN-based motif estimation also hints at how using direct SP estimation can help go past the theoretical limitations that motif estimation faces when performed through subgraph counting.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.15709",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Subspace-Boosted Model Merging",
    "description": "arXiv:2506.16506v1 Announce Type: cross Abstract: Model merging enables the combination of multiple specialized expert models into a single model capable of performing multiple tasks. However, the benefits of merging an increasing amount of specialized experts generally lead to diminishing returns and reduced overall performance gains. In this work, we offer an explanation and analysis from a task arithmetic perspective; revealing that as the merging process (across numerous existing merging methods) continues for more and more experts, the associated task vector space experiences rank collapse. To mitigate this issue, we introduce Subspace Boosting, which operates on the singular value decomposed task vector space and maintains task vector ranks. Subspace Boosting raises merging efficacy for up to 20 expert models by large margins of more than 10% when evaluated on vision benchmarks. Moreover, we propose employing Higher-Order Generalized Singular Value Decomposition to further quantify task similarity, offering a new interpretable perspective on model merging.",
    "summary": "arXiv:2506.16506v1 Announce Type: cross Abstract: Model merging enables the combination of multiple specialized expert models into a single model capable of performing multiple tasks. However, the benefits of merging an increasing amount of specialized experts generally lead to diminishing returns and reduced overall performance gains. In this work, we offer an explanation and analysis from a task arithmetic perspective; revealing that as the merging process (across numerous existing merging methods) continues for more and more experts, the associated task vector space experiences rank collapse. To mitigate this issue, we introduce Subspace Boosting, which operates on the singular value decomposed task vector space and maintains task vector ranks. Subspace Boosting raises merging efficacy for up to 20 expert models by large margins of more than 10% when evaluated on vision benchmarks. Moreover, we propose employing Higher-Order Generalized Singular Value Decomposition to further quantify task similarity, offering a new interpretable perspective on model merging.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16506",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "SwarmThinkers: Learning Physically Consistent Atomic KMC Transitions at Scale",
    "description": "arXiv:2505.20094v2 Announce Type: replace Abstract: Can a scientific simulation system be physically consistent, interpretable by design, and scalable across regimes--all at once? Despite decades of progress, this trifecta remains elusive. Classical methods like Kinetic Monte Carlo ensure thermodynamic accuracy but scale poorly; learning-based methods offer efficiency but often sacrifice physical consistency and interpretability. We present SwarmThinkers, a reinforcement learning framework that recasts atomic-scale simulation as a physically grounded swarm intelligence system. Each diffusing particle is modeled as a local decision-making agent that selects transitions via a shared policy network trained under thermodynamic constraints. A reweighting mechanism fuses learned preferences with transition rates, preserving statistical fidelity while enabling interpretable, step-wise decision making. Training follows a centralized-training, decentralized-execution paradigm, allowing the policy to generalize across system sizes, concentrations, and temperatures without retraining. On a benchmark simulating radiation-induced Fe-Cu alloy precipitation, SwarmThinkers is the first system to achieve full-scale, physically consistent simulation on a single A100 GPU, previously attainable only via OpenKMC on a supercomputer. It delivers up to 4963x (3185x on average) faster computation with 485x lower memory usage. By treating particles as decision-makers, not passive samplers, SwarmThinkers marks a paradigm shift in scientific simulation--one that unifies physical consistency, interpretability, and scalability through agent-driven intelligence.",
    "summary": "arXiv:2505.20094v2 Announce Type: replace Abstract: Can a scientific simulation system be physically consistent, interpretable by design, and scalable across regimes--all at once? Despite decades of progress, this trifecta remains elusive. Classical methods like Kinetic Monte Carlo ensure thermodynamic accuracy but scale poorly; learning-based methods offer efficiency but often sacrifice physical consistency and interpretability. We present SwarmThinkers, a reinforcement learning framework that recasts atomic-scale simulation as a physically grounded swarm intelligence system. Each diffusing particle is modeled as a local decision-making agent that selects transitions via a shared policy network trained under thermodynamic constraints. A reweighting mechanism fuses learned preferences with transition rates, preserving statistical fidelity while enabling interpretable, step-wise decision making. Training follows a centralized-training, decentralized-execution paradigm, allowing the policy to generalize across system sizes, concentrations, and temperatures without retraining. On a benchmark simulating radiation-induced Fe-Cu alloy precipitation, SwarmThinkers is the first system to achieve full-scale, physically consistent simulation on a single A100 GPU, previously attainable only via OpenKMC on a supercomputer. It delivers up to 4963x (3185x on average) faster computation with 485x lower memory usage. By treating particles as decision-makers, not passive samplers, SwarmThinkers marks a paradigm shift in scientific simulation--one that unifies physical consistency, interpretability, and scalability through agent-driven intelligence.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2505.20094",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "SWE-Factory: Your Automated Factory for Issue Resolution Training Data and Evaluation Benchmarks",
    "description": "arXiv:2506.10954v2 Announce Type: replace-cross Abstract: Constructing large-scale datasets for the GitHub issue resolution task is crucial for both training and evaluating the software engineering capabilities of Large Language Models (LLMs). However, the traditional process for creating such benchmarks is notoriously challenging and labor-intensive, particularly in the stages of setting up evaluation environments, grading test outcomes, and validating task instances. In this paper, we propose SWE-Factory, an automated pipeline designed to address these challenges. To tackle these issues, our pipeline integrates three core automated components. First, we introduce SWE-Builder, a multi-agent system that automates evaluation environment construction, which employs four specialized agents that work in a collaborative, iterative loop and leverages an environment memory pool to enhance efficiency. Second, we introduce a standardized, exit-code-based grading method that eliminates the need for manually writing custom parsers. Finally, we automate the fail2pass validation process using these reliable exit code signals. Experiments on 671 issues across four programming languages show that our pipeline can effectively construct valid task instances; for example, with GPT-4.1-mini, our SWE-Builder constructs 269 valid instances at $0.045 per instance, while with Gemini-2.5-flash, it achieves comparable performance at the lowest cost of $0.024 per instance. We also demonstrate that our exit-code-based grading achieves 100% accuracy compared to manual inspection, and our automated fail2pass validation reaches a precision of 0.92 and a recall of 1.00. We hope our automated pipeline will accelerate the collection of large-scale, high-quality GitHub issue resolution datasets for both training and evaluation. Our code and datasets are released at https://github.com/DeepSoftwareAnalytics/swe-factory.",
    "summary": "arXiv:2506.10954v2 Announce Type: replace-cross Abstract: Constructing large-scale datasets for the GitHub issue resolution task is crucial for both training and evaluating the software engineering capabilities of Large Language Models (LLMs). However, the traditional process for creating such benchmarks is notoriously challenging and labor-intensive, particularly in the stages of setting up evaluation environments, grading test outcomes, and validating task instances. In this paper, we propose SWE-Factory, an automated pipeline designed to address these challenges. To tackle these issues, our pipeline integrates three core automated components. First, we introduce SWE-Builder, a multi-agent system that automates evaluation environment construction, which employs four specialized agents that work in a collaborative, iterative loop and leverages an environment memory pool to enhance efficiency. Second, we introduce a standardized, exit-code-based grading method that eliminates the need for manually writing custom parsers. Finally, we automate the fail2pass validation process using these reliable exit code signals. Experiments on 671 issues across four programming languages show that our pipeline can effectively construct valid task instances; for example, with GPT-4.1-mini, our SWE-Builder constructs 269 valid instances at $0.045 per instance, while with Gemini-2.5-flash, it achieves comparable performance at the lowest cost of $0.024 per instance. We also demonstrate that our exit-code-based grading achieves 100% accuracy compared to manual inspection, and our automated fail2pass validation reaches a precision of 0.92 and a recall of 1.00. We hope our automated pipeline will accelerate the collection of large-scale, high-quality GitHub issue resolution datasets for both training and evaluation. Our code and datasets are released at https://github.com/DeepSoftwareAnalytics/swe-factory.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.10954",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "SycnMapV2: Robust and Adaptive Unsupervised Segmentation",
    "description": "arXiv:2506.16297v1 Announce Type: cross Abstract: Human vision excels at segmenting visual cues without the need for explicit training, and it remains remarkably robust even as noise severity increases. In contrast, existing AI algorithms struggle to maintain accuracy under similar conditions. Here, we present SyncMapV2, the first to solve unsupervised segmentation with state-of-the-art robustness. SyncMapV2 exhibits a minimal drop in mIoU, only 0.01%, under digital corruption, compared to a 23.8% drop observed in SOTA methods.This superior performance extends across various types of corruption: noise (7.3% vs. 37.7%), weather (7.5% vs. 33.8%), and blur (7.0% vs. 29.5%). Notably, SyncMapV2 accomplishes this without any robust training, supervision, or loss functions. It is based on a learning paradigm that uses self-organizing dynamical equations combined with concepts from random networks. Moreover,unlike conventional methods that require re-initialization for each new input, SyncMapV2 adapts online, mimicking the continuous adaptability of human vision. Thus, we go beyond the accurate and robust results, and present the first algorithm that can do all the above online, adapting to input rather than re-initializing. In adaptability tests, SyncMapV2 demonstrates near-zero performance degradation, which motivates and fosters a new generation of robust and adaptive intelligence in the near future.",
    "summary": "arXiv:2506.16297v1 Announce Type: cross Abstract: Human vision excels at segmenting visual cues without the need for explicit training, and it remains remarkably robust even as noise severity increases. In contrast, existing AI algorithms struggle to maintain accuracy under similar conditions. Here, we present SyncMapV2, the first to solve unsupervised segmentation with state-of-the-art robustness. SyncMapV2 exhibits a minimal drop in mIoU, only 0.01%, under digital corruption, compared to a 23.8% drop observed in SOTA methods.This superior performance extends across various types of corruption: noise (7.3% vs. 37.7%), weather (7.5% vs. 33.8%), and blur (7.0% vs. 29.5%). Notably, SyncMapV2 accomplishes this without any robust training, supervision, or loss functions. It is based on a learning paradigm that uses self-organizing dynamical equations combined with concepts from random networks. Moreover,unlike conventional methods that require re-initialization for each new input, SyncMapV2 adapts online, mimicking the continuous adaptability of human vision. Thus, we go beyond the accurate and robust results, and present the first algorithm that can do all the above online, adapting to input rather than re-initializing. In adaptability tests, SyncMapV2 demonstrates near-zero performance degradation, which motivates and fosters a new generation of robust and adaptive intelligence in the near future.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16297",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Synthesizing Composite Hierarchical Structure from Symbolic Music Corpora",
    "description": "arXiv:2502.15849v4 Announce Type: replace Abstract: Western music is an innately hierarchical system of interacting levels of structure, from fine-grained melody to high-level form. In order to analyze music compositions holistically and at multiple granularities, we propose a unified, hierarchical meta-representation of musical structure called the structural temporal graph (STG). For a single piece, the STG is a data structure that defines a hierarchy of progressively finer structural musical features and the temporal relationships between them. We use the STG to enable a novel approach for deriving a representative structural summary of a music corpus, which we formalize as a nested NP-hard combinatorial optimization problem extending the Generalized Median Graph problem. Our approach first applies simulated annealing to develop a measure of structural distance between two music pieces rooted in graph isomorphism. Our approach then combines the formal guarantees of SMT solvers with nested simulated annealing over structural distances to produce a structurally sound, representative centroid STG for an entire corpus of STGs from individual pieces. To evaluate our approach, we conduct experiments verifying that structural distance accurately differentiates between music pieces, and that derived centroids accurately structurally characterize their corpora.",
    "summary": "arXiv:2502.15849v4 Announce Type: replace Abstract: Western music is an innately hierarchical system of interacting levels of structure, from fine-grained melody to high-level form. In order to analyze music compositions holistically and at multiple granularities, we propose a unified, hierarchical meta-representation of musical structure called the structural temporal graph (STG). For a single piece, the STG is a data structure that defines a hierarchy of progressively finer structural musical features and the temporal relationships between them. We use the STG to enable a novel approach for deriving a representative structural summary of a music corpus, which we formalize as a nested NP-hard combinatorial optimization problem extending the Generalized Median Graph problem. Our approach first applies simulated annealing to develop a measure of structural distance between two music pieces rooted in graph isomorphism. Our approach then combines the formal guarantees of SMT solvers with nested simulated annealing over structural distances to produce a structurally sound, representative centroid STG for an entire corpus of STGs from individual pieces. To evaluate our approach, we conduct experiments verifying that structural distance accurately differentiates between music pieces, and that derived centroids accurately structurally characterize their corpora.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2502.15849",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Synthetic ALS-EEG Data Augmentation for ALS Diagnosis Using Conditional WGAN with Weight Clipping",
    "description": "arXiv:2506.16243v1 Announce Type: cross Abstract: Amyotrophic Lateral Sclerosis (ALS) is a rare neurodegenerative disease, and high-quality EEG data from ALS patients are scarce. This data scarcity, coupled with severe class imbalance between ALS and healthy control recordings, poses a challenge for training reliable machine learning classifiers. In this work, we address these issues by generating synthetic EEG signals for ALS patients using a Conditional Wasserstein Generative Adversarial Network (CWGAN). We train CWGAN on a private EEG dataset (ALS vs. non-ALS) to learn the distribution of ALS EEG signals and produce realistic synthetic samples. We preprocess and normalize EEG recordings, and train a CWGAN model to generate synthetic ALS signals. The CWGAN architecture and training routine are detailed, with key hyperparameters chosen for stable training. Qualitative evaluation of generated signals shows that they closely mimic real ALS EEG patterns. The CWGAN training converged with generator and discriminator loss curves stabilizing, indicating successful learning. The synthetic EEG signals appear realistic and have potential use as augmented data for training classifiers, helping to mitigate class imbalance and improve ALS detection accuracy. We discuss how this approach can facilitate data sharing and enhance diagnostic models.",
    "summary": "arXiv:2506.16243v1 Announce Type: cross Abstract: Amyotrophic Lateral Sclerosis (ALS) is a rare neurodegenerative disease, and high-quality EEG data from ALS patients are scarce. This data scarcity, coupled with severe class imbalance between ALS and healthy control recordings, poses a challenge for training reliable machine learning classifiers. In this work, we address these issues by generating synthetic EEG signals for ALS patients using a Conditional Wasserstein Generative Adversarial Network (CWGAN). We train CWGAN on a private EEG dataset (ALS vs. non-ALS) to learn the distribution of ALS EEG signals and produce realistic synthetic samples. We preprocess and normalize EEG recordings, and train a CWGAN model to generate synthetic ALS signals. The CWGAN architecture and training routine are detailed, with key hyperparameters chosen for stable training. Qualitative evaluation of generated signals shows that they closely mimic real ALS EEG patterns. The CWGAN training converged with generator and discriminator loss curves stabilizing, indicating successful learning. The synthetic EEG signals appear realistic and have potential use as augmented data for training classifiers, helping to mitigate class imbalance and improve ALS detection accuracy. We discuss how this approach can facilitate data sharing and enhance diagnostic models.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16243",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Sysformer: Safeguarding Frozen Large Language Models with Adaptive System Prompts",
    "description": "arXiv:2506.15751v1 Announce Type: new Abstract: As large language models (LLMs) are deployed in safety-critical settings, it is essential to ensure that their responses comply with safety standards. Prior research has revealed that LLMs often fail to grasp the notion of safe behaviors, resulting in either unjustified refusals to harmless prompts or the generation of harmful content. While substantial efforts have been made to improve their robustness, existing defenses often rely on costly fine-tuning of model parameters or employ suboptimal heuristic techniques. In this work, we take a novel approach to safeguard LLMs by learning to adapt the system prompts in instruction-tuned LLMs. While LLMs are typically pre-trained to follow a fixed system prompt, we investigate the impact of tailoring the system prompt to each specific user input on the safety of the responses. To this end, we propose $textbf{Sysformer}$, a trans$textbf{former}$ model that updates an initial $textbf{sys}$tem prompt to a more robust system prompt in the LLM input embedding space while attending to the user prompt. While keeping the LLM parameters frozen, the Sysformer is trained to refuse to respond to a set of harmful prompts while responding ideally to a set of safe ones. Through extensive experiments on $5$ LLMs from different families and $2$ recent benchmarks, we demonstrate that Sysformer can significantly enhance the robustness of LLMs, leading to upto $80%$ gain in the refusal rate on harmful prompts while enhancing the compliance with the safe prompts by upto $90%$. Results also generalize well to sophisticated jailbreaking attacks, making LLMs upto $100%$ more robust against different attack strategies. We hope our findings lead to cheaper safeguarding of LLMs and motivate future investigations into designing variable system prompts.",
    "summary": "arXiv:2506.15751v1 Announce Type: new Abstract: As large language models (LLMs) are deployed in safety-critical settings, it is essential to ensure that their responses comply with safety standards. Prior research has revealed that LLMs often fail to grasp the notion of safe behaviors, resulting in either unjustified refusals to harmless prompts or the generation of harmful content. While substantial efforts have been made to improve their robustness, existing defenses often rely on costly fine-tuning of model parameters or employ suboptimal heuristic techniques. In this work, we take a novel approach to safeguard LLMs by learning to adapt the system prompts in instruction-tuned LLMs. While LLMs are typically pre-trained to follow a fixed system prompt, we investigate the impact of tailoring the system prompt to each specific user input on the safety of the responses. To this end, we propose $textbf{Sysformer}$, a trans$textbf{former}$ model that updates an initial $textbf{sys}$tem prompt to a more robust system prompt in the LLM input embedding space while attending to the user prompt. While keeping the LLM parameters frozen, the Sysformer is trained to refuse to respond to a set of harmful prompts while responding ideally to a set of safe ones. Through extensive experiments on $5$ LLMs from different families and $2$ recent benchmarks, we demonstrate that Sysformer can significantly enhance the robustness of LLMs, leading to upto $80%$ gain in the refusal rate on harmful prompts while enhancing the compliance with the safe prompts by upto $90%$. Results also generalize well to sophisticated jailbreaking attacks, making LLMs upto $100%$ more robust against different attack strategies. We hope our findings lead to cheaper safeguarding of LLMs and motivate future investigations into designing variable system prompts.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.15751",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "TabArena: A Living Benchmark for Machine Learning on Tabular Data",
    "description": "arXiv:2506.16791v1 Announce Type: cross Abstract: With the growing popularity of deep learning and foundation models for tabular data, the need for standardized and reliable benchmarks is higher than ever. However, current benchmarks are static. Their design is not updated even if flaws are discovered, model versions are updated, or new models are released. To address this, we introduce TabArena, the first continuously maintained living tabular benchmarking system. To launch TabArena, we manually curate a representative collection of datasets and well-implemented models, conduct a large-scale benchmarking study to initialize a public leaderboard, and assemble a team of experienced maintainers. Our results highlight the influence of validation method and ensembling of hyperparameter configurations to benchmark models at their full potential. While gradient-boosted trees are still strong contenders on practical tabular datasets, we observe that deep learning methods have caught up under larger time budgets with ensembling. At the same time, foundation models excel on smaller datasets. Finally, we show that ensembles across models advance the state-of-the-art in tabular machine learning and investigate the contributions of individual models. We launch TabArena with a public leaderboard, reproducible code, and maintenance protocols to create a living benchmark available at https://tabarena.ai.",
    "summary": "arXiv:2506.16791v1 Announce Type: cross Abstract: With the growing popularity of deep learning and foundation models for tabular data, the need for standardized and reliable benchmarks is higher than ever. However, current benchmarks are static. Their design is not updated even if flaws are discovered, model versions are updated, or new models are released. To address this, we introduce TabArena, the first continuously maintained living tabular benchmarking system. To launch TabArena, we manually curate a representative collection of datasets and well-implemented models, conduct a large-scale benchmarking study to initialize a public leaderboard, and assemble a team of experienced maintainers. Our results highlight the influence of validation method and ensembling of hyperparameter configurations to benchmark models at their full potential. While gradient-boosted trees are still strong contenders on practical tabular datasets, we observe that deep learning methods have caught up under larger time budgets with ensembling. At the same time, foundation models excel on smaller datasets. Finally, we show that ensembles across models advance the state-of-the-art in tabular machine learning and investigate the contributions of individual models. We launch TabArena with a public leaderboard, reproducible code, and maintenance protocols to create a living benchmark available at https://tabarena.ai.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16791",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "TALE: A Tool-Augmented Framework for Reference-Free Evaluation of Large Language Models",
    "description": "arXiv:2504.07385v2 Announce Type: replace-cross Abstract: As Large Language Models (LLMs) become increasingly integrated into real-world, autonomous applications, relying on static, pre-annotated references for evaluation poses significant challenges in cost, scalability, and completeness. We propose Tool-Augmented LLM Evaluation (TALE), a framework to assess LLM outputs without predetermined ground-truth answers. Unlike conventional metrics that compare to fixed references or depend solely on LLM-as-a-judge knowledge, TALE employs an agent with tool-access capabilities that actively retrieves and synthesizes external evidence. It iteratively generates web queries, collects information, summarizes findings, and refines subsequent searches through reflection. By shifting away from static references, TALE aligns with free-form question-answering tasks common in real-world scenarios. Experimental results on multiple free-form QA benchmarks show that TALE not only outperforms standard reference-based metrics for measuring response accuracy but also achieves substantial to near-perfect agreement with human evaluations. TALE enhances the reliability of LLM evaluations in real-world, dynamic scenarios without relying on static references.",
    "summary": "arXiv:2504.07385v2 Announce Type: replace-cross Abstract: As Large Language Models (LLMs) become increasingly integrated into real-world, autonomous applications, relying on static, pre-annotated references for evaluation poses significant challenges in cost, scalability, and completeness. We propose Tool-Augmented LLM Evaluation (TALE), a framework to assess LLM outputs without predetermined ground-truth answers. Unlike conventional metrics that compare to fixed references or depend solely on LLM-as-a-judge knowledge, TALE employs an agent with tool-access capabilities that actively retrieves and synthesizes external evidence. It iteratively generates web queries, collects information, summarizes findings, and refines subsequent searches through reflection. By shifting away from static references, TALE aligns with free-form question-answering tasks common in real-world scenarios. Experimental results on multiple free-form QA benchmarks show that TALE not only outperforms standard reference-based metrics for measuring response accuracy but also achieves substantial to near-perfect agreement with human evaluations. TALE enhances the reliability of LLM evaluations in real-world, dynamic scenarios without relying on static references.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2504.07385",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "TARDIS STRIDE: A Spatio-Temporal Road Image Dataset and World Model for Autonomy",
    "description": "arXiv:2506.11302v3 Announce Type: replace-cross Abstract: World models aim to simulate environments and enable effective agent behavior. However, modeling real-world environments presents unique challenges as they dynamically change across both space and, crucially, time. To capture these composed dynamics, we introduce a Spatio-Temporal Road Image Dataset for Exploration (STRIDE) permuting 360-degree panoramic imagery into rich interconnected observation, state and action nodes. Leveraging this structure, we can simultaneously model the relationship between egocentric views, positional coordinates, and movement commands across both space and time. We benchmark this dataset via TARDIS, a transformer-based generative world model that integrates spatial and temporal dynamics through a unified autoregressive framework trained on STRIDE. We demonstrate robust performance across a range of agentic tasks such as controllable photorealistic image synthesis, instruction following, autonomous self-control, and state-of-the-art georeferencing. These results suggest a promising direction towards sophisticated generalist agents--capable of understanding and manipulating the spatial and temporal aspects of their material environments--with enhanced embodied reasoning capabilities. Training code, datasets, and model checkpoints are made available at https://huggingface.co/datasets/Tera-AI/STRIDE.",
    "summary": "arXiv:2506.11302v3 Announce Type: replace-cross Abstract: World models aim to simulate environments and enable effective agent behavior. However, modeling real-world environments presents unique challenges as they dynamically change across both space and, crucially, time. To capture these composed dynamics, we introduce a Spatio-Temporal Road Image Dataset for Exploration (STRIDE) permuting 360-degree panoramic imagery into rich interconnected observation, state and action nodes. Leveraging this structure, we can simultaneously model the relationship between egocentric views, positional coordinates, and movement commands across both space and time. We benchmark this dataset via TARDIS, a transformer-based generative world model that integrates spatial and temporal dynamics through a unified autoregressive framework trained on STRIDE. We demonstrate robust performance across a range of agentic tasks such as controllable photorealistic image synthesis, instruction following, autonomous self-control, and state-of-the-art georeferencing. These results suggest a promising direction towards sophisticated generalist agents--capable of understanding and manipulating the spatial and temporal aspects of their material environments--with enhanced embodied reasoning capabilities. Training code, datasets, and model checkpoints are made available at https://huggingface.co/datasets/Tera-AI/STRIDE.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.11302",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "TeXpert: A Multi-Level Benchmark for Evaluating LaTeX Code Generation by LLMs",
    "description": "arXiv:2506.16990v1 Announce Type: cross Abstract: LaTeX's precision and flexibility in typesetting have made it the gold standard for the preparation of scientific documentation. Large Language Models (LLMs) present a promising opportunity for researchers to produce publication-ready material using LaTeX with natural language instructions, yet current benchmarks completely lack evaluation of this ability. By introducing TeXpert, our benchmark dataset with natural language prompts for generating LaTeX code focused on components of scientific documents across multiple difficulty levels, we conduct an in-depth analysis of LLM performance in this regard and identify frequent error types. Our evaluation across open and closed-source LLMs highlights multiple key findings: LLMs excelling on standard benchmarks perform poorly in LaTeX generation with a significant accuracy drop-off as the complexity of tasks increases; open-source models like DeepSeek v3 and DeepSeek Coder strongly rival closed-source counterparts in LaTeX tasks; and formatting and package errors are unexpectedly prevalent, suggesting a lack of diverse LaTeX examples in the training datasets of most LLMs. Our dataset, code, and model evaluations are available at https://github.com/knowledge-verse-ai/TeXpert.",
    "summary": "arXiv:2506.16990v1 Announce Type: cross Abstract: LaTeX's precision and flexibility in typesetting have made it the gold standard for the preparation of scientific documentation. Large Language Models (LLMs) present a promising opportunity for researchers to produce publication-ready material using LaTeX with natural language instructions, yet current benchmarks completely lack evaluation of this ability. By introducing TeXpert, our benchmark dataset with natural language prompts for generating LaTeX code focused on components of scientific documents across multiple difficulty levels, we conduct an in-depth analysis of LLM performance in this regard and identify frequent error types. Our evaluation across open and closed-source LLMs highlights multiple key findings: LLMs excelling on standard benchmarks perform poorly in LaTeX generation with a significant accuracy drop-off as the complexity of tasks increases; open-source models like DeepSeek v3 and DeepSeek Coder strongly rival closed-source counterparts in LaTeX tasks; and formatting and package errors are unexpectedly prevalent, suggesting a lack of diverse LaTeX examples in the training datasets of most LLMs. Our dataset, code, and model evaluations are available at https://github.com/knowledge-verse-ai/TeXpert.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16990",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "$texttt{SPECS}$: Faster Test-Time Scaling through Speculative Drafts",
    "description": "arXiv:2506.15733v1 Announce Type: new Abstract: Scaling test-time compute has driven the recent advances in the reasoning capabilities of large language models (LLMs), typically by allocating additional computation for more thorough exploration. However, increased compute often comes at the expense of higher user-facing latency, directly impacting user experience. Current test-time scaling methods primarily optimize for accuracy based on total compute resources (FLOPS), often overlooking latency constraints. To address this gap, we propose $texttt{SPECS}$, a latency-aware test-time scaling method inspired by speculative decoding. $texttt{SPECS}$~uses a smaller, faster model to generate candidate sequences efficiently, and evaluates these candidates using signals from both a larger target model and a dedicated reward model. We introduce new integration strategies, including reward-guided soft verification and a reward-based deferral mechanism. Empirical results on MATH500, AMC23 and OlympiadBench datasets show that $texttt{SPECS}$~matches or surpasses beam search accuracy while reducing latency by up to $sim$19.1%. Our theoretical analysis shows that our algorithm converges to the solution of a KL-regularized reinforcement learning objective with increasing beam width.",
    "summary": "arXiv:2506.15733v1 Announce Type: new Abstract: Scaling test-time compute has driven the recent advances in the reasoning capabilities of large language models (LLMs), typically by allocating additional computation for more thorough exploration. However, increased compute often comes at the expense of higher user-facing latency, directly impacting user experience. Current test-time scaling methods primarily optimize for accuracy based on total compute resources (FLOPS), often overlooking latency constraints. To address this gap, we propose $texttt{SPECS}$, a latency-aware test-time scaling method inspired by speculative decoding. $texttt{SPECS}$~uses a smaller, faster model to generate candidate sequences efficiently, and evaluates these candidates using signals from both a larger target model and a dedicated reward model. We introduce new integration strategies, including reward-guided soft verification and a reward-based deferral mechanism. Empirical results on MATH500, AMC23 and OlympiadBench datasets show that $texttt{SPECS}$~matches or surpasses beam search accuracy while reducing latency by up to $sim$19.1%. Our theoretical analysis shows that our algorithm converges to the solution of a KL-regularized reinforcement learning objective with increasing beam width.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.15733",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "The AI Imperative: Scaling High-Quality Peer Review in Machine Learning",
    "description": "arXiv:2506.08134v2 Announce Type: replace Abstract: Peer review, the bedrock of scientific advancement in machine learning (ML), is strained by a crisis of scale. Exponential growth in manuscript submissions to premier ML venues such as NeurIPS, ICML, and ICLR is outpacing the finite capacity of qualified reviewers, leading to concerns about review quality, consistency, and reviewer fatigue. This position paper argues that AI-assisted peer review must become an urgent research and infrastructure priority. We advocate for a comprehensive AI-augmented ecosystem, leveraging Large Language Models (LLMs) not as replacements for human judgment, but as sophisticated collaborators for authors, reviewers, and Area Chairs (ACs). We propose specific roles for AI in enhancing factual verification, guiding reviewer performance, assisting authors in quality improvement, and supporting ACs in decision-making. Crucially, we contend that the development of such systems hinges on access to more granular, structured, and ethically-sourced peer review process data. We outline a research agenda, including illustrative experiments, to develop and validate these AI assistants, and discuss significant technical and ethical challenges. We call upon the ML community to proactively build this AI-assisted future, ensuring the continued integrity and scalability of scientific validation, while maintaining high standards of peer review.",
    "summary": "arXiv:2506.08134v2 Announce Type: replace Abstract: Peer review, the bedrock of scientific advancement in machine learning (ML), is strained by a crisis of scale. Exponential growth in manuscript submissions to premier ML venues such as NeurIPS, ICML, and ICLR is outpacing the finite capacity of qualified reviewers, leading to concerns about review quality, consistency, and reviewer fatigue. This position paper argues that AI-assisted peer review must become an urgent research and infrastructure priority. We advocate for a comprehensive AI-augmented ecosystem, leveraging Large Language Models (LLMs) not as replacements for human judgment, but as sophisticated collaborators for authors, reviewers, and Area Chairs (ACs). We propose specific roles for AI in enhancing factual verification, guiding reviewer performance, assisting authors in quality improvement, and supporting ACs in decision-making. Crucially, we contend that the development of such systems hinges on access to more granular, structured, and ethically-sourced peer review process data. We outline a research agenda, including illustrative experiments, to develop and validate these AI assistants, and discuss significant technical and ethical challenges. We call upon the ML community to proactively build this AI-assisted future, ensuring the continued integrity and scalability of scientific validation, while maintaining high standards of peer review.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.08134",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "The Importance of Being Lazy: Scaling Limits of Continual Learning",
    "description": "arXiv:2506.16884v1 Announce Type: cross Abstract: Despite recent efforts, neural networks still struggle to learn in non-stationary environments, and our understanding of catastrophic forgetting (CF) is far from complete. In this work, we perform a systematic study on the impact of model scale and the degree of feature learning in continual learning. We reconcile existing contradictory observations on scale in the literature, by differentiating between lazy and rich training regimes through a variable parameterization of the architecture. We show that increasing model width is only beneficial when it reduces the amount of feature learning, yielding more laziness. Using the framework of dynamical mean field theory, we then study the infinite width dynamics of the model in the feature learning regime and characterize CF, extending prior theoretical results limited to the lazy regime. We study the intricate relationship between feature learning, task non-stationarity, and forgetting, finding that high feature learning is only beneficial with highly similar tasks. We identify a transition modulated by task similarity where the model exits an effectively lazy regime with low forgetting to enter a rich regime with significant forgetting. Finally, our findings reveal that neural networks achieve optimal performance at a critical level of feature learning, which depends on task non-stationarity and transfers across model scales. This work provides a unified perspective on the role of scale and feature learning in continual learning.",
    "summary": "arXiv:2506.16884v1 Announce Type: cross Abstract: Despite recent efforts, neural networks still struggle to learn in non-stationary environments, and our understanding of catastrophic forgetting (CF) is far from complete. In this work, we perform a systematic study on the impact of model scale and the degree of feature learning in continual learning. We reconcile existing contradictory observations on scale in the literature, by differentiating between lazy and rich training regimes through a variable parameterization of the architecture. We show that increasing model width is only beneficial when it reduces the amount of feature learning, yielding more laziness. Using the framework of dynamical mean field theory, we then study the infinite width dynamics of the model in the feature learning regime and characterize CF, extending prior theoretical results limited to the lazy regime. We study the intricate relationship between feature learning, task non-stationarity, and forgetting, finding that high feature learning is only beneficial with highly similar tasks. We identify a transition modulated by task similarity where the model exits an effectively lazy regime with low forgetting to enter a rich regime with significant forgetting. Finally, our findings reveal that neural networks achieve optimal performance at a critical level of feature learning, which depends on task non-stationarity and transfers across model scales. This work provides a unified perspective on the role of scale and feature learning in continual learning.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16884",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "The MedPerturb Dataset: What Non-Content Perturbations Reveal About Human and Clinical LLM Decision Making",
    "description": "arXiv:2506.17163v1 Announce Type: new Abstract: Clinical robustness is critical to the safe deployment of medical Large Language Models (LLMs), but key questions remain about how LLMs and humans may differ in response to the real-world variability typified by clinical settings. To address this, we introduce MedPerturb, a dataset designed to systematically evaluate medical LLMs under controlled perturbations of clinical input. MedPerturb consists of clinical vignettes spanning a range of pathologies, each transformed along three axes: (1) gender modifications (e.g., gender-swapping or gender-removal); (2) style variation (e.g., uncertain phrasing or colloquial tone); and (3) format changes (e.g., LLM-generated multi-turn conversations or summaries). With MedPerturb, we release a dataset of 800 clinical contexts grounded in realistic input variability, outputs from four LLMs, and three human expert reads per clinical context. We use MedPerturb in two case studies to reveal how shifts in gender identity cues, language style, or format reflect diverging treatment selections between humans and LLMs. We find that LLMs are more sensitive to gender and style perturbations while human annotators are more sensitive to LLM-generated format perturbations such as clinical summaries. Our results highlight the need for evaluation frameworks that go beyond static benchmarks to assess the similarity between human clinician and LLM decisions under the variability characteristic of clinical settings.",
    "summary": "arXiv:2506.17163v1 Announce Type: new Abstract: Clinical robustness is critical to the safe deployment of medical Large Language Models (LLMs), but key questions remain about how LLMs and humans may differ in response to the real-world variability typified by clinical settings. To address this, we introduce MedPerturb, a dataset designed to systematically evaluate medical LLMs under controlled perturbations of clinical input. MedPerturb consists of clinical vignettes spanning a range of pathologies, each transformed along three axes: (1) gender modifications (e.g., gender-swapping or gender-removal); (2) style variation (e.g., uncertain phrasing or colloquial tone); and (3) format changes (e.g., LLM-generated multi-turn conversations or summaries). With MedPerturb, we release a dataset of 800 clinical contexts grounded in realistic input variability, outputs from four LLMs, and three human expert reads per clinical context. We use MedPerturb in two case studies to reveal how shifts in gender identity cues, language style, or format reflect diverging treatment selections between humans and LLMs. We find that LLMs are more sensitive to gender and style perturbations while human annotators are more sensitive to LLM-generated format perturbations such as clinical summaries. Our results highlight the need for evaluation frameworks that go beyond static benchmarks to assess the similarity between human clinician and LLM decisions under the variability characteristic of clinical settings.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.17163",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "The Memory Paradox: Why Our Brains Need Knowledge in an Age of AI",
    "description": "arXiv:2506.11015v2 Announce Type: replace-cross Abstract: In the age of generative AI and ubiquitous digital tools, human cognition faces a structural paradox: as external aids become more capable, internal memory systems risk atrophy. Drawing on neuroscience and cognitive psychology, this paper examines how heavy reliance on AI systems and discovery-based pedagogies may impair the consolidation of declarative and procedural memory -- systems essential for expertise, critical thinking, and long-term retention. We review how tools like ChatGPT and calculators can short-circuit the retrieval, error correction, and schema-building processes necessary for robust neural encoding. Notably, we highlight striking parallels between deep learning phenomena such as 'grokking' and the neuroscience of overlearning and intuition. Empirical studies are discussed showing how premature reliance on AI during learning inhibits proceduralization and intuitive mastery. We argue that effective human-AI interaction depends on strong internal models -- biological 'schemata' and neural manifolds -- that enable users to evaluate, refine, and guide AI output. The paper concludes with policy implications for education and workforce training in the age of large language models.",
    "summary": "arXiv:2506.11015v2 Announce Type: replace-cross Abstract: In the age of generative AI and ubiquitous digital tools, human cognition faces a structural paradox: as external aids become more capable, internal memory systems risk atrophy. Drawing on neuroscience and cognitive psychology, this paper examines how heavy reliance on AI systems and discovery-based pedagogies may impair the consolidation of declarative and procedural memory -- systems essential for expertise, critical thinking, and long-term retention. We review how tools like ChatGPT and calculators can short-circuit the retrieval, error correction, and schema-building processes necessary for robust neural encoding. Notably, we highlight striking parallels between deep learning phenomena such as 'grokking' and the neuroscience of overlearning and intuition. Empirical studies are discussed showing how premature reliance on AI during learning inhibits proceduralization and intuitive mastery. We argue that effective human-AI interaction depends on strong internal models -- biological 'schemata' and neural manifolds -- that enable users to evaluate, refine, and guide AI output. The paper concludes with policy implications for education and workforce training in the age of large language models.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.11015",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "The Role of Explanation Styles and Perceived Accuracy on Decision Making in Predictive Process Monitoring",
    "description": "arXiv:2506.16617v1 Announce Type: new Abstract: Predictive Process Monitoring (PPM) often uses deep learning models to predict the future behavior of ongoing processes, such as predicting process outcomes. While these models achieve high accuracy, their lack of interpretability undermines user trust and adoption. Explainable AI (XAI) aims to address this challenge by providing the reasoning behind the predictions. However, current evaluations of XAI in PPM focus primarily on functional metrics (such as fidelity), overlooking user-centered aspects such as their effect on task performance and decision-making. This study investigates the effects of explanation styles (feature importance, rule-based, and counterfactual) and perceived AI accuracy (low or high) on decision-making in PPM. We conducted a decision-making experiment, where users were presented with the AI predictions, perceived accuracy levels, and explanations of different styles. Users' decisions were measured both before and after receiving explanations, allowing the assessment of objective metrics (Task Performance and Agreement) and subjective metrics (Decision Confidence). Our findings show that perceived accuracy and explanation style have a significant effect.",
    "summary": "arXiv:2506.16617v1 Announce Type: new Abstract: Predictive Process Monitoring (PPM) often uses deep learning models to predict the future behavior of ongoing processes, such as predicting process outcomes. While these models achieve high accuracy, their lack of interpretability undermines user trust and adoption. Explainable AI (XAI) aims to address this challenge by providing the reasoning behind the predictions. However, current evaluations of XAI in PPM focus primarily on functional metrics (such as fidelity), overlooking user-centered aspects such as their effect on task performance and decision-making. This study investigates the effects of explanation styles (feature importance, rule-based, and counterfactual) and perceived AI accuracy (low or high) on decision-making in PPM. We conducted a decision-making experiment, where users were presented with the AI predictions, perceived accuracy levels, and explanations of different styles. Users' decisions were measured both before and after receiving explanations, allowing the assessment of objective metrics (Task Performance and Agreement) and subjective metrics (Decision Confidence). Our findings show that perceived accuracy and explanation style have a significant effect.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16617",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "The Role of Model Confidence on Bias Effects in Measured Uncertainties",
    "description": "arXiv:2506.16724v1 Announce Type: cross Abstract: With the growing adoption of Large Language Models (LLMs) for open-ended tasks, accurately assessing epistemic uncertainty, which reflects a model's lack of knowledge, has become crucial to ensuring reliable outcomes. However, quantifying epistemic uncertainty in such tasks is challenging due to the presence of aleatoric uncertainty, which arises from multiple valid answers. While bias can introduce noise into epistemic uncertainty estimation, it may also reduce noise from aleatoric uncertainty. To investigate this trade-off, we conduct experiments on Visual Question Answering (VQA) tasks and find that mitigating prompt-introduced bias improves uncertainty quantification in GPT-4o. Building on prior work showing that LLMs tend to copy input information when model confidence is low, we further analyze how these prompt biases affect measured epistemic and aleatoric uncertainty across varying bias-free confidence levels with GPT-4o and Qwen2-VL. We find that all considered biases induce greater changes in both uncertainties when bias-free model confidence is lower. Moreover, lower bias-free model confidence leads to greater underestimation of epistemic uncertainty (i.e. overconfidence) due to bias, whereas it has no significant effect on the direction of changes in aleatoric uncertainty estimation. These distinct effects deepen our understanding of bias mitigation for uncertainty quantification and potentially inform the development of more advanced techniques.",
    "summary": "arXiv:2506.16724v1 Announce Type: cross Abstract: With the growing adoption of Large Language Models (LLMs) for open-ended tasks, accurately assessing epistemic uncertainty, which reflects a model's lack of knowledge, has become crucial to ensuring reliable outcomes. However, quantifying epistemic uncertainty in such tasks is challenging due to the presence of aleatoric uncertainty, which arises from multiple valid answers. While bias can introduce noise into epistemic uncertainty estimation, it may also reduce noise from aleatoric uncertainty. To investigate this trade-off, we conduct experiments on Visual Question Answering (VQA) tasks and find that mitigating prompt-introduced bias improves uncertainty quantification in GPT-4o. Building on prior work showing that LLMs tend to copy input information when model confidence is low, we further analyze how these prompt biases affect measured epistemic and aleatoric uncertainty across varying bias-free confidence levels with GPT-4o and Qwen2-VL. We find that all considered biases induce greater changes in both uncertainties when bias-free model confidence is lower. Moreover, lower bias-free model confidence leads to greater underestimation of epistemic uncertainty (i.e. overconfidence) due to bias, whereas it has no significant effect on the direction of changes in aleatoric uncertainty estimation. These distinct effects deepen our understanding of bias mitigation for uncertainty quantification and potentially inform the development of more advanced techniques.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16724",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "The Safety Reminder: A Soft Prompt to Reactivate Delayed Safety Awareness in Vision-Language Models",
    "description": "arXiv:2506.15734v1 Announce Type: new Abstract: As Vision-Language Models (VLMs) demonstrate increasing capabilities across real-world applications such as code generation and chatbot assistance, ensuring their safety has become paramount. Unlike traditional Large Language Models (LLMs), VLMs face unique vulnerabilities due to their multimodal nature, allowing adversaries to modify visual or textual inputs to bypass safety guardrails and trigger the generation of harmful content. Through systematic analysis of VLM behavior under attack, we identify a novel phenomenon termed ``delayed safety awareness''. Specifically, we observe that safety-aligned VLMs may initially be compromised to produce harmful content, but eventually recognize the associated risks and attempt to self-correct. This pattern suggests that VLMs retain their underlying safety awareness but experience a temporal delay in their activation. Building on this insight, we hypothesize that VLMs' safety awareness can be proactively reactivated through carefully designed prompts. To this end, we introduce ``The Safety Reminder'', a soft prompt tuning approach that optimizes learnable prompt tokens, which are periodically injected during the text generation process to enhance safety awareness, effectively preventing harmful content generation. Additionally, our safety reminder only activates when harmful content is detected, leaving normal conversations unaffected and preserving the model's performance on benign tasks. Through comprehensive evaluation across three established safety benchmarks and one adversarial attacks, we demonstrate that our approach significantly reduces attack success rates while maintaining model utility, offering a practical solution for deploying safer VLMs in real-world applications.",
    "summary": "arXiv:2506.15734v1 Announce Type: new Abstract: As Vision-Language Models (VLMs) demonstrate increasing capabilities across real-world applications such as code generation and chatbot assistance, ensuring their safety has become paramount. Unlike traditional Large Language Models (LLMs), VLMs face unique vulnerabilities due to their multimodal nature, allowing adversaries to modify visual or textual inputs to bypass safety guardrails and trigger the generation of harmful content. Through systematic analysis of VLM behavior under attack, we identify a novel phenomenon termed ``delayed safety awareness''. Specifically, we observe that safety-aligned VLMs may initially be compromised to produce harmful content, but eventually recognize the associated risks and attempt to self-correct. This pattern suggests that VLMs retain their underlying safety awareness but experience a temporal delay in their activation. Building on this insight, we hypothesize that VLMs' safety awareness can be proactively reactivated through carefully designed prompts. To this end, we introduce ``The Safety Reminder'', a soft prompt tuning approach that optimizes learnable prompt tokens, which are periodically injected during the text generation process to enhance safety awareness, effectively preventing harmful content generation. Additionally, our safety reminder only activates when harmful content is detected, leaving normal conversations unaffected and preserving the model's performance on benign tasks. Through comprehensive evaluation across three established safety benchmarks and one adversarial attacks, we demonstrate that our approach significantly reduces attack success rates while maintaining model utility, offering a practical solution for deploying safer VLMs in real-world applications.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.15734",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Towards Advanced Mathematical Reasoning for LLMs via First-Order Logic Theorem Proving",
    "description": "arXiv:2506.17104v1 Announce Type: new Abstract: Large language models (LLMs) have shown promising first-order logic (FOL) reasoning capabilities with applications in various areas. However, their effectiveness in complex mathematical reasoning involving multi-step FOL deductions is still under-researched. While LLMs perform competitively on established mathematical reasoning benchmarks, they struggle with multi-step FOL tasks, as demonstrated by Deepseek-Prover-V2-7B's low accuracy (4.2%) on our proposed theorem proving dataset. This issue arises from the limited exploration of diverse proof strategies and the potential for early reasoning mistakes to undermine entire proofs. To address these issues, we propose DREAM, a self-adaptive solution that enhances the Diversity and REAsonability of LLMs' generation strategies. DREAM incorporates an Axiom-Driven Strategy Diversification mechanism to promote varied strategic outcomes and a Sub-Proposition Error Feedback to help LLMs reflect on and correct their proofs. Our contributions include pioneering advancements in LLMs' mathematical reasoning through FOL theorem proving, introducing a novel inference stage solution that improves performance by 0.6% to 6.4%, and providing a curated dataset of 447 mathematical theorems in Lean 4 format for evaluation.",
    "summary": "arXiv:2506.17104v1 Announce Type: new Abstract: Large language models (LLMs) have shown promising first-order logic (FOL) reasoning capabilities with applications in various areas. However, their effectiveness in complex mathematical reasoning involving multi-step FOL deductions is still under-researched. While LLMs perform competitively on established mathematical reasoning benchmarks, they struggle with multi-step FOL tasks, as demonstrated by Deepseek-Prover-V2-7B's low accuracy (4.2%) on our proposed theorem proving dataset. This issue arises from the limited exploration of diverse proof strategies and the potential for early reasoning mistakes to undermine entire proofs. To address these issues, we propose DREAM, a self-adaptive solution that enhances the Diversity and REAsonability of LLMs' generation strategies. DREAM incorporates an Axiom-Driven Strategy Diversification mechanism to promote varied strategic outcomes and a Sub-Proposition Error Feedback to help LLMs reflect on and correct their proofs. Our contributions include pioneering advancements in LLMs' mathematical reasoning through FOL theorem proving, introducing a novel inference stage solution that improves performance by 0.6% to 6.4%, and providing a curated dataset of 447 mathematical theorems in Lean 4 format for evaluation.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.17104",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Towards AI-Driven Policing: Interdisciplinary Knowledge Discovery from Police Body-Worn Camera Footage",
    "description": "arXiv:2504.20007v3 Announce Type: replace Abstract: This paper proposes a novel interdisciplinary framework for analyzing police body-worn camera (BWC) footage from the Rochester Police Department (RPD) using advanced artificial intelligence (AI) and statistical machine learning (ML) techniques. Our goal is to detect, classify, and analyze patterns of interaction between police officers and civilians to identify key behavioral dynamics, such as respect, disrespect, escalation, and de-escalation. We apply multimodal data analysis by integrating image, audio, and natural language processing (NLP) techniques to extract meaningful insights from BWC footage. The framework incorporates speaker separation, transcription, and large language models (LLMs) to produce structured, interpretable summaries of police-civilian encounters. We also employ a custom evaluation pipeline to assess transcription quality and behavior detection accuracy in high-stakes, real-world policing scenarios. Our methodology, computational techniques, and findings outline a practical approach for law enforcement review, training, and accountability processes while advancing the frontiers of knowledge discovery from complex police BWC data.",
    "summary": "arXiv:2504.20007v3 Announce Type: replace Abstract: This paper proposes a novel interdisciplinary framework for analyzing police body-worn camera (BWC) footage from the Rochester Police Department (RPD) using advanced artificial intelligence (AI) and statistical machine learning (ML) techniques. Our goal is to detect, classify, and analyze patterns of interaction between police officers and civilians to identify key behavioral dynamics, such as respect, disrespect, escalation, and de-escalation. We apply multimodal data analysis by integrating image, audio, and natural language processing (NLP) techniques to extract meaningful insights from BWC footage. The framework incorporates speaker separation, transcription, and large language models (LLMs) to produce structured, interpretable summaries of police-civilian encounters. We also employ a custom evaluation pipeline to assess transcription quality and behavior detection accuracy in high-stakes, real-world policing scenarios. Our methodology, computational techniques, and findings outline a practical approach for law enforcement review, training, and accountability processes while advancing the frontiers of knowledge discovery from complex police BWC data.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2504.20007",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Towards AI Search Paradigm",
    "description": "arXiv:2506.17188v1 Announce Type: cross Abstract: In this paper, we introduce the AI Search Paradigm, a comprehensive blueprint for next-generation search systems capable of emulating human information processing and decision-making. The paradigm employs a modular architecture of four LLM-powered agents (Master, Planner, Executor and Writer) that dynamically adapt to the full spectrum of information needs, from simple factual queries to complex multi-stage reasoning tasks. These agents collaborate dynamically through coordinated workflows to evaluate query complexity, decompose problems into executable plans, and orchestrate tool usage, task execution, and content synthesis. We systematically present key methodologies for realizing this paradigm, including task planning and tool integration, execution strategies, aligned and robust retrieval-augmented generation, and efficient LLM inference, spanning both algorithmic techniques and infrastructure-level optimizations. By providing an in-depth guide to these foundational components, this work aims to inform the development of trustworthy, adaptive, and scalable AI search systems.",
    "summary": "arXiv:2506.17188v1 Announce Type: cross Abstract: In this paper, we introduce the AI Search Paradigm, a comprehensive blueprint for next-generation search systems capable of emulating human information processing and decision-making. The paradigm employs a modular architecture of four LLM-powered agents (Master, Planner, Executor and Writer) that dynamically adapt to the full spectrum of information needs, from simple factual queries to complex multi-stage reasoning tasks. These agents collaborate dynamically through coordinated workflows to evaluate query complexity, decompose problems into executable plans, and orchestrate tool usage, task execution, and content synthesis. We systematically present key methodologies for realizing this paradigm, including task planning and tool integration, execution strategies, aligned and robust retrieval-augmented generation, and efficient LLM inference, spanning both algorithmic techniques and infrastructure-level optimizations. By providing an in-depth guide to these foundational components, this work aims to inform the development of trustworthy, adaptive, and scalable AI search systems.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.17188",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Towards Effective Complementary Security Analysis using Large Language Models",
    "description": "arXiv:2506.16899v1 Announce Type: cross Abstract: A key challenge in security analysis is the manual evaluation of potential security weaknesses generated by static application security testing (SAST) tools. Numerous false positives (FPs) in these reports reduce the effectiveness of security analysis. We propose using Large Language Models (LLMs) to improve the assessment of SAST findings. We investigate the ability of LLMs to reduce FPs while trying to maintain a perfect true positive rate, using datasets extracted from the OWASP Benchmark (v1.2) and a real-world software project. Our results indicate that advanced prompting techniques, such as Chain-of-Thought and Self-Consistency, substantially improve FP detection. Notably, some LLMs identified approximately 62.5% of FPs in the OWASP Benchmark dataset without missing genuine weaknesses. Combining detections from different LLMs would increase this FP detection to approximately 78.9%. Additionally, we demonstrate our approach's generalizability using a real-world dataset covering five SAST tools, three programming languages, and infrastructure files. The best LLM detected 33.85% of all FPs without missing genuine weaknesses, while combining detections from different LLMs would increase this detection to 38.46%. Our findings highlight the potential of LLMs to complement traditional SAST tools, enhancing automation and reducing resources spent addressing false alarms.",
    "summary": "arXiv:2506.16899v1 Announce Type: cross Abstract: A key challenge in security analysis is the manual evaluation of potential security weaknesses generated by static application security testing (SAST) tools. Numerous false positives (FPs) in these reports reduce the effectiveness of security analysis. We propose using Large Language Models (LLMs) to improve the assessment of SAST findings. We investigate the ability of LLMs to reduce FPs while trying to maintain a perfect true positive rate, using datasets extracted from the OWASP Benchmark (v1.2) and a real-world software project. Our results indicate that advanced prompting techniques, such as Chain-of-Thought and Self-Consistency, substantially improve FP detection. Notably, some LLMs identified approximately 62.5% of FPs in the OWASP Benchmark dataset without missing genuine weaknesses. Combining detections from different LLMs would increase this FP detection to approximately 78.9%. Additionally, we demonstrate our approach's generalizability using a real-world dataset covering five SAST tools, three programming languages, and infrastructure files. The best LLM detected 33.85% of all FPs without missing genuine weaknesses, while combining detections from different LLMs would increase this detection to 38.46%. Our findings highlight the potential of LLMs to complement traditional SAST tools, enhancing automation and reducing resources spent addressing false alarms.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16899",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Towards Efficient Few-shot Graph Neural Architecture Search via Partitioning Gradient Contribution",
    "description": "arXiv:2506.01231v2 Announce Type: replace-cross Abstract: To address the weight coupling problem, certain studies introduced few-shot Neural Architecture Search (NAS) methods, which partition the supernet into multiple sub-supernets. However, these methods often suffer from computational inefficiency and tend to provide suboptimal partitioning schemes. To address this problem more effectively, we analyze the weight coupling problem from a novel perspective, which primarily stems from distinct modules in succeeding layers imposing conflicting gradient directions on the preceding layer modules. Based on this perspective, we propose the Gradient Contribution (GC) method that efficiently computes the cosine similarity of gradient directions among modules by decomposing the Vector-Jacobian Product during supernet backpropagation. Subsequently, the modules with conflicting gradient directions are allocated to distinct sub-supernets while similar ones are grouped together. To assess the advantages of GC and address the limitations of existing Graph Neural Architecture Search methods, which are limited to searching a single type of Graph Neural Networks (Message Passing Neural Networks (MPNNs) or Graph Transformers (GTs)), we propose the Unified Graph Neural Architecture Search (UGAS) framework, which explores optimal combinations of MPNNs and GTs. The experimental results demonstrate that GC achieves state-of-the-art (SOTA) performance in supernet partitioning quality and time efficiency. In addition, the architectures searched by UGAS+GC outperform both the manually designed GNNs and those obtained by existing NAS methods. Finally, ablation studies further demonstrate the effectiveness of all proposed methods.",
    "summary": "arXiv:2506.01231v2 Announce Type: replace-cross Abstract: To address the weight coupling problem, certain studies introduced few-shot Neural Architecture Search (NAS) methods, which partition the supernet into multiple sub-supernets. However, these methods often suffer from computational inefficiency and tend to provide suboptimal partitioning schemes. To address this problem more effectively, we analyze the weight coupling problem from a novel perspective, which primarily stems from distinct modules in succeeding layers imposing conflicting gradient directions on the preceding layer modules. Based on this perspective, we propose the Gradient Contribution (GC) method that efficiently computes the cosine similarity of gradient directions among modules by decomposing the Vector-Jacobian Product during supernet backpropagation. Subsequently, the modules with conflicting gradient directions are allocated to distinct sub-supernets while similar ones are grouped together. To assess the advantages of GC and address the limitations of existing Graph Neural Architecture Search methods, which are limited to searching a single type of Graph Neural Networks (Message Passing Neural Networks (MPNNs) or Graph Transformers (GTs)), we propose the Unified Graph Neural Architecture Search (UGAS) framework, which explores optimal combinations of MPNNs and GTs. The experimental results demonstrate that GC achieves state-of-the-art (SOTA) performance in supernet partitioning quality and time efficiency. In addition, the architectures searched by UGAS+GC outperform both the manually designed GNNs and those obtained by existing NAS methods. Finally, ablation studies further demonstrate the effectiveness of all proposed methods.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.01231",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Towards Generalizable Generic Harmful Speech Datasets for Implicit Hate Speech Detection",
    "description": "arXiv:2506.16476v1 Announce Type: cross Abstract: Implicit hate speech has recently emerged as a critical challenge for social media platforms. While much of the research has traditionally focused on harmful speech in general, the need for generalizable techniques to detect veiled and subtle forms of hate has become increasingly pressing. Based on lexicon analysis, we hypothesize that implicit hate speech is already present in publicly available harmful speech datasets but may not have been explicitly recognized or labeled by annotators. Additionally, crowdsourced datasets are prone to mislabeling due to the complexity of the task and often influenced by annotators' subjective interpretations. In this paper, we propose an approach to address the detection of implicit hate speech and enhance generalizability across diverse datasets by leveraging existing harmful speech datasets. Our method comprises three key components: influential sample identification, reannotation, and augmentation using Llama-3 70B and GPT-4o. Experimental results demonstrate the effectiveness of our approach in improving implicit hate detection, achieving a +12.9-point F1 score improvement compared to the baseline.",
    "summary": "arXiv:2506.16476v1 Announce Type: cross Abstract: Implicit hate speech has recently emerged as a critical challenge for social media platforms. While much of the research has traditionally focused on harmful speech in general, the need for generalizable techniques to detect veiled and subtle forms of hate has become increasingly pressing. Based on lexicon analysis, we hypothesize that implicit hate speech is already present in publicly available harmful speech datasets but may not have been explicitly recognized or labeled by annotators. Additionally, crowdsourced datasets are prone to mislabeling due to the complexity of the task and often influenced by annotators' subjective interpretations. In this paper, we propose an approach to address the detection of implicit hate speech and enhance generalizability across diverse datasets by leveraging existing harmful speech datasets. Our method comprises three key components: influential sample identification, reannotation, and augmentation using Llama-3 70B and GPT-4o. Experimental results demonstrate the effectiveness of our approach in improving implicit hate detection, achieving a +12.9-point F1 score improvement compared to the baseline.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16476",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Tower+: Bridging Generality and Translation Specialization in Multilingual LLMs",
    "description": "arXiv:2506.17080v1 Announce Type: cross Abstract: Fine-tuning pretrained LLMs has been shown to be an effective strategy for reaching state-of-the-art performance on specific tasks like machine translation. However, this process of adaptation often implies sacrificing general-purpose capabilities, such as conversational reasoning and instruction-following, hampering the utility of the system in real-world applications that require a mixture of skills. In this paper, we introduce Tower+, a suite of models designed to deliver strong performance across both translation and multilingual general-purpose text capabilities. We achieve a Pareto frontier between translation specialization and multilingual general-purpose capabilities by introducing a novel training recipe that builds on Tower (Alves et al., 2024), comprising continued pretraining, supervised fine-tuning, preference optimization, and reinforcement learning with verifiable rewards. At each stage of training, we carefully generate and curate data to strengthen performance on translation as well as general-purpose tasks involving code generation, mathematics problem solving, and general instruction-following. We develop models at multiple scales: 2B, 9B, and 72B. Our smaller models often outperform larger general-purpose open-weight and proprietary LLMs (e.g., Llama 3.3 70B, GPT-4o). Our largest model delivers best-in-class translation performance for high-resource languages and top results in multilingual Arena Hard evaluations and in IF-MT, a benchmark we introduce for evaluating both translation and instruction-following. Our findings highlight that it is possible to rival frontier models in general capabilities, while optimizing for specific business domains, such as translation and localization.",
    "summary": "arXiv:2506.17080v1 Announce Type: cross Abstract: Fine-tuning pretrained LLMs has been shown to be an effective strategy for reaching state-of-the-art performance on specific tasks like machine translation. However, this process of adaptation often implies sacrificing general-purpose capabilities, such as conversational reasoning and instruction-following, hampering the utility of the system in real-world applications that require a mixture of skills. In this paper, we introduce Tower+, a suite of models designed to deliver strong performance across both translation and multilingual general-purpose text capabilities. We achieve a Pareto frontier between translation specialization and multilingual general-purpose capabilities by introducing a novel training recipe that builds on Tower (Alves et al., 2024), comprising continued pretraining, supervised fine-tuning, preference optimization, and reinforcement learning with verifiable rewards. At each stage of training, we carefully generate and curate data to strengthen performance on translation as well as general-purpose tasks involving code generation, mathematics problem solving, and general instruction-following. We develop models at multiple scales: 2B, 9B, and 72B. Our smaller models often outperform larger general-purpose open-weight and proprietary LLMs (e.g., Llama 3.3 70B, GPT-4o). Our largest model delivers best-in-class translation performance for high-resource languages and top results in multilingual Arena Hard evaluations and in IF-MT, a benchmark we introduce for evaluating both translation and instruction-following. Our findings highlight that it is possible to rival frontier models in general capabilities, while optimizing for specific business domains, such as translation and localization.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.17080",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "TrainVerify: Equivalence-Based Verification for Distributed LLM Training",
    "description": "arXiv:2506.15961v1 Announce Type: cross Abstract: Training large language models (LLMs) at scale requires parallel execution across thousands of devices, incurring enormous computational costs. Yet, these costly distributed trainings are rarely verified, leaving them prone to silent errors and potentially wasting millions of GPU hours. We introduce TrainVerify, a system for verifiable distributed training of LLMs. Given a deep learning model's logical specification as the ground truth, TrainVerify formally verifies that a distributed parallel execution plan is mathematically equivalent to it. Direct verification is notoriously difficult due to the sheer scale of LLMs which often involves billions of variables and highly intricate computation graphs. Therefore, TrainVerify introduces shape-reduction techniques and a stage-wise parallel verification algorithm that significantly reduces complexity while preserving formal correctness. TrainVerify scales to frontier LLMs, including the successful verification of the Llama3 (405B) and DeepSeek-V3 (671B) training plans.",
    "summary": "arXiv:2506.15961v1 Announce Type: cross Abstract: Training large language models (LLMs) at scale requires parallel execution across thousands of devices, incurring enormous computational costs. Yet, these costly distributed trainings are rarely verified, leaving them prone to silent errors and potentially wasting millions of GPU hours. We introduce TrainVerify, a system for verifiable distributed training of LLMs. Given a deep learning model's logical specification as the ground truth, TrainVerify formally verifies that a distributed parallel execution plan is mathematically equivalent to it. Direct verification is notoriously difficult due to the sheer scale of LLMs which often involves billions of variables and highly intricate computation graphs. Therefore, TrainVerify introduces shape-reduction techniques and a stage-wise parallel verification algorithm that significantly reduces complexity while preserving formal correctness. TrainVerify scales to frontier LLMs, including the successful verification of the Llama3 (405B) and DeepSeek-V3 (671B) training plans.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.15961",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "TransDreamerV3: Implanting Transformer In DreamerV3",
    "description": "arXiv:2506.17103v1 Announce Type: cross Abstract: This paper introduces TransDreamerV3, a reinforcement learning model that enhances the DreamerV3 architecture by integrating a transformer encoder. The model is designed to improve memory and decision-making capabilities in complex environments. We conducted experiments on Atari-Boxing, Atari-Freeway, Atari-Pong, and Crafter tasks, where TransDreamerV3 demonstrated improved performance over DreamerV3, particularly in the Atari-Freeway and Crafter tasks. While issues in the Minecraft task and limited training across all tasks were noted, TransDreamerV3 displays advancement in world model-based reinforcement learning, leveraging transformer architectures.",
    "summary": "arXiv:2506.17103v1 Announce Type: cross Abstract: This paper introduces TransDreamerV3, a reinforcement learning model that enhances the DreamerV3 architecture by integrating a transformer encoder. The model is designed to improve memory and decision-making capabilities in complex environments. We conducted experiments on Atari-Boxing, Atari-Freeway, Atari-Pong, and Crafter tasks, where TransDreamerV3 demonstrated improved performance over DreamerV3, particularly in the Atari-Freeway and Crafter tasks. While issues in the Minecraft task and limited training across all tasks were noted, TransDreamerV3 displays advancement in world model-based reinforcement learning, leveraging transformer architectures.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.17103",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Transformers backend integration in SGLang",
    "description": "",
    "summary": "",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/transformers-backend-sglang",
    "thumbnail": "https://huggingface.co/blog/assets/196_transformers_backend_sglang/thumbnail.jpg"
  },
  {
    "title": "TriCon-SF: A Triple-Shuffle and Contribution-Aware Serial Federated Learning Framework for Heterogeneous Healthcare Data",
    "description": "arXiv:2506.16723v1 Announce Type: cross Abstract: Serial pipeline training is an efficient paradigm for handling data heterogeneity in cross-silo federated learning with low communication overhead. However, even without centralized aggregation, direct transfer of models between clients can violate privacy regulations and remain susceptible to gradient leakage and linkage attacks. Additionally, ensuring resilience against semi-honest or malicious clients who may manipulate or misuse received models remains a grand challenge, particularly in privacy-sensitive domains such as healthcare. To address these challenges, we propose TriCon-SF, a novel serial federated learning framework that integrates triple shuffling and contribution awareness. TriCon-SF introduces three levels of randomization by shuffling model layers, data segments, and training sequences to break deterministic learning patterns and disrupt potential attack vectors, thereby enhancing privacy and robustness. In parallel, it leverages Shapley value methods to dynamically evaluate client contributions during training, enabling the detection of dishonest behavior and enhancing system accountability. Extensive experiments on non-IID healthcare datasets demonstrate that TriCon-SF outperforms standard serial and parallel federated learning in both accuracy and communication efficiency. Security analysis further supports its resilience against client-side privacy attacks.",
    "summary": "arXiv:2506.16723v1 Announce Type: cross Abstract: Serial pipeline training is an efficient paradigm for handling data heterogeneity in cross-silo federated learning with low communication overhead. However, even without centralized aggregation, direct transfer of models between clients can violate privacy regulations and remain susceptible to gradient leakage and linkage attacks. Additionally, ensuring resilience against semi-honest or malicious clients who may manipulate or misuse received models remains a grand challenge, particularly in privacy-sensitive domains such as healthcare. To address these challenges, we propose TriCon-SF, a novel serial federated learning framework that integrates triple shuffling and contribution awareness. TriCon-SF introduces three levels of randomization by shuffling model layers, data segments, and training sequences to break deterministic learning patterns and disrupt potential attack vectors, thereby enhancing privacy and robustness. In parallel, it leverages Shapley value methods to dynamically evaluate client contributions during training, enabling the detection of dishonest behavior and enhancing system accountability. Extensive experiments on non-IID healthcare datasets demonstrate that TriCon-SF outperforms standard serial and parallel federated learning in both accuracy and communication efficiency. Security analysis further supports its resilience against client-side privacy attacks.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16723",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "TRUST: Transparent, Robust and Ultra-Sparse Trees",
    "description": "arXiv:2506.15791v1 Announce Type: cross Abstract: Piecewise-constant regression trees remain popular for their interpretability, yet often lag behind black-box models like Random Forest in predictive accuracy. In this work, we introduce TRUST (Transparent, Robust, and Ultra-Sparse Trees), a novel regression tree model that combines the accuracy of Random Forests with the interpretability of shallow decision trees and sparse linear models. TRUST further enhances transparency by leveraging Large Language Models to generate tailored, user-friendly explanations. Extensive validation on synthetic and real-world benchmark datasets demonstrates that TRUST consistently outperforms other interpretable models -- including CART, Lasso, and Node Harvest -- in predictive accuracy, while matching the accuracy of Random Forest and offering substantial gains in both accuracy and interpretability over M5', a well-established model that is conceptually related.",
    "summary": "arXiv:2506.15791v1 Announce Type: cross Abstract: Piecewise-constant regression trees remain popular for their interpretability, yet often lag behind black-box models like Random Forest in predictive accuracy. In this work, we introduce TRUST (Transparent, Robust, and Ultra-Sparse Trees), a novel regression tree model that combines the accuracy of Random Forests with the interpretability of shallow decision trees and sparse linear models. TRUST further enhances transparency by leveraging Large Language Models to generate tailored, user-friendly explanations. Extensive validation on synthetic and real-world benchmark datasets demonstrates that TRUST consistently outperforms other interpretable models -- including CART, Lasso, and Node Harvest -- in predictive accuracy, while matching the accuracy of Random Forest and offering substantial gains in both accuracy and interpretability over M5', a well-established model that is conceptually related.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.15791",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Two Heads Are Better than One: Simulating Large Transformers with Small Ones",
    "description": "arXiv:2506.12220v2 Announce Type: replace-cross Abstract: The quadratic complexity of self-attention prevents transformers from scaling effectively to long input sequences. On the other hand, modern GPUs and other specialized hardware accelerators are well-optimized for processing small input sequences in transformers during both training and inference. A natural question arises: can we take advantage of the efficiency of small transformers to deal with long input sequences? In this paper, we show that transformers with long input sequences (large transformers) can be efficiently simulated by transformers that can only take short input sequences (small transformers). Specifically, we prove that any transformer with input length $N$ can be efficiently simulated by only $O((N/M)^2)$ transformers with input length $M ll N$, and that this cannot be improved in the worst case. However, we then prove that in various natural scenarios including average-case inputs, sliding window masking and attention sinks, the optimal number $O(N/M)$ of small transformers suffice.",
    "summary": "arXiv:2506.12220v2 Announce Type: replace-cross Abstract: The quadratic complexity of self-attention prevents transformers from scaling effectively to long input sequences. On the other hand, modern GPUs and other specialized hardware accelerators are well-optimized for processing small input sequences in transformers during both training and inference. A natural question arises: can we take advantage of the efficiency of small transformers to deal with long input sequences? In this paper, we show that transformers with long input sequences (large transformers) can be efficiently simulated by transformers that can only take short input sequences (small transformers). Specifically, we prove that any transformer with input length $N$ can be efficiently simulated by only $O((N/M)^2)$ transformers with input length $M ll N$, and that this cannot be improved in the worst case. However, we then prove that in various natural scenarios including average-case inputs, sliding window masking and attention sinks, the optimal number $O(N/M)$ of small transformers suffice.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.12220",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Uncertainty Estimation by Human Perception versus Neural Models",
    "description": "arXiv:2506.15850v1 Announce Type: cross Abstract: Modern neural networks (NNs) often achieve high predictive accuracy but remain poorly calibrated, producing overconfident predictions even when wrong. This miscalibration poses serious challenges in applications where reliable uncertainty estimates are critical. In this work, we investigate how human perceptual uncertainty compares to uncertainty estimated by NNs. Using three vision benchmarks annotated with both human disagreement and crowdsourced confidence, we assess the correlation between model-predicted uncertainty and human-perceived uncertainty. Our results show that current methods only weakly align with human intuition, with correlations varying significantly across tasks and uncertainty metrics. Notably, we find that incorporating human-derived soft labels into the training process can improve calibration without compromising accuracy. These findings reveal a persistent gap between model and human uncertainty and highlight the potential of leveraging human insights to guide the development of more trustworthy AI systems.",
    "summary": "arXiv:2506.15850v1 Announce Type: cross Abstract: Modern neural networks (NNs) often achieve high predictive accuracy but remain poorly calibrated, producing overconfident predictions even when wrong. This miscalibration poses serious challenges in applications where reliable uncertainty estimates are critical. In this work, we investigate how human perceptual uncertainty compares to uncertainty estimated by NNs. Using three vision benchmarks annotated with both human disagreement and crowdsourced confidence, we assess the correlation between model-predicted uncertainty and human-perceived uncertainty. Our results show that current methods only weakly align with human intuition, with correlations varying significantly across tasks and uncertainty metrics. Notably, we find that incorporating human-derived soft labels into the training process can improve calibration without compromising accuracy. These findings reveal a persistent gap between model and human uncertainty and highlight the potential of leveraging human insights to guide the development of more trustworthy AI systems.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.15850",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Under the Shadow of Babel: How Language Shapes Reasoning in LLMs",
    "description": "arXiv:2506.16151v1 Announce Type: cross Abstract: Language is not only a tool for communication but also a medium for human cognition and reasoning. If, as linguistic relativity suggests, the structure of language shapes cognitive patterns, then large language models (LLMs) trained on human language may also internalize the habitual logical structures embedded in different languages. To examine this hypothesis, we introduce BICAUSE, a structured bilingual dataset for causal reasoning, which includes semantically aligned Chinese and English samples in both forward and reversed causal forms. Our study reveals three key findings: (1) LLMs exhibit typologically aligned attention patterns, focusing more on causes and sentence-initial connectives in Chinese, while showing a more balanced distribution in English. (2) Models internalize language-specific preferences for causal word order and often rigidly apply them to atypical inputs, leading to degraded performance, especially in Chinese. (3) When causal reasoning succeeds, model representations converge toward semantically aligned abstractions across languages, indicating a shared understanding beyond surface form. Overall, these results suggest that LLMs not only mimic surface linguistic forms but also internalize the reasoning biases shaped by language. Rooted in cognitive linguistic theory, this phenomenon is for the first time empirically verified through structural analysis of model internals.",
    "summary": "arXiv:2506.16151v1 Announce Type: cross Abstract: Language is not only a tool for communication but also a medium for human cognition and reasoning. If, as linguistic relativity suggests, the structure of language shapes cognitive patterns, then large language models (LLMs) trained on human language may also internalize the habitual logical structures embedded in different languages. To examine this hypothesis, we introduce BICAUSE, a structured bilingual dataset for causal reasoning, which includes semantically aligned Chinese and English samples in both forward and reversed causal forms. Our study reveals three key findings: (1) LLMs exhibit typologically aligned attention patterns, focusing more on causes and sentence-initial connectives in Chinese, while showing a more balanced distribution in English. (2) Models internalize language-specific preferences for causal word order and often rigidly apply them to atypical inputs, leading to degraded performance, especially in Chinese. (3) When causal reasoning succeeds, model representations converge toward semantically aligned abstractions across languages, indicating a shared understanding beyond surface form. Overall, these results suggest that LLMs not only mimic surface linguistic forms but also internalize the reasoning biases shaped by language. Rooted in cognitive linguistic theory, this phenomenon is for the first time empirically verified through structural analysis of model internals.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16151",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Understanding and Reducing the Class-Dependent Effects of Data Augmentation with A Two-Player Game Approach",
    "description": "arXiv:2407.03146v4 Announce Type: replace-cross Abstract: Data augmentation is widely applied and has shown its benefits in different machine learning tasks. However, as recently observed, it may have an unfair effect in multi-class classification. While data augmentation generally improves the overall performance (and therefore is beneficial for many classes), it can actually be detrimental for other classes, which can be problematic in some application domains. In this paper, to counteract this phenomenon, we propose CLAM, a CLAss-dependent Multiplicative-weights method. To derive it, we first formulate the training of a classifier as a non-linear optimization problem that aims at simultaneously maximizing the individual class performances and balancing them. By rewriting this optimization problem as an adversarial two-player game, we propose a novel multiplicative weight algorithm, for which we prove the convergence. Interestingly, our formulation also reveals that the class-dependent effects of data augmentation is not due to data augmentation only, but is in fact a general phenomenon. Our empirical results over six datasets demonstrate that the performance of learned classifiers is indeed more fairly distributed over classes, with only limited impact on the average accuracy.",
    "summary": "arXiv:2407.03146v4 Announce Type: replace-cross Abstract: Data augmentation is widely applied and has shown its benefits in different machine learning tasks. However, as recently observed, it may have an unfair effect in multi-class classification. While data augmentation generally improves the overall performance (and therefore is beneficial for many classes), it can actually be detrimental for other classes, which can be problematic in some application domains. In this paper, to counteract this phenomenon, we propose CLAM, a CLAss-dependent Multiplicative-weights method. To derive it, we first formulate the training of a classifier as a non-linear optimization problem that aims at simultaneously maximizing the individual class performances and balancing them. By rewriting this optimization problem as an adversarial two-player game, we propose a novel multiplicative weight algorithm, for which we prove the convergence. Interestingly, our formulation also reveals that the class-dependent effects of data augmentation is not due to data augmentation only, but is in fact a general phenomenon. Our empirical results over six datasets demonstrate that the performance of learned classifiers is indeed more fairly distributed over classes, with only limited impact on the average accuracy.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2407.03146",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "UniMate: A Unified Model for Mechanical Metamaterial Generation, Property Prediction, and Condition Confirmation",
    "description": "arXiv:2506.15722v1 Announce Type: cross Abstract: Metamaterials are artificial materials that are designed to meet unseen properties in nature, such as ultra-stiffness and negative materials indices. In mechanical metamaterial design, three key modalities are typically involved, i.e., 3D topology, density condition, and mechanical property. Real-world complex application scenarios place the demanding requirements on machine learning models to consider all three modalities together. However, a comprehensive literature review indicates that most existing works only consider two modalities, e.g., predicting mechanical properties given the 3D topology or generating 3D topology given the required properties. Therefore, there is still a significant gap for the state-of-the-art machine learning models capturing the whole. Hence, we propose a unified model named UNIMATE, which consists of a modality alignment module and a synergetic diffusion generation module. Experiments indicate that UNIMATE outperforms the other baseline models in topology generation task, property prediction task, and condition confirmation task by up to 80.2%, 5.1%, and 50.2%, respectively. We opensource our proposed UNIMATE model and corresponding results at https://github.com/wzhan24/UniMate.",
    "summary": "arXiv:2506.15722v1 Announce Type: cross Abstract: Metamaterials are artificial materials that are designed to meet unseen properties in nature, such as ultra-stiffness and negative materials indices. In mechanical metamaterial design, three key modalities are typically involved, i.e., 3D topology, density condition, and mechanical property. Real-world complex application scenarios place the demanding requirements on machine learning models to consider all three modalities together. However, a comprehensive literature review indicates that most existing works only consider two modalities, e.g., predicting mechanical properties given the 3D topology or generating 3D topology given the required properties. Therefore, there is still a significant gap for the state-of-the-art machine learning models capturing the whole. Hence, we propose a unified model named UNIMATE, which consists of a modality alignment module and a synergetic diffusion generation module. Experiments indicate that UNIMATE outperforms the other baseline models in topology generation task, property prediction task, and condition confirmation task by up to 80.2%, 5.1%, and 50.2%, respectively. We opensource our proposed UNIMATE model and corresponding results at https://github.com/wzhan24/UniMate.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.15722",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "UniWorld-V1: High-Resolution Semantic Encoders for Unified Visual Understanding and Generation",
    "description": "arXiv:2506.03147v4 Announce Type: replace-cross Abstract: Although existing unified models achieve strong performance in vision-language understanding and text-to-image generation, they remain limited in addressing image perception and manipulation -- capabilities increasingly demanded in practical applications. Recently, OpenAI introduced the powerful GPT-4o-Image model, which showcases advanced capabilities in comprehensive image perception and manipulation, sparking widespread interest. Through carefully designed experiments, we observe that GPT-4o-Image likely relies on semantic encoders rather than VAEs for feature extraction, despite VAEs being commonly regarded as crucial for image manipulation tasks. Inspired by this insight, we propose UniWorld-V1, a unified generative framework built upon semantic features extracted from powerful multimodal large language models and contrastive semantic encoders. Using only 2.7M training data, UniWorld-V1 achieves impressive performance across diverse tasks, including image understanding, generation, manipulation, and perception. We fully open-source the UniWorld-V1 framework, including model weights, training and evaluation scripts, and datasets to promote reproducibility and further research.",
    "summary": "arXiv:2506.03147v4 Announce Type: replace-cross Abstract: Although existing unified models achieve strong performance in vision-language understanding and text-to-image generation, they remain limited in addressing image perception and manipulation -- capabilities increasingly demanded in practical applications. Recently, OpenAI introduced the powerful GPT-4o-Image model, which showcases advanced capabilities in comprehensive image perception and manipulation, sparking widespread interest. Through carefully designed experiments, we observe that GPT-4o-Image likely relies on semantic encoders rather than VAEs for feature extraction, despite VAEs being commonly regarded as crucial for image manipulation tasks. Inspired by this insight, we propose UniWorld-V1, a unified generative framework built upon semantic features extracted from powerful multimodal large language models and contrastive semantic encoders. Using only 2.7M training data, UniWorld-V1 achieves impressive performance across diverse tasks, including image understanding, generation, manipulation, and perception. We fully open-source the UniWorld-V1 framework, including model weights, training and evaluation scripts, and datasets to promote reproducibility and further research.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.03147",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Unsupervised deep learning model for fast energy layer pre-selection of delivery-efficient proton arc therapy plan optimization of nasopharyngeal carcinoma",
    "description": "arXiv:2506.15803v1 Announce Type: cross Abstract: Objective. Proton arc therapy (PAT) is an emerging and promising modality in radiotherapy, offering several advantages over conventional intensitymodulated proton therapy (IMPT). However, identifying the optimal energy layer (EL) sequence remains computationally intensive due to the large number of possible energy layer transitions. This study proposes an unsupervised deep learning framework for fast and effective EL pre-selection, aiming to minimize energy layer switch time while preserving high plan quality. Approach. We introduce a novel data representation method, spot-count representation, which encodes the number of proton spots intersecting the target and organs at risk (OARs) in a matrix structured by sorted gantry angles and energy layers. This representation is the input of a UNet-based architecture, SPArcdl, which is trained to optimize a tri-objective function: maximizing target coverage, minimizing OAR exposure, and reducing energy switching time. The model is evaluated on 54 nasopharyngeal cancer cases, and its performance is benchmarked against plans generated by SPArcparticle swarm. Main results. SPArcdl produces EL pre-selection that significantly improves both plan quality and delivery efficiency. Compared to SPArc particle swarm, it enhances the conformity index by 0.16 (p < 0.01), reduces the homogeneity index by 0.71 (p < 0.01), shortens the energy switching time by 38.4% (p < 0.01), and lowers the mean dose to brainstem by 0.21 (p < 0.01). The results unintentionally reveal employing unchanged ELS is more time-wise efficient than descended ELS. SPArcdl's inference time is within 1 second. Significance. SPArcdl is a fast and effective tool for generating high-quality PAT plans by strategically pre-selecting energy layers to reduce delivery time while maintaining excellent dosimetric performance.",
    "summary": "arXiv:2506.15803v1 Announce Type: cross Abstract: Objective. Proton arc therapy (PAT) is an emerging and promising modality in radiotherapy, offering several advantages over conventional intensitymodulated proton therapy (IMPT). However, identifying the optimal energy layer (EL) sequence remains computationally intensive due to the large number of possible energy layer transitions. This study proposes an unsupervised deep learning framework for fast and effective EL pre-selection, aiming to minimize energy layer switch time while preserving high plan quality. Approach. We introduce a novel data representation method, spot-count representation, which encodes the number of proton spots intersecting the target and organs at risk (OARs) in a matrix structured by sorted gantry angles and energy layers. This representation is the input of a UNet-based architecture, SPArcdl, which is trained to optimize a tri-objective function: maximizing target coverage, minimizing OAR exposure, and reducing energy switching time. The model is evaluated on 54 nasopharyngeal cancer cases, and its performance is benchmarked against plans generated by SPArcparticle swarm. Main results. SPArcdl produces EL pre-selection that significantly improves both plan quality and delivery efficiency. Compared to SPArc particle swarm, it enhances the conformity index by 0.16 (p < 0.01), reduces the homogeneity index by 0.71 (p < 0.01), shortens the energy switching time by 38.4% (p < 0.01), and lowers the mean dose to brainstem by 0.21 (p < 0.01). The results unintentionally reveal employing unchanged ELS is more time-wise efficient than descended ELS. SPArcdl's inference time is within 1 second. Significance. SPArcdl is a fast and effective tool for generating high-quality PAT plans by strategically pre-selecting energy layers to reduce delivery time while maintaining excellent dosimetric performance.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.15803",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Using Language and Road Manuals to Inform Map Reconstruction for Autonomous Driving",
    "description": "arXiv:2506.10317v2 Announce Type: replace-cross Abstract: Lane-topology prediction is a critical component of safe and reliable autonomous navigation. An accurate understanding of the road environment aids this task. We observe that this information often follows conventions encoded in natural language, through design codes that reflect the road structure and road names that capture the road functionality. We augment this information in a lightweight manner to SMERF, a map-prior-based online lane-topology prediction model, by combining structured road metadata from OSM maps and lane-width priors from Road design manuals with the road centerline encodings. We evaluate our method on two geo-diverse complex intersection scenarios. Our method shows improvement in both lane and traffic element detection and their association. We report results using four topology-aware metrics to comprehensively assess the model performance. These results demonstrate the ability of our approach to generalize and scale to diverse topologies and conditions.",
    "summary": "arXiv:2506.10317v2 Announce Type: replace-cross Abstract: Lane-topology prediction is a critical component of safe and reliable autonomous navigation. An accurate understanding of the road environment aids this task. We observe that this information often follows conventions encoded in natural language, through design codes that reflect the road structure and road names that capture the road functionality. We augment this information in a lightweight manner to SMERF, a map-prior-based online lane-topology prediction model, by combining structured road metadata from OSM maps and lane-width priors from Road design manuals with the road centerline encodings. We evaluate our method on two geo-diverse complex intersection scenarios. Our method shows improvement in both lane and traffic element detection and their association. We report results using four topology-aware metrics to comprehensively assess the model performance. These results demonstrate the ability of our approach to generalize and scale to diverse topologies and conditions.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.10317",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "V2X-VLM: End-to-End V2X Cooperative Autonomous Driving Through Large Vision-Language Models",
    "description": "arXiv:2408.09251v3 Announce Type: replace-cross Abstract: Vehicle-to-everything (V2X) cooperation has emerged as a promising paradigm to overcome the perception limitations of classical autonomous driving by leveraging information from both ego-vehicle and infrastructure sensors. However, effectively fusing heterogeneous visual and semantic information while ensuring robust trajectory planning remains a significant challenge. This paper introduces V2X-VLM, a novel end-to-end (E2E) cooperative autonomous driving framework based on vision-language models (VLMs). V2X-VLM integrates multiperspective camera views from vehicles and infrastructure with text-based scene descriptions to enable a more comprehensive understanding of driving environments. Specifically, we propose a contrastive learning-based mechanism to reinforce the alignment of heterogeneous visual and textual characteristics, which enhances the semantic understanding of complex driving scenarios, and employ a knowledge distillation strategy to stabilize training. Experiments on a large real-world dataset demonstrate that V2X-VLM achieves state-of-the-art trajectory planning accuracy, significantly reducing L2 error and collision rate compared to existing cooperative autonomous driving baselines. Ablation studies validate the contributions of each component. Moreover, the evaluation of robustness and efficiency highlights the practicality of V2X-VLM for real-world deployment to enhance overall autonomous driving safety and decision-making.",
    "summary": "arXiv:2408.09251v3 Announce Type: replace-cross Abstract: Vehicle-to-everything (V2X) cooperation has emerged as a promising paradigm to overcome the perception limitations of classical autonomous driving by leveraging information from both ego-vehicle and infrastructure sensors. However, effectively fusing heterogeneous visual and semantic information while ensuring robust trajectory planning remains a significant challenge. This paper introduces V2X-VLM, a novel end-to-end (E2E) cooperative autonomous driving framework based on vision-language models (VLMs). V2X-VLM integrates multiperspective camera views from vehicles and infrastructure with text-based scene descriptions to enable a more comprehensive understanding of driving environments. Specifically, we propose a contrastive learning-based mechanism to reinforce the alignment of heterogeneous visual and textual characteristics, which enhances the semantic understanding of complex driving scenarios, and employ a knowledge distillation strategy to stabilize training. Experiments on a large real-world dataset demonstrate that V2X-VLM achieves state-of-the-art trajectory planning accuracy, significantly reducing L2 error and collision rate compared to existing cooperative autonomous driving baselines. Ablation studies validate the contributions of each component. Moreover, the evaluation of robustness and efficiency highlights the practicality of V2X-VLM for real-world deployment to enhance overall autonomous driving safety and decision-making.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2408.09251",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "VEIGAR: View-consistent Explicit Inpainting and Geometry Alignment for 3D object Removal",
    "description": "arXiv:2506.15821v1 Announce Type: cross Abstract: Recent advances in Novel View Synthesis (NVS) and 3D generation have significantly improved editing tasks, with a primary emphasis on maintaining cross-view consistency throughout the generative process. Contemporary methods typically address this challenge using a dual-strategy framework: performing consistent 2D inpainting across all views guided by embedded priors either explicitly in pixel space or implicitly in latent space; and conducting 3D reconstruction with additional consistency guidance. Previous strategies, in particular, often require an initial 3D reconstruction phase to establish geometric structure, introducing considerable computational overhead. Even with the added cost, the resulting reconstruction quality often remains suboptimal. In this paper, we present VEIGAR, a computationally efficient framework that outperforms existing methods without relying on an initial reconstruction phase. VEIGAR leverages a lightweight foundation model to reliably align priors explicitly in the pixel space. In addition, we introduce a novel supervision strategy based on scale-invariant depth loss, which removes the need for traditional scale-and-shift operations in monocular depth regularization. Through extensive experimentation, VEIGAR establishes a new state-of-the-art benchmark in reconstruction quality and cross-view consistency, while achieving a threefold reduction in training time compared to the fastest existing method, highlighting its superior balance of efficiency and effectiveness.",
    "summary": "arXiv:2506.15821v1 Announce Type: cross Abstract: Recent advances in Novel View Synthesis (NVS) and 3D generation have significantly improved editing tasks, with a primary emphasis on maintaining cross-view consistency throughout the generative process. Contemporary methods typically address this challenge using a dual-strategy framework: performing consistent 2D inpainting across all views guided by embedded priors either explicitly in pixel space or implicitly in latent space; and conducting 3D reconstruction with additional consistency guidance. Previous strategies, in particular, often require an initial 3D reconstruction phase to establish geometric structure, introducing considerable computational overhead. Even with the added cost, the resulting reconstruction quality often remains suboptimal. In this paper, we present VEIGAR, a computationally efficient framework that outperforms existing methods without relying on an initial reconstruction phase. VEIGAR leverages a lightweight foundation model to reliably align priors explicitly in the pixel space. In addition, we introduce a novel supervision strategy based on scale-invariant depth loss, which removes the need for traditional scale-and-shift operations in monocular depth regularization. Through extensive experimentation, VEIGAR establishes a new state-of-the-art benchmark in reconstruction quality and cross-view consistency, while achieving a threefold reduction in training time compared to the fastest existing method, highlighting its superior balance of efficiency and effectiveness.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.15821",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Veracity: An Open-Source AI Fact-Checking System",
    "description": "arXiv:2506.15794v1 Announce Type: cross Abstract: The proliferation of misinformation poses a significant threat to society, exacerbated by the capabilities of generative AI. This demo paper introduces Veracity, an open-source AI system designed to empower individuals to combat misinformation through transparent and accessible fact-checking. Veracity leverages the synergy between Large Language Models (LLMs) and web retrieval agents to analyze user-submitted claims and provide grounded veracity assessments with intuitive explanations. Key features include multilingual support, numerical scoring of claim veracity, and an interactive interface inspired by familiar messaging applications. This paper will showcase Veracity's ability to not only detect misinformation but also explain its reasoning, fostering media literacy and promoting a more informed society.",
    "summary": "arXiv:2506.15794v1 Announce Type: cross Abstract: The proliferation of misinformation poses a significant threat to society, exacerbated by the capabilities of generative AI. This demo paper introduces Veracity, an open-source AI system designed to empower individuals to combat misinformation through transparent and accessible fact-checking. Veracity leverages the synergy between Large Language Models (LLMs) and web retrieval agents to analyze user-submitted claims and provide grounded veracity assessments with intuitive explanations. Key features include multilingual support, numerical scoring of claim veracity, and an interactive interface inspired by familiar messaging applications. This paper will showcase Veracity's ability to not only detect misinformation but also explain its reasoning, fostering media literacy and promoting a more informed society.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.15794",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Vision-Guided Chunking Is All You Need: Enhancing RAG with Multimodal Document Understanding",
    "description": "arXiv:2506.16035v1 Announce Type: cross Abstract: Retrieval-Augmented Generation (RAG) systems have revolutionized information retrieval and question answering, but traditional text-based chunking methods struggle with complex document structures, multi-page tables, embedded figures, and contextual dependencies across page boundaries. We present a novel multimodal document chunking approach that leverages Large Multimodal Models (LMMs) to process PDF documents in batches while maintaining semantic coherence and structural integrity. Our method processes documents in configurable page batches with cross-batch context preservation, enabling accurate handling of tables spanning multiple pages, embedded visual elements, and procedural content. We evaluate our approach on a curated dataset of PDF documents with manually crafted queries, demonstrating improvements in chunk quality and downstream RAG performance. Our vision-guided approach achieves better accuracy compared to traditional vanilla RAG systems, with qualitative analysis showing superior preservation of document structure and semantic coherence.",
    "summary": "arXiv:2506.16035v1 Announce Type: cross Abstract: Retrieval-Augmented Generation (RAG) systems have revolutionized information retrieval and question answering, but traditional text-based chunking methods struggle with complex document structures, multi-page tables, embedded figures, and contextual dependencies across page boundaries. We present a novel multimodal document chunking approach that leverages Large Multimodal Models (LMMs) to process PDF documents in batches while maintaining semantic coherence and structural integrity. Our method processes documents in configurable page batches with cross-batch context preservation, enabling accurate handling of tables spanning multiple pages, embedded visual elements, and procedural content. We evaluate our approach on a curated dataset of PDF documents with manually crafted queries, demonstrating improvements in chunk quality and downstream RAG performance. Our vision-guided approach achieves better accuracy compared to traditional vanilla RAG systems, with qualitative analysis showing superior preservation of document structure and semantic coherence.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16035",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Voices of Her: Analyzing Gender Differences in the AI Publication World",
    "description": "arXiv:2305.14597v2 Announce Type: replace-cross Abstract: While several previous studies have analyzed gender bias in research, we are still missing a comprehensive analysis of gender differences in the AI community, covering diverse topics and different development trends. Using the AI Scholar dataset of 78K researchers in the field of AI, we identify several gender differences: (1) Although female researchers tend to have fewer overall citations than males, this citation difference does not hold for all academic-age groups; (2) There exist large gender homophily in co-authorship on AI papers; (3) Female first-authored papers show distinct linguistic styles, such as longer text, more positive emotion words, and more catchy titles than male first-authored papers. Our analysis provides a window into the current demographic trends in our AI community, and encourages more gender equality and diversity in the future. Our code and data are at https://github.com/causalNLP/ai-scholar-gender.",
    "summary": "arXiv:2305.14597v2 Announce Type: replace-cross Abstract: While several previous studies have analyzed gender bias in research, we are still missing a comprehensive analysis of gender differences in the AI community, covering diverse topics and different development trends. Using the AI Scholar dataset of 78K researchers in the field of AI, we identify several gender differences: (1) Although female researchers tend to have fewer overall citations than males, this citation difference does not hold for all academic-age groups; (2) There exist large gender homophily in co-authorship on AI papers; (3) Female first-authored papers show distinct linguistic styles, such as longer text, more positive emotion words, and more catchy titles than male first-authored papers. Our analysis provides a window into the current demographic trends in our AI community, and encourages more gender equality and diversity in the future. Our code and data are at https://github.com/causalNLP/ai-scholar-gender.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2305.14597",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "VRAIL: Vectorized Reward-based Attribution for Interpretable Learning",
    "description": "arXiv:2506.16014v1 Announce Type: cross Abstract: We propose VRAIL (Vectorized Reward-based Attribution for Interpretable Learning), a bi-level framework for value-based reinforcement learning (RL) that learns interpretable weight representations from state features. VRAIL consists of two stages: a deep learning (DL) stage that fits an estimated value function using state features, and an RL stage that uses this to shape learning via potential-based reward transformations. The estimator is modeled in either linear or quadratic form, allowing attribution of importance to individual features and their interactions. Empirical results on the Taxi-v3 environment demonstrate that VRAIL improves training stability and convergence compared to standard DQN, without requiring environment modifications. Further analysis shows that VRAIL uncovers semantically meaningful subgoals, such as passenger possession, highlighting its ability to produce human-interpretable behavior. Our findings suggest that VRAIL serves as a general, model-agnostic framework for reward shaping that enhances both learning and interpretability.",
    "summary": "arXiv:2506.16014v1 Announce Type: cross Abstract: We propose VRAIL (Vectorized Reward-based Attribution for Interpretable Learning), a bi-level framework for value-based reinforcement learning (RL) that learns interpretable weight representations from state features. VRAIL consists of two stages: a deep learning (DL) stage that fits an estimated value function using state features, and an RL stage that uses this to shape learning via potential-based reward transformations. The estimator is modeled in either linear or quadratic form, allowing attribution of importance to individual features and their interactions. Empirical results on the Taxi-v3 environment demonstrate that VRAIL improves training stability and convergence compared to standard DQN, without requiring environment modifications. Further analysis shows that VRAIL uncovers semantically meaningful subgoals, such as passenger possession, highlighting its ability to produce human-interpretable behavior. Our findings suggest that VRAIL serves as a general, model-agnostic framework for reward shaping that enhances both learning and interpretability.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16014",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Watermarking Autoregressive Image Generation",
    "description": "arXiv:2506.16349v1 Announce Type: cross Abstract: Watermarking the outputs of generative models has emerged as a promising approach for tracking their provenance. Despite significant interest in autoregressive image generation models and their potential for misuse, no prior work has attempted to watermark their outputs at the token level. In this work, we present the first such approach by adapting language model watermarking techniques to this setting. We identify a key challenge: the lack of reverse cycle-consistency (RCC), wherein re-tokenizing generated image tokens significantly alters the token sequence, effectively erasing the watermark. To address this and to make our method robust to common image transformations, neural compression, and removal attacks, we introduce (i) a custom tokenizer-detokenizer finetuning procedure that improves RCC, and (ii) a complementary watermark synchronization layer. As our experiments demonstrate, our approach enables reliable and robust watermark detection with theoretically grounded p-values.",
    "summary": "arXiv:2506.16349v1 Announce Type: cross Abstract: Watermarking the outputs of generative models has emerged as a promising approach for tracking their provenance. Despite significant interest in autoregressive image generation models and their potential for misuse, no prior work has attempted to watermark their outputs at the token level. In this work, we present the first such approach by adapting language model watermarking techniques to this setting. We identify a key challenge: the lack of reverse cycle-consistency (RCC), wherein re-tokenizing generated image tokens significantly alters the token sequence, effectively erasing the watermark. To address this and to make our method robust to common image transformations, neural compression, and removal attacks, we introduce (i) a custom tokenizer-detokenizer finetuning procedure that improves RCC, and (ii) a complementary watermark synchronization layer. As our experiments demonstrate, our approach enables reliable and robust watermark detection with theoretically grounded p-values.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16349",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Web Archives Metadata Generation with GPT-4o: Challenges and Insights",
    "description": "arXiv:2411.05409v3 Announce Type: replace-cross Abstract: Current metadata creation for web archives is time consuming and costly due to reliance on human effort. This paper explores the use of gpt-4o for metadata generation within the Web Archive Singapore, focusing on scalability, efficiency, and cost effectiveness. We processed 112 Web ARChive (WARC) files using data reduction techniques, achieving a notable 99.9% reduction in metadata generation costs. By prompt engineering, we generated titles and abstracts, which were evaluated both intrinsically using Levenshtein Distance and BERTScore, and extrinsically with human cataloguers using McNemar's test. Results indicate that while our method offers significant cost savings and efficiency gains, human curated metadata maintains an edge in quality. The study identifies key challenges including content inaccuracies, hallucinations, and translation issues, suggesting that Large Language Models (LLMs) should serve as complements rather than replacements for human cataloguers. Future work will focus on refining prompts, improving content filtering, and addressing privacy concerns through experimentation with smaller models. This research advances the integration of LLMs in web archiving, offering valuable insights into their current capabilities and outlining directions for future enhancements. The code is available at https://github.com/masamune-prog/warc2summary for further development and use by institutions facing similar challenges.",
    "summary": "arXiv:2411.05409v3 Announce Type: replace-cross Abstract: Current metadata creation for web archives is time consuming and costly due to reliance on human effort. This paper explores the use of gpt-4o for metadata generation within the Web Archive Singapore, focusing on scalability, efficiency, and cost effectiveness. We processed 112 Web ARChive (WARC) files using data reduction techniques, achieving a notable 99.9% reduction in metadata generation costs. By prompt engineering, we generated titles and abstracts, which were evaluated both intrinsically using Levenshtein Distance and BERTScore, and extrinsically with human cataloguers using McNemar's test. Results indicate that while our method offers significant cost savings and efficiency gains, human curated metadata maintains an edge in quality. The study identifies key challenges including content inaccuracies, hallucinations, and translation issues, suggesting that Large Language Models (LLMs) should serve as complements rather than replacements for human cataloguers. Future work will focus on refining prompts, improving content filtering, and addressing privacy concerns through experimentation with smaller models. This research advances the integration of LLMs in web archiving, offering valuable insights into their current capabilities and outlining directions for future enhancements. The code is available at https://github.com/masamune-prog/warc2summary for further development and use by institutions facing similar challenges.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2411.05409",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "WebXAII: an open-source web framework to study human-XAI interaction",
    "description": "arXiv:2506.14777v2 Announce Type: replace-cross Abstract: This article introduces WebXAII, an open-source web framework designed to facilitate research on human interaction with eXplainable Artificial Intelligence (XAI) systems. The field of XAI is rapidly expanding, driven by the growing societal implications of the widespread adoption of AI (and in particular machine learning) across diverse applications. Researchers who study the interaction between humans and XAI techniques typically develop ad hoc interfaces in order to conduct their studies. These interfaces are usually not shared alongside the results of the studies, which limits their reusability and the reproducibility of experiments. In response, we design and implement WebXAII, a web-based platform that can embody full experimental protocols, meaning that it can present all aspects of the experiment to human participants and record their responses. The experimental protocols are translated into a composite architecture of generic views and modules, which offers a lot of flexibility. The architecture is defined in a structured configuration file, so that protocols can be implemented with minimal programming skills. We demonstrate that WebXAII can effectively embody relevant protocols, by reproducing the protocol of a state-of-the-art study of the literature.",
    "summary": "arXiv:2506.14777v2 Announce Type: replace-cross Abstract: This article introduces WebXAII, an open-source web framework designed to facilitate research on human interaction with eXplainable Artificial Intelligence (XAI) systems. The field of XAI is rapidly expanding, driven by the growing societal implications of the widespread adoption of AI (and in particular machine learning) across diverse applications. Researchers who study the interaction between humans and XAI techniques typically develop ad hoc interfaces in order to conduct their studies. These interfaces are usually not shared alongside the results of the studies, which limits their reusability and the reproducibility of experiments. In response, we design and implement WebXAII, a web-based platform that can embody full experimental protocols, meaning that it can present all aspects of the experiment to human participants and record their responses. The experimental protocols are translated into a composite architecture of generic views and modules, which offers a lot of flexibility. The architecture is defined in a structured configuration file, so that protocols can be implemented with minimal programming skills. We demonstrate that WebXAII can effectively embody relevant protocols, by reproducing the protocol of a state-of-the-art study of the literature.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.14777",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "What Do Latent Action Models Actually Learn?",
    "description": "arXiv:2506.15691v1 Announce Type: cross Abstract: Latent action models (LAMs) aim to learn action-relevant changes from unlabeled videos by compressing changes between frames as latents. However, differences between video frames can be caused by controllable changes as well as exogenous noise, leading to an important concern -- do latents capture the changes caused by actions or irrelevant noise? This paper studies this issue analytically, presenting a linear model that encapsulates the essence of LAM learning, while being tractable.This provides several insights, including connections between LAM and principal component analysis (PCA), desiderata of the data-generating policy, and justification of strategies to encourage learning controllable changes using data augmentation, data cleaning, and auxiliary action-prediction. We also provide illustrative results based on numerical simulation, shedding light on the specific structure of observations, actions, and noise in data that influence LAM learning.",
    "summary": "arXiv:2506.15691v1 Announce Type: cross Abstract: Latent action models (LAMs) aim to learn action-relevant changes from unlabeled videos by compressing changes between frames as latents. However, differences between video frames can be caused by controllable changes as well as exogenous noise, leading to an important concern -- do latents capture the changes caused by actions or irrelevant noise? This paper studies this issue analytically, presenting a linear model that encapsulates the essence of LAM learning, while being tractable.This provides several insights, including connections between LAM and principal component analysis (PCA), desiderata of the data-generating policy, and justification of strategies to encourage learning controllable changes using data augmentation, data cleaning, and auxiliary action-prediction. We also provide illustrative results based on numerical simulation, shedding light on the specific structure of observations, actions, and noise in data that influence LAM learning.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.15691",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "What Is the Point of Equality in Machine Learning Fairness? Beyond Equality of Opportunity",
    "description": "arXiv:2506.16782v1 Announce Type: cross Abstract: Fairness in machine learning (ML) has become a rapidly growing area of research. But why, in the first place, is unfairness in ML morally wrong? And why should we care about improving fairness? Most fair-ML research implicitly appeals to distributive equality: the idea that desirable goods and benefits, such as opportunities (e.g., Barocas et al., 2023), should be equally distributed across society. Unfair ML models, then, are seen as wrong because they unequally distribute such benefits. This paper argues that this exclusive focus on distributive equality offers an incomplete and potentially misleading ethical foundation. Grounding ML fairness in egalitarianism -- the view that equality is a fundamental moral and social ideal -- requires challenging structural inequality: systematic, institutional, and durable arrangements that privilege some groups while disadvantaging others. Structural inequality manifests through ML systems in two primary forms: allocative harms (e.g., economic loss) and representational harms (e.g., stereotypes, erasure). While distributive equality helps address allocative harms, it fails to explain why representational harms are wrong -- why it is wrong for ML systems to reinforce social hierarchies that stratify people into superior and inferior groups -- and why ML systems should aim to foster a society where people relate as equals (i.e., relational equality). To address these limitations, the paper proposes a multifaceted egalitarian framework for ML fairness that integrates both distributive and relational equality. Drawing on critical social and political philosophy, this framework offers a more comprehensive ethical foundation for tackling the full spectrum of harms perpetuated by ML systems. The paper also outlines practical pathways for implementing the framework across the ML pipeline.",
    "summary": "arXiv:2506.16782v1 Announce Type: cross Abstract: Fairness in machine learning (ML) has become a rapidly growing area of research. But why, in the first place, is unfairness in ML morally wrong? And why should we care about improving fairness? Most fair-ML research implicitly appeals to distributive equality: the idea that desirable goods and benefits, such as opportunities (e.g., Barocas et al., 2023), should be equally distributed across society. Unfair ML models, then, are seen as wrong because they unequally distribute such benefits. This paper argues that this exclusive focus on distributive equality offers an incomplete and potentially misleading ethical foundation. Grounding ML fairness in egalitarianism -- the view that equality is a fundamental moral and social ideal -- requires challenging structural inequality: systematic, institutional, and durable arrangements that privilege some groups while disadvantaging others. Structural inequality manifests through ML systems in two primary forms: allocative harms (e.g., economic loss) and representational harms (e.g., stereotypes, erasure). While distributive equality helps address allocative harms, it fails to explain why representational harms are wrong -- why it is wrong for ML systems to reinforce social hierarchies that stratify people into superior and inferior groups -- and why ML systems should aim to foster a society where people relate as equals (i.e., relational equality). To address these limitations, the paper proposes a multifaceted egalitarian framework for ML fairness that integrates both distributive and relational equality. Drawing on critical social and political philosophy, this framework offers a more comprehensive ethical foundation for tackling the full spectrum of harms perpetuated by ML systems. The paper also outlines practical pathways for implementing the framework across the ML pipeline.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16782",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "When Can Model-Free Reinforcement Learning be Enough for Thinking?",
    "description": "arXiv:2506.17124v1 Announce Type: new Abstract: Recent work on large language models has demonstrated the use of model-free reinforcement learning (RL) to train reasoning-like capabilities. The emergence of 'thinking' through model-free RL is interesting as thinking actions neither produce reward nor change the external world state to one where the agent is more likely to get reward. This paper seeks to build a domain-independent understanding of when model-free RL will lead to 'thinking' as a strategy for reward maximization. To build this understanding, we first introduce a theoretical model which we call a textit{thought Markov decision process} (MDP). Thought MDPs minimally extend the classical MDP model to include an abstract notion of thought state and thought action. Using the thought MDP model, we prove the importance of policy initialization in determining whether or not thinking emerges and show formally that thought actions are equivalent to the agent choosing to perform a step of policy improvement before continuing to act. We then show that open-source LLMs satisfy the conditions that our theory predicts are necessary for model-free RL to produce thinking-like behavior. Finally, we hypothesize sufficient conditions that would enable thinking to be learned outside of language generation and introduce a toy domain where a combination of multi-task pre-training and designated thought actions enable more data-efficient RL compared to non-thinking agents.",
    "summary": "arXiv:2506.17124v1 Announce Type: new Abstract: Recent work on large language models has demonstrated the use of model-free reinforcement learning (RL) to train reasoning-like capabilities. The emergence of 'thinking' through model-free RL is interesting as thinking actions neither produce reward nor change the external world state to one where the agent is more likely to get reward. This paper seeks to build a domain-independent understanding of when model-free RL will lead to 'thinking' as a strategy for reward maximization. To build this understanding, we first introduce a theoretical model which we call a textit{thought Markov decision process} (MDP). Thought MDPs minimally extend the classical MDP model to include an abstract notion of thought state and thought action. Using the thought MDP model, we prove the importance of policy initialization in determining whether or not thinking emerges and show formally that thought actions are equivalent to the agent choosing to perform a step of policy improvement before continuing to act. We then show that open-source LLMs satisfy the conditions that our theory predicts are necessary for model-free RL to produce thinking-like behavior. Finally, we hypothesize sufficient conditions that would enable thinking to be learned outside of language generation and introduce a toy domain where a combination of multi-task pre-training and designated thought actions enable more data-efficient RL compared to non-thinking agents.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.17124",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "With Limited Data for Multimodal Alignment, Let the STRUCTURE Guide You",
    "description": "arXiv:2506.16895v1 Announce Type: cross Abstract: Multimodal models have demonstrated powerful capabilities in complex tasks requiring multimodal alignment including zero-shot classification and cross-modal retrieval. However, existing models typically rely on millions of paired multimodal samples, which are prohibitively expensive or infeasible to obtain in many domains. In this work, we explore the feasibility of building multimodal models with limited amount of paired data by aligning pretrained unimodal foundation models. We show that high-quality alignment is possible with as few as tens of thousands of paired samples$unicode{x2013}$less than $1%$ of the data typically used in the field. To achieve this, we introduce STRUCTURE, an effective regularization technique that preserves the neighborhood geometry of the latent space of unimodal encoders. Additionally, we show that aligning last layers is often suboptimal and demonstrate the benefits of aligning the layers with the highest representational similarity across modalities. These two components can be readily incorporated into existing alignment methods, yielding substantial gains across 24 zero-shot image classification and retrieval benchmarks, with average relative improvement of $51.6%$ in classification and $91.8%$ in retrieval tasks. Our results highlight the effectiveness and broad applicability of our framework for limited-sample multimodal learning and offer a promising path forward for resource-constrained domains.",
    "summary": "arXiv:2506.16895v1 Announce Type: cross Abstract: Multimodal models have demonstrated powerful capabilities in complex tasks requiring multimodal alignment including zero-shot classification and cross-modal retrieval. However, existing models typically rely on millions of paired multimodal samples, which are prohibitively expensive or infeasible to obtain in many domains. In this work, we explore the feasibility of building multimodal models with limited amount of paired data by aligning pretrained unimodal foundation models. We show that high-quality alignment is possible with as few as tens of thousands of paired samples$unicode{x2013}$less than $1%$ of the data typically used in the field. To achieve this, we introduce STRUCTURE, an effective regularization technique that preserves the neighborhood geometry of the latent space of unimodal encoders. Additionally, we show that aligning last layers is often suboptimal and demonstrate the benefits of aligning the layers with the highest representational similarity across modalities. These two components can be readily incorporated into existing alignment methods, yielding substantial gains across 24 zero-shot image classification and retrieval benchmarks, with average relative improvement of $51.6%$ in classification and $91.8%$ in retrieval tasks. Our results highlight the effectiveness and broad applicability of our framework for limited-sample multimodal learning and offer a promising path forward for resource-constrained domains.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16895",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "xGen-MM (BLIP-3): A Family of Open Large Multimodal Models",
    "description": "arXiv:2408.08872v3 Announce Type: replace-cross Abstract: This paper introduces BLIP-3, an open framework for developing Large Multimodal Models (LMMs). The framework comprises meticulously curated datasets, a training recipe, model architectures, and a resulting suite of LMMs. We release 4B and 14B models, including both the pre-trained base model and the instruction fine-tuned ones. Our models undergo rigorous evaluation across a range of tasks, including both single and multi-image benchmarks. Our models demonstrate competitive performance among open-source LMMs with similar model sizes. Our resulting LMMs demonstrate competitive performance among open-source LMMs with similar model sizes, with the ability to comprehend interleaved image-text inputs. Our training code, models, and all datasets used in this work, including the three largescale datasets we create and the preprocessed ones, will be open-sourced to better support the research community.",
    "summary": "arXiv:2408.08872v3 Announce Type: replace-cross Abstract: This paper introduces BLIP-3, an open framework for developing Large Multimodal Models (LMMs). The framework comprises meticulously curated datasets, a training recipe, model architectures, and a resulting suite of LMMs. We release 4B and 14B models, including both the pre-trained base model and the instruction fine-tuned ones. Our models undergo rigorous evaluation across a range of tasks, including both single and multi-image benchmarks. Our models demonstrate competitive performance among open-source LMMs with similar model sizes. Our resulting LMMs demonstrate competitive performance among open-source LMMs with similar model sizes, with the ability to comprehend interleaved image-text inputs. Our training code, models, and all datasets used in this work, including the three largescale datasets we create and the preprocessed ones, will be open-sourced to better support the research community.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2408.08872",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "ゆうちょ銀行、YouTubeの“ニセ情報動画”に注意喚起　生成AI利用とみられるフェイク相次ぐ",
    "description": "ゆうちょ銀行は、YouTube上で偽の情報を発信する動画について、注意を呼びかけた。「7月からゆうちょ銀行の口座が使えなくなる」など、誤った内容の動画を複数確認。7月以降も、同社の全ての商品・サービスは通常通り利用できるとしている。",
    "summary": "ゆうちょ銀行は、YouTube上で偽の情報を発信する動画について、注意を呼びかけた。「7月からゆうちょ銀行の口座が使えなくなる」など、誤った内容の動画を複数確認。7月以降も、同社の全ての商品・サービスは通常通り利用できるとしている。",
    "pubDate": "Mon, 23 Jun 2025 18:59:00 +0900",
    "source": "ITmedia AI",
    "url": "https://www.itmedia.co.jp/aiplus/articles/2506/23/news094.html",
    "thumbnail": "https://image.itmedia.co.jp/aiplus/articles/2506/23/cover_news094.jpg"
  },
  {
    "title": "アイスマイリー、「第37回 ものづくり ワールド [東京]」にブース出展　7/9（水）から3日間、幕張メッセにて開催",
    "description": "<p>AIsmileyは、2025年7月9日（水）～7月11日（金）に幕張メッセにて開催の「第37回 ものづくり ワールド [東京]」にブースを出展します。 会場では、最新のAIソリューションやニュース等を取り上げるAIポータ [&#8230;]</p> <p>The post <a href='https://aismiley.co.jp/ai_news/monodukuri-world-2025-no37/'>アイスマイリー、「第37回 ものづくり ワールド [東京]」にブース出展　7/9（水）から3日間、幕張メッセにて開催</a> first appeared on <a href='https://aismiley.co.jp'>AIポータルメディアAIsmiley</a>.</p>",
    "summary": "<p>AIsmileyは、2025年7月9日（水）～7月11日（金）に幕張メッセにて開催の「第37回 ものづくり ワールド [東京]」にブースを出展します。 会場では、最新のAIソリューションやニュース等を取り上げるAIポータ [&#8230;]</p> <p>The post <a href='https://aismiley.co.jp/ai_news/monodukuri-world-2025-no37/'>アイスマイリー、「第37回 ものづくり ワールド [東京]」にブース出展　7/9（水）から3日間、幕張メッセにて開催</a> first appeared on <a href='https://aismiley.co.jp'>AIポータルメディアAIsmiley</a>.</p>",
    "pubDate": "Mon, 23 Jun 2025 04:00:20 +0000",
    "source": "AI Smily",
    "url": "https://aismiley.co.jp/ai_news/monodukuri-world-2025-no37/",
    "thumbnail": "https://aismiley.co.jp/wp-content/uploads/2025/05/monodukuri-world-tokyo-no37.png"
  },
  {
    "title": "テスラのロボタクシー、予定通り走行開始　テキサス州で",
    "description": "米南部テキサス州オースティンで6月22日、電気自動車大手Teslaによるロボタクシー（自動運転タクシー）走行が予定通り始まった。",
    "summary": "米南部テキサス州オースティンで6月22日、電気自動車大手Teslaによるロボタクシー（自動運転タクシー）走行が予定通り始まった。",
    "pubDate": "Mon, 23 Jun 2025 11:20:00 +0900",
    "source": "ITmedia AI",
    "url": "https://www.itmedia.co.jp/news/articles/2506/23/news054.html",
    "thumbnail": "https://image.itmedia.co.jp/news/articles/2506/23/cover_news054.jpg"
  },
  {
    "title": "「企業の主体はヒトからAIエージェントに」PwCが生成AIの技術動向を分析",
    "description": "PwCコンサルティングは、「生成AIの将来技術動向」と題したレポートを発表した。現在のLLMが抱える技術的な課題とその克服に向けた進化の方向性などについて分析している。",
    "summary": "PwCコンサルティングは、「生成AIの将来技術動向」と題したレポートを発表した。現在のLLMが抱える技術的な課題とその克服に向けた進化の方向性などについて分析している。",
    "pubDate": "Mon, 23 Jun 2025 08:00:00 +0900",
    "source": "ITmedia AI",
    "url": "https://atmarkit.itmedia.co.jp/ait/articles/2506/23/news025.html",
    "thumbnail": "https://image.itmedia.co.jp/ait/articles/2506/23/cover_news025.jpg"
  },
  {
    "title": "Driving scalable growth with OpenAI o3, GPT-4.1, and CUA",
    "description": "Unify, an AI-powered GTM platform, uses OpenAI’s o3, GPT-4.1, and CUA to automate prospecting, research, and outreach. With hyper-personalized messaging and an always-on workflow, Unify helps teams generate pipeline at scale while focusing on high-impact customer interactions.",
    "summary": "Unify, an AI-powered GTM platform, uses OpenAI’s o3, GPT-4.1, and CUA to automate prospecting, research, and outreach. With hyper-personalized messaging and an always-on workflow, Unify helps teams generate pipeline at scale while focusing on high-impact customer interactions.",
    "pubDate": "Tue, 24 Jun 2025 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/unify",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "FANZA同人、AI生成作品をトップページなどから除外へ　具体的な仕様は「必要に応じて告知」と運営元",
    "description": "成人向け同人作品のECサイト「FANZA同人」のトップページなどからAI生成作品を除外する――FANZA運営元のデジタルコマースは、同人サークル向けにこのような告知をしたと、ITmedia AI＋編集部の取材に対して明かした。",
    "summary": "成人向け同人作品のECサイト「FANZA同人」のトップページなどからAI生成作品を除外する――FANZA運営元のデジタルコマースは、同人サークル向けにこのような告知をしたと、ITmedia AI＋編集部の取材に対して明かした。",
    "pubDate": "Tue, 24 Jun 2025 07:00:00 +0900",
    "source": "ITmedia AI",
    "url": "https://www.itmedia.co.jp/aiplus/articles/2506/24/news053.html",
    "thumbnail": "https://image.itmedia.co.jp/aiplus/articles/2506/24/cover_news053.jpg"
  },
  {
    "title": "Gemini Robotics On-Device brings AI to local robotic devices",
    "description": "We’re introducing an efficient, on-device robotics model with general-purpose dexterity and fast task adaptation.",
    "summary": "We’re introducing an efficient, on-device robotics model with general-purpose dexterity and fast task adaptation.",
    "pubDate": "Tue, 24 Jun 2025 14:00:36 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/gemini-robotics-on-device-brings-ai-to-local-robotic-devices/",
    "thumbnail": "https://lh3.googleusercontent.com/Jt_Vw7PIJEZtXcMIKM1HbWbBCLxv7RUyjyf07eHp-YOfxMCUZA6mPI9kSCaz65UkMoGcZ8CwlD3dNBvy7bnnYchjSkWyN-SugglT3dmg1A9KdoDqdQM=w1200-h630-n-nu"
  },
  {
    "title": "GoogleのAIも信じる「万博80歳以上無料」の偽情報　誤回答の新機能「さらなる改善」",
    "description": "大阪・関西万博の入場料を巡り、80歳以上は「無料」とする誤った情報がインターネット上に広がっている。米IT大手Googleの検索サイトでも「万博」「高齢者」と打ち込むと、AIの回答で80歳以上は無料と示される状況だ。日本国際博覧会協会（万博協会）の相談窓口にも「80歳以上は無料なのか」との問い合わせが複数あり、Googleは「さらなる改善を続ける」としている。",
    "summary": "大阪・関西万博の入場料を巡り、80歳以上は「無料」とする誤った情報がインターネット上に広がっている。米IT大手Googleの検索サイトでも「万博」「高齢者」と打ち込むと、AIの回答で80歳以上は無料と示される状況だ。日本国際博覧会協会（万博協会）の相談窓口にも「80歳以上は無料なのか」との問い合わせが複数あり、Googleは「さらなる改善を続ける」としている。",
    "pubDate": "Tue, 24 Jun 2025 13:00:00 +0900",
    "source": "ITmedia AI",
    "url": "https://www.itmedia.co.jp/news/articles/2506/24/news082.html",
    "thumbnail": "https://image.itmedia.co.jp/news/articles/2506/24/cover_news082.jpg"
  },
  {
    "title": "［Pythonクイズ］「1.0 + 2.0 == 3.0」は期待通りにTrueになるはず？　その理由は分かる？",
    "description": "普段何気なく使っている浮動小数点数値ですが、ときには思わぬ結果を生むことがあります。その代表例が今回の問題です。どっちのメッセージが表示されるか分かってますよね？",
    "summary": "普段何気なく使っている浮動小数点数値ですが、ときには思わぬ結果を生むことがあります。その代表例が今回の問題です。どっちのメッセージが表示されるか分かってますよね？",
    "pubDate": "Tue, 24 Jun 2025 05:00:00 +0900",
    "source": "ITmedia AI",
    "url": "https://atmarkit.itmedia.co.jp/ait/articles/2506/24/news014.html",
    "thumbnail": "https://image.itmedia.co.jp/ait/articles/2506/24/cover_news014.jpg"
  },
  {
    "title": "デジタル先進地・神戸市が実践　「4つのステージ」で着実に進めるDX推進術",
    "description": "新たな技術やツールを導入する際、いきなり全庁展開しても決してうまくいかない――。DX先進地として知られる神戸市は、このポイントを押さえ、段階を踏んだDXを重視している。市のDX推進の司令塔を担うデジタル戦略部は、DX進捗を「4つのステージ」に分け、それぞれのステージにおいて「やるべきこと」と「やってはいけないこと」を明確化。職員自体の行動変容を伴う改革へとつなげている。",
    "summary": "新たな技術やツールを導入する際、いきなり全庁展開しても決してうまくいかない――。DX先進地として知られる神戸市は、このポイントを押さえ、段階を踏んだDXを重視している。市のDX推進の司令塔を担うデジタル戦略部は、DX進捗を「4つのステージ」に分け、それぞれのステージにおいて「やるべきこと」と「やってはいけないこと」を明確化。職員自体の行動変容を伴う改革へとつなげている。",
    "pubDate": "Tue, 24 Jun 2025 07:00:00 +0900",
    "source": "ITmedia AI",
    "url": "https://www.itmedia.co.jp/business/articles/2506/24/news018.html",
    "thumbnail": "https://image.itmedia.co.jp/business/articles/2506/24/cover_news018.jpg"
  },
  {
    "title": "リコー、GENIACでマルチモーダルLLMの基本モデルを開発。7月に無償公開",
    "description": "<p>リコーは、経済産業省およびNEDOが推進するGENIACプロジェクトにおいて、日本企業向け図表を含むドキュメント読み取りに特化したマルチモーダルLLMの基本モデルを開発しました。7月29日開催のMIRU2025で論文発表 [&#8230;]</p> <p>The post <a href='https://aismiley.co.jp/ai_news/ricoh-genia-multimodal-llm/'>リコー、GENIACでマルチモーダルLLMの基本モデルを開発。7月に無償公開</a> first appeared on <a href='https://aismiley.co.jp'>AIポータルメディアAIsmiley</a>.</p>",
    "summary": "<p>リコーは、経済産業省およびNEDOが推進するGENIACプロジェクトにおいて、日本企業向け図表を含むドキュメント読み取りに特化したマルチモーダルLLMの基本モデルを開発しました。7月29日開催のMIRU2025で論文発表 [&#8230;]</p> <p>The post <a href='https://aismiley.co.jp/ai_news/ricoh-genia-multimodal-llm/'>リコー、GENIACでマルチモーダルLLMの基本モデルを開発。7月に無償公開</a> first appeared on <a href='https://aismiley.co.jp'>AIポータルメディアAIsmiley</a>.</p>",
    "pubDate": "Tue, 24 Jun 2025 07:52:10 +0000",
    "source": "AI Smily",
    "url": "https://aismiley.co.jp/ai_news/ricoh-genia-multimodal-llm/",
    "thumbnail": "https://aismiley.co.jp/wp-content/uploads/2025/06/ricoh-genia-multimodal-llm.png"
  },
  {
    "title": "中古車の傷やへこみ、再塗装跡などを30秒で可視化する外装スキャナー",
    "description": "双日は、Preferred Networksと共同で開発を進めている、中古車の瑕疵（かし）や修復歴を判別可能なドライブスルー型外装スキャナーを発表。併せて、車両の事故歴を可視化するボッシュの評価サービス「Bosch Car History Report」の取り扱いも開始した。",
    "summary": "双日は、Preferred Networksと共同で開発を進めている、中古車の瑕疵（かし）や修復歴を判別可能なドライブスルー型外装スキャナーを発表。併せて、車両の事故歴を可視化するボッシュの評価サービス「Bosch Car History Report」の取り扱いも開始した。",
    "pubDate": "Tue, 24 Jun 2025 09:00:00 +0900",
    "source": "ITmedia AI",
    "url": "https://monoist.itmedia.co.jp/mn/articles/2506/24/news035.html",
    "thumbnail": "https://image.itmedia.co.jp/mn/articles/2506/24/cover_news035.jpg"
  },
  {
    "title": "中小企業のホンネ　「AIは期待ほどの成果を上げていない」",
    "description": "American Expressの調査によると、AIの活用により一定のメリットはあったものの期待されていたほどの成果は出ていないという。",
    "summary": "American Expressの調査によると、AIの活用により一定のメリットはあったものの期待されていたほどの成果は出ていないという。",
    "pubDate": "Tue, 24 Jun 2025 10:00:00 +0900",
    "source": "ITmedia AI",
    "url": "https://kn.itmedia.co.jp/kn/articles/2506/24/news026.html",
    "thumbnail": "https://image.itmedia.co.jp/kn/articles/2506/24/cover_news026.jpg"
  },
  {
    "title": "東武ホテルが直面する人手不足　社長が提唱する「観光業界のAI活用」",
    "description": "ホテル業界は人手不足やDXの課題にどう向き合えばよいのか。東武ホテルマネジメントの三輪裕章社長に、ホテル経営の現場で直面する課題と、その打開策を聞いた。",
    "summary": "ホテル業界は人手不足やDXの課題にどう向き合えばよいのか。東武ホテルマネジメントの三輪裕章社長に、ホテル経営の現場で直面する課題と、その打開策を聞いた。",
    "pubDate": "Tue, 24 Jun 2025 08:00:00 +0900",
    "source": "ITmedia AI",
    "url": "https://www.itmedia.co.jp/business/articles/2506/24/news019.html",
    "thumbnail": "https://image.itmedia.co.jp/business/articles/2506/24/cover_news019.jpg"
  },
  {
    "title": "A Certified Proof Checker for Deep Neural Network Verification in Imandra",
    "description": "arXiv:2405.10611v2 Announce Type: replace-cross Abstract: Recent advances in the verification of deep neural networks (DNNs) have opened the way for a broader usage of DNN verification technology in many application areas, including safety-critical ones. However, DNN verifiers are themselves complex programs that have been shown to be susceptible to errors and numerical imprecision; this, in turn, has raised the question of trust in DNN verifiers. One prominent attempt to address this issue is enhancing DNN verifiers with the capability of producing certificates of their results that are subject to independent algorithmic checking. While formulations of Marabou certificate checking already exist on top of the state-of-the-art DNN verifier Marabou, they are implemented in C++, and that code itself raises the question of trust (e.g., in the precision of floating point calculations or guarantees for implementation soundness). Here, we present an alternative implementation of the Marabou certificate checking in Imandra -- an industrial functional programming language and an interactive theorem prover (ITP) -- that allows us to obtain full proof of certificate correctness. The significance of the result is two-fold. Firstly, it gives stronger independent guarantees for Marabou proofs. Secondly, it opens the way for the wider adoption of DNN verifiers in interactive theorem proving in the same way as many ITPs already incorporate SMT solvers.",
    "summary": "arXiv:2405.10611v2 Announce Type: replace-cross Abstract: Recent advances in the verification of deep neural networks (DNNs) have opened the way for a broader usage of DNN verification technology in many application areas, including safety-critical ones. However, DNN verifiers are themselves complex programs that have been shown to be susceptible to errors and numerical imprecision; this, in turn, has raised the question of trust in DNN verifiers. One prominent attempt to address this issue is enhancing DNN verifiers with the capability of producing certificates of their results that are subject to independent algorithmic checking. While formulations of Marabou certificate checking already exist on top of the state-of-the-art DNN verifier Marabou, they are implemented in C++, and that code itself raises the question of trust (e.g., in the precision of floating point calculations or guarantees for implementation soundness). Here, we present an alternative implementation of the Marabou certificate checking in Imandra -- an industrial functional programming language and an interactive theorem prover (ITP) -- that allows us to obtain full proof of certificate correctness. The significance of the result is two-fold. Firstly, it gives stronger independent guarantees for Marabou proofs. Secondly, it opens the way for the wider adoption of DNN verifiers in interactive theorem proving in the same way as many ITPs already incorporate SMT solvers.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2405.10611",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "A Comment On 'The Illusion of Thinking': Reframing the Reasoning Cliff as an Agentic Gap",
    "description": "arXiv:2506.18957v1 Announce Type: new Abstract: The recent work by Shojaee et al. (2025), titled The Illusion of Thinking: Understanding the Strengths and Limitations of Reasoning Models via the Lens of Problem Complexity, presents a compelling empirical finding, a reasoning cliff, where the performance of Large Reasoning Models (LRMs) collapses beyond a specific complexity threshold, which the authors posit as an intrinsic scaling limitation of Chain-of-Thought (CoT) reasoning. This commentary, while acknowledging the study's methodological rigor, contends that this conclusion is confounded by experimental artifacts. We argue that the observed failure is not evidence of a fundamental cognitive boundary, but rather a predictable outcome of system-level constraints in the static, text-only evaluation paradigm, including tool use restrictions, context window recall issues, the absence of crucial cognitive baselines, inadequate statistical reporting, and output generation limits. We reframe this performance collapse through the lens of an agentic gap, asserting that the models are not failing at reasoning, but at execution within a profoundly restrictive interface. We empirically substantiate this critique by demonstrating a striking reversal. A model, initially declaring a puzzle impossible when confined to text-only generation, now employs agentic tools to not only solve it but also master variations of complexity far beyond the reasoning cliff it previously failed to surmount. Additionally, our empirical analysis of tool-enabled models like o4-mini and GPT-4o reveals a hierarchy of agentic reasoning, from simple procedural execution to complex meta-cognitive self-correction, which has significant implications for how we define and measure machine intelligence. The illusion of thinking attributed to LRMs is less a reasoning deficit and more a consequence of an otherwise capable mind lacking the tools for action.",
    "summary": "arXiv:2506.18957v1 Announce Type: new Abstract: The recent work by Shojaee et al. (2025), titled The Illusion of Thinking: Understanding the Strengths and Limitations of Reasoning Models via the Lens of Problem Complexity, presents a compelling empirical finding, a reasoning cliff, where the performance of Large Reasoning Models (LRMs) collapses beyond a specific complexity threshold, which the authors posit as an intrinsic scaling limitation of Chain-of-Thought (CoT) reasoning. This commentary, while acknowledging the study's methodological rigor, contends that this conclusion is confounded by experimental artifacts. We argue that the observed failure is not evidence of a fundamental cognitive boundary, but rather a predictable outcome of system-level constraints in the static, text-only evaluation paradigm, including tool use restrictions, context window recall issues, the absence of crucial cognitive baselines, inadequate statistical reporting, and output generation limits. We reframe this performance collapse through the lens of an agentic gap, asserting that the models are not failing at reasoning, but at execution within a profoundly restrictive interface. We empirically substantiate this critique by demonstrating a striking reversal. A model, initially declaring a puzzle impossible when confined to text-only generation, now employs agentic tools to not only solve it but also master variations of complexity far beyond the reasoning cliff it previously failed to surmount. Additionally, our empirical analysis of tool-enabled models like o4-mini and GPT-4o reveals a hierarchy of agentic reasoning, from simple procedural execution to complex meta-cognitive self-correction, which has significant implications for how we define and measure machine intelligence. The illusion of thinking attributed to LRMs is less a reasoning deficit and more a consequence of an otherwise capable mind lacking the tools for action.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.18957",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "A Global-Local Cross-Attention Network for Ultra-high Resolution Remote Sensing Image Semantic Segmentation",
    "description": "arXiv:2506.19406v1 Announce Type: cross Abstract: With the rapid development of ultra-high resolution (UHR) remote sensing technology, the demand for accurate and efficient semantic segmentation has increased significantly. However, existing methods face challenges in computational efficiency and multi-scale feature fusion. To address these issues, we propose GLCANet (Global-Local Cross-Attention Network), a lightweight segmentation framework designed for UHR remote sensing imagery.GLCANet employs a dual-stream architecture to efficiently fuse global semantics and local details while minimizing GPU usage. A self-attention mechanism enhances long-range dependencies, refines global features, and preserves local details for better semantic consistency. A masked cross-attention mechanism also adaptively fuses global-local features, selectively enhancing fine-grained details while exploiting global context to improve segmentation accuracy. Experimental results show that GLCANet outperforms state-of-the-art methods regarding accuracy and computational efficiency. The model effectively processes large, high-resolution images with a small memory footprint, providing a promising solution for real-world remote sensing applications.",
    "summary": "arXiv:2506.19406v1 Announce Type: cross Abstract: With the rapid development of ultra-high resolution (UHR) remote sensing technology, the demand for accurate and efficient semantic segmentation has increased significantly. However, existing methods face challenges in computational efficiency and multi-scale feature fusion. To address these issues, we propose GLCANet (Global-Local Cross-Attention Network), a lightweight segmentation framework designed for UHR remote sensing imagery.GLCANet employs a dual-stream architecture to efficiently fuse global semantics and local details while minimizing GPU usage. A self-attention mechanism enhances long-range dependencies, refines global features, and preserves local details for better semantic consistency. A masked cross-attention mechanism also adaptively fuses global-local features, selectively enhancing fine-grained details while exploiting global context to improve segmentation accuracy. Experimental results show that GLCANet outperforms state-of-the-art methods regarding accuracy and computational efficiency. The model effectively processes large, high-resolution images with a small memory footprint, providing a promising solution for real-world remote sensing applications.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19406",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "A standard transformer and attention with linear biases for molecular conformer generation",
    "description": "arXiv:2506.19834v1 Announce Type: cross Abstract: Sampling low-energy molecular conformations, spatial arrangements of atoms in a molecule, is a critical task for many different calculations performed in the drug discovery and optimization process. Numerous specialized equivariant networks have been designed to generate molecular conformations from 2D molecular graphs. Recently, non-equivariant transformer models have emerged as a viable alternative due to their capability to scale to improve generalization. However, the concern has been that non-equivariant models require a large model size to compensate the lack of equivariant bias. In this paper, we demonstrate that a well-chosen positional encoding effectively addresses these size limitations. A standard transformer model incorporating relative positional encoding for molecular graphs when scaled to 25 million parameters surpasses the current state-of-the-art non-equivariant base model with 64 million parameters on the GEOM-DRUGS benchmark. We implemented relative positional encoding as a negative attention bias that linearly increases with the shortest path distances between graph nodes at varying slopes for different attention heads, similar to ALiBi, a widely adopted relative positional encoding technique in the NLP domain. This architecture has the potential to serve as a foundation for a novel class of generative models for molecular conformations.",
    "summary": "arXiv:2506.19834v1 Announce Type: cross Abstract: Sampling low-energy molecular conformations, spatial arrangements of atoms in a molecule, is a critical task for many different calculations performed in the drug discovery and optimization process. Numerous specialized equivariant networks have been designed to generate molecular conformations from 2D molecular graphs. Recently, non-equivariant transformer models have emerged as a viable alternative due to their capability to scale to improve generalization. However, the concern has been that non-equivariant models require a large model size to compensate the lack of equivariant bias. In this paper, we demonstrate that a well-chosen positional encoding effectively addresses these size limitations. A standard transformer model incorporating relative positional encoding for molecular graphs when scaled to 25 million parameters surpasses the current state-of-the-art non-equivariant base model with 64 million parameters on the GEOM-DRUGS benchmark. We implemented relative positional encoding as a negative attention bias that linearly increases with the shortest path distances between graph nodes at varying slopes for different attention heads, similar to ALiBi, a widely adopted relative positional encoding technique in the NLP domain. This architecture has the potential to serve as a foundation for a novel class of generative models for molecular conformations.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19834",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "A Survey of Multi-sensor Fusion Perception for Embodied AI: Background, Methods, Challenges and Prospects",
    "description": "arXiv:2506.19769v1 Announce Type: cross Abstract: Multi-sensor fusion perception (MSFP) is a key technology for embodied AI, which can serve a variety of downstream tasks (e.g., 3D object detection and semantic segmentation) and application scenarios (e.g., autonomous driving and swarm robotics). Recently, impressive achievements on AI-based MSFP methods have been reviewed in relevant surveys. However, we observe that the existing surveys have some limitations after a rigorous and detailed investigation. For one thing, most surveys are oriented to a single task or research field, such as 3D object detection or autonomous driving. Therefore, researchers in other related tasks often find it difficult to benefit directly. For another, most surveys only introduce MSFP from a single perspective of multi-modal fusion, while lacking consideration of the diversity of MSFP methods, such as multi-view fusion and time-series fusion. To this end, in this paper, we hope to organize MSFP research from a task-agnostic perspective, where methods are reported from various technical views. Specifically, we first introduce the background of MSFP. Next, we review multi-modal and multi-agent fusion methods. A step further, time-series fusion methods are analyzed. In the era of LLM, we also investigate multimodal LLM fusion methods. Finally, we discuss open challenges and future directions for MSFP. We hope this survey can help researchers understand the important progress in MSFP and provide possible insights for future research.",
    "summary": "arXiv:2506.19769v1 Announce Type: cross Abstract: Multi-sensor fusion perception (MSFP) is a key technology for embodied AI, which can serve a variety of downstream tasks (e.g., 3D object detection and semantic segmentation) and application scenarios (e.g., autonomous driving and swarm robotics). Recently, impressive achievements on AI-based MSFP methods have been reviewed in relevant surveys. However, we observe that the existing surveys have some limitations after a rigorous and detailed investigation. For one thing, most surveys are oriented to a single task or research field, such as 3D object detection or autonomous driving. Therefore, researchers in other related tasks often find it difficult to benefit directly. For another, most surveys only introduce MSFP from a single perspective of multi-modal fusion, while lacking consideration of the diversity of MSFP methods, such as multi-view fusion and time-series fusion. To this end, in this paper, we hope to organize MSFP research from a task-agnostic perspective, where methods are reported from various technical views. Specifically, we first introduce the background of MSFP. Next, we review multi-modal and multi-agent fusion methods. A step further, time-series fusion methods are analyzed. In the era of LLM, we also investigate multimodal LLM fusion methods. Finally, we discuss open challenges and future directions for MSFP. We hope this survey can help researchers understand the important progress in MSFP and provide possible insights for future research.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19769",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Adaptive Domain Modeling with Language Models: A Multi-Agent Approach to Task Planning",
    "description": "arXiv:2506.19592v1 Announce Type: new Abstract: We introduce TAPAS (Task-based Adaptation and Planning using AgentS), a multi-agent framework that integrates Large Language Models (LLMs) with symbolic planning to solve complex tasks without the need for manually defined environment models. TAPAS employs specialized LLM-based agents that collaboratively generate and adapt domain models, initial states, and goal specifications as needed using structured tool-calling mechanisms. Through this tool-based interaction, downstream agents can request modifications from upstream agents, enabling adaptation to novel attributes and constraints without manual domain redefinition. A ReAct (Reason+Act)-style execution agent, coupled with natural language plan translation, bridges the gap between dynamically generated plans and real-world robot capabilities. TAPAS demonstrates strong performance in benchmark planning domains and in the VirtualHome simulated real-world environment.",
    "summary": "arXiv:2506.19592v1 Announce Type: new Abstract: We introduce TAPAS (Task-based Adaptation and Planning using AgentS), a multi-agent framework that integrates Large Language Models (LLMs) with symbolic planning to solve complex tasks without the need for manually defined environment models. TAPAS employs specialized LLM-based agents that collaboratively generate and adapt domain models, initial states, and goal specifications as needed using structured tool-calling mechanisms. Through this tool-based interaction, downstream agents can request modifications from upstream agents, enabling adaptation to novel attributes and constraints without manual domain redefinition. A ReAct (Reason+Act)-style execution agent, coupled with natural language plan translation, bridges the gap between dynamically generated plans and real-world robot capabilities. TAPAS demonstrates strong performance in benchmark planning domains and in the VirtualHome simulated real-world environment.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19592",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "AI-Assisted Transport of Radioactive Ion Beams",
    "description": "arXiv:2504.06469v3 Announce Type: replace-cross Abstract: Beams of radioactive heavy ions allow researchers to study rare and unstable atomic nuclei, shedding light into the internal structure of exotic nuclei and on how chemical elements are formed in stars. However, the extraction and transport of radioactive beams rely on time-consuming expert-driven tuning methods, where hundreds of parameters are manually optimized. Here, we introduce a system that employs Artificial Intelligence (AI), specifically utilizing Bayesian Optimization, to assist in the transport process of radioactive beams. We apply our methodology to real-life scenarios showing advantages when compared with standard tuning methods. This AI-assisted approach can be extended to other radioactive beam facilities around the world to improve operational efficiency and enhance scientific output.",
    "summary": "arXiv:2504.06469v3 Announce Type: replace-cross Abstract: Beams of radioactive heavy ions allow researchers to study rare and unstable atomic nuclei, shedding light into the internal structure of exotic nuclei and on how chemical elements are formed in stars. However, the extraction and transport of radioactive beams rely on time-consuming expert-driven tuning methods, where hundreds of parameters are manually optimized. Here, we introduce a system that employs Artificial Intelligence (AI), specifically utilizing Bayesian Optimization, to assist in the transport process of radioactive beams. We apply our methodology to real-life scenarios showing advantages when compared with standard tuning methods. This AI-assisted approach can be extended to other radioactive beam facilities around the world to improve operational efficiency and enhance scientific output.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2504.06469",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "AI-based Approach in Early Warning Systems: Focus on Emergency Communication Ecosystem and Citizen Participation in Nordic Countries",
    "description": "arXiv:2506.18926v1 Announce Type: cross Abstract: Climate change and natural disasters are recognized as worldwide challenges requiring complex and efficient ecosystems to deal with social, economic, and environmental effects. This chapter advocates a holistic approach, distinguishing preparedness, emergency responses, and postcrisis phases. The role of the Early Warning System (EWS), Risk modeling and mitigation measures are particularly emphasized. The chapter reviews the various Artificial Intelligence (AI)-enabler technologies that can be leveraged at each phase, focusing on the INFORM risk framework and EWSs. Emergency communication and psychological risk perception have been emphasized in emergency response times. Finally, a set of case studies from Nordic countries has been highlighted.",
    "summary": "arXiv:2506.18926v1 Announce Type: cross Abstract: Climate change and natural disasters are recognized as worldwide challenges requiring complex and efficient ecosystems to deal with social, economic, and environmental effects. This chapter advocates a holistic approach, distinguishing preparedness, emergency responses, and postcrisis phases. The role of the Early Warning System (EWS), Risk modeling and mitigation measures are particularly emphasized. The chapter reviews the various Artificial Intelligence (AI)-enabler technologies that can be leveraged at each phase, focusing on the INFORM risk framework and EWSs. Emergency communication and psychological risk perception have been emphasized in emergency response times. Finally, a set of case studies from Nordic countries has been highlighted.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.18926",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "AI-based Multimodal Biometrics for Detecting Smartphone Distractions: Application to Online Learning",
    "description": "arXiv:2506.17364v2 Announce Type: replace-cross Abstract: This work investigates the use of multimodal biometrics to detect distractions caused by smartphone use during tasks that require sustained attention, with a focus on computer-based online learning. Although the methods are applicable to various domains, such as autonomous driving, we concentrate on the challenges learners face in maintaining engagement amid internal (e.g., motivation), system-related (e.g., course design) and contextual (e.g., smartphone use) factors. Traditional learning platforms often lack detailed behavioral data, but Multimodal Learning Analytics (MMLA) and biosensors provide new insights into learner attention. We propose an AI-based approach that leverages physiological signals and head pose data to detect phone use. Our results show that single biometric signals, such as brain waves or heart rate, offer limited accuracy, while head pose alone achieves 87%. A multimodal model combining all signals reaches 91% accuracy, highlighting the benefits of integration. We conclude by discussing the implications and limitations of deploying these models for real-time support in online learning environments.",
    "summary": "arXiv:2506.17364v2 Announce Type: replace-cross Abstract: This work investigates the use of multimodal biometrics to detect distractions caused by smartphone use during tasks that require sustained attention, with a focus on computer-based online learning. Although the methods are applicable to various domains, such as autonomous driving, we concentrate on the challenges learners face in maintaining engagement amid internal (e.g., motivation), system-related (e.g., course design) and contextual (e.g., smartphone use) factors. Traditional learning platforms often lack detailed behavioral data, but Multimodal Learning Analytics (MMLA) and biosensors provide new insights into learner attention. We propose an AI-based approach that leverages physiological signals and head pose data to detect phone use. Our results show that single biometric signals, such as brain waves or heart rate, offer limited accuracy, while head pose alone achieves 87%. A multimodal model combining all signals reaches 91% accuracy, highlighting the benefits of integration. We conclude by discussing the implications and limitations of deploying these models for real-time support in online learning environments.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.17364",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "AI-Enhanced Deliberative Democracy and the Future of the Collective Will",
    "description": "arXiv:2503.05830v2 Announce Type: replace-cross Abstract: This article unpacks the design choices behind longstanding and newly proposed computational frameworks aimed at finding common grounds across collective preferences and examines their potential future impacts, both technically and normatively. It begins by situating AI-assisted preference elicitation within the historical role of opinion polls, emphasizing that preferences are shaped by the decision-making context and are seldom objectively captured. With that caveat in mind, we explore AI-based democratic innovations as discovery tools for fostering reasonable representations of a collective will, sense-making, and agreement-seeking. At the same time, we caution against dangerously misguided uses, such as enabling binding decisions, fostering gradual disempowerment or post-rationalizing political outcomes.",
    "summary": "arXiv:2503.05830v2 Announce Type: replace-cross Abstract: This article unpacks the design choices behind longstanding and newly proposed computational frameworks aimed at finding common grounds across collective preferences and examines their potential future impacts, both technically and normatively. It begins by situating AI-assisted preference elicitation within the historical role of opinion polls, emphasizing that preferences are shaped by the decision-making context and are seldom objectively captured. With that caveat in mind, we explore AI-based democratic innovations as discovery tools for fostering reasonable representations of a collective will, sense-making, and agreement-seeking. At the same time, we caution against dangerously misguided uses, such as enabling binding decisions, fostering gradual disempowerment or post-rationalizing political outcomes.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2503.05830",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "AI-Facilitated Episodic Future Thinking For Adults with Obesity",
    "description": "arXiv:2503.16484v2 Announce Type: replace-cross Abstract: Episodic Future Thinking (EFT) involves vividly imagining personal future events and experiences in detail. It has shown promise as an intervention to reduce delay discounting-the tendency to devalue delayed rewards in favor of immediate gratification- and to promote behavior change in a range of maladaptive health behaviors. We present EFTeacher, an AI chatbot powered by the GPT-4-Turbo large language model, designed to generate EFT cues for users with lifestyle-related conditions. To evaluate the feasibility and usability of EFTeacher, we conducted a mixed-methods study that included usability assessments, user evaluations based on content characteristics questionnaires, and semi-structured interviews. Qualitative findings indicate that participants perceived EFTeacher as communicative and supportive through an engaging dialogue. The chatbot facilitated imaginative thinking and reflection on future goals. Participants appreciated its adaptability and personalization features, though some noted challenges such as repetitive dialogue and verbose responses. Our findings underscore the potential of large language model-based chatbots in EFT interventions targeting maladaptive health behaviors.",
    "summary": "arXiv:2503.16484v2 Announce Type: replace-cross Abstract: Episodic Future Thinking (EFT) involves vividly imagining personal future events and experiences in detail. It has shown promise as an intervention to reduce delay discounting-the tendency to devalue delayed rewards in favor of immediate gratification- and to promote behavior change in a range of maladaptive health behaviors. We present EFTeacher, an AI chatbot powered by the GPT-4-Turbo large language model, designed to generate EFT cues for users with lifestyle-related conditions. To evaluate the feasibility and usability of EFTeacher, we conducted a mixed-methods study that included usability assessments, user evaluations based on content characteristics questionnaires, and semi-structured interviews. Qualitative findings indicate that participants perceived EFTeacher as communicative and supportive through an engaging dialogue. The chatbot facilitated imaginative thinking and reflection on future goals. Participants appreciated its adaptability and personalization features, though some noted challenges such as repetitive dialogue and verbose responses. Our findings underscore the potential of large language model-based chatbots in EFT interventions targeting maladaptive health behaviors.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2503.16484",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "AI Safety vs. AI Security: Demystifying the Distinction and Boundaries",
    "description": "arXiv:2506.18932v1 Announce Type: cross Abstract: Artificial Intelligence (AI) is rapidly being integrated into critical systems across various domains, from healthcare to autonomous vehicles. While its integration brings immense benefits, it also introduces significant risks, including those arising from AI misuse. Within the discourse on managing these risks, the terms 'AI Safety' and 'AI Security' are often used, sometimes interchangeably, resulting in conceptual confusion. This paper aims to demystify the distinction and delineate the precise research boundaries between AI Safety and AI Security. We provide rigorous definitions, outline their respective research focuses, and explore their interdependency, including how security breaches can precipitate safety failures and vice versa. Using clear analogies from message transmission and building construction, we illustrate these distinctions. Clarifying these boundaries is crucial for guiding precise research directions, fostering effective cross-disciplinary collaboration, enhancing policy effectiveness, and ultimately, promoting the deployment of trustworthy AI systems.",
    "summary": "arXiv:2506.18932v1 Announce Type: cross Abstract: Artificial Intelligence (AI) is rapidly being integrated into critical systems across various domains, from healthcare to autonomous vehicles. While its integration brings immense benefits, it also introduces significant risks, including those arising from AI misuse. Within the discourse on managing these risks, the terms 'AI Safety' and 'AI Security' are often used, sometimes interchangeably, resulting in conceptual confusion. This paper aims to demystify the distinction and delineate the precise research boundaries between AI Safety and AI Security. We provide rigorous definitions, outline their respective research focuses, and explore their interdependency, including how security breaches can precipitate safety failures and vice versa. Using clear analogies from message transmission and building construction, we illustrate these distinctions. Clarifying these boundaries is crucial for guiding precise research directions, fostering effective cross-disciplinary collaboration, enhancing policy effectiveness, and ultimately, promoting the deployment of trustworthy AI systems.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.18932",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "AirV2X: Unified Air-Ground Vehicle-to-Everything Collaboration",
    "description": "arXiv:2506.19283v1 Announce Type: cross Abstract: While multi-vehicular collaborative driving demonstrates clear advantages over single-vehicle autonomy, traditional infrastructure-based V2X systems remain constrained by substantial deployment costs and the creation of 'uncovered danger zones' in rural and suburban areas. We present AirV2X-Perception, a large-scale dataset that leverages Unmanned Aerial Vehicles (UAVs) as a flexible alternative or complement to fixed Road-Side Units (RSUs). Drones offer unique advantages over ground-based perception: complementary bird's-eye-views that reduce occlusions, dynamic positioning capabilities that enable hovering, patrolling, and escorting navigation rules, and significantly lower deployment costs compared to fixed infrastructure. Our dataset comprises 6.73 hours of drone-assisted driving scenarios across urban, suburban, and rural environments with varied weather and lighting conditions. The AirV2X-Perception dataset facilitates the development and standardized evaluation of Vehicle-to-Drone (V2D) algorithms, addressing a critical gap in the rapidly expanding field of aerial-assisted autonomous driving systems. The dataset and development kits are open-sourced at https://github.com/taco-group/AirV2X-Perception.",
    "summary": "arXiv:2506.19283v1 Announce Type: cross Abstract: While multi-vehicular collaborative driving demonstrates clear advantages over single-vehicle autonomy, traditional infrastructure-based V2X systems remain constrained by substantial deployment costs and the creation of 'uncovered danger zones' in rural and suburban areas. We present AirV2X-Perception, a large-scale dataset that leverages Unmanned Aerial Vehicles (UAVs) as a flexible alternative or complement to fixed Road-Side Units (RSUs). Drones offer unique advantages over ground-based perception: complementary bird's-eye-views that reduce occlusions, dynamic positioning capabilities that enable hovering, patrolling, and escorting navigation rules, and significantly lower deployment costs compared to fixed infrastructure. Our dataset comprises 6.73 hours of drone-assisted driving scenarios across urban, suburban, and rural environments with varied weather and lighting conditions. The AirV2X-Perception dataset facilitates the development and standardized evaluation of Vehicle-to-Drone (V2D) algorithms, addressing a critical gap in the rapidly expanding field of aerial-assisted autonomous driving systems. The dataset and development kits are open-sourced at https://github.com/taco-group/AirV2X-Perception.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19283",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "AIエージェントを悪用した攻撃手法3選　対策の考え方にも転換が必要（前編）",
    "description": "AIエージェントのセキュリティ脅威に対し、学術界と産業界では新たな対策フレームワークの構築が活発化しています。どのような戦略的アプローチが有効なのでしょうか。最新の研究成果が示す新しい脅威分類と、それに対応する包括的セキュリティフレームワークの設計思想について解説します。",
    "summary": "AIエージェントのセキュリティ脅威に対し、学術界と産業界では新たな対策フレームワークの構築が活発化しています。どのような戦略的アプローチが有効なのでしょうか。最新の研究成果が示す新しい脅威分類と、それに対応する包括的セキュリティフレームワークの設計思想について解説します。",
    "pubDate": "Wed, 25 Jun 2025 10:00:00 +0900",
    "source": "ITmedia AI",
    "url": "https://www.itmedia.co.jp/enterprise/articles/2506/25/news041.html",
    "thumbnail": "https://image.itmedia.co.jp/enterprise/articles/2506/25/cover_news041.jpg"
  },
  {
    "title": "Align and Distill: Unifying and Improving Domain Adaptive Object Detection",
    "description": "arXiv:2403.12029v4 Announce Type: replace-cross Abstract: Object detectors often perform poorly on data that differs from their training set. Domain adaptive object detection (DAOD) methods have recently demonstrated strong results on addressing this challenge. Unfortunately, we identify systemic benchmarking pitfalls that call past results into question and hamper further progress: (a) Overestimation of performance due to underpowered baselines, (b) Inconsistent implementation practices preventing transparent comparisons of methods, and (c) Lack of generality due to outdated backbones and lack of diversity in benchmarks. We address these problems by introducing: (1) A unified benchmarking and implementation framework, Align and Distill (ALDI), enabling comparison of DAOD methods and supporting future development, (2) A fair and modern training and evaluation protocol for DAOD that addresses benchmarking pitfalls, (3) A new DAOD benchmark dataset, CFC-DAOD, enabling evaluation on diverse real-world data, and (4) A new method, ALDI++, that achieves state-of-the-art results by a large margin. ALDI++ outperforms the previous state-of-the-art by +3.5 AP50 on Cityscapes to Foggy Cityscapes, +5.7 AP50 on Sim10k to Cityscapes (where ours is the only method to outperform a fair baseline), and +0.6 AP50 on CFC Kenai to Channel. ALDI and ALDI++ are architecture-agnostic, setting a new state-of-the-art for YOLO and DETR-based DAOD as well without additional hyperparameter tuning. Our framework, dataset, and state-of-the-art method offer a critical reset for DAOD and provide a strong foundation for future research. Code and data are available: https://github.com/justinkay/aldi and https://github.com/visipedia/caltech-fish-counting.",
    "summary": "arXiv:2403.12029v4 Announce Type: replace-cross Abstract: Object detectors often perform poorly on data that differs from their training set. Domain adaptive object detection (DAOD) methods have recently demonstrated strong results on addressing this challenge. Unfortunately, we identify systemic benchmarking pitfalls that call past results into question and hamper further progress: (a) Overestimation of performance due to underpowered baselines, (b) Inconsistent implementation practices preventing transparent comparisons of methods, and (c) Lack of generality due to outdated backbones and lack of diversity in benchmarks. We address these problems by introducing: (1) A unified benchmarking and implementation framework, Align and Distill (ALDI), enabling comparison of DAOD methods and supporting future development, (2) A fair and modern training and evaluation protocol for DAOD that addresses benchmarking pitfalls, (3) A new DAOD benchmark dataset, CFC-DAOD, enabling evaluation on diverse real-world data, and (4) A new method, ALDI++, that achieves state-of-the-art results by a large margin. ALDI++ outperforms the previous state-of-the-art by +3.5 AP50 on Cityscapes to Foggy Cityscapes, +5.7 AP50 on Sim10k to Cityscapes (where ours is the only method to outperform a fair baseline), and +0.6 AP50 on CFC Kenai to Channel. ALDI and ALDI++ are architecture-agnostic, setting a new state-of-the-art for YOLO and DETR-based DAOD as well without additional hyperparameter tuning. Our framework, dataset, and state-of-the-art method offer a critical reset for DAOD and provide a strong foundation for future research. Code and data are available: https://github.com/justinkay/aldi and https://github.com/visipedia/caltech-fish-counting.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2403.12029",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Alleviating User-Sensitive bias with Fair Generative Sequential Recommendation Model",
    "description": "arXiv:2506.19777v1 Announce Type: cross Abstract: Recommendation fairness has recently attracted much attention. In the real world, recommendation systems are driven by user behavior, and since users with the same sensitive feature (e.g., gender and age) tend to have the same patterns, recommendation models can easily capture the strong correlation preference of sensitive features and thus cause recommendation unfairness. Diffusion model (DM) as a new generative model paradigm has achieved great success in recommendation systems. DM's ability to model uncertainty and represent diversity, and its modeling mechanism has a high degree of adaptability with the real-world recommendation process with bias. Therefore, we use DM to effectively model the fairness of recommendation and enhance the diversity. This paper proposes a FairGENerative sequential Recommendation model based on DM, FairGENRec. In the training phase, we inject random noise into the original distribution under the guidance of the sensitive feature recognition model, and a sequential denoise model is designed for the reverse reconstruction of items. Simultaneously, recommendation fairness modeling is completed by injecting multi-interests representational information that eliminates the bias of sensitive user features into the generated results. In the inference phase, the model obtains the noise in the form of noise addition by using the history interactions which is followed by reverse iteration to reconstruct the target item representation. Finally, our extensive experiments on three datasets demonstrate the dual enhancement effect of FairGENRec on accuracy and fairness, while the statistical analysis of the cases visualizes the degree of improvement on the fairness of the recommendation.",
    "summary": "arXiv:2506.19777v1 Announce Type: cross Abstract: Recommendation fairness has recently attracted much attention. In the real world, recommendation systems are driven by user behavior, and since users with the same sensitive feature (e.g., gender and age) tend to have the same patterns, recommendation models can easily capture the strong correlation preference of sensitive features and thus cause recommendation unfairness. Diffusion model (DM) as a new generative model paradigm has achieved great success in recommendation systems. DM's ability to model uncertainty and represent diversity, and its modeling mechanism has a high degree of adaptability with the real-world recommendation process with bias. Therefore, we use DM to effectively model the fairness of recommendation and enhance the diversity. This paper proposes a FairGENerative sequential Recommendation model based on DM, FairGENRec. In the training phase, we inject random noise into the original distribution under the guidance of the sensitive feature recognition model, and a sequential denoise model is designed for the reverse reconstruction of items. Simultaneously, recommendation fairness modeling is completed by injecting multi-interests representational information that eliminates the bias of sensitive user features into the generated results. In the inference phase, the model obtains the noise in the form of noise addition by using the history interactions which is followed by reverse iteration to reconstruct the target item representation. Finally, our extensive experiments on three datasets demonstrate the dual enhancement effect of FairGENRec on accuracy and fairness, while the statistical analysis of the cases visualizes the degree of improvement on the fairness of the recommendation.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19777",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "AnchorDP3: 3D Affordance Guided Sparse Diffusion Policy for Robotic Manipulation",
    "description": "arXiv:2506.19269v1 Announce Type: cross Abstract: We present AnchorDP3, a diffusion policy framework for dual-arm robotic manipulation that achieves state-of-the-art performance in highly randomized environments. AnchorDP3 integrates three key innovations: (1) Simulator-Supervised Semantic Segmentation, using rendered ground truth to explicitly segment task-critical objects within the point cloud, which provides strong affordance priors; (2) Task-Conditioned Feature Encoders, lightweight modules processing augmented point clouds per task, enabling efficient multi-task learning through a shared diffusion-based action expert; (3) Affordance-Anchored Keypose Diffusion with Full State Supervision, replacing dense trajectory prediction with sparse, geometrically meaningful action anchors, i.e., keyposes such as pre-grasp pose, grasp pose directly anchored to affordances, drastically simplifying the prediction space; the action expert is forced to predict both robot joint angles and end-effector poses simultaneously, which exploits geometric consistency to accelerate convergence and boost accuracy. Trained on large-scale, procedurally generated simulation data, AnchorDP3 achieves a 98.7% average success rate in the RoboTwin benchmark across diverse tasks under extreme randomization of objects, clutter, table height, lighting, and backgrounds. This framework, when integrated with the RoboTwin real-to-sim pipeline, has the potential to enable fully autonomous generation of deployable visuomotor policies from only scene and instruction, totally eliminating human demonstrations from learning manipulation skills.",
    "summary": "arXiv:2506.19269v1 Announce Type: cross Abstract: We present AnchorDP3, a diffusion policy framework for dual-arm robotic manipulation that achieves state-of-the-art performance in highly randomized environments. AnchorDP3 integrates three key innovations: (1) Simulator-Supervised Semantic Segmentation, using rendered ground truth to explicitly segment task-critical objects within the point cloud, which provides strong affordance priors; (2) Task-Conditioned Feature Encoders, lightweight modules processing augmented point clouds per task, enabling efficient multi-task learning through a shared diffusion-based action expert; (3) Affordance-Anchored Keypose Diffusion with Full State Supervision, replacing dense trajectory prediction with sparse, geometrically meaningful action anchors, i.e., keyposes such as pre-grasp pose, grasp pose directly anchored to affordances, drastically simplifying the prediction space; the action expert is forced to predict both robot joint angles and end-effector poses simultaneously, which exploits geometric consistency to accelerate convergence and boost accuracy. Trained on large-scale, procedurally generated simulation data, AnchorDP3 achieves a 98.7% average success rate in the RoboTwin benchmark across diverse tasks under extreme randomization of objects, clutter, table height, lighting, and backgrounds. This framework, when integrated with the RoboTwin real-to-sim pipeline, has the potential to enable fully autonomous generation of deployable visuomotor policies from only scene and instruction, totally eliminating human demonstrations from learning manipulation skills.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19269",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "AntiGrounding: Lifting Robotic Actions into VLM Representation Space for Decision Making",
    "description": "arXiv:2506.12374v2 Announce Type: replace-cross Abstract: Vision-Language Models (VLMs) encode knowledge and reasoning capabilities for robotic manipulation within high-dimensional representation spaces. However, current approaches often project them into compressed intermediate representations, discarding important task-specific information such as fine-grained spatial or semantic details. To address this, we propose AntiGrounding, a new framework that reverses the instruction grounding process. It lifts candidate actions directly into the VLM representation space, renders trajectories from multiple views, and uses structured visual question answering for instruction-based decision making. This enables zero-shot synthesis of optimal closed-loop robot trajectories for new tasks. We also propose an offline policy refinement module that leverages past experience to enhance long-term performance. Experiments in both simulation and real-world environments show that our method outperforms baselines across diverse robotic manipulation tasks.",
    "summary": "arXiv:2506.12374v2 Announce Type: replace-cross Abstract: Vision-Language Models (VLMs) encode knowledge and reasoning capabilities for robotic manipulation within high-dimensional representation spaces. However, current approaches often project them into compressed intermediate representations, discarding important task-specific information such as fine-grained spatial or semantic details. To address this, we propose AntiGrounding, a new framework that reverses the instruction grounding process. It lifts candidate actions directly into the VLM representation space, renders trajectories from multiple views, and uses structured visual question answering for instruction-based decision making. This enables zero-shot synthesis of optimal closed-loop robot trajectories for new tasks. We also propose an offline policy refinement module that leverages past experience to enhance long-term performance. Experiments in both simulation and real-world environments show that our method outperforms baselines across diverse robotic manipulation tasks.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.12374",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Arabic Dialect Classification using RNNs, Transformers, and Large Language Models: A Comparative Analysis",
    "description": "arXiv:2506.19753v1 Announce Type: cross Abstract: The Arabic language is among the most popular languages in the world with a huge variety of dialects spoken in 22 countries. In this study, we address the problem of classifying 18 Arabic dialects of the QADI dataset of Arabic tweets. RNN models, Transformer models, and large language models (LLMs) via prompt engineering are created and tested. Among these, MARBERTv2 performed best with 65% accuracy and 64% F1-score. Through the use of state-of-the-art preprocessing techniques and the latest NLP models, this paper identifies the most significant linguistic issues in Arabic dialect identification. The results corroborate applications like personalized chatbots that respond in users' dialects, social media monitoring, and greater accessibility for Arabic communities.",
    "summary": "arXiv:2506.19753v1 Announce Type: cross Abstract: The Arabic language is among the most popular languages in the world with a huge variety of dialects spoken in 22 countries. In this study, we address the problem of classifying 18 Arabic dialects of the QADI dataset of Arabic tweets. RNN models, Transformer models, and large language models (LLMs) via prompt engineering are created and tested. Among these, MARBERTv2 performed best with 65% accuracy and 64% F1-score. Through the use of state-of-the-art preprocessing techniques and the latest NLP models, this paper identifies the most significant linguistic issues in Arabic dialect identification. The results corroborate applications like personalized chatbots that respond in users' dialects, social media monitoring, and greater accessibility for Arabic communities.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19753",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Are We There Yet? A Brief Survey of Music Emotion Prediction Datasets, Models and Outstanding Challenges",
    "description": "arXiv:2406.08809v3 Announce Type: replace-cross Abstract: Deep learning models for music have advanced drastically in recent years, but how good are machine learning models at capturing emotion, and what challenges are researchers facing? In this paper, we provide a comprehensive overview of the available music-emotion datasets and discuss evaluation standards as well as competitions in the field. We also offer a brief overview of various types of music emotion prediction models that have been built over the years, providing insights into the diverse approaches within the field. Through this examination, we highlight the challenges that persist in accurately capturing emotion in music, including issues related to dataset quality, annotation consistency, and model generalization. Additionally, we explore the impact of different modalities, such as audio, MIDI, and physiological signals, on the effectiveness of emotion prediction models. Through this examination, we identify persistent challenges in music emotion recognition (MER), including issues related to dataset quality, the ambiguity in emotion labels, and the difficulties of cross-dataset generalization. We argue that future advancements in MER require standardized benchmarks, larger and more diverse datasets, and improved model interpretability. Recognizing the dynamic nature of this field, we have complemented our findings with an accompanying GitHub repository. This repository contains a comprehensive list of music emotion datasets and recent predictive models.",
    "summary": "arXiv:2406.08809v3 Announce Type: replace-cross Abstract: Deep learning models for music have advanced drastically in recent years, but how good are machine learning models at capturing emotion, and what challenges are researchers facing? In this paper, we provide a comprehensive overview of the available music-emotion datasets and discuss evaluation standards as well as competitions in the field. We also offer a brief overview of various types of music emotion prediction models that have been built over the years, providing insights into the diverse approaches within the field. Through this examination, we highlight the challenges that persist in accurately capturing emotion in music, including issues related to dataset quality, annotation consistency, and model generalization. Additionally, we explore the impact of different modalities, such as audio, MIDI, and physiological signals, on the effectiveness of emotion prediction models. Through this examination, we identify persistent challenges in music emotion recognition (MER), including issues related to dataset quality, the ambiguity in emotion labels, and the difficulties of cross-dataset generalization. We argue that future advancements in MER require standardized benchmarks, larger and more diverse datasets, and improved model interpretability. Recognizing the dynamic nature of this field, we have complemented our findings with an accompanying GitHub repository. This repository contains a comprehensive list of music emotion datasets and recent predictive models.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2406.08809",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "ASR-enhanced Multimodal Representation Learning for Cross-Domain Product Retrieval",
    "description": "arXiv:2408.02978v2 Announce Type: replace-cross Abstract: E-commerce is increasingly multimedia-enriched, with products exhibited in a broad-domain manner as images, short videos, or live stream promotions. A unified and vectorized cross-domain production representation is essential. Due to large intra-product variance and high inter-product similarity in the broad-domain scenario, a visual-only representation is inadequate. While Automatic Speech Recognition (ASR) text derived from the short or live-stream videos is readily accessible, how to de-noise the excessively noisy text for multimodal representation learning is mostly untouched. We propose ASR-enhanced Multimodal Product Representation Learning (AMPere). In order to extract product-specific information from the raw ASR text, AMPere uses an easy-to-implement LLM-based ASR text summarizer. The LLM-summarized text, together with visual data, is then fed into a multi-branch network to generate compact multimodal embeddings. Extensive experiments on a large-scale tri-domain dataset verify the effectiveness of AMPere in obtaining a unified multimodal product representation that clearly improves cross-domain product retrieval.",
    "summary": "arXiv:2408.02978v2 Announce Type: replace-cross Abstract: E-commerce is increasingly multimedia-enriched, with products exhibited in a broad-domain manner as images, short videos, or live stream promotions. A unified and vectorized cross-domain production representation is essential. Due to large intra-product variance and high inter-product similarity in the broad-domain scenario, a visual-only representation is inadequate. While Automatic Speech Recognition (ASR) text derived from the short or live-stream videos is readily accessible, how to de-noise the excessively noisy text for multimodal representation learning is mostly untouched. We propose ASR-enhanced Multimodal Product Representation Learning (AMPere). In order to extract product-specific information from the raw ASR text, AMPere uses an easy-to-implement LLM-based ASR text summarizer. The LLM-summarized text, together with visual data, is then fed into a multi-branch network to generate compact multimodal embeddings. Extensive experiments on a large-scale tri-domain dataset verify the effectiveness of AMPere in obtaining a unified multimodal product representation that clearly improves cross-domain product retrieval.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2408.02978",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Automated Detection of Pre-training Text in Black-box LLMs",
    "description": "arXiv:2506.19399v1 Announce Type: cross Abstract: Detecting whether a given text is a member of the pre-training data of Large Language Models (LLMs) is crucial for ensuring data privacy and copyright protection. Most existing methods rely on the LLM's hidden information (e.g., model parameters or token probabilities), making them ineffective in the black-box setting, where only input and output texts are accessible. Although some methods have been proposed for the black-box setting, they rely on massive manual efforts such as designing complicated questions or instructions. To address these issues, we propose VeilProbe, the first framework for automatically detecting LLMs' pre-training texts in a black-box setting without human intervention. VeilProbe utilizes a sequence-to-sequence mapping model to infer the latent mapping feature between the input text and the corresponding output suffix generated by the LLM. Then it performs the key token perturbations to obtain more distinguishable membership features. Additionally, considering real-world scenarios where the ground-truth training text samples are limited, a prototype-based membership classifier is introduced to alleviate the overfitting issue. Extensive evaluations on three widely used datasets demonstrate that our framework is effective and superior in the black-box setting.",
    "summary": "arXiv:2506.19399v1 Announce Type: cross Abstract: Detecting whether a given text is a member of the pre-training data of Large Language Models (LLMs) is crucial for ensuring data privacy and copyright protection. Most existing methods rely on the LLM's hidden information (e.g., model parameters or token probabilities), making them ineffective in the black-box setting, where only input and output texts are accessible. Although some methods have been proposed for the black-box setting, they rely on massive manual efforts such as designing complicated questions or instructions. To address these issues, we propose VeilProbe, the first framework for automatically detecting LLMs' pre-training texts in a black-box setting without human intervention. VeilProbe utilizes a sequence-to-sequence mapping model to infer the latent mapping feature between the input text and the corresponding output suffix generated by the LLM. Then it performs the key token perturbations to obtain more distinguishable membership features. Additionally, considering real-world scenarios where the ground-truth training text samples are limited, a prototype-based membership classifier is introduced to alleviate the overfitting issue. Extensive evaluations on three widely used datasets demonstrate that our framework is effective and superior in the black-box setting.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19399",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Automatic Depression Assessment using Machine Learning: A Comprehensive Survey",
    "description": "arXiv:2506.18915v1 Announce Type: cross Abstract: Depression is a common mental illness across current human society. Traditional depression assessment relying on inventories and interviews with psychologists frequently suffer from subjective diagnosis results, slow and expensive diagnosis process as well as lack of human resources. Since there is a solid evidence that depression is reflected by various human internal brain activities and external expressive behaviours, early traditional machine learning (ML) and advanced deep learning (DL) models have been widely explored for human behaviour-based automatic depression assessment (ADA) since 2012. However, recent ADA surveys typically only focus on a limited number of human behaviour modalities. Despite being used as a theoretical basis for developing ADA approaches, existing ADA surveys lack a comprehensive review and summary of multi-modal depression-related human behaviours. To bridge this gap, this paper specifically summarises depression-related human behaviours across a range of modalities (e.g. the human brain, verbal language and non-verbal audio/facial/body behaviours). We focus on conducting an up-to-date and comprehensive survey of ML-based ADA approaches for learning depression cues from these behaviours as well as discussing and comparing their distinctive features and limitations. In addition, we also review existing ADA competitions and datasets, identify and discuss the main challenges and opportunities to provide further research directions for future ADA researchers.",
    "summary": "arXiv:2506.18915v1 Announce Type: cross Abstract: Depression is a common mental illness across current human society. Traditional depression assessment relying on inventories and interviews with psychologists frequently suffer from subjective diagnosis results, slow and expensive diagnosis process as well as lack of human resources. Since there is a solid evidence that depression is reflected by various human internal brain activities and external expressive behaviours, early traditional machine learning (ML) and advanced deep learning (DL) models have been widely explored for human behaviour-based automatic depression assessment (ADA) since 2012. However, recent ADA surveys typically only focus on a limited number of human behaviour modalities. Despite being used as a theoretical basis for developing ADA approaches, existing ADA surveys lack a comprehensive review and summary of multi-modal depression-related human behaviours. To bridge this gap, this paper specifically summarises depression-related human behaviours across a range of modalities (e.g. the human brain, verbal language and non-verbal audio/facial/body behaviours). We focus on conducting an up-to-date and comprehensive survey of ML-based ADA approaches for learning depression cues from these behaviours as well as discussing and comparing their distinctive features and limitations. In addition, we also review existing ADA competitions and datasets, identify and discuss the main challenges and opportunities to provide further research directions for future ADA researchers.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.18915",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Automatic Posology Structuration : What role for LLMs?",
    "description": "arXiv:2506.19525v1 Announce Type: cross Abstract: Automatically structuring posology instructions is essential for improving medication safety and enabling clinical decision support. In French prescriptions, these instructions are often ambiguous, irregular, or colloquial, limiting the effectiveness of classic ML pipelines. We explore the use of Large Language Models (LLMs) to convert free-text posologies into structured formats, comparing prompt-based methods and fine-tuning against a 'pre-LLM' system based on Named Entity Recognition and Linking (NERL). Our results show that while prompting improves performance, only fine-tuned LLMs match the accuracy of the baseline. Through error analysis, we observe complementary strengths: NERL offers structural precision, while LLMs better handle semantic nuances. Based on this, we propose a hybrid pipeline that routes low-confidence cases from NERL (<0.8) to the LLM, selecting outputs based on confidence scores. This strategy achieves 91% structuration accuracy while minimizing latency and compute. Our results show that this hybrid approach improves structuration accuracy while limiting computational cost, offering a scalable solution for real-world clinical use.",
    "summary": "arXiv:2506.19525v1 Announce Type: cross Abstract: Automatically structuring posology instructions is essential for improving medication safety and enabling clinical decision support. In French prescriptions, these instructions are often ambiguous, irregular, or colloquial, limiting the effectiveness of classic ML pipelines. We explore the use of Large Language Models (LLMs) to convert free-text posologies into structured formats, comparing prompt-based methods and fine-tuning against a 'pre-LLM' system based on Named Entity Recognition and Linking (NERL). Our results show that while prompting improves performance, only fine-tuned LLMs match the accuracy of the baseline. Through error analysis, we observe complementary strengths: NERL offers structural precision, while LLMs better handle semantic nuances. Based on this, we propose a hybrid pipeline that routes low-confidence cases from NERL (<0.8) to the LLM, selecting outputs based on confidence scores. This strategy achieves 91% structuration accuracy while minimizing latency and compute. Our results show that this hybrid approach improves structuration accuracy while limiting computational cost, offering a scalable solution for real-world clinical use.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19525",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Automatic Prompt Optimization for Knowledge Graph Construction: Insights from an Empirical Study",
    "description": "arXiv:2506.19773v1 Announce Type: new Abstract: A KG represents a network of entities and illustrates relationships between them. KGs are used for various applications, including semantic search and discovery, reasoning, decision-making, natural language processing, machine learning, and recommendation systems. Triple (subject-relation-object) extraction from text is the fundamental building block of KG construction and has been widely studied, for example, in early benchmarks such as ACE 2002 to more recent ones, such as WebNLG 2020, REBEL and SynthIE. While the use of LLMs is explored for KG construction, handcrafting reasonable task-specific prompts for LLMs is a labour-intensive exercise and can be brittle due to subtle changes in the LLM models employed. Recent work in NLP tasks (e.g. autonomy generation) uses automatic prompt optimization/engineering to address this challenge by generating optimal or near-optimal task-specific prompts given input-output examples. This empirical study explores the application of automatic prompt optimization for the triple extraction task using experimental benchmarking. We evaluate different settings by changing (a) the prompting strategy, (b) the LLM being used for prompt optimization and task execution, (c) the number of canonical relations in the schema (schema complexity), (d) the length and diversity of input text, (e) the metric used to drive the prompt optimization, and (f) the dataset being used for training and testing. We evaluate three different automatic prompt optimizers, namely, DSPy, APE, and TextGrad and use two different triple extraction datasets, SynthIE and REBEL. Through rigorous empirical evaluation, our main contribution highlights that automatic prompt optimization techniques can generate reasonable prompts similar to humans for triple extraction. In turn, these optimized prompts achieve improved results, particularly with increasing schema complexity and text size.",
    "summary": "arXiv:2506.19773v1 Announce Type: new Abstract: A KG represents a network of entities and illustrates relationships between them. KGs are used for various applications, including semantic search and discovery, reasoning, decision-making, natural language processing, machine learning, and recommendation systems. Triple (subject-relation-object) extraction from text is the fundamental building block of KG construction and has been widely studied, for example, in early benchmarks such as ACE 2002 to more recent ones, such as WebNLG 2020, REBEL and SynthIE. While the use of LLMs is explored for KG construction, handcrafting reasonable task-specific prompts for LLMs is a labour-intensive exercise and can be brittle due to subtle changes in the LLM models employed. Recent work in NLP tasks (e.g. autonomy generation) uses automatic prompt optimization/engineering to address this challenge by generating optimal or near-optimal task-specific prompts given input-output examples. This empirical study explores the application of automatic prompt optimization for the triple extraction task using experimental benchmarking. We evaluate different settings by changing (a) the prompting strategy, (b) the LLM being used for prompt optimization and task execution, (c) the number of canonical relations in the schema (schema complexity), (d) the length and diversity of input text, (e) the metric used to drive the prompt optimization, and (f) the dataset being used for training and testing. We evaluate three different automatic prompt optimizers, namely, DSPy, APE, and TextGrad and use two different triple extraction datasets, SynthIE and REBEL. Through rigorous empirical evaluation, our main contribution highlights that automatic prompt optimization techniques can generate reasonable prompts similar to humans for triple extraction. In turn, these optimized prompts achieve improved results, particularly with increasing schema complexity and text size.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19773",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Baba is LLM: Reasoning in a Game with Dynamic Rules",
    "description": "arXiv:2506.19095v1 Announce Type: new Abstract: Large language models (LLMs) are known to perform well on language tasks, but struggle with reasoning tasks. This paper explores the ability of LLMs to play the 2D puzzle game Baba is You, in which players manipulate rules by rearranging text blocks that define object properties. Given that this rule-manipulation relies on language abilities and reasoning, it is a compelling challenge for LLMs. Six LLMs are evaluated using different prompt types, including (1) simple, (2) rule-extended and (3) action-extended prompts. In addition, two models (Mistral, OLMo) are finetuned using textual and structural data from the game. Results show that while larger models (particularly GPT-4o) perform better in reasoning and puzzle solving, smaller unadapted models struggle to recognize game mechanics or apply rule changes. Finetuning improves the ability to analyze the game levels, but does not significantly improve solution formulation. We conclude that even for state-of-the-art and finetuned LLMs, reasoning about dynamic rule changes is difficult (specifically, understanding the use-mention distinction). The results provide insights into the applicability of LLMs to complex problem-solving tasks and highlight the suitability of games with dynamically changing rules for testing reasoning and reflection by LLMs.",
    "summary": "arXiv:2506.19095v1 Announce Type: new Abstract: Large language models (LLMs) are known to perform well on language tasks, but struggle with reasoning tasks. This paper explores the ability of LLMs to play the 2D puzzle game Baba is You, in which players manipulate rules by rearranging text blocks that define object properties. Given that this rule-manipulation relies on language abilities and reasoning, it is a compelling challenge for LLMs. Six LLMs are evaluated using different prompt types, including (1) simple, (2) rule-extended and (3) action-extended prompts. In addition, two models (Mistral, OLMo) are finetuned using textual and structural data from the game. Results show that while larger models (particularly GPT-4o) perform better in reasoning and puzzle solving, smaller unadapted models struggle to recognize game mechanics or apply rule changes. Finetuning improves the ability to analyze the game levels, but does not significantly improve solution formulation. We conclude that even for state-of-the-art and finetuned LLMs, reasoning about dynamic rule changes is difficult (specifically, understanding the use-mention distinction). The results provide insights into the applicability of LLMs to complex problem-solving tasks and highlight the suitability of games with dynamically changing rules for testing reasoning and reflection by LLMs.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19095",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Bayesian Evolutionary Swarm Architecture: A Formal Epistemic System Grounded in Truth-Based Competition",
    "description": "arXiv:2506.19191v1 Announce Type: new Abstract: We introduce a mathematically rigorous framework for an artificial intelligence system composed of probabilistic agents evolving through structured competition and belief revision. The architecture, grounded in Bayesian inference, measure theory, and population dynamics, defines agent fitness as a function of alignment with a fixed external oracle representing ground truth. Agents compete in a discrete-time environment, adjusting posterior beliefs through observed outcomes, with higher-rated agents reproducing and lower-rated agents undergoing extinction. Ratings are updated via pairwise truth-aligned utility comparisons, and belief updates preserve measurable consistency and stochastic convergence. We introduce hash-based cryptographic identity commitments to ensure traceability, alongside causal inference operators using do-calculus. Formal theorems on convergence, robustness, and evolutionary stability are provided. The system establishes truth as an evolutionary attractor, demonstrating that verifiable knowledge arises from adversarial epistemic pressure within a computable, self-regulating swarm.",
    "summary": "arXiv:2506.19191v1 Announce Type: new Abstract: We introduce a mathematically rigorous framework for an artificial intelligence system composed of probabilistic agents evolving through structured competition and belief revision. The architecture, grounded in Bayesian inference, measure theory, and population dynamics, defines agent fitness as a function of alignment with a fixed external oracle representing ground truth. Agents compete in a discrete-time environment, adjusting posterior beliefs through observed outcomes, with higher-rated agents reproducing and lower-rated agents undergoing extinction. Ratings are updated via pairwise truth-aligned utility comparisons, and belief updates preserve measurable consistency and stochastic convergence. We introduce hash-based cryptographic identity commitments to ensure traceability, alongside causal inference operators using do-calculus. Formal theorems on convergence, robustness, and evolutionary stability are provided. The system establishes truth as an evolutionary attractor, demonstrating that verifiable knowledge arises from adversarial epistemic pressure within a computable, self-regulating swarm.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19191",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Benchmarking the Pedagogical Knowledge of Large Language Models",
    "description": "arXiv:2506.18710v2 Announce Type: replace-cross Abstract: Benchmarks like Massive Multitask Language Understanding (MMLU) have played a pivotal role in evaluating AI's knowledge and abilities across diverse domains. However, existing benchmarks predominantly focus on content knowledge, leaving a critical gap in assessing models' understanding of pedagogy - the method and practice of teaching. This paper introduces The Pedagogy Benchmark, a novel dataset designed to evaluate large language models on their Cross-Domain Pedagogical Knowledge (CDPK) and Special Education Needs and Disability (SEND) pedagogical knowledge. These benchmarks are built on a carefully curated set of questions sourced from professional development exams for teachers, which cover a range of pedagogical subdomains such as teaching strategies and assessment methods. Here we outline the methodology and development of these benchmarks. We report results for 97 models, with accuracies spanning a range from 28% to 89% on the pedagogical knowledge questions. We consider the relationship between cost and accuracy and chart the progression of the Pareto value frontier over time. We provide online leaderboards at https://rebrand.ly/pedagogy which are updated with new models and allow interactive exploration and filtering based on various model properties, such as cost per token and open-vs-closed weights, as well as looking at performance in different subjects. LLMs and generative AI have tremendous potential to influence education and help to address the global learning crisis. Education-focused benchmarks are crucial to measure models' capacities to understand pedagogical concepts, respond appropriately to learners' needs, and support effective teaching practices across diverse contexts. They are needed for informing the responsible and evidence-based deployment of LLMs and LLM-based tools in educational settings, and for guiding both development and policy decisions.",
    "summary": "arXiv:2506.18710v2 Announce Type: replace-cross Abstract: Benchmarks like Massive Multitask Language Understanding (MMLU) have played a pivotal role in evaluating AI's knowledge and abilities across diverse domains. However, existing benchmarks predominantly focus on content knowledge, leaving a critical gap in assessing models' understanding of pedagogy - the method and practice of teaching. This paper introduces The Pedagogy Benchmark, a novel dataset designed to evaluate large language models on their Cross-Domain Pedagogical Knowledge (CDPK) and Special Education Needs and Disability (SEND) pedagogical knowledge. These benchmarks are built on a carefully curated set of questions sourced from professional development exams for teachers, which cover a range of pedagogical subdomains such as teaching strategies and assessment methods. Here we outline the methodology and development of these benchmarks. We report results for 97 models, with accuracies spanning a range from 28% to 89% on the pedagogical knowledge questions. We consider the relationship between cost and accuracy and chart the progression of the Pareto value frontier over time. We provide online leaderboards at https://rebrand.ly/pedagogy which are updated with new models and allow interactive exploration and filtering based on various model properties, such as cost per token and open-vs-closed weights, as well as looking at performance in different subjects. LLMs and generative AI have tremendous potential to influence education and help to address the global learning crisis. Education-focused benchmarks are crucial to measure models' capacities to understand pedagogical concepts, respond appropriately to learners' needs, and support effective teaching practices across diverse contexts. They are needed for informing the responsible and evidence-based deployment of LLMs and LLM-based tools in educational settings, and for guiding both development and policy decisions.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.18710",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Can AI support student engagement in classroom activities in higher education?",
    "description": "arXiv:2506.18941v1 Announce Type: cross Abstract: Lucrative career prospects and creative opportunities often attract students to enroll in computer science majors and pursue advanced studies in the field. Consequently, there has been a significant surge in enrollment in computer science courses, resulting in large class sizes that can range from hundreds to even thousands of students. A common challenge in such large classrooms is the lack of engagement between students and both the instructor and the learning material. However, with advancements in technology and improvements in large language models (LLMs), there is a considerable opportunity to utilize LLM-based AI models, such as conversational artificial intelligence (CAI), to enhance student engagement with learning content in large classes. To explore the potential of CAI to support engagement, especially with learning content, we designed an activity in a software Engineering course (with a large class size) where students used CAI for an in-class activity. We conducted a within-subject investigation in a large classroom at a US university where we compared student engagement during an in-class activity that used CAI tool vs. one without CAI tool. The CAI tool we used was ChatGPT due to its widespread popularity and familiarity. Our results indicate that CAI (ChatGPT) has the potential to support engagement with learning content during in-class activities, especially in large class sizes. We further discuss the implications of our findings.",
    "summary": "arXiv:2506.18941v1 Announce Type: cross Abstract: Lucrative career prospects and creative opportunities often attract students to enroll in computer science majors and pursue advanced studies in the field. Consequently, there has been a significant surge in enrollment in computer science courses, resulting in large class sizes that can range from hundreds to even thousands of students. A common challenge in such large classrooms is the lack of engagement between students and both the instructor and the learning material. However, with advancements in technology and improvements in large language models (LLMs), there is a considerable opportunity to utilize LLM-based AI models, such as conversational artificial intelligence (CAI), to enhance student engagement with learning content in large classes. To explore the potential of CAI to support engagement, especially with learning content, we designed an activity in a software Engineering course (with a large class size) where students used CAI for an in-class activity. We conducted a within-subject investigation in a large classroom at a US university where we compared student engagement during an in-class activity that used CAI tool vs. one without CAI tool. The CAI tool we used was ChatGPT due to its widespread popularity and familiarity. Our results indicate that CAI (ChatGPT) has the potential to support engagement with learning content during in-class activities, especially in large class sizes. We further discuss the implications of our findings.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.18941",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Can Large Language Models Capture Human Annotator Disagreements?",
    "description": "arXiv:2506.19467v1 Announce Type: cross Abstract: Human annotation variation (i.e., annotation disagreements) is common in NLP and often reflects important information such as task subjectivity and sample ambiguity. While Large Language Models (LLMs) are increasingly used for automatic annotation to reduce human effort, their evaluation often focuses on predicting the majority-voted 'ground truth' labels. It is still unclear, however, whether these models also capture informative human annotation variation. Our work addresses this gap by extensively evaluating LLMs' ability to predict annotation disagreements without access to repeated human labels. Our results show that LLMs struggle with modeling disagreements, which can be overlooked by majority label-based evaluations. Notably, while RLVR-style (Reinforcement learning with verifiable rewards) reasoning generally boosts LLM performance, it degrades performance in disagreement prediction. Our findings highlight the critical need for evaluating and improving LLM annotators in disagreement modeling. Code and data at https://github.com/EdisonNi-hku/Disagreement_Prediction.",
    "summary": "arXiv:2506.19467v1 Announce Type: cross Abstract: Human annotation variation (i.e., annotation disagreements) is common in NLP and often reflects important information such as task subjectivity and sample ambiguity. While Large Language Models (LLMs) are increasingly used for automatic annotation to reduce human effort, their evaluation often focuses on predicting the majority-voted 'ground truth' labels. It is still unclear, however, whether these models also capture informative human annotation variation. Our work addresses this gap by extensively evaluating LLMs' ability to predict annotation disagreements without access to repeated human labels. Our results show that LLMs struggle with modeling disagreements, which can be overlooked by majority label-based evaluations. Notably, while RLVR-style (Reinforcement learning with verifiable rewards) reasoning generally boosts LLM performance, it degrades performance in disagreement prediction. Our findings highlight the critical need for evaluating and improving LLM annotators in disagreement modeling. Code and data at https://github.com/EdisonNi-hku/Disagreement_Prediction.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19467",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Capturing Fine-Grained Alignments Improves 3D Affordance Detection",
    "description": "arXiv:2506.19312v1 Announce Type: cross Abstract: In this work, we address the challenge of affordance detection in 3D point clouds, a task that requires effectively capturing fine-grained alignments between point clouds and text. Existing methods often struggle to model such alignments, resulting in limited performance on standard benchmarks. A key limitation of these approaches is their reliance on simple cosine similarity between point cloud and text embeddings, which lacks the expressiveness needed for fine-grained reasoning. To address this limitation, we propose LM-AD, a novel method for affordance detection in 3D point clouds. Moreover, we introduce the Affordance Query Module (AQM), which efficiently captures fine-grained alignment between point clouds and text by leveraging a pretrained language model. We demonstrated that our method outperformed existing approaches in terms of accuracy and mean Intersection over Union on the 3D AffordanceNet dataset.",
    "summary": "arXiv:2506.19312v1 Announce Type: cross Abstract: In this work, we address the challenge of affordance detection in 3D point clouds, a task that requires effectively capturing fine-grained alignments between point clouds and text. Existing methods often struggle to model such alignments, resulting in limited performance on standard benchmarks. A key limitation of these approaches is their reliance on simple cosine similarity between point cloud and text embeddings, which lacks the expressiveness needed for fine-grained reasoning. To address this limitation, we propose LM-AD, a novel method for affordance detection in 3D point clouds. Moreover, we introduce the Affordance Query Module (AQM), which efficiently captures fine-grained alignment between point clouds and text by leveraging a pretrained language model. We demonstrated that our method outperformed existing approaches in terms of accuracy and mean Intersection over Union on the 3D AffordanceNet dataset.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19312",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "ChatSR: Multimodal Large Language Models for Scientific Formula Discovery",
    "description": "arXiv:2406.05410v2 Announce Type: replace Abstract: Formulas are the language of communication between humans and nature. The discovery of formulas to describe natural laws from observational data is the purpose of scientific research. It is also an important research topic in artificial intelligence, which is called a symbolic regression problem. Most of the existing symbolic regression methods generate expressions directly from observed data. Although in some methods, we can inject some prior knowledge into the model by adding constraints or introducing some special character hints. However, these methods can only introduce a limited amount of prior knowledge specified in advance. Not to mention understanding natural language instructions. In this article, based on the powerful knowledge reserve and language understanding ability of multi-modal large language models, we present ChatSR, which acts like a knowledgeable human scientist, and we can tell it any prior knowledge through natural language to guide it in formula generation. By testing on 13 datasets, ChatSR not only shows state-of-the-art performance on traditional symbolic regression tasks. More notably, ChatSR can well understand the prior knowledge contained in natural language prompts and improve the quality of generated expressions. In addition, it is exciting that ChatSR has a good zero-shot capability to understand prior knowledge that is not present in the training data.",
    "summary": "arXiv:2406.05410v2 Announce Type: replace Abstract: Formulas are the language of communication between humans and nature. The discovery of formulas to describe natural laws from observational data is the purpose of scientific research. It is also an important research topic in artificial intelligence, which is called a symbolic regression problem. Most of the existing symbolic regression methods generate expressions directly from observed data. Although in some methods, we can inject some prior knowledge into the model by adding constraints or introducing some special character hints. However, these methods can only introduce a limited amount of prior knowledge specified in advance. Not to mention understanding natural language instructions. In this article, based on the powerful knowledge reserve and language understanding ability of multi-modal large language models, we present ChatSR, which acts like a knowledgeable human scientist, and we can tell it any prior knowledge through natural language to guide it in formula generation. By testing on 13 datasets, ChatSR not only shows state-of-the-art performance on traditional symbolic regression tasks. More notably, ChatSR can well understand the prior knowledge contained in natural language prompts and improve the quality of generated expressions. In addition, it is exciting that ChatSR has a good zero-shot capability to understand prior knowledge that is not present in the training data.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2406.05410",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "ChordPrompt: Orchestrating Cross-Modal Prompt Synergy for Multi-Domain Incremental Learning in CLIP",
    "description": "arXiv:2506.19608v1 Announce Type: new Abstract: Continual learning (CL) empowers pre-trained vision-language models to adapt effectively to novel or previously underrepresented data distributions without comprehensive retraining, enhancing their adaptability and efficiency. While vision-language models like CLIP show great promise, they struggle to maintain performance across domains in incremental learning scenarios. Existing prompt learning methods face two main limitations: 1) they primarily focus on class-incremental learning scenarios, lacking specific strategies for multi-domain task incremental learning; 2) most current approaches employ single-modal prompts, neglecting the potential benefits of cross-modal information exchange. To address these challenges, we propose the ChordPrompt framework, which facilitates a harmonious interplay between visual and textual prompts. ChordPrompt introduces cross-modal prompts to leverage interactions between visual and textual information. Our approach also employs domain-adaptive text prompts to select appropriate prompts for continual adaptation across multiple domains. Comprehensive experiments on multi-domain incremental learning benchmarks demonstrate that ChordPrompt outperforms state-of-the-art methods in zero-shot generalization and downstream task performance.",
    "summary": "arXiv:2506.19608v1 Announce Type: new Abstract: Continual learning (CL) empowers pre-trained vision-language models to adapt effectively to novel or previously underrepresented data distributions without comprehensive retraining, enhancing their adaptability and efficiency. While vision-language models like CLIP show great promise, they struggle to maintain performance across domains in incremental learning scenarios. Existing prompt learning methods face two main limitations: 1) they primarily focus on class-incremental learning scenarios, lacking specific strategies for multi-domain task incremental learning; 2) most current approaches employ single-modal prompts, neglecting the potential benefits of cross-modal information exchange. To address these challenges, we propose the ChordPrompt framework, which facilitates a harmonious interplay between visual and textual prompts. ChordPrompt introduces cross-modal prompts to leverage interactions between visual and textual information. Our approach also employs domain-adaptive text prompts to select appropriate prompts for continual adaptation across multiple domains. Comprehensive experiments on multi-domain incremental learning benchmarks demonstrate that ChordPrompt outperforms state-of-the-art methods in zero-shot generalization and downstream task performance.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19608",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Citizenship Challenges in Artificial Intelligence Education",
    "description": "arXiv:2506.18955v1 Announce Type: cross Abstract: This chapter addresses the citizenship challenges related to AI in education, particularly concerning students, teachers, and other educational stakeholders in the context of AI integration. We first explore how to foster AI awareness and education, along with various strategies to promote a socio-critical approach to AI training, aiming to identify relevant and ethical uses to prioritise. In the second part, we discuss critical thinking and computational thinking skills that can be mobilised within certain AI-supported educational activities, depending on the degree of creative and transformative engagement those activities require.",
    "summary": "arXiv:2506.18955v1 Announce Type: cross Abstract: This chapter addresses the citizenship challenges related to AI in education, particularly concerning students, teachers, and other educational stakeholders in the context of AI integration. We first explore how to foster AI awareness and education, along with various strategies to promote a socio-critical approach to AI training, aiming to identify relevant and ethical uses to prioritise. In the second part, we discuss critical thinking and computational thinking skills that can be mobilised within certain AI-supported educational activities, depending on the degree of creative and transformative engagement those activities require.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.18955",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "ClimateIQA: A New Dataset and Benchmark to Advance Vision-Language Models in Meteorology Anomalies Analysis",
    "description": "arXiv:2406.09838v2 Announce Type: replace-cross Abstract: Meteorological heatmaps play a vital role in deciphering extreme weather phenomena, yet their inherent complexities marked by irregular contours, unstructured patterns, and complex color variations present unique analytical hurdles for state-of-the-art Vision-Language Models (VLMs). Current state-of-the-art models like GPT-4o, Qwen-VL, and LLaVA 1.6 struggle with tasks such as precise color identification and spatial localization, resulting in inaccurate or incomplete interpretations. To address these challenges, we introduce Sparse Position and Outline Tracking (SPOT), a novel algorithm specifically designed to process irregularly shaped colored regions in visual data. SPOT identifies and localizes these regions by extracting their spatial coordinates, enabling structured representations of irregular shapes. Building on SPOT, we construct ClimateIQA, a novel meteorological visual question answering (VQA) dataset, comprising 26,280 high-resolution heatmaps and 762,120 instruction samples for wind gust, total precipitation, wind chill index and heat index analysis. ClimateIQA enhances VLM training by incorporating spatial cues, geographic metadata, and reanalysis data, improving model accuracy in interpreting and describing extreme weather features. Furthermore, we develop Climate-Zoo, a suite of fine-tuned VLMs based on SPOT-empowered ClimateIQA, which significantly outperforms existing models in meteorological heatmap tasks.",
    "summary": "arXiv:2406.09838v2 Announce Type: replace-cross Abstract: Meteorological heatmaps play a vital role in deciphering extreme weather phenomena, yet their inherent complexities marked by irregular contours, unstructured patterns, and complex color variations present unique analytical hurdles for state-of-the-art Vision-Language Models (VLMs). Current state-of-the-art models like GPT-4o, Qwen-VL, and LLaVA 1.6 struggle with tasks such as precise color identification and spatial localization, resulting in inaccurate or incomplete interpretations. To address these challenges, we introduce Sparse Position and Outline Tracking (SPOT), a novel algorithm specifically designed to process irregularly shaped colored regions in visual data. SPOT identifies and localizes these regions by extracting their spatial coordinates, enabling structured representations of irregular shapes. Building on SPOT, we construct ClimateIQA, a novel meteorological visual question answering (VQA) dataset, comprising 26,280 high-resolution heatmaps and 762,120 instruction samples for wind gust, total precipitation, wind chill index and heat index analysis. ClimateIQA enhances VLM training by incorporating spatial cues, geographic metadata, and reanalysis data, improving model accuracy in interpreting and describing extreme weather features. Furthermore, we develop Climate-Zoo, a suite of fine-tuned VLMs based on SPOT-empowered ClimateIQA, which significantly outperforms existing models in meteorological heatmap tasks.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2406.09838",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Commander-GPT: Dividing and Routing for Multimodal Sarcasm Detection",
    "description": "arXiv:2506.19420v1 Announce Type: new Abstract: Multimodal sarcasm understanding is a high-order cognitive task. Although large language models (LLMs) have shown impressive performance on many downstream NLP tasks, growing evidence suggests that they struggle with sarcasm understanding. In this paper, we propose Commander-GPT, a modular decision routing framework inspired by military command theory. Rather than relying on a single LLM's capability, Commander-GPT orchestrates a team of specialized LLM agents where each agent will be selectively assigned to a focused sub-task such as context modeling, sentiment analysis, etc. Their outputs are then routed back to the commander, which integrates the information and performs the final sarcasm judgment. To coordinate these agents, we introduce three types of centralized commanders: (1) a trained lightweight encoder-based commander (e.g., multi-modal BERT); (2) four small autoregressive language models, serving as moderately capable commanders (e.g., DeepSeek-VL); (3) two large LLM-based commander (Gemini Pro and GPT-4o) that performs task routing, output aggregation, and sarcasm decision-making in a zero-shot fashion. We evaluate Commander-GPT on the MMSD and MMSD 2.0 benchmarks, comparing five prompting strategies. Experimental results show that our framework achieves 4.4% and 11.7% improvement in F1 score over state-of-the-art (SoTA) baselines on average, demonstrating its effectiveness.",
    "summary": "arXiv:2506.19420v1 Announce Type: new Abstract: Multimodal sarcasm understanding is a high-order cognitive task. Although large language models (LLMs) have shown impressive performance on many downstream NLP tasks, growing evidence suggests that they struggle with sarcasm understanding. In this paper, we propose Commander-GPT, a modular decision routing framework inspired by military command theory. Rather than relying on a single LLM's capability, Commander-GPT orchestrates a team of specialized LLM agents where each agent will be selectively assigned to a focused sub-task such as context modeling, sentiment analysis, etc. Their outputs are then routed back to the commander, which integrates the information and performs the final sarcasm judgment. To coordinate these agents, we introduce three types of centralized commanders: (1) a trained lightweight encoder-based commander (e.g., multi-modal BERT); (2) four small autoregressive language models, serving as moderately capable commanders (e.g., DeepSeek-VL); (3) two large LLM-based commander (Gemini Pro and GPT-4o) that performs task routing, output aggregation, and sarcasm decision-making in a zero-shot fashion. We evaluate Commander-GPT on the MMSD and MMSD 2.0 benchmarks, comparing five prompting strategies. Experimental results show that our framework achieves 4.4% and 11.7% improvement in F1 score over state-of-the-art (SoTA) baselines on average, demonstrating its effectiveness.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19420",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "ConciseHint: Boosting Efficient Reasoning via Continuous Concise Hints during Generation",
    "description": "arXiv:2506.18810v2 Announce Type: replace Abstract: Recent advancements in large reasoning models (LRMs) like DeepSeek-R1 and OpenAI o1 series have achieved notable performance enhancements on complex reasoning tasks by scaling up the generation length by Chain-of-Thought (CoT). However, an emerging issue is their inclination to produce excessively verbose reasoning processes, leading to the inefficiency problem. Existing literature on improving efficiency mainly adheres to the before-reasoning paradigms such as prompting and reasoning or fine-tuning and reasoning, but ignores the promising direction of directly encouraging the model to speak concisely by intervening during the generation of reasoning. In order to fill the blank, we propose a framework dubbed ConciseHint, which continuously encourages the reasoning model to speak concisely by injecting the textual hint (manually designed or trained on the concise data) during the token generation of the reasoning process. Besides, ConciseHint is adaptive to the complexity of the query by adaptively adjusting the hint intensity, which ensures it will not undermine model performance. Experiments on the state-of-the-art LRMs, including DeepSeek-R1 and Qwen-3 series, demonstrate that our method can effectively produce concise reasoning processes while maintaining performance well. For instance, we achieve a reduction ratio of 65% for the reasoning length on GSM8K benchmark with Qwen-3 4B with nearly no accuracy loss.",
    "summary": "arXiv:2506.18810v2 Announce Type: replace Abstract: Recent advancements in large reasoning models (LRMs) like DeepSeek-R1 and OpenAI o1 series have achieved notable performance enhancements on complex reasoning tasks by scaling up the generation length by Chain-of-Thought (CoT). However, an emerging issue is their inclination to produce excessively verbose reasoning processes, leading to the inefficiency problem. Existing literature on improving efficiency mainly adheres to the before-reasoning paradigms such as prompting and reasoning or fine-tuning and reasoning, but ignores the promising direction of directly encouraging the model to speak concisely by intervening during the generation of reasoning. In order to fill the blank, we propose a framework dubbed ConciseHint, which continuously encourages the reasoning model to speak concisely by injecting the textual hint (manually designed or trained on the concise data) during the token generation of the reasoning process. Besides, ConciseHint is adaptive to the complexity of the query by adaptively adjusting the hint intensity, which ensures it will not undermine model performance. Experiments on the state-of-the-art LRMs, including DeepSeek-R1 and Qwen-3 series, demonstrate that our method can effectively produce concise reasoning processes while maintaining performance well. For instance, we achieve a reduction ratio of 65% for the reasoning length on GSM8K benchmark with Qwen-3 4B with nearly no accuracy loss.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.18810",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Connecting Vision and Emissions: A Behavioural AI Approach to Carbon Estimation in Road Design",
    "description": "arXiv:2506.18924v1 Announce Type: cross Abstract: We present an enhanced YOLOv8 real time vehicle detection and classification framework, for estimating carbon emissions in urban environments. The system enhances YOLOv8 architecture to detect, segment, and track vehicles from live traffic video streams. Once a vehicle is localized, a dedicated deep learning-based identification module is employed to recognize license plates and classify vehicle types. Since YOLOv8 lacks the built-in capacity for fine grained recognition tasks such as reading license plates or determining vehicle attributes beyond class labels, our framework incorporates a hybrid pipeline where each detected vehicle is tracked and its bounding box is cropped and passed to a deep Optical Character Recognition (OCR) module. This OCR system, composed of multiple convolutional neural network (CNN) layers, is trained specifically for character-level detection and license plate decoding under varied conditions such as motion blur, occlusion, and diverse font styles. Additionally, the recognized plate information is validated using a real time API that cross references with an external vehicle registration database to ensure accurate classification and emission estimation. This multi-stage approach enables precise, automated calculation of per vehicle carbon emissions. Extensive evaluation was conducted using a diverse vehicle dataset enriched with segmentation masks and annotated license plates. The YOLOv8 detector achieved a mean Average Precision (mAP@0.5) of approximately 71% for bounding boxes and 70% for segmentation masks. Character level OCR accuracy reached up to 99% with the best performing CNN model. These results affirm the feasibility of combining real time object detection with deep OCR for practical deployment in smart transportation systems, offering a scalable solution for automated, vehicle specific carbon emission monitoring.",
    "summary": "arXiv:2506.18924v1 Announce Type: cross Abstract: We present an enhanced YOLOv8 real time vehicle detection and classification framework, for estimating carbon emissions in urban environments. The system enhances YOLOv8 architecture to detect, segment, and track vehicles from live traffic video streams. Once a vehicle is localized, a dedicated deep learning-based identification module is employed to recognize license plates and classify vehicle types. Since YOLOv8 lacks the built-in capacity for fine grained recognition tasks such as reading license plates or determining vehicle attributes beyond class labels, our framework incorporates a hybrid pipeline where each detected vehicle is tracked and its bounding box is cropped and passed to a deep Optical Character Recognition (OCR) module. This OCR system, composed of multiple convolutional neural network (CNN) layers, is trained specifically for character-level detection and license plate decoding under varied conditions such as motion blur, occlusion, and diverse font styles. Additionally, the recognized plate information is validated using a real time API that cross references with an external vehicle registration database to ensure accurate classification and emission estimation. This multi-stage approach enables precise, automated calculation of per vehicle carbon emissions. Extensive evaluation was conducted using a diverse vehicle dataset enriched with segmentation masks and annotated license plates. The YOLOv8 detector achieved a mean Average Precision (mAP@0.5) of approximately 71% for bounding boxes and 70% for segmentation masks. Character level OCR accuracy reached up to 99% with the best performing CNN model. These results affirm the feasibility of combining real time object detection with deep OCR for practical deployment in smart transportation systems, offering a scalable solution for automated, vehicle specific carbon emission monitoring.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.18924",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "ContactDexNet: Multi-fingered Robotic Hand Grasping in Cluttered Environments through Hand-object Contact Semantic Mapping",
    "description": "arXiv:2404.08844v3 Announce Type: replace-cross Abstract: The deep learning models has significantly advanced dexterous manipulation techniques for multi-fingered hand grasping. However, the contact information-guided grasping in cluttered environments remains largely underexplored. To address this gap, we have developed a method for generating multi-fingered hand grasp samples in cluttered settings through contact semantic map. We introduce a contact semantic conditional variational autoencoder network (CoSe-CVAE) for creating comprehensive contact semantic map from object point cloud. We utilize grasp detection method to estimate hand grasp poses from the contact semantic map. Finally, an unified grasp evaluation model PointNetGPD++ is designed to assess grasp quality and collision probability, substantially improving the reliability of identifying optimal grasps in cluttered scenarios. Our grasp generation method has demonstrated remarkable success, outperforming state-of-the-art methods by at least 4.65% with 81.0% average grasping success rate in real-world single-object environment and 75.3% grasping success rate in cluttered scenes. We also proposed the multi-modal multi-fingered grasping dataset generation method. Our multi-fingered hand grasping dataset outperforms previous datasets in scene diversity, modality diversity. The dataset, code and supplementary materials can be found at https://sites.google.com/view/contact-dexnet.",
    "summary": "arXiv:2404.08844v3 Announce Type: replace-cross Abstract: The deep learning models has significantly advanced dexterous manipulation techniques for multi-fingered hand grasping. However, the contact information-guided grasping in cluttered environments remains largely underexplored. To address this gap, we have developed a method for generating multi-fingered hand grasp samples in cluttered settings through contact semantic map. We introduce a contact semantic conditional variational autoencoder network (CoSe-CVAE) for creating comprehensive contact semantic map from object point cloud. We utilize grasp detection method to estimate hand grasp poses from the contact semantic map. Finally, an unified grasp evaluation model PointNetGPD++ is designed to assess grasp quality and collision probability, substantially improving the reliability of identifying optimal grasps in cluttered scenarios. Our grasp generation method has demonstrated remarkable success, outperforming state-of-the-art methods by at least 4.65% with 81.0% average grasping success rate in real-world single-object environment and 75.3% grasping success rate in cluttered scenes. We also proposed the multi-modal multi-fingered grasping dataset generation method. Our multi-fingered hand grasping dataset outperforms previous datasets in scene diversity, modality diversity. The dataset, code and supplementary materials can be found at https://sites.google.com/view/contact-dexnet.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2404.08844",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Controllable Video Generation with Provable Disentanglement",
    "description": "arXiv:2502.02690v2 Announce Type: replace-cross Abstract: Controllable video generation remains a significant challenge, despite recent advances in generating high-quality and consistent videos. Most existing methods for controlling video generation treat the video as a whole, neglecting intricate fine-grained spatiotemporal relationships, which limits both control precision and efficiency. In this paper, we propose Controllable Video Generative Adversarial Networks (CoVoGAN) to disentangle the video concepts, thus facilitating efficient and independent control over individual concepts. Specifically, following the minimal change principle, we first disentangle static and dynamic latent variables. We then leverage the sufficient change property to achieve component-wise identifiability of dynamic latent variables, enabling disentangled control of video generation. To establish the theoretical foundation, we provide a rigorous analysis demonstrating the identifiability of our approach. Building on these theoretical insights, we design a Temporal Transition Module to disentangle latent dynamics. To enforce the minimal change principle and sufficient change property, we minimize the dimensionality of latent dynamic variables and impose temporal conditional independence. To validate our approach, we integrate this module as a plug-in for GANs. Extensive qualitative and quantitative experiments on various video generation benchmarks demonstrate that our method significantly improves generation quality and controllability across diverse real-world scenarios.",
    "summary": "arXiv:2502.02690v2 Announce Type: replace-cross Abstract: Controllable video generation remains a significant challenge, despite recent advances in generating high-quality and consistent videos. Most existing methods for controlling video generation treat the video as a whole, neglecting intricate fine-grained spatiotemporal relationships, which limits both control precision and efficiency. In this paper, we propose Controllable Video Generative Adversarial Networks (CoVoGAN) to disentangle the video concepts, thus facilitating efficient and independent control over individual concepts. Specifically, following the minimal change principle, we first disentangle static and dynamic latent variables. We then leverage the sufficient change property to achieve component-wise identifiability of dynamic latent variables, enabling disentangled control of video generation. To establish the theoretical foundation, we provide a rigorous analysis demonstrating the identifiability of our approach. Building on these theoretical insights, we design a Temporal Transition Module to disentangle latent dynamics. To enforce the minimal change principle and sufficient change property, we minimize the dimensionality of latent dynamic variables and impose temporal conditional independence. To validate our approach, we integrate this module as a plug-in for GANs. Extensive qualitative and quantitative experiments on various video generation benchmarks demonstrate that our method significantly improves generation quality and controllability across diverse real-world scenarios.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2502.02690",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Conversational Intent-Driven GraphRAG: Enhancing Multi-Turn Dialogue Systems through Adaptive Dual-Retrieval of Flow Patterns and Context Semantics",
    "description": "arXiv:2506.19385v1 Announce Type: new Abstract: We present CID-GraphRAG (Conversational Intent-Driven Graph Retrieval Augmented Generation), a novel framework that addresses the limitations of existing dialogue systems in maintaining both contextual coherence and goal-oriented progression in multi-turn customer service conversations. Unlike traditional RAG systems that rely solely on semantic similarity (Conversation RAG) or standard knowledge graphs (GraphRAG), CID-GraphRAG constructs dynamic intent transition graphs from goal achieved historical dialogues and implements a dual-retrieval mechanism that adaptively balances intent-based graph traversal with semantic search. This approach enables the system to simultaneously leverage both conversional intent flow patterns and contextual semantics, significantly improving retrieval quality and response quality. In extensive experiments on real-world customer service dialogues, we employ both automatic metrics and LLM-as-judge assessments, demonstrating that CID-GraphRAG significantly outperforms both semantic-based Conversation RAG and intent-based GraphRAG baselines across all evaluation criteria. Quantitatively, CID-GraphRAG demonstrates substantial improvements over Conversation RAG across automatic metrics, with relative gains of 11% in BLEU, 5% in ROUGE-L, 6% in METEOR, and most notably, a 58% improvement in response quality according to LLM-as-judge evaluations. These results demonstrate that the integration of intent transition structures with semantic retrieval creates a synergistic effect that neither approach achieves independently, establishing CID-GraphRAG as an effective framework for addressing the challenges of maintaining contextual coherence and goal-oriented progression in knowledge-intensive multi-turn dialogues.",
    "summary": "arXiv:2506.19385v1 Announce Type: new Abstract: We present CID-GraphRAG (Conversational Intent-Driven Graph Retrieval Augmented Generation), a novel framework that addresses the limitations of existing dialogue systems in maintaining both contextual coherence and goal-oriented progression in multi-turn customer service conversations. Unlike traditional RAG systems that rely solely on semantic similarity (Conversation RAG) or standard knowledge graphs (GraphRAG), CID-GraphRAG constructs dynamic intent transition graphs from goal achieved historical dialogues and implements a dual-retrieval mechanism that adaptively balances intent-based graph traversal with semantic search. This approach enables the system to simultaneously leverage both conversional intent flow patterns and contextual semantics, significantly improving retrieval quality and response quality. In extensive experiments on real-world customer service dialogues, we employ both automatic metrics and LLM-as-judge assessments, demonstrating that CID-GraphRAG significantly outperforms both semantic-based Conversation RAG and intent-based GraphRAG baselines across all evaluation criteria. Quantitatively, CID-GraphRAG demonstrates substantial improvements over Conversation RAG across automatic metrics, with relative gains of 11% in BLEU, 5% in ROUGE-L, 6% in METEOR, and most notably, a 58% improvement in response quality according to LLM-as-judge evaluations. These results demonstrate that the integration of intent transition structures with semantic retrieval creates a synergistic effect that neither approach achieves independently, establishing CID-GraphRAG as an effective framework for addressing the challenges of maintaining contextual coherence and goal-oriented progression in knowledge-intensive multi-turn dialogues.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19385",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Cross-regularization: Adaptive Model Complexity through Validation Gradients",
    "description": "arXiv:2506.19755v1 Announce Type: cross Abstract: Model regularization requires extensive manual tuning to balance complexity against overfitting. Cross-regularization resolves this tradeoff by directly adapting regularization parameters through validation gradients during training. The method splits parameter optimization - training data guides feature learning while validation data shapes complexity controls - converging provably to cross-validation optima. When implemented through noise injection in neural networks, this approach reveals striking patterns: unexpectedly high noise tolerance and architecture-specific regularization that emerges organically during training. Beyond complexity control, the framework integrates seamlessly with data augmentation, uncertainty calibration and growing datasets while maintaining single-run efficiency through a simple gradient-based approach.",
    "summary": "arXiv:2506.19755v1 Announce Type: cross Abstract: Model regularization requires extensive manual tuning to balance complexity against overfitting. Cross-regularization resolves this tradeoff by directly adapting regularization parameters through validation gradients during training. The method splits parameter optimization - training data guides feature learning while validation data shapes complexity controls - converging provably to cross-validation optima. When implemented through noise injection in neural networks, this approach reveals striking patterns: unexpectedly high noise tolerance and architecture-specific regularization that emerges organically during training. Beyond complexity control, the framework integrates seamlessly with data augmentation, uncertainty calibration and growing datasets while maintaining single-run efficiency through a simple gradient-based approach.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19755",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "CUPID: Curating Data your Robot Loves with Influence Functions",
    "description": "arXiv:2506.19121v1 Announce Type: cross Abstract: In robot imitation learning, policy performance is tightly coupled with the quality and composition of the demonstration data. Yet, developing a precise understanding of how individual demonstrations contribute to downstream outcomes - such as closed-loop task success or failure - remains a persistent challenge. We propose CUPID, a robot data curation method based on a novel influence function-theoretic formulation for imitation learning policies. Given a set of evaluation rollouts, CUPID estimates the influence of each training demonstration on the policy's expected return. This enables ranking and selection of demonstrations according to their impact on the policy's closed-loop performance. We use CUPID to curate data by 1) filtering out training demonstrations that harm policy performance and 2) subselecting newly collected trajectories that will most improve the policy. Extensive simulated and hardware experiments show that our approach consistently identifies which data drives test-time performance. For example, training with less than 33% of curated data can yield state-of-the-art diffusion policies on the simulated RoboMimic benchmark, with similar gains observed in hardware. Furthermore, hardware experiments show that our method can identify robust strategies under distribution shift, isolate spurious correlations, and even enhance the post-training of generalist robot policies. Additional materials are made available at: https://cupid-curation.github.io.",
    "summary": "arXiv:2506.19121v1 Announce Type: cross Abstract: In robot imitation learning, policy performance is tightly coupled with the quality and composition of the demonstration data. Yet, developing a precise understanding of how individual demonstrations contribute to downstream outcomes - such as closed-loop task success or failure - remains a persistent challenge. We propose CUPID, a robot data curation method based on a novel influence function-theoretic formulation for imitation learning policies. Given a set of evaluation rollouts, CUPID estimates the influence of each training demonstration on the policy's expected return. This enables ranking and selection of demonstrations according to their impact on the policy's closed-loop performance. We use CUPID to curate data by 1) filtering out training demonstrations that harm policy performance and 2) subselecting newly collected trajectories that will most improve the policy. Extensive simulated and hardware experiments show that our approach consistently identifies which data drives test-time performance. For example, training with less than 33% of curated data can yield state-of-the-art diffusion policies on the simulated RoboMimic benchmark, with similar gains observed in hardware. Furthermore, hardware experiments show that our method can identify robust strategies under distribution shift, isolate spurious correlations, and even enhance the post-training of generalist robot policies. Additional materials are made available at: https://cupid-curation.github.io.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19121",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "cuVSLAM: CUDA accelerated visual odometry and mapping",
    "description": "arXiv:2506.04359v2 Announce Type: replace-cross Abstract: Accurate and robust pose estimation is a key requirement for any autonomous robot. We present cuVSLAM, a state-of-the-art solution for visual simultaneous localization and mapping, which can operate with a variety of visual-inertial sensor suites, including multiple RGB and depth cameras, and inertial measurement units. cuVSLAM supports operation with as few as one RGB camera to as many as 32 cameras, in arbitrary geometric configurations, thus supporting a wide range of robotic setups. cuVSLAM is specifically optimized using CUDA to deploy in real-time applications with minimal computational overhead on edge-computing devices such as the NVIDIA Jetson. We present the design and implementation of cuVSLAM, example use cases, and empirical results on several state-of-the-art benchmarks demonstrating the best-in-class performance of cuVSLAM.",
    "summary": "arXiv:2506.04359v2 Announce Type: replace-cross Abstract: Accurate and robust pose estimation is a key requirement for any autonomous robot. We present cuVSLAM, a state-of-the-art solution for visual simultaneous localization and mapping, which can operate with a variety of visual-inertial sensor suites, including multiple RGB and depth cameras, and inertial measurement units. cuVSLAM supports operation with as few as one RGB camera to as many as 32 cameras, in arbitrary geometric configurations, thus supporting a wide range of robotic setups. cuVSLAM is specifically optimized using CUDA to deploy in real-time applications with minimal computational overhead on edge-computing devices such as the NVIDIA Jetson. We present the design and implementation of cuVSLAM, example use cases, and empirical results on several state-of-the-art benchmarks demonstrating the best-in-class performance of cuVSLAM.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.04359",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "CVE-Bench: A Benchmark for AI Agents' Ability to Exploit Real-World Web Application Vulnerabilities",
    "description": "arXiv:2503.17332v4 Announce Type: replace-cross Abstract: Large language model (LLM) agents are increasingly capable of autonomously conducting cyberattacks, posing significant threats to existing applications. This growing risk highlights the urgent need for a real-world benchmark to evaluate the ability of LLM agents to exploit web application vulnerabilities. However, existing benchmarks fall short as they are limited to abstracted Capture the Flag competitions or lack comprehensive coverage. Building a benchmark for real-world vulnerabilities involves both specialized expertise to reproduce exploits and a systematic approach to evaluating unpredictable threats. To address this challenge, we introduce CVE-Bench, a real-world cybersecurity benchmark based on critical-severity Common Vulnerabilities and Exposures. In CVE-Bench, we design a sandbox framework that enables LLM agents to exploit vulnerable web applications in scenarios that mimic real-world conditions, while also providing effective evaluation of their exploits. Our evaluation shows that the state-of-the-art agent framework can resolve up to 13% of vulnerabilities.",
    "summary": "arXiv:2503.17332v4 Announce Type: replace-cross Abstract: Large language model (LLM) agents are increasingly capable of autonomously conducting cyberattacks, posing significant threats to existing applications. This growing risk highlights the urgent need for a real-world benchmark to evaluate the ability of LLM agents to exploit web application vulnerabilities. However, existing benchmarks fall short as they are limited to abstracted Capture the Flag competitions or lack comprehensive coverage. Building a benchmark for real-world vulnerabilities involves both specialized expertise to reproduce exploits and a systematic approach to evaluating unpredictable threats. To address this challenge, we introduce CVE-Bench, a real-world cybersecurity benchmark based on critical-severity Common Vulnerabilities and Exposures. In CVE-Bench, we design a sandbox framework that enables LLM agents to exploit vulnerable web applications in scenarios that mimic real-world conditions, while also providing effective evaluation of their exploits. Our evaluation shows that the state-of-the-art agent framework can resolve up to 13% of vulnerabilities.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2503.17332",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Damba-ST: Domain-Adaptive Mamba for Efficient Urban Spatio-Temporal Prediction",
    "description": "arXiv:2506.18939v1 Announce Type: cross Abstract: Training urban spatio-temporal foundation models that generalize well across diverse regions and cities is critical for deploying urban services in unseen or data-scarce regions. Recent studies have typically focused on fusing cross-domain spatio-temporal data to train unified Transformer-based models. However, these models suffer from quadratic computational complexity and high memory overhead, limiting their scalability and practical deployment. Inspired by the efficiency of Mamba, a state space model with linear time complexity, we explore its potential for efficient urban spatio-temporal prediction. However, directly applying Mamba as a spatio-temporal backbone leads to negative transfer and severe performance degradation. This is primarily due to spatio-temporal heterogeneity and the recursive mechanism of Mamba's hidden state updates, which limit cross-domain generalization. To overcome these challenges, we propose Damba-ST, a novel domain-adaptive Mamba-based model for efficient urban spatio-temporal prediction. Damba-ST retains Mamba's linear complexity advantage while significantly enhancing its adaptability to heterogeneous domains. Specifically, we introduce two core innovations: (1) a domain-adaptive state space model that partitions the latent representation space into a shared subspace for learning cross-domain commonalities and independent, domain-specific subspaces for capturing intra-domain discriminative features; (2) three distinct Domain Adapters, which serve as domain-aware proxies to bridge disparate domain distributions and facilitate the alignment of cross-domain commonalities. Extensive experiments demonstrate the generalization and efficiency of Damba-ST. It achieves state-of-the-art performance on prediction tasks and demonstrates strong zero-shot generalization, enabling seamless deployment in new urban environments without extensive retraining or fine-tuning.",
    "summary": "arXiv:2506.18939v1 Announce Type: cross Abstract: Training urban spatio-temporal foundation models that generalize well across diverse regions and cities is critical for deploying urban services in unseen or data-scarce regions. Recent studies have typically focused on fusing cross-domain spatio-temporal data to train unified Transformer-based models. However, these models suffer from quadratic computational complexity and high memory overhead, limiting their scalability and practical deployment. Inspired by the efficiency of Mamba, a state space model with linear time complexity, we explore its potential for efficient urban spatio-temporal prediction. However, directly applying Mamba as a spatio-temporal backbone leads to negative transfer and severe performance degradation. This is primarily due to spatio-temporal heterogeneity and the recursive mechanism of Mamba's hidden state updates, which limit cross-domain generalization. To overcome these challenges, we propose Damba-ST, a novel domain-adaptive Mamba-based model for efficient urban spatio-temporal prediction. Damba-ST retains Mamba's linear complexity advantage while significantly enhancing its adaptability to heterogeneous domains. Specifically, we introduce two core innovations: (1) a domain-adaptive state space model that partitions the latent representation space into a shared subspace for learning cross-domain commonalities and independent, domain-specific subspaces for capturing intra-domain discriminative features; (2) three distinct Domain Adapters, which serve as domain-aware proxies to bridge disparate domain distributions and facilitate the alignment of cross-domain commonalities. Extensive experiments demonstrate the generalization and efficiency of Damba-ST. It achieves state-of-the-art performance on prediction tasks and demonstrates strong zero-shot generalization, enabling seamless deployment in new urban environments without extensive retraining or fine-tuning.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.18939",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "DaMO: A Data-Efficient Multimodal Orchestrator for Temporal Reasoning with Video LLMs",
    "description": "arXiv:2506.11558v2 Announce Type: replace-cross Abstract: Large Language Models (LLMs) have recently been extended to the video domain, enabling sophisticated video-language understanding. However, existing Video LLMs often exhibit limitations in fine-grained temporal reasoning, restricting their ability to precisely attribute responses to specific video moments, especially under constrained supervision. We introduce DaMO, a data-efficient Video LLM explicitly designed for accurate temporal reasoning and multimodal understanding. At its core, the proposed Temporal-aware Fuseformer employs a hierarchical dual-stream architecture that progressively captures temporal dynamics within each modality and effectively fuses complementary visual and audio information. To further enhance computational efficiency, DaMO integrates a global residual that reduces spatial redundancy while preserving essential semantic details. We train DaMO via a structured four-stage progressive training paradigm, incrementally equipping the model with multimodal alignment, semantic grounding, and temporal reasoning capabilities. This work also contributes multiple datasets augmented from existing ones with GPT-generated temporally grounded QA pairs for tasks requiring temporal supervision. Comprehensive experiments on temporal grounding and video QA benchmarks demonstrate that DaMO consistently surpasses prior methods, particularly in tasks demanding precise temporal alignment and reasoning. Our work establishes a promising direction for data-efficient video-language modeling.",
    "summary": "arXiv:2506.11558v2 Announce Type: replace-cross Abstract: Large Language Models (LLMs) have recently been extended to the video domain, enabling sophisticated video-language understanding. However, existing Video LLMs often exhibit limitations in fine-grained temporal reasoning, restricting their ability to precisely attribute responses to specific video moments, especially under constrained supervision. We introduce DaMO, a data-efficient Video LLM explicitly designed for accurate temporal reasoning and multimodal understanding. At its core, the proposed Temporal-aware Fuseformer employs a hierarchical dual-stream architecture that progressively captures temporal dynamics within each modality and effectively fuses complementary visual and audio information. To further enhance computational efficiency, DaMO integrates a global residual that reduces spatial redundancy while preserving essential semantic details. We train DaMO via a structured four-stage progressive training paradigm, incrementally equipping the model with multimodal alignment, semantic grounding, and temporal reasoning capabilities. This work also contributes multiple datasets augmented from existing ones with GPT-generated temporally grounded QA pairs for tasks requiring temporal supervision. Comprehensive experiments on temporal grounding and video QA benchmarks demonstrate that DaMO consistently surpasses prior methods, particularly in tasks demanding precise temporal alignment and reasoning. Our work establishes a promising direction for data-efficient video-language modeling.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.11558",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Defeating Prompt Injections by Design",
    "description": "arXiv:2503.18813v2 Announce Type: replace-cross Abstract: Large Language Models (LLMs) are increasingly deployed in agentic systems that interact with an untrusted environment. However, LLM agents are vulnerable to prompt injection attacks when handling untrusted data. In this paper we propose CaMeL, a robust defense that creates a protective system layer around the LLM, securing it even when underlying models are susceptible to attacks. To operate, CaMeL explicitly extracts the control and data flows from the (trusted) query; therefore, the untrusted data retrieved by the LLM can never impact the program flow. To further improve security, CaMeL uses a notion of a capability to prevent the exfiltration of private data over unauthorized data flows by enforcing security policies when tools are called. We demonstrate effectiveness of CaMeL by solving $77%$ of tasks with provable security (compared to $84%$ with an undefended system) in AgentDojo. We release CaMeL at https://github.com/google-research/camel-prompt-injection.",
    "summary": "arXiv:2503.18813v2 Announce Type: replace-cross Abstract: Large Language Models (LLMs) are increasingly deployed in agentic systems that interact with an untrusted environment. However, LLM agents are vulnerable to prompt injection attacks when handling untrusted data. In this paper we propose CaMeL, a robust defense that creates a protective system layer around the LLM, securing it even when underlying models are susceptible to attacks. To operate, CaMeL explicitly extracts the control and data flows from the (trusted) query; therefore, the untrusted data retrieved by the LLM can never impact the program flow. To further improve security, CaMeL uses a notion of a capability to prevent the exfiltration of private data over unauthorized data flows by enforcing security policies when tools are called. We demonstrate effectiveness of CaMeL by solving $77%$ of tasks with provable security (compared to $84%$ with an undefended system) in AgentDojo. We release CaMeL at https://github.com/google-research/camel-prompt-injection.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2503.18813",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "DeltaSpace: A Semantic-aligned Feature Space for Flexible Text-guided Image Editing",
    "description": "arXiv:2310.08785v2 Announce Type: replace-cross Abstract: Text-guided image editing faces significant challenges when considering training and inference flexibility. Much literature collects large amounts of annotated image-text pairs to train text-conditioned generative models from scratch, which is expensive and not efficient. After that, some approaches that leverage pre-trained vision-language models have been proposed to avoid data collection, but they are limited by either per text-prompt optimization or inference-time hyper-parameters tuning. To address these issues, we investigate and identify a specific space, referred to as CLIP DeltaSpace, where the CLIP visual feature difference of two images is semantically aligned with the CLIP textual feature difference of their corresponding text descriptions. Based on DeltaSpace, we propose a novel framework called DeltaEdit, which maps the CLIP visual feature differences to the latent space directions of a generative model during the training phase, and predicts the latent space directions from the CLIP textual feature differences during the inference phase. And this design endows DeltaEdit with two advantages: (1) text-free training; (2) generalization to various text prompts for zero-shot inference. Extensive experiments validate the effectiveness and versatility of DeltaEdit with different generative models, including both the GAN model and the diffusion model, in achieving flexible text-guided image editing. Code is available at https://github.com/Yueming6568/DeltaEdit.",
    "summary": "arXiv:2310.08785v2 Announce Type: replace-cross Abstract: Text-guided image editing faces significant challenges when considering training and inference flexibility. Much literature collects large amounts of annotated image-text pairs to train text-conditioned generative models from scratch, which is expensive and not efficient. After that, some approaches that leverage pre-trained vision-language models have been proposed to avoid data collection, but they are limited by either per text-prompt optimization or inference-time hyper-parameters tuning. To address these issues, we investigate and identify a specific space, referred to as CLIP DeltaSpace, where the CLIP visual feature difference of two images is semantically aligned with the CLIP textual feature difference of their corresponding text descriptions. Based on DeltaSpace, we propose a novel framework called DeltaEdit, which maps the CLIP visual feature differences to the latent space directions of a generative model during the training phase, and predicts the latent space directions from the CLIP textual feature differences during the inference phase. And this design endows DeltaEdit with two advantages: (1) text-free training; (2) generalization to various text prompts for zero-shot inference. Extensive experiments validate the effectiveness and versatility of DeltaEdit with different generative models, including both the GAN model and the diffusion model, in achieving flexible text-guided image editing. Code is available at https://github.com/Yueming6568/DeltaEdit.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2310.08785",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Detecting Machine-Generated Texts: Not Just 'AI vs Humans' and Explainability is Complicated",
    "description": "arXiv:2406.18259v2 Announce Type: replace-cross Abstract: As LLMs rapidly advance, increasing concerns arise regarding risks about actual authorship of texts we see online and in real world. The task of distinguishing LLM-authored texts is complicated by the nuanced and overlapping behaviors of both machines and humans. In this paper, we challenge the current practice of considering LLM-generated text detection a binary classification task of differentiating human from AI. Instead, we introduce a novel ternary text classification scheme, adding an 'undecided' category for texts that could be attributed to either source, and we show that this new category is crucial to understand how to make the detection result more explainable to lay users. This research shifts the paradigm from merely classifying to explaining machine-generated texts, emphasizing need for detectors to provide clear and understandable explanations to users. Our study involves creating four new datasets comprised of texts from various LLMs and human authors. Based on new datasets, we performed binary classification tests to ascertain the most effective SOTA detection methods and identified SOTA LLMs capable of producing harder-to-detect texts. We constructed a new dataset of texts generated by two top-performing LLMs and human authors, and asked three human annotators to produce ternary labels with explanation notes. This dataset was used to investigate how three top-performing SOTA detectors behave in new ternary classification context. Our results highlight why 'undecided' category is much needed from the viewpoint of explainability. Additionally, we conducted an analysis of explainability of the three best-performing detectors and the explanation notes of the human annotators, revealing insights about the complexity of explainable detection of machine-generated texts. Finally, we propose guidelines for developing future detection systems with improved explanatory power.",
    "summary": "arXiv:2406.18259v2 Announce Type: replace-cross Abstract: As LLMs rapidly advance, increasing concerns arise regarding risks about actual authorship of texts we see online and in real world. The task of distinguishing LLM-authored texts is complicated by the nuanced and overlapping behaviors of both machines and humans. In this paper, we challenge the current practice of considering LLM-generated text detection a binary classification task of differentiating human from AI. Instead, we introduce a novel ternary text classification scheme, adding an 'undecided' category for texts that could be attributed to either source, and we show that this new category is crucial to understand how to make the detection result more explainable to lay users. This research shifts the paradigm from merely classifying to explaining machine-generated texts, emphasizing need for detectors to provide clear and understandable explanations to users. Our study involves creating four new datasets comprised of texts from various LLMs and human authors. Based on new datasets, we performed binary classification tests to ascertain the most effective SOTA detection methods and identified SOTA LLMs capable of producing harder-to-detect texts. We constructed a new dataset of texts generated by two top-performing LLMs and human authors, and asked three human annotators to produce ternary labels with explanation notes. This dataset was used to investigate how three top-performing SOTA detectors behave in new ternary classification context. Our results highlight why 'undecided' category is much needed from the viewpoint of explainability. Additionally, we conducted an analysis of explainability of the three best-performing detectors and the explanation notes of the human annotators, revealing insights about the complexity of explainable detection of machine-generated texts. Finally, we propose guidelines for developing future detection systems with improved explanatory power.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2406.18259",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "DF2: Distribution-Free Decision-Focused Learning",
    "description": "arXiv:2308.05889v2 Announce Type: replace-cross Abstract: Decision-focused learning (DFL), which differentiates through the KKT conditions, has recently emerged as a powerful approach for predict-then-optimize problems. However, under probabilistic settings, DFL faces three major bottlenecks: model mismatch error, sample average approximation error, and gradient approximation error. Model mismatch error stems from the misalignment between the model's parameterized predictive distribution and the true probability distribution. Sample average approximation error arises when using finite samples to approximate the expected optimization objective. Gradient approximation error occurs when the objectives are non-convex and KKT conditions cannot be directly applied. In this paper, we present DF2, the first distribution-free decision-focused learning method designed to mitigate these three bottlenecks. Rather than depending on a task-specific forecaster that requires precise model assumptions, our method directly learns the expected optimization function during training. To efficiently learn this function in a data-driven manner, we devise an attention-based model architecture inspired by the distribution-based parameterization of the expected objective. We evaluate DF2 on two synthetic problems and three real-world problems, demonstrating the effectiveness of DF2. Our code is available at: https://github.com/Lingkai-Kong/DF2.",
    "summary": "arXiv:2308.05889v2 Announce Type: replace-cross Abstract: Decision-focused learning (DFL), which differentiates through the KKT conditions, has recently emerged as a powerful approach for predict-then-optimize problems. However, under probabilistic settings, DFL faces three major bottlenecks: model mismatch error, sample average approximation error, and gradient approximation error. Model mismatch error stems from the misalignment between the model's parameterized predictive distribution and the true probability distribution. Sample average approximation error arises when using finite samples to approximate the expected optimization objective. Gradient approximation error occurs when the objectives are non-convex and KKT conditions cannot be directly applied. In this paper, we present DF2, the first distribution-free decision-focused learning method designed to mitigate these three bottlenecks. Rather than depending on a task-specific forecaster that requires precise model assumptions, our method directly learns the expected optimization function during training. To efficiently learn this function in a data-driven manner, we devise an attention-based model architecture inspired by the distribution-based parameterization of the expected objective. We evaluate DF2 on two synthetic problems and three real-world problems, demonstrating the effectiveness of DF2. Our code is available at: https://github.com/Lingkai-Kong/DF2.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2308.05889",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Dialogic Pedagogy for Large Language Models: Aligning Conversational AI with Proven Theories of Learning",
    "description": "arXiv:2506.19484v1 Announce Type: cross Abstract: Large Language Models (LLMs) are rapidly transforming education by enabling rich conversational learning experiences. This article provides a comprehensive review of how LLM-based conversational agents are being used in higher education, with extensions to secondary and lifelong learning contexts. We synthesize existing literature on LLMs in education and theories of conversational and dialogic pedagogy - including Vygotsky's sociocultural learning (scaffolding and the Zone of Proximal Development), the Socratic method, and Laurillard's conversational framework - and examine how prompting strategies and retrieval-augmented generation (RAG) can align LLM behaviors with these pedagogical theories, and how it can support personalized, adaptive learning. We map educational theories to LLM capabilities, highlighting where LLM-driven dialogue supports established learning principles and where it challenges or falls short of traditional pedagogical assumptions. Notable gaps in applying prior theories to LLMs are identified, such as the models tendency to provide direct answers instead of fostering co-construction of knowledge, and the need to account for the constant availability and broad but non-human expertise of LLM tutors. In response, we propose practical strategies to better align LLM interactions with sound pedagogy - for example, designing prompts that encourage Socratic questioning, scaffolded guidance, and student reflection, as well as integrating retrieval mechanisms to ensure accuracy and contextual relevance. Our aim is to bridge the gap between educational theory and the emerging practice of AI-driven conversational learning, offering insights and tools for making LLM-based dialogues more educationally productive and theory-aligned.",
    "summary": "arXiv:2506.19484v1 Announce Type: cross Abstract: Large Language Models (LLMs) are rapidly transforming education by enabling rich conversational learning experiences. This article provides a comprehensive review of how LLM-based conversational agents are being used in higher education, with extensions to secondary and lifelong learning contexts. We synthesize existing literature on LLMs in education and theories of conversational and dialogic pedagogy - including Vygotsky's sociocultural learning (scaffolding and the Zone of Proximal Development), the Socratic method, and Laurillard's conversational framework - and examine how prompting strategies and retrieval-augmented generation (RAG) can align LLM behaviors with these pedagogical theories, and how it can support personalized, adaptive learning. We map educational theories to LLM capabilities, highlighting where LLM-driven dialogue supports established learning principles and where it challenges or falls short of traditional pedagogical assumptions. Notable gaps in applying prior theories to LLMs are identified, such as the models tendency to provide direct answers instead of fostering co-construction of knowledge, and the need to account for the constant availability and broad but non-human expertise of LLM tutors. In response, we propose practical strategies to better align LLM interactions with sound pedagogy - for example, designing prompts that encourage Socratic questioning, scaffolded guidance, and student reflection, as well as integrating retrieval mechanisms to ensure accuracy and contextual relevance. Our aim is to bridge the gap between educational theory and the emerging practice of AI-driven conversational learning, offering insights and tools for making LLM-based dialogues more educationally productive and theory-aligned.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19484",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "DiffRIS: Enhancing Referring Remote Sensing Image Segmentation with Pre-trained Text-to-Image Diffusion Models",
    "description": "arXiv:2506.18946v1 Announce Type: cross Abstract: Referring remote sensing image segmentation (RRSIS) enables the precise delineation of regions within remote sensing imagery through natural language descriptions, serving critical applications in disaster response, urban development, and environmental monitoring. Despite recent advances, current approaches face significant challenges in processing aerial imagery due to complex object characteristics including scale variations, diverse orientations, and semantic ambiguities inherent to the overhead perspective. To address these limitations, we propose DiffRIS, a novel framework that harnesses the semantic understanding capabilities of pre-trained text-to-image diffusion models for enhanced cross-modal alignment in RRSIS tasks. Our framework introduces two key innovations: a context perception adapter (CP-adapter) that dynamically refines linguistic features through global context modeling and object-aware reasoning, and a progressive cross-modal reasoning decoder (PCMRD) that iteratively aligns textual descriptions with visual regions for precise segmentation. The CP-adapter bridges the domain gap between general vision-language understanding and remote sensing applications, while PCMRD enables fine-grained semantic alignment through multi-scale feature interaction. Comprehensive experiments on three benchmark datasets-RRSIS-D, RefSegRS, and RISBench-demonstrate that DiffRIS consistently outperforms existing methods across all standard metrics, establishing a new state-of-the-art for RRSIS tasks. The significant performance improvements validate the effectiveness of leveraging pre-trained diffusion models for remote sensing applications through our proposed adaptive framework.",
    "summary": "arXiv:2506.18946v1 Announce Type: cross Abstract: Referring remote sensing image segmentation (RRSIS) enables the precise delineation of regions within remote sensing imagery through natural language descriptions, serving critical applications in disaster response, urban development, and environmental monitoring. Despite recent advances, current approaches face significant challenges in processing aerial imagery due to complex object characteristics including scale variations, diverse orientations, and semantic ambiguities inherent to the overhead perspective. To address these limitations, we propose DiffRIS, a novel framework that harnesses the semantic understanding capabilities of pre-trained text-to-image diffusion models for enhanced cross-modal alignment in RRSIS tasks. Our framework introduces two key innovations: a context perception adapter (CP-adapter) that dynamically refines linguistic features through global context modeling and object-aware reasoning, and a progressive cross-modal reasoning decoder (PCMRD) that iteratively aligns textual descriptions with visual regions for precise segmentation. The CP-adapter bridges the domain gap between general vision-language understanding and remote sensing applications, while PCMRD enables fine-grained semantic alignment through multi-scale feature interaction. Comprehensive experiments on three benchmark datasets-RRSIS-D, RefSegRS, and RISBench-demonstrate that DiffRIS consistently outperforms existing methods across all standard metrics, establishing a new state-of-the-art for RRSIS tasks. The significant performance improvements validate the effectiveness of leveraging pre-trained diffusion models for remote sensing applications through our proposed adaptive framework.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.18946",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Discrepancy-Aware Graph Mask Auto-Encoder",
    "description": "arXiv:2506.19343v1 Announce Type: cross Abstract: Masked Graph Auto-Encoder, a powerful graph self-supervised training paradigm, has recently shown superior performance in graph representation learning. Existing works typically rely on node contextual information to recover the masked information. However, they fail to generalize well to heterophilic graphs where connected nodes may be not similar, because they focus only on capturing the neighborhood information and ignoring the discrepancy information between different nodes, resulting in indistinguishable node representations. In this paper, to address this issue, we propose a Discrepancy-Aware Graph Mask Auto-Encoder (DGMAE). It obtains more distinguishable node representations by reconstructing the discrepancy information of neighboring nodes during the masking process. We conduct extensive experiments on 17 widely-used benchmark datasets. The results show that our DGMAE can effectively preserve the discrepancies of nodes in low-dimensional space. Moreover, DGMAE significantly outperforms state-of-the-art graph self-supervised learning methods on three graph analytic including tasks node classification, node clustering, and graph classification, demonstrating its remarkable superiority. The code of DGMAE is available at https://github.com/zhengziyu77/DGMAE.",
    "summary": "arXiv:2506.19343v1 Announce Type: cross Abstract: Masked Graph Auto-Encoder, a powerful graph self-supervised training paradigm, has recently shown superior performance in graph representation learning. Existing works typically rely on node contextual information to recover the masked information. However, they fail to generalize well to heterophilic graphs where connected nodes may be not similar, because they focus only on capturing the neighborhood information and ignoring the discrepancy information between different nodes, resulting in indistinguishable node representations. In this paper, to address this issue, we propose a Discrepancy-Aware Graph Mask Auto-Encoder (DGMAE). It obtains more distinguishable node representations by reconstructing the discrepancy information of neighboring nodes during the masking process. We conduct extensive experiments on 17 widely-used benchmark datasets. The results show that our DGMAE can effectively preserve the discrepancies of nodes in low-dimensional space. Moreover, DGMAE significantly outperforms state-of-the-art graph self-supervised learning methods on three graph analytic including tasks node classification, node clustering, and graph classification, demonstrating its remarkable superiority. The code of DGMAE is available at https://github.com/zhengziyu77/DGMAE.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19343",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Disentangling Reasoning and Knowledge in Medical Large Language Models",
    "description": "arXiv:2505.11462v2 Announce Type: replace-cross Abstract: Medical reasoning in large language models (LLMs) aims to emulate clinicians' diagnostic thinking, but current benchmarks such as MedQA-USMLE, MedMCQA, and PubMedQA often mix reasoning with factual recall. We address this by separating 11 biomedical QA benchmarks into reasoning- and knowledge-focused subsets using a PubMedBERT classifier that reaches 81 percent accuracy, comparable to human performance. Our analysis shows that only 32.8 percent of questions require complex reasoning. We evaluate biomedical models (HuatuoGPT-o1, MedReason, m1) and general-domain models (DeepSeek-R1, o4-mini, Qwen3), finding consistent gaps between knowledge and reasoning performance. For example, HuatuoGPT-o1 scores 56.9 on knowledge but only 44.8 on reasoning. In adversarial tests where models are misled with incorrect initial reasoning, biomedical models degrade sharply, while larger or RL-trained general models show more robustness. To address this, we train BioMed-R1 using fine-tuning and reinforcement learning on reasoning-heavy examples. It achieves the strongest performance among similarly sized models. Further gains may come from incorporating clinical case reports and training with adversarial and backtracking scenarios.",
    "summary": "arXiv:2505.11462v2 Announce Type: replace-cross Abstract: Medical reasoning in large language models (LLMs) aims to emulate clinicians' diagnostic thinking, but current benchmarks such as MedQA-USMLE, MedMCQA, and PubMedQA often mix reasoning with factual recall. We address this by separating 11 biomedical QA benchmarks into reasoning- and knowledge-focused subsets using a PubMedBERT classifier that reaches 81 percent accuracy, comparable to human performance. Our analysis shows that only 32.8 percent of questions require complex reasoning. We evaluate biomedical models (HuatuoGPT-o1, MedReason, m1) and general-domain models (DeepSeek-R1, o4-mini, Qwen3), finding consistent gaps between knowledge and reasoning performance. For example, HuatuoGPT-o1 scores 56.9 on knowledge but only 44.8 on reasoning. In adversarial tests where models are misled with incorrect initial reasoning, biomedical models degrade sharply, while larger or RL-trained general models show more robustness. To address this, we train BioMed-R1 using fine-tuning and reinforcement learning on reasoning-heavy examples. It achieves the strongest performance among similarly sized models. Further gains may come from incorporating clinical case reports and training with adversarial and backtracking scenarios.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2505.11462",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Do LLMs Know When to Flip a Coin? Strategic Randomization through Reasoning and Experience",
    "description": "arXiv:2506.18928v1 Announce Type: new Abstract: Strategic randomization is a key principle in game theory, yet it remains underexplored in large language models (LLMs). Prior work often conflates the cognitive decision to randomize with the mechanical generation of randomness, leading to incomplete evaluations. To address this, we propose a novel zero-sum game inspired by the Tian Ji Horse Race, where the Nash equilibrium corresponds to a maximal entropy strategy. The game's complexity masks this property from untrained humans and underdeveloped LLMs. We evaluate five LLMs across prompt styles -- framed, neutral, and hinted -- using competitive multi-tournament gameplay with system-provided random choices, isolating the decision to randomize. Results show that weaker models remain deterministic regardless of prompts, while stronger models exhibit increased randomization under explicit hints. When facing weaker models, strong LLMs adopt deterministic strategies to exploit biases, but converge toward equilibrium play when facing peers. Through win/loss outcomes and Bayes factor analysis, we demonstrate meaningful variation in LLMs' strategic reasoning capabilities, highlighting opportunities for improvement in abstract reasoning and adaptive learning. We make our implementation publicly available at https://github.com/ocelopus/llm-when-to-throw-coin to ensure full reproducibility.",
    "summary": "arXiv:2506.18928v1 Announce Type: new Abstract: Strategic randomization is a key principle in game theory, yet it remains underexplored in large language models (LLMs). Prior work often conflates the cognitive decision to randomize with the mechanical generation of randomness, leading to incomplete evaluations. To address this, we propose a novel zero-sum game inspired by the Tian Ji Horse Race, where the Nash equilibrium corresponds to a maximal entropy strategy. The game's complexity masks this property from untrained humans and underdeveloped LLMs. We evaluate five LLMs across prompt styles -- framed, neutral, and hinted -- using competitive multi-tournament gameplay with system-provided random choices, isolating the decision to randomize. Results show that weaker models remain deterministic regardless of prompts, while stronger models exhibit increased randomization under explicit hints. When facing weaker models, strong LLMs adopt deterministic strategies to exploit biases, but converge toward equilibrium play when facing peers. Through win/loss outcomes and Bayes factor analysis, we demonstrate meaningful variation in LLMs' strategic reasoning capabilities, highlighting opportunities for improvement in abstract reasoning and adaptive learning. We make our implementation publicly available at https://github.com/ocelopus/llm-when-to-throw-coin to ensure full reproducibility.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.18928",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Do Vendi Scores Converge with Finite Samples? Truncated Vendi Score for Finite-Sample Convergence Guarantees",
    "description": "arXiv:2410.21719v3 Announce Type: replace-cross Abstract: Evaluating the diversity of generative models without reference data poses methodological challenges. The reference-free Vendi and RKE scores address this by quantifying the diversity of generated data using matrix-based entropy measures. Among these two, the Vendi score is typically computed via the eigendecomposition of an $n times n$ kernel matrix constructed from n generated samples. However, the prohibitive computational cost of eigendecomposition for large $n$ often limits the number of samples used to fewer than 20,000. In this paper, we investigate the statistical convergence of the Vendi and RKE scores under restricted sample sizes. We numerically demonstrate that, in general, the Vendi score computed with standard sample sizes below 20,000 may not converge to its asymptotic value under infinite sampling. To address this, we introduce the $t$-truncated Vendi score by truncating the eigenspectrum of the kernel matrix, which is provably guaranteed to converge to its population limit with $n=mathcal{O}(t)$ samples. We further show that existing Nystr'om and FKEA approximation methods converge to the asymptotic limit of the truncated Vendi score. In contrast to the Vendi score, we prove that the RKE score enjoys universal convergence guarantees across all kernel functions. We conduct several numerical experiments to illustrate the concentration of Nystr'om and FKEA computed Vendi scores around the truncated Vendi score, and we analyze how the truncated Vendi and RKE scores correlate with the diversity of image and text data. The code is available at https://github.com/aziksh-ospanov/truncated-vendi.",
    "summary": "arXiv:2410.21719v3 Announce Type: replace-cross Abstract: Evaluating the diversity of generative models without reference data poses methodological challenges. The reference-free Vendi and RKE scores address this by quantifying the diversity of generated data using matrix-based entropy measures. Among these two, the Vendi score is typically computed via the eigendecomposition of an $n times n$ kernel matrix constructed from n generated samples. However, the prohibitive computational cost of eigendecomposition for large $n$ often limits the number of samples used to fewer than 20,000. In this paper, we investigate the statistical convergence of the Vendi and RKE scores under restricted sample sizes. We numerically demonstrate that, in general, the Vendi score computed with standard sample sizes below 20,000 may not converge to its asymptotic value under infinite sampling. To address this, we introduce the $t$-truncated Vendi score by truncating the eigenspectrum of the kernel matrix, which is provably guaranteed to converge to its population limit with $n=mathcal{O}(t)$ samples. We further show that existing Nystr'om and FKEA approximation methods converge to the asymptotic limit of the truncated Vendi score. In contrast to the Vendi score, we prove that the RKE score enjoys universal convergence guarantees across all kernel functions. We conduct several numerical experiments to illustrate the concentration of Nystr'om and FKEA computed Vendi scores around the truncated Vendi score, and we analyze how the truncated Vendi and RKE scores correlate with the diversity of image and text data. The code is available at https://github.com/aziksh-ospanov/truncated-vendi.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2410.21719",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "eccDNAMamba: A Pre-Trained Model for Ultra-Long eccDNA Sequence Analysis",
    "description": "arXiv:2506.18940v1 Announce Type: cross Abstract: Extrachromosomal circular DNA (eccDNA) plays key regulatory roles and contributes to oncogene overexpression in cancer through high-copy amplification and long-range interactions. Despite advances in modeling, no pre-trained models currently support full-length circular eccDNA for downstream analysis. Existing genomic models are either limited to single-nucleotide resolution or hindered by the inefficiency of the quadratic attention mechanism. Here, we introduce eccDNAMamba, the first bidirectional state-space encoder tailored for circular DNA sequences. It combines forward and reverse passes for full-context representation learning with linear-time complexity, and preserves circular structure through a novel augmentation strategy. Tested on two real-world datasets, eccDNAMamba achieves strong classification performance and scales to sequences up to 200 Kbp, offering a robust and efficient framework for modeling circular genomes. Our codes are available at https://github.com/zzq1zh/GenAI-Lab.",
    "summary": "arXiv:2506.18940v1 Announce Type: cross Abstract: Extrachromosomal circular DNA (eccDNA) plays key regulatory roles and contributes to oncogene overexpression in cancer through high-copy amplification and long-range interactions. Despite advances in modeling, no pre-trained models currently support full-length circular eccDNA for downstream analysis. Existing genomic models are either limited to single-nucleotide resolution or hindered by the inefficiency of the quadratic attention mechanism. Here, we introduce eccDNAMamba, the first bidirectional state-space encoder tailored for circular DNA sequences. It combines forward and reverse passes for full-context representation learning with linear-time complexity, and preserves circular structure through a novel augmentation strategy. Tested on two real-world datasets, eccDNAMamba achieves strong classification performance and scales to sequences up to 200 Kbp, offering a robust and efficient framework for modeling circular genomes. Our codes are available at https://github.com/zzq1zh/GenAI-Lab.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.18940",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "ECCoT: A Framework for Enhancing Effective Cognition via Chain of Thought in Large Language Model",
    "description": "arXiv:2506.19599v1 Announce Type: cross Abstract: In the era of large-scale artificial intelligence, Large Language Models (LLMs) have made significant strides in natural language processing. However, they often lack transparency and generate unreliable outputs, raising concerns about their interpretability. To address this, the Chain of Thought (CoT) prompting method structures reasoning into step-by-step deductions. Yet, not all reasoning chains are valid, and errors can lead to unreliable conclusions. We propose ECCoT, an End-to-End Cognitive Chain of Thought Validation Framework, to evaluate and refine reasoning chains in LLMs. ECCoT integrates the Markov Random Field-Embedded Topic Model (MRF-ETM) for topic-aware CoT generation and Causal Sentence-BERT (CSBert) for causal reasoning alignment. By filtering ineffective chains using structured ordering statistics, ECCoT improves interpretability, reduces biases, and enhances the trustworthiness of LLM-based decision-making. Key contributions include the introduction of ECCoT, MRF-ETM for topic-driven CoT generation, and CSBert for causal reasoning enhancement. Code is released at: https://github.com/erwinmsmith/ECCoT.git.",
    "summary": "arXiv:2506.19599v1 Announce Type: cross Abstract: In the era of large-scale artificial intelligence, Large Language Models (LLMs) have made significant strides in natural language processing. However, they often lack transparency and generate unreliable outputs, raising concerns about their interpretability. To address this, the Chain of Thought (CoT) prompting method structures reasoning into step-by-step deductions. Yet, not all reasoning chains are valid, and errors can lead to unreliable conclusions. We propose ECCoT, an End-to-End Cognitive Chain of Thought Validation Framework, to evaluate and refine reasoning chains in LLMs. ECCoT integrates the Markov Random Field-Embedded Topic Model (MRF-ETM) for topic-aware CoT generation and Causal Sentence-BERT (CSBert) for causal reasoning alignment. By filtering ineffective chains using structured ordering statistics, ECCoT improves interpretability, reduces biases, and enhances the trustworthiness of LLM-based decision-making. Key contributions include the introduction of ECCoT, MRF-ETM for topic-driven CoT generation, and CSBert for causal reasoning enhancement. Code is released at: https://github.com/erwinmsmith/ECCoT.git.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19599",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "ECG-SMART-NET: A Deep Learning Architecture for Precise ECG Diagnosis of Occlusion Myocardial Infarction",
    "description": "arXiv:2405.09567v2 Announce Type: replace-cross Abstract: Objective: In this paper we develop and evaluate ECG-SMART-NET for occlusion myocardial infarction (OMI) identification. OMI is a severe form of heart attack characterized by complete blockage of one or more coronary arteries requiring immediate referral for cardiac catheterization to restore blood flow to the heart. Two thirds of OMI cases are difficult to visually identify from a 12-lead electrocardiogram (ECG) and can be potentially fatal if not identified quickly. Previous works on this topic are scarce, and current state-of-the-art evidence suggests both feature-based random forests and convolutional neural networks (CNNs) are promising approaches to improve ECG detection of OMI. Methods: While the ResNet architecture has been adapted for use with ECG recordings, it is not ideally suited to capture informative temporal features within each lead and the spatial concordance or discordance across leads. We propose a clinically informed modification of the ResNet-18 architecture. The model first learns temporal features through temporal convolutional layers with 1xk kernels followed by a spatial convolutional layer, after the residual blocks, with 12x1 kernels to learn spatial features. Results: ECG-SMART-NET was benchmarked against the original ResNet-18 and other state-of-the-art models on a multisite real-word clinical dataset that consists of 10,393 ECGs from 7,397 unique patients (rate of OMI =7.2%). ECG-SMART-NET outperformed other models in the classification of OMI with a test AUC of 0.953 [0.921, 0.978]. Conclusion and Significance: ECG-SMART-NET can outperform the state-of-the-art random forest for OMI prediction and is better suited for this task than the original ResNet-18 architecture.",
    "summary": "arXiv:2405.09567v2 Announce Type: replace-cross Abstract: Objective: In this paper we develop and evaluate ECG-SMART-NET for occlusion myocardial infarction (OMI) identification. OMI is a severe form of heart attack characterized by complete blockage of one or more coronary arteries requiring immediate referral for cardiac catheterization to restore blood flow to the heart. Two thirds of OMI cases are difficult to visually identify from a 12-lead electrocardiogram (ECG) and can be potentially fatal if not identified quickly. Previous works on this topic are scarce, and current state-of-the-art evidence suggests both feature-based random forests and convolutional neural networks (CNNs) are promising approaches to improve ECG detection of OMI. Methods: While the ResNet architecture has been adapted for use with ECG recordings, it is not ideally suited to capture informative temporal features within each lead and the spatial concordance or discordance across leads. We propose a clinically informed modification of the ResNet-18 architecture. The model first learns temporal features through temporal convolutional layers with 1xk kernels followed by a spatial convolutional layer, after the residual blocks, with 12x1 kernels to learn spatial features. Results: ECG-SMART-NET was benchmarked against the original ResNet-18 and other state-of-the-art models on a multisite real-word clinical dataset that consists of 10,393 ECGs from 7,397 unique patients (rate of OMI =7.2%). ECG-SMART-NET outperformed other models in the classification of OMI with a test AUC of 0.953 [0.921, 0.978]. Conclusion and Significance: ECG-SMART-NET can outperform the state-of-the-art random forest for OMI prediction and is better suited for this task than the original ResNet-18 architecture.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2405.09567",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Emergent Risk Awareness in Rational Agents under Resource Constraints",
    "description": "arXiv:2505.23436v3 Announce Type: replace Abstract: Advanced reasoning models with agentic capabilities (AI agents) are deployed to interact with humans and to solve sequential decision-making problems under (approximate) utility functions and internal models. When such problems have resource or failure constraints where action sequences may be forcibly terminated once resources are exhausted, agents face implicit trade-offs that reshape their utility-driven (rational) behaviour. Additionally, since these agents are typically commissioned by a human principal to act on their behalf, asymmetries in constraint exposure can give rise to previously unanticipated misalignment between human objectives and agent incentives. We formalise this setting through a survival bandit framework, provide theoretical and empirical results that quantify the impact of survival-driven preference shifts, identify conditions under which misalignment emerges and propose mechanisms to mitigate the emergence of risk-seeking or risk-averse behaviours. As a result, this work aims to increase understanding and interpretability of emergent behaviours of AI agents operating under such survival pressure, and offer guidelines for safely deploying such AI systems in critical resource-limited environments.",
    "summary": "arXiv:2505.23436v3 Announce Type: replace Abstract: Advanced reasoning models with agentic capabilities (AI agents) are deployed to interact with humans and to solve sequential decision-making problems under (approximate) utility functions and internal models. When such problems have resource or failure constraints where action sequences may be forcibly terminated once resources are exhausted, agents face implicit trade-offs that reshape their utility-driven (rational) behaviour. Additionally, since these agents are typically commissioned by a human principal to act on their behalf, asymmetries in constraint exposure can give rise to previously unanticipated misalignment between human objectives and agent incentives. We formalise this setting through a survival bandit framework, provide theoretical and empirical results that quantify the impact of survival-driven preference shifts, identify conditions under which misalignment emerges and propose mechanisms to mitigate the emergence of risk-seeking or risk-averse behaviours. As a result, this work aims to increase understanding and interpretability of emergent behaviours of AI agents operating under such survival pressure, and offer guidelines for safely deploying such AI systems in critical resource-limited environments.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2505.23436",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "EmoStage: A Framework for Accurate Empathetic Response Generation via Perspective-Taking and Phase Recognition",
    "description": "arXiv:2506.19279v1 Announce Type: cross Abstract: The rising demand for mental health care has fueled interest in AI-driven counseling systems. While large language models (LLMs) offer significant potential, current approaches face challenges, including limited understanding of clients' psychological states and counseling stages, reliance on high-quality training data, and privacy concerns associated with commercial deployment. To address these issues, we propose EmoStage, a framework that enhances empathetic response generation by leveraging the inference capabilities of open-source LLMs without additional training data. Our framework introduces perspective-taking to infer clients' psychological states and support needs, enabling the generation of emotionally resonant responses. In addition, phase recognition is incorporated to ensure alignment with the counseling process and to prevent contextually inappropriate or inopportune responses. Experiments conducted in both Japanese and Chinese counseling settings demonstrate that EmoStage improves the quality of responses generated by base models and performs competitively with data-driven methods.",
    "summary": "arXiv:2506.19279v1 Announce Type: cross Abstract: The rising demand for mental health care has fueled interest in AI-driven counseling systems. While large language models (LLMs) offer significant potential, current approaches face challenges, including limited understanding of clients' psychological states and counseling stages, reliance on high-quality training data, and privacy concerns associated with commercial deployment. To address these issues, we propose EmoStage, a framework that enhances empathetic response generation by leveraging the inference capabilities of open-source LLMs without additional training data. Our framework introduces perspective-taking to infer clients' psychological states and support needs, enabling the generation of emotionally resonant responses. In addition, phase recognition is incorporated to ensure alignment with the counseling process and to prevent contextually inappropriate or inopportune responses. Experiments conducted in both Japanese and Chinese counseling settings demonstrate that EmoStage improves the quality of responses generated by base models and performs competitively with data-driven methods.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19279",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Emotion Detection on User Front-Facing App Interfaces for Enhanced Schedule Optimization: A Machine Learning Approach",
    "description": "arXiv:2506.19280v1 Announce Type: new Abstract: Human-Computer Interaction (HCI) has evolved significantly to incorporate emotion recognition capabilities, creating unprecedented opportunities for adaptive and personalized user experiences. This paper explores the integration of emotion detection into calendar applications, enabling user interfaces to dynamically respond to users' emotional states and stress levels, thereby enhancing both productivity and engagement. We present and evaluate two complementary approaches to emotion detection: a biometric-based method utilizing heart rate (HR) data extracted from electrocardiogram (ECG) signals processed through Long Short-Term Memory (LSTM) and Gated Recurrent Unit (GRU) neural networks to predict the emotional dimensions of Valence, Arousal, and Dominance; and a behavioral method analyzing computer activity through multiple machine learning models to classify emotions based on fine-grained user interactions such as mouse movements, clicks, and keystroke patterns. Our comparative analysis, from real-world datasets, reveals that while both approaches demonstrate effectiveness, the computer activity-based method delivers superior consistency and accuracy, particularly for mouse-related interactions, which achieved approximately 90% accuracy. Furthermore, GRU networks outperformed LSTM models in the biometric approach, with Valence prediction reaching 84.38% accuracy.",
    "summary": "arXiv:2506.19280v1 Announce Type: new Abstract: Human-Computer Interaction (HCI) has evolved significantly to incorporate emotion recognition capabilities, creating unprecedented opportunities for adaptive and personalized user experiences. This paper explores the integration of emotion detection into calendar applications, enabling user interfaces to dynamically respond to users' emotional states and stress levels, thereby enhancing both productivity and engagement. We present and evaluate two complementary approaches to emotion detection: a biometric-based method utilizing heart rate (HR) data extracted from electrocardiogram (ECG) signals processed through Long Short-Term Memory (LSTM) and Gated Recurrent Unit (GRU) neural networks to predict the emotional dimensions of Valence, Arousal, and Dominance; and a behavioral method analyzing computer activity through multiple machine learning models to classify emotions based on fine-grained user interactions such as mouse movements, clicks, and keystroke patterns. Our comparative analysis, from real-world datasets, reveals that while both approaches demonstrate effectiveness, the computer activity-based method delivers superior consistency and accuracy, particularly for mouse-related interactions, which achieved approximately 90% accuracy. Furthermore, GRU networks outperformed LSTM models in the biometric approach, with Valence prediction reaching 84.38% accuracy.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19280",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Enhancing Generalization of Spiking Neural Networks Through Temporal Regularization",
    "description": "arXiv:2506.19256v1 Announce Type: cross Abstract: Spiking Neural Networks (SNNs) have received widespread attention due to their event-driven and low-power characteristics, making them particularly effective for processing event-based neuromorphic data. Recent studies have shown that directly trained SNNs suffer from severe overfitting issues due to the limited scale of neuromorphic datasets and the gradient mismatching problem, which fundamentally constrain their generalization performance. In this paper, we propose a temporal regularization training (TRT) method by introducing a time-dependent regularization mechanism to enforce stronger constraints on early timesteps. We compare the performance of TRT with other state-of-the-art methods performance on datasets including CIFAR10/100, ImageNet100, DVS-CIFAR10, and N-Caltech101. To validate the effectiveness of TRT, we conducted ablation studies and analyses including loss landscape visualization and learning curve analysis, demonstrating that TRT can effectively mitigate overfitting and flatten the training loss landscape, thereby enhancing generalizability. Furthermore, we establish a theoretical interpretation of TRT's temporal regularization mechanism based on the results of Fisher information analysis. We analyze the temporal information dynamics inside SNNs by tracking Fisher information during the TRT training process, revealing the Temporal Information Concentration (TIC) phenomenon, where Fisher information progressively concentrates in early timesteps. The time-decaying regularization mechanism implemented in TRT effectively guides the network to learn robust features in early timesteps with rich information, thereby leading to significant improvements in model generalization. Code is available at https://github.com/ZBX05/Temporal-Regularization-Training.",
    "summary": "arXiv:2506.19256v1 Announce Type: cross Abstract: Spiking Neural Networks (SNNs) have received widespread attention due to their event-driven and low-power characteristics, making them particularly effective for processing event-based neuromorphic data. Recent studies have shown that directly trained SNNs suffer from severe overfitting issues due to the limited scale of neuromorphic datasets and the gradient mismatching problem, which fundamentally constrain their generalization performance. In this paper, we propose a temporal regularization training (TRT) method by introducing a time-dependent regularization mechanism to enforce stronger constraints on early timesteps. We compare the performance of TRT with other state-of-the-art methods performance on datasets including CIFAR10/100, ImageNet100, DVS-CIFAR10, and N-Caltech101. To validate the effectiveness of TRT, we conducted ablation studies and analyses including loss landscape visualization and learning curve analysis, demonstrating that TRT can effectively mitigate overfitting and flatten the training loss landscape, thereby enhancing generalizability. Furthermore, we establish a theoretical interpretation of TRT's temporal regularization mechanism based on the results of Fisher information analysis. We analyze the temporal information dynamics inside SNNs by tracking Fisher information during the TRT training process, revealing the Temporal Information Concentration (TIC) phenomenon, where Fisher information progressively concentrates in early timesteps. The time-decaying regularization mechanism implemented in TRT effectively guides the network to learn robust features in early timesteps with rich information, thereby leading to significant improvements in model generalization. Code is available at https://github.com/ZBX05/Temporal-Regularization-Training.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19256",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Enhancing Security in LLM Applications: A Performance Evaluation of Early Detection Systems",
    "description": "arXiv:2506.19109v1 Announce Type: cross Abstract: Prompt injection threatens novel applications that emerge from adapting LLMs for various user tasks. The newly developed LLM-based software applications become more ubiquitous and diverse. However, the threat of prompt injection attacks undermines the security of these systems as the mitigation and defenses against them, proposed so far, are insufficient. We investigated the capabilities of early prompt injection detection systems, focusing specifically on the detection performance of techniques implemented in various open-source solutions. These solutions are supposed to detect certain types of prompt injection attacks, including the prompt leak. In prompt leakage attacks, an attacker maliciously manipulates the LLM into outputting its system instructions, violating the system's confidentiality. Our study presents analyzes of distinct prompt leakage detection techniques, and a comparative analysis of several detection solutions, which implement those techniques. We identify the strengths and weaknesses of these techniques and elaborate on their optimal configuration and usage in high-stake deployments. In one of the first studies on existing prompt leak detection solutions, we compared the performances of LLM Guard, Vigil, and Rebuff. We concluded that the implementations of canary word checks in Vigil and Rebuff were not effective at detecting prompt leak attacks, and we proposed improvements for them. We also found an evasion weakness in Rebuff's secondary model-based technique and proposed a mitigation. Then, the result of the comparison of LLM Guard, Vigil, and Rebuff at their peak performance revealed that Vigil is optimal for cases when minimal false positive rate is required, and Rebuff is the most optimal for average needs.",
    "summary": "arXiv:2506.19109v1 Announce Type: cross Abstract: Prompt injection threatens novel applications that emerge from adapting LLMs for various user tasks. The newly developed LLM-based software applications become more ubiquitous and diverse. However, the threat of prompt injection attacks undermines the security of these systems as the mitigation and defenses against them, proposed so far, are insufficient. We investigated the capabilities of early prompt injection detection systems, focusing specifically on the detection performance of techniques implemented in various open-source solutions. These solutions are supposed to detect certain types of prompt injection attacks, including the prompt leak. In prompt leakage attacks, an attacker maliciously manipulates the LLM into outputting its system instructions, violating the system's confidentiality. Our study presents analyzes of distinct prompt leakage detection techniques, and a comparative analysis of several detection solutions, which implement those techniques. We identify the strengths and weaknesses of these techniques and elaborate on their optimal configuration and usage in high-stake deployments. In one of the first studies on existing prompt leak detection solutions, we compared the performances of LLM Guard, Vigil, and Rebuff. We concluded that the implementations of canary word checks in Vigil and Rebuff were not effective at detecting prompt leak attacks, and we proposed improvements for them. We also found an evasion weakness in Rebuff's secondary model-based technique and proposed a mitigation. Then, the result of the comparison of LLM Guard, Vigil, and Rebuff at their peak performance revealed that Vigil is optimal for cases when minimal false positive rate is required, and Rebuff is the most optimal for average needs.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19109",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Evaluating Compliance with Visualization Guidelines in Diagrams for Scientific Publications Using Large Vision Language Models",
    "description": "arXiv:2506.19825v1 Announce Type: new Abstract: Diagrams are widely used to visualize data in publications. The research field of data visualization deals with defining principles and guidelines for the creation and use of these diagrams, which are often not known or adhered to by researchers, leading to misinformation caused by providing inaccurate or incomplete information. In this work, large Vision Language Models (VLMs) are used to analyze diagrams in order to identify potential problems in regards to selected data visualization principles and guidelines. To determine the suitability of VLMs for these tasks, five open source VLMs and five prompting strategies are compared using a set of questions derived from selected data visualization guidelines. The results show that the employed VLMs work well to accurately analyze diagram types (F1-score 82.49 %), 3D effects (F1-score 98.55 %), axes labels (F1-score 76.74 %), lines (RMSE 1.16), colors (RMSE 1.60) and legends (F1-score 96.64 %, RMSE 0.70), while they cannot reliably provide feedback about the image quality (F1-score 0.74 %) and tick marks/labels (F1-score 46.13 %). Among the employed VLMs, Qwen2.5VL performs best, and the summarizing prompting strategy performs best for most of the experimental questions. It is shown that VLMs can be used to automatically identify a number of potential issues in diagrams, such as missing axes labels, missing legends, and unnecessary 3D effects. The approach laid out in this work can be extended for further aspects of data visualization.",
    "summary": "arXiv:2506.19825v1 Announce Type: new Abstract: Diagrams are widely used to visualize data in publications. The research field of data visualization deals with defining principles and guidelines for the creation and use of these diagrams, which are often not known or adhered to by researchers, leading to misinformation caused by providing inaccurate or incomplete information. In this work, large Vision Language Models (VLMs) are used to analyze diagrams in order to identify potential problems in regards to selected data visualization principles and guidelines. To determine the suitability of VLMs for these tasks, five open source VLMs and five prompting strategies are compared using a set of questions derived from selected data visualization guidelines. The results show that the employed VLMs work well to accurately analyze diagram types (F1-score 82.49 %), 3D effects (F1-score 98.55 %), axes labels (F1-score 76.74 %), lines (RMSE 1.16), colors (RMSE 1.60) and legends (F1-score 96.64 %, RMSE 0.70), while they cannot reliably provide feedback about the image quality (F1-score 0.74 %) and tick marks/labels (F1-score 46.13 %). Among the employed VLMs, Qwen2.5VL performs best, and the summarizing prompting strategy performs best for most of the experimental questions. It is shown that VLMs can be used to automatically identify a number of potential issues in diagrams, such as missing axes labels, missing legends, and unnecessary 3D effects. The approach laid out in this work can be extended for further aspects of data visualization.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19825",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Evaluating link prediction: New perspectives and recommendations",
    "description": "arXiv:2502.12777v3 Announce Type: replace-cross Abstract: Link prediction (LP) is an important problem in network science and machine learning research. The state-of-the-art LP methods are usually evaluated in a uniform setup, ignoring several factors associated with the data and application specific needs. We identify a number of such factors, such as, network-type, problem-type, geodesic distance between the end nodes and its distribution over the classes, nature and applicability of LP methods, class imbalance and its impact on early retrieval, evaluation metric, etc., and present an experimental setup which allows us to evaluate LP methods in a rigorous and controlled manner. We perform extensive experiments with a variety of LP methods over real network datasets in this controlled setup, and gather valuable insights on the interactions of these factors with the performance of LP through an array of carefully designed hypotheses. Following the insights, we provide recommendations to be followed as best practice for evaluating LP methods.",
    "summary": "arXiv:2502.12777v3 Announce Type: replace-cross Abstract: Link prediction (LP) is an important problem in network science and machine learning research. The state-of-the-art LP methods are usually evaluated in a uniform setup, ignoring several factors associated with the data and application specific needs. We identify a number of such factors, such as, network-type, problem-type, geodesic distance between the end nodes and its distribution over the classes, nature and applicability of LP methods, class imbalance and its impact on early retrieval, evaluation metric, etc., and present an experimental setup which allows us to evaluate LP methods in a rigorous and controlled manner. We perform extensive experiments with a variety of LP methods over real network datasets in this controlled setup, and gather valuable insights on the interactions of these factors with the performance of LP through an array of carefully designed hypotheses. Following the insights, we provide recommendations to be followed as best practice for evaluating LP methods.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2502.12777",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Evaluating Transparent Reasoning in Large Language Models for Accountable Critical Tasks",
    "description": "arXiv:2408.01933v5 Announce Type: replace-cross Abstract: This paper introduces REACT, a benchmark designed to rigorously evaluate the reasoning capabilities of large language models (LLMs) within accountable, high-stakes decision-making tasks in medical and legal domains. Unlike traditional benchmarks primarily focused on prediction accuracy, REACT emphasizes transparent and interpretable reasoning, requiring models to align their logic closely with expert-derived procedures. To assess whether LLM reasoning aligns closely with human experts, we annotated 511 clinical cases from the medical domain and 86 legal cases from the legal domain, each enriched with detailed expert-extracted rationales and evidence supporting each step of the reasoning process. These annotations were guided by carefully constructed reasoning graphs, which explicitly encode domain-specific inference structures and decision criteria derived by domain experts. These reasoning graphs serve not only as standards for expert annotation but also as structured guidelines enabling models to reason transparently and step-by-step. To address the scalability challenges of manual annotation, we further developed a semi-automatic annotation pipeline leveraging expert-defined reasoning graph templates to efficiently generate new graphs, exploring the potential to extend our approach into additional critical domains. Experimental results demonstrate that reasoning graphs substantially enhance the interpretability and accuracy of LLM reasoning compared to traditional baselines, although significant gaps remain relative to expert-level reasoning performance.",
    "summary": "arXiv:2408.01933v5 Announce Type: replace-cross Abstract: This paper introduces REACT, a benchmark designed to rigorously evaluate the reasoning capabilities of large language models (LLMs) within accountable, high-stakes decision-making tasks in medical and legal domains. Unlike traditional benchmarks primarily focused on prediction accuracy, REACT emphasizes transparent and interpretable reasoning, requiring models to align their logic closely with expert-derived procedures. To assess whether LLM reasoning aligns closely with human experts, we annotated 511 clinical cases from the medical domain and 86 legal cases from the legal domain, each enriched with detailed expert-extracted rationales and evidence supporting each step of the reasoning process. These annotations were guided by carefully constructed reasoning graphs, which explicitly encode domain-specific inference structures and decision criteria derived by domain experts. These reasoning graphs serve not only as standards for expert annotation but also as structured guidelines enabling models to reason transparently and step-by-step. To address the scalability challenges of manual annotation, we further developed a semi-automatic annotation pipeline leveraging expert-defined reasoning graph templates to efficiently generate new graphs, exploring the potential to extend our approach into additional critical domains. Experimental results demonstrate that reasoning graphs substantially enhance the interpretability and accuracy of LLM reasoning compared to traditional baselines, although significant gaps remain relative to expert-level reasoning performance.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2408.01933",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Evolutionary Level Repair",
    "description": "arXiv:2506.19359v1 Announce Type: new Abstract: We address the problem of game level repair, which consists of taking a designed but non-functional game level and making it functional. This might consist of ensuring the completeness of the level, reachability of objects, or other performance characteristics. The repair problem may also be constrained in that it can only make a small number of changes to the level. We investigate search-based solutions to the level repair problem, particularly using evolutionary and quality-diversity algorithms, with good results. This level repair method is applied to levels generated using a machine learning-based procedural content generation (PCGML) method that generates stylistically appropriate but frequently broken levels. This combination of PCGML for generation and search-based methods for repair shows great promise as a hybrid procedural content generation (PCG) method.",
    "summary": "arXiv:2506.19359v1 Announce Type: new Abstract: We address the problem of game level repair, which consists of taking a designed but non-functional game level and making it functional. This might consist of ensuring the completeness of the level, reachability of objects, or other performance characteristics. The repair problem may also be constrained in that it can only make a small number of changes to the level. We investigate search-based solutions to the level repair problem, particularly using evolutionary and quality-diversity algorithms, with good results. This level repair method is applied to levels generated using a machine learning-based procedural content generation (PCGML) method that generates stylistically appropriate but frequently broken levels. This combination of PCGML for generation and search-based methods for repair shows great promise as a hybrid procedural content generation (PCG) method.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19359",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Exclusive Style Removal for Cross Domain Novel Class Discovery",
    "description": "arXiv:2406.18140v4 Announce Type: replace-cross Abstract: As a promising field in open-world learning, textit{Novel Class Discovery} (NCD) is usually a task to cluster unseen novel classes in an unlabeled set based on the prior knowledge of labeled data within the same domain. However, the performance of existing NCD methods could be severely compromised when novel classes are sampled from a different distribution with the labeled ones. In this paper, we explore and establish the solvability of NCD with cross domain setting under the necessary condition that the style information needs to be removed. Based on the theoretical analysis, we introduce an exclusive style removal module for extracting style information that is distinctive from the baseline features, thereby facilitating inference. Moreover, this module is easy to integrate with other NCD methods, acting as a plug-in to improve performance on novel classes with different distributions compared to the labeled set. Additionally, recognizing the non-negligible influence of different backbones and pre-training strategies on the performance of the NCD methods, we build a fair benchmark for future NCD research. Extensive experiments on three common datasets demonstrate the effectiveness of our proposed style removal strategy.",
    "summary": "arXiv:2406.18140v4 Announce Type: replace-cross Abstract: As a promising field in open-world learning, textit{Novel Class Discovery} (NCD) is usually a task to cluster unseen novel classes in an unlabeled set based on the prior knowledge of labeled data within the same domain. However, the performance of existing NCD methods could be severely compromised when novel classes are sampled from a different distribution with the labeled ones. In this paper, we explore and establish the solvability of NCD with cross domain setting under the necessary condition that the style information needs to be removed. Based on the theoretical analysis, we introduce an exclusive style removal module for extracting style information that is distinctive from the baseline features, thereby facilitating inference. Moreover, this module is easy to integrate with other NCD methods, acting as a plug-in to improve performance on novel classes with different distributions compared to the labeled set. Additionally, recognizing the non-negligible influence of different backbones and pre-training strategies on the performance of the NCD methods, we build a fair benchmark for future NCD research. Extensive experiments on three common datasets demonstrate the effectiveness of our proposed style removal strategy.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2406.18140",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Experimental Assessment of Neural 3D Reconstruction for Small UAV-based Applications",
    "description": "arXiv:2506.19491v1 Announce Type: cross Abstract: The increasing miniaturization of Unmanned Aerial Vehicles (UAVs) has expanded their deployment potential to indoor and hard-to-reach areas. However, this trend introduces distinct challenges, particularly in terms of flight dynamics and power consumption, which limit the UAVs' autonomy and mission capabilities. This paper presents a novel approach to overcoming these limitations by integrating Neural 3D Reconstruction (N3DR) with small UAV systems for fine-grained 3-Dimensional (3D) digital reconstruction of small static objects. Specifically, we design, implement, and evaluate an N3DR-based pipeline that leverages advanced models, i.e., Instant-ngp, Nerfacto, and Splatfacto, to improve the quality of 3D reconstructions using images of the object captured by a fleet of small UAVs. We assess the performance of the considered models using various imagery and pointcloud metrics, comparing them against the baseline Structure from Motion (SfM) algorithm. The experimental results demonstrate that the N3DR-enhanced pipeline significantly improves reconstruction quality, making it feasible for small UAVs to support high-precision 3D mapping and anomaly detection in constrained environments. In more general terms, our results highlight the potential of N3DR in advancing the capabilities of miniaturized UAV systems.",
    "summary": "arXiv:2506.19491v1 Announce Type: cross Abstract: The increasing miniaturization of Unmanned Aerial Vehicles (UAVs) has expanded their deployment potential to indoor and hard-to-reach areas. However, this trend introduces distinct challenges, particularly in terms of flight dynamics and power consumption, which limit the UAVs' autonomy and mission capabilities. This paper presents a novel approach to overcoming these limitations by integrating Neural 3D Reconstruction (N3DR) with small UAV systems for fine-grained 3-Dimensional (3D) digital reconstruction of small static objects. Specifically, we design, implement, and evaluate an N3DR-based pipeline that leverages advanced models, i.e., Instant-ngp, Nerfacto, and Splatfacto, to improve the quality of 3D reconstructions using images of the object captured by a fleet of small UAVs. We assess the performance of the considered models using various imagery and pointcloud metrics, comparing them against the baseline Structure from Motion (SfM) algorithm. The experimental results demonstrate that the N3DR-enhanced pipeline significantly improves reconstruction quality, making it feasible for small UAVs to support high-precision 3D mapping and anomaly detection in constrained environments. In more general terms, our results highlight the potential of N3DR in advancing the capabilities of miniaturized UAV systems.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19491",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Exploring the Collaborative Co-Creation Process with AI: A Case Study in Novice Music Production",
    "description": "arXiv:2501.15276v2 Announce Type: replace-cross Abstract: Artificial intelligence is reshaping creative domains, yet its co-creative processes, especially in group settings with novice users, remain under explored. To bridge this gap, we conducted a case study in a college-level course where nine undergraduate students were tasked with creating three original music tracks using AI tools over 10 weeks. The study spanned the entire creative journey from ideation to releasing these songs on Spotify. Participants leveraged AI for music and lyric production, cover art, and distribution. Our findings highlight how AI transforms creative workflows: accelerating ideation but compressing the traditional preparation stage, and requiring novices to navigate a challenging idea selection and validation phase. We also identified a new 'collaging and refinement' stage, where participants creatively combined diverse AI-generated outputs into cohesive works. Furthermore, AI influenced group social dynamics and role division among human creators. Based on these insights, we propose the Human-AI Co-Creation Stage Model and the Human-AI Agency Model, offering new perspectives on collaborative co-creation with AI.",
    "summary": "arXiv:2501.15276v2 Announce Type: replace-cross Abstract: Artificial intelligence is reshaping creative domains, yet its co-creative processes, especially in group settings with novice users, remain under explored. To bridge this gap, we conducted a case study in a college-level course where nine undergraduate students were tasked with creating three original music tracks using AI tools over 10 weeks. The study spanned the entire creative journey from ideation to releasing these songs on Spotify. Participants leveraged AI for music and lyric production, cover art, and distribution. Our findings highlight how AI transforms creative workflows: accelerating ideation but compressing the traditional preparation stage, and requiring novices to navigate a challenging idea selection and validation phase. We also identified a new 'collaging and refinement' stage, where participants creatively combined diverse AI-generated outputs into cohesive works. Furthermore, AI influenced group social dynamics and role division among human creators. Based on these insights, we propose the Human-AI Co-Creation Stage Model and the Human-AI Agency Model, offering new perspectives on collaborative co-creation with AI.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2501.15276",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "FAF: A Feature-Adaptive Framework for Few-Shot Time Series Forecasting",
    "description": "arXiv:2506.19567v1 Announce Type: cross Abstract: Multi-task and few-shot time series forecasting tasks are commonly encountered in scenarios such as the launch of new products in different cities. However, traditional time series forecasting methods suffer from insufficient historical data, which stems from a disregard for the generalized and specific features among different tasks. For the aforementioned challenges, we propose the Feature-Adaptive Time Series Forecasting Framework (FAF), which consists of three key components: the Generalized Knowledge Module (GKM), the Task-Specific Module (TSM), and the Rank Module (RM). During training phase, the GKM is updated through a meta-learning mechanism that enables the model to extract generalized features across related tasks. Meanwhile, the TSM is trained to capture diverse local dynamics through multiple functional regions, each of which learns specific features from individual tasks. During testing phase, the RM dynamically selects the most relevant functional region from the TSM based on input sequence features, which is then combined with the generalized knowledge learned by the GKM to generate accurate forecasts. This design enables FAF to achieve robust and personalized forecasting even with sparse historical observations We evaluate FAF on five diverse real-world datasets under few-shot time series forecasting settings. Experimental results demonstrate that FAF consistently outperforms baselines that include three categories of time series forecasting methods. In particular, FAF achieves a 41.81% improvement over the best baseline, iTransformer, on the CO$_2$ emissions dataset.",
    "summary": "arXiv:2506.19567v1 Announce Type: cross Abstract: Multi-task and few-shot time series forecasting tasks are commonly encountered in scenarios such as the launch of new products in different cities. However, traditional time series forecasting methods suffer from insufficient historical data, which stems from a disregard for the generalized and specific features among different tasks. For the aforementioned challenges, we propose the Feature-Adaptive Time Series Forecasting Framework (FAF), which consists of three key components: the Generalized Knowledge Module (GKM), the Task-Specific Module (TSM), and the Rank Module (RM). During training phase, the GKM is updated through a meta-learning mechanism that enables the model to extract generalized features across related tasks. Meanwhile, the TSM is trained to capture diverse local dynamics through multiple functional regions, each of which learns specific features from individual tasks. During testing phase, the RM dynamically selects the most relevant functional region from the TSM based on input sequence features, which is then combined with the generalized knowledge learned by the GKM to generate accurate forecasts. This design enables FAF to achieve robust and personalized forecasting even with sparse historical observations We evaluate FAF on five diverse real-world datasets under few-shot time series forecasting settings. Experimental results demonstrate that FAF consistently outperforms baselines that include three categories of time series forecasting methods. In particular, FAF achieves a 41.81% improvement over the best baseline, iTransformer, on the CO$_2$ emissions dataset.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19567",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "FairCauseSyn: Towards Causally Fair LLM-Augmented Synthetic Data Generation",
    "description": "arXiv:2506.19082v1 Announce Type: cross Abstract: Synthetic data generation creates data based on real-world data using generative models. In health applications, generating high-quality data while maintaining fairness for sensitive attributes is essential for equitable outcomes. Existing GAN-based and LLM-based methods focus on counterfactual fairness and are primarily applied in finance and legal domains. Causal fairness provides a more comprehensive evaluation framework by preserving causal structure, but current synthetic data generation methods do not address it in health settings. To fill this gap, we develop the first LLM-augmented synthetic data generation method to enhance causal fairness using real-world tabular health data. Our generated data deviates by less than 10% from real data on causal fairness metrics. When trained on causally fair predictors, synthetic data reduces bias on the sensitive attribute by 70% compared to real data. This work improves access to fair synthetic data, supporting equitable health research and healthcare delivery.",
    "summary": "arXiv:2506.19082v1 Announce Type: cross Abstract: Synthetic data generation creates data based on real-world data using generative models. In health applications, generating high-quality data while maintaining fairness for sensitive attributes is essential for equitable outcomes. Existing GAN-based and LLM-based methods focus on counterfactual fairness and are primarily applied in finance and legal domains. Causal fairness provides a more comprehensive evaluation framework by preserving causal structure, but current synthetic data generation methods do not address it in health settings. To fill this gap, we develop the first LLM-augmented synthetic data generation method to enhance causal fairness using real-world tabular health data. Our generated data deviates by less than 10% from real data on causal fairness metrics. When trained on causally fair predictors, synthetic data reduces bias on the sensitive attribute by 70% compared to real data. This work improves access to fair synthetic data, supporting equitable health research and healthcare delivery.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19082",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Fake or Real, Can Robots Tell? Evaluating Embodied Vision-Language Models on Real and 3D-Printed Objects",
    "description": "arXiv:2506.19579v1 Announce Type: cross Abstract: Robotic scene understanding increasingly relies on vision-language models (VLMs) to generate natural language descriptions of the environment. In this work, we present a comparative study of captioning strategies for tabletop scenes captured by a robotic arm equipped with an RGB camera. The robot collects images of objects from multiple viewpoints, and we evaluate several models that generate scene descriptions. We compare the performance of various captioning models, like BLIP and VLMs. Our experiments examine the trade-offs between single-view and multi-view captioning, and difference between recognising real-world and 3D printed objects. We quantitatively evaluate object identification accuracy, completeness, and naturalness of the generated captions. Results show that VLMs can be used in robotic settings where common objects need to be recognised, but fail to generalise to novel representations. Our findings provide practical insights into deploying foundation models for embodied agents in real-world settings.",
    "summary": "arXiv:2506.19579v1 Announce Type: cross Abstract: Robotic scene understanding increasingly relies on vision-language models (VLMs) to generate natural language descriptions of the environment. In this work, we present a comparative study of captioning strategies for tabletop scenes captured by a robotic arm equipped with an RGB camera. The robot collects images of objects from multiple viewpoints, and we evaluate several models that generate scene descriptions. We compare the performance of various captioning models, like BLIP and VLMs. Our experiments examine the trade-offs between single-view and multi-view captioning, and difference between recognising real-world and 3D printed objects. We quantitatively evaluate object identification accuracy, completeness, and naturalness of the generated captions. Results show that VLMs can be used in robotic settings where common objects need to be recognised, but fail to generalise to novel representations. Our findings provide practical insights into deploying foundation models for embodied agents in real-world settings.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19579",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Fast and Distributed Equivariant Graph Neural Networks by Virtual Node Learning",
    "description": "arXiv:2506.19482v1 Announce Type: cross Abstract: Equivariant Graph Neural Networks (GNNs) have achieved remarkable success across diverse scientific applications. However, existing approaches face critical efficiency challenges when scaling to large geometric graphs and suffer significant performance degradation when the input graphs are sparsified for computational tractability. To address these limitations, we introduce FastEGNN and DistEGNN, two novel enhancements to equivariant GNNs for large-scale geometric graphs. FastEGNN employs a key innovation: a small ordered set of virtual nodes that effectively approximates the large unordered graph of real nodes. Specifically, we implement distinct message passing and aggregation mechanisms for different virtual nodes to ensure mutual distinctiveness, and minimize Maximum Mean Discrepancy (MMD) between virtual and real coordinates to achieve global distributedness. This design enables FastEGNN to maintain high accuracy while efficiently processing large-scale sparse graphs. For extremely large-scale geometric graphs, we present DistEGNN, a distributed extension where virtual nodes act as global bridges between subgraphs in different devices, maintaining consistency while dramatically reducing memory and computational overhead. We comprehensively evaluate our models across four challenging domains: N-body systems (100 nodes), protein dynamics (800 nodes), Water-3D (8,000 nodes), and our new Fluid113K benchmark (113,000 nodes). Results demonstrate superior efficiency and performance, establishing new capabilities in large-scale equivariant graph learning. Code is available at https://github.com/GLAD-RUC/DistEGNN.",
    "summary": "arXiv:2506.19482v1 Announce Type: cross Abstract: Equivariant Graph Neural Networks (GNNs) have achieved remarkable success across diverse scientific applications. However, existing approaches face critical efficiency challenges when scaling to large geometric graphs and suffer significant performance degradation when the input graphs are sparsified for computational tractability. To address these limitations, we introduce FastEGNN and DistEGNN, two novel enhancements to equivariant GNNs for large-scale geometric graphs. FastEGNN employs a key innovation: a small ordered set of virtual nodes that effectively approximates the large unordered graph of real nodes. Specifically, we implement distinct message passing and aggregation mechanisms for different virtual nodes to ensure mutual distinctiveness, and minimize Maximum Mean Discrepancy (MMD) between virtual and real coordinates to achieve global distributedness. This design enables FastEGNN to maintain high accuracy while efficiently processing large-scale sparse graphs. For extremely large-scale geometric graphs, we present DistEGNN, a distributed extension where virtual nodes act as global bridges between subgraphs in different devices, maintaining consistency while dramatically reducing memory and computational overhead. We comprehensively evaluate our models across four challenging domains: N-body systems (100 nodes), protein dynamics (800 nodes), Water-3D (8,000 nodes), and our new Fluid113K benchmark (113,000 nodes). Results demonstrate superior efficiency and performance, establishing new capabilities in large-scale equivariant graph learning. Code is available at https://github.com/GLAD-RUC/DistEGNN.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19482",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "FEAT: A Preference Feedback Dataset through a Cost-Effective Auto-Generation and Labeling Framework for English AI Tutoring",
    "description": "arXiv:2506.19325v1 Announce Type: new Abstract: In English education tutoring, teacher feedback is essential for guiding students. Recently, AI-based tutoring systems have emerged to assist teachers; however, these systems require high-quality and large-scale teacher feedback data, which is both time-consuming and costly to generate manually. In this study, we propose FEAT, a cost-effective framework for generating teacher feedback, and have constructed three complementary datasets: (1) DIRECT-Manual (DM), where both humans and large language models (LLMs) collaboratively generate high-quality teacher feedback, albeit at a higher cost; (2) DIRECT-Generated (DG), an LLM-only generated, cost-effective dataset with lower quality;, and (3) DIRECT-Augmented (DA), primarily based on DG with a small portion of DM added to enhance quality while maintaining cost-efficiency. Experimental results showed that incorporating a small portion of DM (5-10%) into DG leads to superior performance compared to using 100% DM alone.",
    "summary": "arXiv:2506.19325v1 Announce Type: new Abstract: In English education tutoring, teacher feedback is essential for guiding students. Recently, AI-based tutoring systems have emerged to assist teachers; however, these systems require high-quality and large-scale teacher feedback data, which is both time-consuming and costly to generate manually. In this study, we propose FEAT, a cost-effective framework for generating teacher feedback, and have constructed three complementary datasets: (1) DIRECT-Manual (DM), where both humans and large language models (LLMs) collaboratively generate high-quality teacher feedback, albeit at a higher cost; (2) DIRECT-Generated (DG), an LLM-only generated, cost-effective dataset with lower quality;, and (3) DIRECT-Augmented (DA), primarily based on DG with a small portion of DM added to enhance quality while maintaining cost-efficiency. Experimental results showed that incorporating a small portion of DM (5-10%) into DG leads to superior performance compared to using 100% DM alone.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19325",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Finding Clustering Algorithms in the Transformer Architecture",
    "description": "arXiv:2506.19125v1 Announce Type: cross Abstract: The invention of the transformer architecture has revolutionized Artificial Intelligence (AI), yielding unprecedented success in areas such as natural language processing, computer vision, and multimodal reasoning. Despite these advances, it is unclear whether transformers are able to learn and implement precise algorithms. Here, we demonstrate that transformers can exactly implement a fundamental and widely used algorithm for $k$-means clustering: Lloyd's algorithm. First, we theoretically prove the existence of such a transformer architecture, which we term the $k$-means transformer, that exactly implements Lloyd's algorithm for $k$-means clustering using the standard ingredients of modern transformers: attention and residual connections. Next, we numerically implement this transformer and demonstrate in experiments the exact correspondence between our architecture and Lloyd's algorithm, providing a fully neural implementation of $k$-means clustering. Finally, we demonstrate that interpretable alterations (e.g., incorporating layer normalizations or multilayer perceptrons) to this architecture yields diverse and novel variants of clustering algorithms, such as soft $k$-means, spherical $k$-means, trimmed $k$-means, and more. Collectively, our findings demonstrate how transformer mechanisms can precisely map onto algorithmic procedures, offering a clear and interpretable perspective on implementing precise algorithms in transformers.",
    "summary": "arXiv:2506.19125v1 Announce Type: cross Abstract: The invention of the transformer architecture has revolutionized Artificial Intelligence (AI), yielding unprecedented success in areas such as natural language processing, computer vision, and multimodal reasoning. Despite these advances, it is unclear whether transformers are able to learn and implement precise algorithms. Here, we demonstrate that transformers can exactly implement a fundamental and widely used algorithm for $k$-means clustering: Lloyd's algorithm. First, we theoretically prove the existence of such a transformer architecture, which we term the $k$-means transformer, that exactly implements Lloyd's algorithm for $k$-means clustering using the standard ingredients of modern transformers: attention and residual connections. Next, we numerically implement this transformer and demonstrate in experiments the exact correspondence between our architecture and Lloyd's algorithm, providing a fully neural implementation of $k$-means clustering. Finally, we demonstrate that interpretable alterations (e.g., incorporating layer normalizations or multilayer perceptrons) to this architecture yields diverse and novel variants of clustering algorithms, such as soft $k$-means, spherical $k$-means, trimmed $k$-means, and more. Collectively, our findings demonstrate how transformer mechanisms can precisely map onto algorithmic procedures, offering a clear and interpretable perspective on implementing precise algorithms in transformers.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19125",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "From High-SNR Radar Signal to ECG: A Transfer Learning Model with Cardio-Focusing Algorithm for Scenarios with Limited Data",
    "description": "arXiv:2506.19358v1 Announce Type: cross Abstract: Electrocardiogram (ECG), as a crucial find-grained cardiac feature, has been successfully recovered from radar signals in the literature, but the performance heavily relies on the high-quality radar signal and numerous radar-ECG pairs for training, restricting the applications in new scenarios due to data scarcity. Therefore, this work will focus on radar-based ECG recovery in new scenarios with limited data and propose a cardio-focusing and -tracking (CFT) algorithm to precisely track the cardiac location to ensure an efficient acquisition of high-quality radar signals. Furthermore, a transfer learning model (RFcardi) is proposed to extract cardio-related information from the radar signal without ECG ground truth based on the intrinsic sparsity of cardiac features, and only a few synchronous radar-ECG pairs are required to fine-tune the pre-trained model for the ECG recovery. The experimental results reveal that the proposed CFT can dynamically identify the cardiac location, and the RFcardi model can effectively generate faithful ECG recoveries after using a small number of radar-ECG pairs for training. The code and dataset are available after the publication.",
    "summary": "arXiv:2506.19358v1 Announce Type: cross Abstract: Electrocardiogram (ECG), as a crucial find-grained cardiac feature, has been successfully recovered from radar signals in the literature, but the performance heavily relies on the high-quality radar signal and numerous radar-ECG pairs for training, restricting the applications in new scenarios due to data scarcity. Therefore, this work will focus on radar-based ECG recovery in new scenarios with limited data and propose a cardio-focusing and -tracking (CFT) algorithm to precisely track the cardiac location to ensure an efficient acquisition of high-quality radar signals. Furthermore, a transfer learning model (RFcardi) is proposed to extract cardio-related information from the radar signal without ECG ground truth based on the intrinsic sparsity of cardiac features, and only a few synchronous radar-ECG pairs are required to fine-tune the pre-trained model for the ECG recovery. The experimental results reveal that the proposed CFT can dynamically identify the cardiac location, and the RFcardi model can effectively generate faithful ECG recoveries after using a small number of radar-ECG pairs for training. The code and dataset are available after the publication.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19358",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "From memories to maps: Mechanisms of in context reinforcement learning in transformers",
    "description": "arXiv:2506.19686v1 Announce Type: new Abstract: Humans and animals show remarkable learning efficiency, adapting to new environments with minimal experience. This capability is not well captured by standard reinforcement learning algorithms that rely on incremental value updates. Rapid adaptation likely depends on episodic memory -- the ability to retrieve specific past experiences to guide decisions in novel contexts. Transformers provide a useful setting for studying these questions because of their ability to learn rapidly in-context and because their key-value architecture resembles episodic memory systems in the brain. We train a transformer to in-context reinforcement learn in a distribution of planning tasks inspired by rodent behavior. We then characterize the learning algorithms that emerge in the model. We first find that representation learning is supported by in-context structure learning and cross-context alignment, where representations are aligned across environments with different sensory stimuli. We next demonstrate that the reinforcement learning strategies developed by the model are not interpretable as standard model-free or model-based planning. Instead, we show that in-context reinforcement learning is supported by caching intermediate computations within the model's memory tokens, which are then accessed at decision time. Overall, we find that memory may serve as a computational resource, storing both raw experience and cached computations to support flexible behavior. Furthermore, the representations developed in the model resemble computations associated with the hippocampal-entorhinal system in the brain, suggesting that our findings may be relevant for natural cognition. Taken together, our work offers a mechanistic hypothesis for the rapid adaptation that underlies in-context learning in artificial and natural settings.",
    "summary": "arXiv:2506.19686v1 Announce Type: new Abstract: Humans and animals show remarkable learning efficiency, adapting to new environments with minimal experience. This capability is not well captured by standard reinforcement learning algorithms that rely on incremental value updates. Rapid adaptation likely depends on episodic memory -- the ability to retrieve specific past experiences to guide decisions in novel contexts. Transformers provide a useful setting for studying these questions because of their ability to learn rapidly in-context and because their key-value architecture resembles episodic memory systems in the brain. We train a transformer to in-context reinforcement learn in a distribution of planning tasks inspired by rodent behavior. We then characterize the learning algorithms that emerge in the model. We first find that representation learning is supported by in-context structure learning and cross-context alignment, where representations are aligned across environments with different sensory stimuli. We next demonstrate that the reinforcement learning strategies developed by the model are not interpretable as standard model-free or model-based planning. Instead, we show that in-context reinforcement learning is supported by caching intermediate computations within the model's memory tokens, which are then accessed at decision time. Overall, we find that memory may serve as a computational resource, storing both raw experience and cached computations to support flexible behavior. Furthermore, the representations developed in the model resemble computations associated with the hippocampal-entorhinal system in the brain, suggesting that our findings may be relevant for natural cognition. Taken together, our work offers a mechanistic hypothesis for the rapid adaptation that underlies in-context learning in artificial and natural settings.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19686",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "From Reproduction to Replication: Evaluating Research Agents with Progressive Code Masking",
    "description": "arXiv:2506.19724v1 Announce Type: new Abstract: Recent progress in autonomous code generation has fueled excitement around AI agents capable of accelerating scientific discovery by running experiments. However, there is currently no benchmark that evaluates whether such agents can implement scientific ideas when given varied amounts of code as a starting point, interpolating between reproduction (running code) and from-scratch replication (fully re-implementing and running code). We introduce AutoExperiment, a benchmark that evaluates AI agents' ability to implement and run machine learning experiments based on natural language descriptions in research papers. In each task, agents are given a research paper, a codebase with key functions masked out, and a command to run the experiment. The goal is to generate the missing code, execute the experiment in a sandboxed environment, and reproduce the results. AutoExperiment scales in difficulty by varying the number of missing functions $n$, ranging from partial reproduction to full replication. We evaluate state-of-the-art agents and find that performance degrades rapidly as $n$ increases. Agents that can dynamically interact with the environment (e.g. to debug their code) can outperform agents in fixed 'agentless' harnesses, and there exists a significant gap between single-shot and multi-trial success rates (Pass@1 vs. Pass@5), motivating verifier approaches to our benchmark. Our findings highlight critical challenges in long-horizon code generation, context retrieval, and autonomous experiment execution, establishing AutoExperiment as a new benchmark for evaluating progress in AI-driven scientific experimentation. Our data and code are open-sourced at https://github.com/j1mk1m/AutoExperiment .",
    "summary": "arXiv:2506.19724v1 Announce Type: new Abstract: Recent progress in autonomous code generation has fueled excitement around AI agents capable of accelerating scientific discovery by running experiments. However, there is currently no benchmark that evaluates whether such agents can implement scientific ideas when given varied amounts of code as a starting point, interpolating between reproduction (running code) and from-scratch replication (fully re-implementing and running code). We introduce AutoExperiment, a benchmark that evaluates AI agents' ability to implement and run machine learning experiments based on natural language descriptions in research papers. In each task, agents are given a research paper, a codebase with key functions masked out, and a command to run the experiment. The goal is to generate the missing code, execute the experiment in a sandboxed environment, and reproduce the results. AutoExperiment scales in difficulty by varying the number of missing functions $n$, ranging from partial reproduction to full replication. We evaluate state-of-the-art agents and find that performance degrades rapidly as $n$ increases. Agents that can dynamically interact with the environment (e.g. to debug their code) can outperform agents in fixed 'agentless' harnesses, and there exists a significant gap between single-shot and multi-trial success rates (Pass@1 vs. Pass@5), motivating verifier approaches to our benchmark. Our findings highlight critical challenges in long-horizon code generation, context retrieval, and autonomous experiment execution, establishing AutoExperiment as a new benchmark for evaluating progress in AI-driven scientific experimentation. Our data and code are open-sourced at https://github.com/j1mk1m/AutoExperiment .",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19724",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "From Rows to Yields: How Foundation Models for Tabular Data Simplify Crop Yield Prediction",
    "description": "arXiv:2506.19046v1 Announce Type: new Abstract: We present an application of a foundation model for small- to medium-sized tabular data (TabPFN), to sub-national yield forecasting task in South Africa. TabPFN has recently demonstrated superior performance compared to traditional machine learning (ML) models in various regression and classification tasks. We used the dekadal (10-days) time series of Earth Observation (EO; FAPAR and soil moisture) and gridded weather data (air temperature, precipitation and radiation) to forecast the yield of summer crops at the sub-national level. The crop yield data was available for 23 years and for up to 8 provinces. Covariate variables for TabPFN (i.e., EO and weather) were extracted by region and aggregated at a monthly scale. We benchmarked the results of the TabPFN against six ML models and three baseline models. Leave-one-year-out cross-validation experiment setting was used in order to ensure the assessment of the models capacity to forecast an unseen year. Results showed that TabPFN and ML models exhibit comparable accuracy, outperforming the baselines. Nonetheless, TabPFN demonstrated superior practical utility due to its significantly faster tuning time and reduced requirement for feature engineering. This renders TabPFN a more viable option for real-world operation yield forecasting applications, where efficiency and ease of implementation are paramount.",
    "summary": "arXiv:2506.19046v1 Announce Type: new Abstract: We present an application of a foundation model for small- to medium-sized tabular data (TabPFN), to sub-national yield forecasting task in South Africa. TabPFN has recently demonstrated superior performance compared to traditional machine learning (ML) models in various regression and classification tasks. We used the dekadal (10-days) time series of Earth Observation (EO; FAPAR and soil moisture) and gridded weather data (air temperature, precipitation and radiation) to forecast the yield of summer crops at the sub-national level. The crop yield data was available for 23 years and for up to 8 provinces. Covariate variables for TabPFN (i.e., EO and weather) were extracted by region and aggregated at a monthly scale. We benchmarked the results of the TabPFN against six ML models and three baseline models. Leave-one-year-out cross-validation experiment setting was used in order to ensure the assessment of the models capacity to forecast an unseen year. Results showed that TabPFN and ML models exhibit comparable accuracy, outperforming the baselines. Nonetheless, TabPFN demonstrated superior practical utility due to its significantly faster tuning time and reduced requirement for feature engineering. This renders TabPFN a more viable option for real-world operation yield forecasting applications, where efficiency and ease of implementation are paramount.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19046",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "GBGC: Efficient and Adaptive Graph Coarsening via Granular-ball Computing",
    "description": "arXiv:2506.19224v1 Announce Type: new Abstract: The objective of graph coarsening is to generate smaller, more manageable graphs while preserving key information of the original graph. Previous work were mainly based on the perspective of spectrum-preserving, using some predefined coarsening rules to make the eigenvalues of the Laplacian matrix of the original graph and the coarsened graph match as much as possible. However, they largely overlooked the fact that the original graph is composed of subregions at different levels of granularity, where highly connected and similar nodes should be more inclined to be aggregated together as nodes in the coarsened graph. By combining the multi-granularity characteristics of the graph structure, we can generate coarsened graph at the optimal granularity. To this end, inspired by the application of granular-ball computing in multi-granularity, we propose a new multi-granularity, efficient, and adaptive coarsening method via granular-ball (GBGC), which significantly improves the coarsening results and efficiency. Specifically, GBGC introduces an adaptive granular-ball graph refinement mechanism, which adaptively splits the original graph from coarse to fine into granular-balls of different sizes and optimal granularity, and constructs the coarsened graph using these granular-balls as supernodes. In addition, compared with other state-of-the-art graph coarsening methods, the processing speed of this method can be increased by tens to hundreds of times and has lower time complexity. The accuracy of GBGC is almost always higher than that of the original graph due to the good robustness and generalization of the granular-ball computing, so it has the potential to become a standard graph data preprocessing method.",
    "summary": "arXiv:2506.19224v1 Announce Type: new Abstract: The objective of graph coarsening is to generate smaller, more manageable graphs while preserving key information of the original graph. Previous work were mainly based on the perspective of spectrum-preserving, using some predefined coarsening rules to make the eigenvalues of the Laplacian matrix of the original graph and the coarsened graph match as much as possible. However, they largely overlooked the fact that the original graph is composed of subregions at different levels of granularity, where highly connected and similar nodes should be more inclined to be aggregated together as nodes in the coarsened graph. By combining the multi-granularity characteristics of the graph structure, we can generate coarsened graph at the optimal granularity. To this end, inspired by the application of granular-ball computing in multi-granularity, we propose a new multi-granularity, efficient, and adaptive coarsening method via granular-ball (GBGC), which significantly improves the coarsening results and efficiency. Specifically, GBGC introduces an adaptive granular-ball graph refinement mechanism, which adaptively splits the original graph from coarse to fine into granular-balls of different sizes and optimal granularity, and constructs the coarsened graph using these granular-balls as supernodes. In addition, compared with other state-of-the-art graph coarsening methods, the processing speed of this method can be increased by tens to hundreds of times and has lower time complexity. The accuracy of GBGC is almost always higher than that of the original graph due to the good robustness and generalization of the granular-ball computing, so it has the potential to become a standard graph data preprocessing method.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19224",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Gemini CLI: your open-source AI agent",
    "description": "Gemini CLI icon on a background with code snippets",
    "summary": "Gemini CLI icon on a background with code snippets",
    "pubDate": "Wed, 25 Jun 2025 13:00:00 +0000",
    "source": "Google AI Blog",
    "url": "https://blog.google/technology/developers/introducing-gemini-cli/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Gemini_CLI_Hero.width-1300.png"
  },
  {
    "title": "General Methods Make Great Domain-specific Foundation Models: A Case-study on Fetal Ultrasound",
    "description": "arXiv:2506.19552v1 Announce Type: cross Abstract: With access to large-scale, unlabeled medical datasets, researchers are confronted with two questions: Should they attempt to pretrain a custom foundation model on this medical data, or use transfer-learning from an existing generalist model? And, if a custom model is pretrained, are novel methods required? In this paper we explore these questions by conducting a case-study, in which we train a foundation model on a large regional fetal ultrasound dataset of 2M images. By selecting the well-established DINOv2 method for pretraining, we achieve state-of-the-art results on three fetal ultrasound datasets, covering data from different countries, classification, segmentation, and few-shot tasks. We compare against a series of models pretrained on natural images, ultrasound images, and supervised baselines. Our results demonstrate two key insights: (i) Pretraining on custom data is worth it, even if smaller models are trained on less data, as scaling in natural image pretraining does not translate to ultrasound performance. (ii) Well-tuned methods from computer vision are making it feasible to train custom foundation models for a given medical domain, requiring no hyperparameter tuning and little methodological adaptation. Given these findings, we argue that a bias towards methodological innovation should be avoided when developing domain specific foundation models under common computational resource constraints.",
    "summary": "arXiv:2506.19552v1 Announce Type: cross Abstract: With access to large-scale, unlabeled medical datasets, researchers are confronted with two questions: Should they attempt to pretrain a custom foundation model on this medical data, or use transfer-learning from an existing generalist model? And, if a custom model is pretrained, are novel methods required? In this paper we explore these questions by conducting a case-study, in which we train a foundation model on a large regional fetal ultrasound dataset of 2M images. By selecting the well-established DINOv2 method for pretraining, we achieve state-of-the-art results on three fetal ultrasound datasets, covering data from different countries, classification, segmentation, and few-shot tasks. We compare against a series of models pretrained on natural images, ultrasound images, and supervised baselines. Our results demonstrate two key insights: (i) Pretraining on custom data is worth it, even if smaller models are trained on less data, as scaling in natural image pretraining does not translate to ultrasound performance. (ii) Well-tuned methods from computer vision are making it feasible to train custom foundation models for a given medical domain, requiring no hyperparameter tuning and little methodological adaptation. Given these findings, we argue that a bias towards methodological innovation should be avoided when developing domain specific foundation models under common computational resource constraints.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19552",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Geometric-Aware Variational Inference: Robust and Adaptive Regularization with Directional Weight Uncertainty",
    "description": "arXiv:2506.19726v1 Announce Type: cross Abstract: Deep neural networks require principled uncertainty quantification, yet existing variational inference methods often employ isotropic Gaussian approximations in weight space that poorly match the network's inherent geometry. We address this mismatch by introducing Concentration-Adapted Perturbations (CAP), a variational framework that models weight uncertainties directly on the unit hypersphere using von Mises-Fisher distributions. Building on recent work in radial-directional posterior decompositions and spherical weight constraints, CAP provides the first complete theoretical framework connecting directional statistics to practical noise regularization in neural networks. Our key contribution is an analytical derivation linking vMF concentration parameters to activation noise variance, enabling each layer to learn its optimal uncertainty level through a novel closed-form KL divergence regularizer. In experiments on CIFAR-10, CAP significantly improves model calibration - reducing Expected Calibration Error by 5.6x - while providing interpretable layer-wise uncertainty profiles. CAP requires minimal computational overhead and integrates seamlessly into standard architectures, offering a theoretically grounded yet practical approach to uncertainty quantification in deep learning.",
    "summary": "arXiv:2506.19726v1 Announce Type: cross Abstract: Deep neural networks require principled uncertainty quantification, yet existing variational inference methods often employ isotropic Gaussian approximations in weight space that poorly match the network's inherent geometry. We address this mismatch by introducing Concentration-Adapted Perturbations (CAP), a variational framework that models weight uncertainties directly on the unit hypersphere using von Mises-Fisher distributions. Building on recent work in radial-directional posterior decompositions and spherical weight constraints, CAP provides the first complete theoretical framework connecting directional statistics to practical noise regularization in neural networks. Our key contribution is an analytical derivation linking vMF concentration parameters to activation noise variance, enabling each layer to learn its optimal uncertainty level through a novel closed-form KL divergence regularizer. In experiments on CIFAR-10, CAP significantly improves model calibration - reducing Expected Calibration Error by 5.6x - while providing interpretable layer-wise uncertainty profiles. CAP requires minimal computational overhead and integrates seamlessly into standard architectures, offering a theoretically grounded yet practical approach to uncertainty quantification in deep learning.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19726",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "GLIMPSE: Gradient-Layer Importance Mapping for Prompted Visual Saliency Explanation for Generative LVLMs",
    "description": "arXiv:2506.18985v1 Announce Type: cross Abstract: Recent advances in large vision language models (LVLMs) have unlocked unprecedented capabilities in generating coherent responses from visual inputs. However, interpreting where LVLMs direct their visual attention while generating free-form textual responses remains a significant challenge, yet is essential for understanding model behavior, diagnosing hallucination, exposing bias and ensuring transparency. We introduce GLIMPSE (Gradient-Layer Importance Mapping for Prompted Visual Saliency Explanation), a lightweight, model-agnostic framework for visualizing the salient image regions that LVLMs rely upon during open-ended visual question answering (VQA), while concurrently revealing the multimodal textual saliency. GLIMPSE fuses gradient-weighted attention, adaptive layer propagation, and weighted token aggregation to produce holistic response-level attribution heat maps for interpreting cross-modal reasoning, outperforming prior interpretability methods in human-alignment. We demonstrate an analytic explainable AI (XAI) approach using GLIMPSE to uncover fine-grained insights into LVLM cross-modal attribution, trace token-level reasoning dynamics, and analyze systematic human-attention misalignment, hallucination, and bias.",
    "summary": "arXiv:2506.18985v1 Announce Type: cross Abstract: Recent advances in large vision language models (LVLMs) have unlocked unprecedented capabilities in generating coherent responses from visual inputs. However, interpreting where LVLMs direct their visual attention while generating free-form textual responses remains a significant challenge, yet is essential for understanding model behavior, diagnosing hallucination, exposing bias and ensuring transparency. We introduce GLIMPSE (Gradient-Layer Importance Mapping for Prompted Visual Saliency Explanation), a lightweight, model-agnostic framework for visualizing the salient image regions that LVLMs rely upon during open-ended visual question answering (VQA), while concurrently revealing the multimodal textual saliency. GLIMPSE fuses gradient-weighted attention, adaptive layer propagation, and weighted token aggregation to produce holistic response-level attribution heat maps for interpreting cross-modal reasoning, outperforming prior interpretability methods in human-alignment. We demonstrate an analytic explainable AI (XAI) approach using GLIMPSE to uncover fine-grained insights into LVLM cross-modal attribution, trace token-level reasoning dynamics, and analyze systematic human-attention misalignment, hallucination, and bias.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.18985",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Google DeepMind、ロボットを完全ローカルで動かせるAIモデル「Gemini Robotics On-Device」を初期リリース",
    "description": "Google DeepMindは、ロボット上で完全にローカル実行できるAIモデル「Gemini Robotics On-Device」を初期リリースした。ネットワーク接続に依存せず低遅延で動作するため、オフライン環境でのロボット活用が期待される。",
    "summary": "Google DeepMindは、ロボット上で完全にローカル実行できるAIモデル「Gemini Robotics On-Device」を初期リリースした。ネットワーク接続に依存せず低遅延で動作するため、オフライン環境でのロボット活用が期待される。",
    "pubDate": "Wed, 25 Jun 2025 08:26:00 +0900",
    "source": "ITmedia AI",
    "url": "https://www.itmedia.co.jp/aiplus/articles/2506/25/news056.html",
    "thumbnail": "https://image.itmedia.co.jp/aiplus/articles/2506/25/cover_news056.jpg"
  },
  {
    "title": "Has Machine Translation Evaluation Achieved Human Parity? The Human Reference and the Limits of Progress",
    "description": "arXiv:2506.19571v1 Announce Type: cross Abstract: In Machine Translation (MT) evaluation, metric performance is assessed based on agreement with human judgments. In recent years, automatic metrics have demonstrated increasingly high levels of agreement with humans. To gain a clearer understanding of metric performance and establish an upper bound, we incorporate human baselines in the MT meta-evaluation, that is, the assessment of MT metrics' capabilities. Our results show that human annotators are not consistently superior to automatic metrics, with state-of-the-art metrics often ranking on par with or higher than human baselines. Despite these findings suggesting human parity, we discuss several reasons for caution. Finally, we explore the broader implications of our results for the research field, asking: Can we still reliably measure improvements in MT evaluation? With this work, we aim to shed light on the limits of our ability to measure progress in the field, fostering discussion on an issue that we believe is crucial to the entire MT evaluation community.",
    "summary": "arXiv:2506.19571v1 Announce Type: cross Abstract: In Machine Translation (MT) evaluation, metric performance is assessed based on agreement with human judgments. In recent years, automatic metrics have demonstrated increasingly high levels of agreement with humans. To gain a clearer understanding of metric performance and establish an upper bound, we incorporate human baselines in the MT meta-evaluation, that is, the assessment of MT metrics' capabilities. Our results show that human annotators are not consistently superior to automatic metrics, with state-of-the-art metrics often ranking on par with or higher than human baselines. Despite these findings suggesting human parity, we discuss several reasons for caution. Finally, we explore the broader implications of our results for the research field, asking: Can we still reliably measure improvements in MT evaluation? With this work, we aim to shed light on the limits of our ability to measure progress in the field, fostering discussion on an issue that we believe is crucial to the entire MT evaluation community.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19571",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "HAWAII: Hierarchical Visual Knowledge Transfer for Efficient Vision-Language Models",
    "description": "arXiv:2506.19072v1 Announce Type: cross Abstract: Improving the visual understanding ability of vision-language models (VLMs) is crucial for enhancing their performance across various tasks. While using multiple pretrained visual experts has shown great promise, it often incurs significant computational costs during training and inference. To address this challenge, we propose HAWAII, a novel framework that distills knowledge from multiple visual experts into a single vision encoder, enabling it to inherit the complementary strengths of several experts with minimal computational overhead. To mitigate conflicts among different teachers and switch between different teacher-specific knowledge, instead of using a fixed set of adapters for multiple teachers, we propose to use teacher-specific Low-Rank Adaptation (LoRA) adapters with a corresponding router. Each adapter is aligned with a specific teacher, avoiding noisy guidance during distillation. To enable efficient knowledge distillation, we propose fine-grained and coarse-grained distillation. At the fine-grained level, token importance scores are employed to emphasize the most informative tokens from each teacher adaptively. At the coarse-grained level, we summarize the knowledge from multiple teachers and transfer it to the student using a set of general-knowledge LoRA adapters with a router. Extensive experiments on various vision-language tasks demonstrate the superiority of HAWAII, compared to the popular open-source VLMs.",
    "summary": "arXiv:2506.19072v1 Announce Type: cross Abstract: Improving the visual understanding ability of vision-language models (VLMs) is crucial for enhancing their performance across various tasks. While using multiple pretrained visual experts has shown great promise, it often incurs significant computational costs during training and inference. To address this challenge, we propose HAWAII, a novel framework that distills knowledge from multiple visual experts into a single vision encoder, enabling it to inherit the complementary strengths of several experts with minimal computational overhead. To mitigate conflicts among different teachers and switch between different teacher-specific knowledge, instead of using a fixed set of adapters for multiple teachers, we propose to use teacher-specific Low-Rank Adaptation (LoRA) adapters with a corresponding router. Each adapter is aligned with a specific teacher, avoiding noisy guidance during distillation. To enable efficient knowledge distillation, we propose fine-grained and coarse-grained distillation. At the fine-grained level, token importance scores are employed to emphasize the most informative tokens from each teacher adaptively. At the coarse-grained level, we summarize the knowledge from multiple teachers and transfer it to the student using a set of general-knowledge LoRA adapters with a router. Extensive experiments on various vision-language tasks demonstrate the superiority of HAWAII, compared to the popular open-source VLMs.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19072",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "HeurAgenix: Leveraging LLMs for Solving Complex Combinatorial Optimization Challenges",
    "description": "arXiv:2506.15196v2 Announce Type: replace Abstract: Heuristic algorithms play a vital role in solving combinatorial optimization (CO) problems, yet traditional designs depend heavily on manual expertise and struggle to generalize across diverse instances. We introduce textbf{HeurAgenix}, a two-stage hyper-heuristic framework powered by large language models (LLMs) that first evolves heuristics and then selects among them automatically. In the heuristic evolution phase, HeurAgenix leverages an LLM to compare seed heuristic solutions with higher-quality solutions and extract reusable evolution strategies. During problem solving, it dynamically picks the most promising heuristic for each problem state, guided by the LLM's perception ability. For flexibility, this selector can be either a state-of-the-art LLM or a fine-tuned lightweight model with lower inference cost. To mitigate the scarcity of reliable supervision caused by CO complexity, we fine-tune the lightweight heuristic selector with a dual-reward mechanism that jointly exploits singals from selection preferences and state perception, enabling robust selection under noisy annotations. Extensive experiments on canonical benchmarks show that HeurAgenix not only outperforms existing LLM-based hyper-heuristics but also matches or exceeds specialized solvers. Code is available at https://github.com/microsoft/HeurAgenix.",
    "summary": "arXiv:2506.15196v2 Announce Type: replace Abstract: Heuristic algorithms play a vital role in solving combinatorial optimization (CO) problems, yet traditional designs depend heavily on manual expertise and struggle to generalize across diverse instances. We introduce textbf{HeurAgenix}, a two-stage hyper-heuristic framework powered by large language models (LLMs) that first evolves heuristics and then selects among them automatically. In the heuristic evolution phase, HeurAgenix leverages an LLM to compare seed heuristic solutions with higher-quality solutions and extract reusable evolution strategies. During problem solving, it dynamically picks the most promising heuristic for each problem state, guided by the LLM's perception ability. For flexibility, this selector can be either a state-of-the-art LLM or a fine-tuned lightweight model with lower inference cost. To mitigate the scarcity of reliable supervision caused by CO complexity, we fine-tune the lightweight heuristic selector with a dual-reward mechanism that jointly exploits singals from selection preferences and state perception, enabling robust selection under noisy annotations. Extensive experiments on canonical benchmarks show that HeurAgenix not only outperforms existing LLM-based hyper-heuristics but also matches or exceeds specialized solvers. Code is available at https://github.com/microsoft/HeurAgenix.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.15196",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Hierarchical Time Series Forecasting Via Latent Mean Encoding",
    "description": "arXiv:2506.19633v1 Announce Type: cross Abstract: Coherently forecasting the behaviour of a target variable across both coarse and fine temporal scales is crucial for profit-optimized decision-making in several business applications, and remains an open research problem in temporal hierarchical forecasting. Here, we propose a new hierarchical architecture that tackles this problem by leveraging modules that specialize in forecasting the different temporal aggregation levels of interest. The architecture, which learns to encode the average behaviour of the target variable within its hidden layers, makes accurate and coherent forecasts across the target temporal hierarchies. We validate our architecture on the challenging, real-world M5 dataset and show that it outperforms established methods, such as the TSMixer model.",
    "summary": "arXiv:2506.19633v1 Announce Type: cross Abstract: Coherently forecasting the behaviour of a target variable across both coarse and fine temporal scales is crucial for profit-optimized decision-making in several business applications, and remains an open research problem in temporal hierarchical forecasting. Here, we propose a new hierarchical architecture that tackles this problem by leveraging modules that specialize in forecasting the different temporal aggregation levels of interest. The architecture, which learns to encode the average behaviour of the target variable within its hidden layers, makes accurate and coherent forecasts across the target temporal hierarchies. We validate our architecture on the challenging, real-world M5 dataset and show that it outperforms established methods, such as the TSMixer model.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19633",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Human-Centered Editable Speech-to-Sign-Language Generation via Streaming Conformer-Transformer and Resampling Hook",
    "description": "arXiv:2506.14677v2 Announce Type: replace-cross Abstract: Existing end-to-end sign-language animation systems suffer from low naturalness, limited facial/body expressivity, and no user control. We propose a human-centered, real-time speech-to-sign animation framework that integrates (1) a streaming Conformer encoder with an autoregressive Transformer-MDN decoder for synchronized upper-body and facial motion generation, (2) a transparent, editable JSON intermediate representation empowering deaf users and experts to inspect and modify each sign segment, and (3) a human-in-the-loop optimization loop that refines the model based on user edits and ratings. Deployed on Unity3D, our system achieves a 13 ms average frame-inference time and a 103 ms end-to-end latency on an RTX 4070. Our key contributions include the design of a JSON-centric editing mechanism for fine-grained sign-level personalization and the first application of an MDN-based feedback loop for continuous model adaptation. This combination establishes a generalizable, explainable AI paradigm for user-adaptive, low-latency multimodal systems. In studies with 20 deaf signers and 5 professional interpreters, we observe a +13 point SUS improvement, 6.7 point reduction in cognitive load, and significant gains in naturalness and trust (p $<$ .001) over baselines. This work establishes a scalable, explainable AI paradigm for accessible sign-language technologies.",
    "summary": "arXiv:2506.14677v2 Announce Type: replace-cross Abstract: Existing end-to-end sign-language animation systems suffer from low naturalness, limited facial/body expressivity, and no user control. We propose a human-centered, real-time speech-to-sign animation framework that integrates (1) a streaming Conformer encoder with an autoregressive Transformer-MDN decoder for synchronized upper-body and facial motion generation, (2) a transparent, editable JSON intermediate representation empowering deaf users and experts to inspect and modify each sign segment, and (3) a human-in-the-loop optimization loop that refines the model based on user edits and ratings. Deployed on Unity3D, our system achieves a 13 ms average frame-inference time and a 103 ms end-to-end latency on an RTX 4070. Our key contributions include the design of a JSON-centric editing mechanism for fine-grained sign-level personalization and the first application of an MDN-based feedback loop for continuous model adaptation. This combination establishes a generalizable, explainable AI paradigm for user-adaptive, low-latency multimodal systems. In studies with 20 deaf signers and 5 professional interpreters, we observe a +13 point SUS improvement, 6.7 point reduction in cognitive load, and significant gains in naturalness and trust (p $<$ .001) over baselines. This work establishes a scalable, explainable AI paradigm for accessible sign-language technologies.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.14677",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "'I know myself better, but not really greatly': How Well Can LLMs Detect and Explain LLM-Generated Texts?",
    "description": "arXiv:2502.12743v2 Announce Type: replace-cross Abstract: Distinguishing between human- and LLM-generated texts is crucial given the risks associated with misuse of LLMs. This paper investigates detection and explanation capabilities of current LLMs across two settings: binary (human vs. LLM-generated) and ternary classification (including an ``undecided'' class). We evaluate 6 close- and open-source LLMs of varying sizes and find that self-detection (LLMs identifying their own outputs) consistently outperforms cross-detection (identifying outputs from other LLMs), though both remain suboptimal. Introducing a ternary classification framework improves both detection accuracy and explanation quality across all models. Through comprehensive quantitative and qualitative analyses using our human-annotated dataset, we identify key explanation failures, primarily reliance on inaccurate features, hallucinations, and flawed reasoning. Our findings underscore the limitations of current LLMs in self-detection and self-explanation, highlighting the need for further research to address overfitting and enhance generalizability.",
    "summary": "arXiv:2502.12743v2 Announce Type: replace-cross Abstract: Distinguishing between human- and LLM-generated texts is crucial given the risks associated with misuse of LLMs. This paper investigates detection and explanation capabilities of current LLMs across two settings: binary (human vs. LLM-generated) and ternary classification (including an ``undecided'' class). We evaluate 6 close- and open-source LLMs of varying sizes and find that self-detection (LLMs identifying their own outputs) consistently outperforms cross-detection (identifying outputs from other LLMs), though both remain suboptimal. Introducing a ternary classification framework improves both detection accuracy and explanation quality across all models. Through comprehensive quantitative and qualitative analyses using our human-annotated dataset, we identify key explanation failures, primarily reliance on inaccurate features, hallucinations, and flawed reasoning. Our findings underscore the limitations of current LLMs in self-detection and self-explanation, highlighting the need for further research to address overfitting and enhance generalizability.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2502.12743",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Identifying Macro Causal Effects in C-DMGs over DMGs",
    "description": "arXiv:2506.19650v1 Announce Type: new Abstract: The do-calculus is a sound and complete tool for identifying causal effects in acyclic directed mixed graphs (ADMGs) induced by structural causal models (SCMs). However, in many real-world applications, especially in high-dimensional setting, constructing a fully specified ADMG is often infeasible. This limitation has led to growing interest in partially specified causal representations, particularly through cluster-directed mixed graphs (C-DMGs), which group variables into clusters and offer a more abstract yet practical view of causal dependencies. While these representations can include cycles, recent work has shown that the do-calculus remains sound and complete for identifying macro-level causal effects in C-DMGs over ADMGs under the assumption that all clusters size are greater than 1. Nevertheless, real-world systems often exhibit cyclic causal dynamics at the structural level. To account for this, input-output structural causal models (ioSCMs) have been introduced as a generalization of SCMs that allow for cycles. ioSCMs induce another type of graph structure known as a directed mixed graph (DMG). Analogous to the ADMG setting, one can define C-DMGs over DMGs as high-level representations of causal relations among clusters of variables. In this paper, we prove that, unlike in the ADMG setting, the do-calculus is unconditionally sound and complete for identifying macro causal effects in C-DMGs over DMGs. Furthermore, we show that the graphical criteria for non-identifiability of macro causal effects previously established C-DMGs over ADMGs naturally extends to a subset of C-DMGs over DMGs.",
    "summary": "arXiv:2506.19650v1 Announce Type: new Abstract: The do-calculus is a sound and complete tool for identifying causal effects in acyclic directed mixed graphs (ADMGs) induced by structural causal models (SCMs). However, in many real-world applications, especially in high-dimensional setting, constructing a fully specified ADMG is often infeasible. This limitation has led to growing interest in partially specified causal representations, particularly through cluster-directed mixed graphs (C-DMGs), which group variables into clusters and offer a more abstract yet practical view of causal dependencies. While these representations can include cycles, recent work has shown that the do-calculus remains sound and complete for identifying macro-level causal effects in C-DMGs over ADMGs under the assumption that all clusters size are greater than 1. Nevertheless, real-world systems often exhibit cyclic causal dynamics at the structural level. To account for this, input-output structural causal models (ioSCMs) have been introduced as a generalization of SCMs that allow for cycles. ioSCMs induce another type of graph structure known as a directed mixed graph (DMG). Analogous to the ADMG setting, one can define C-DMGs over DMGs as high-level representations of causal relations among clusters of variables. In this paper, we prove that, unlike in the ADMG setting, the do-calculus is unconditionally sound and complete for identifying macro causal effects in C-DMGs over DMGs. Furthermore, we show that the graphical criteria for non-identifiability of macro causal effects previously established C-DMGs over ADMGs naturally extends to a subset of C-DMGs over DMGs.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19650",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Impact of Visual Context on Noisy Multimodal NMT: An Empirical Study for English to Indian Languages",
    "description": "arXiv:2308.16075v2 Announce Type: replace-cross Abstract: Neural Machine Translation (NMT) has made remarkable progress using large-scale textual data, but the potential of incorporating multimodal inputs, especially visual information, remains underexplored in high-resource settings. While prior research has focused on using multimodal data in low-resource scenarios, this study examines how image features impact translation when added to a large-scale, pre-trained unimodal NMT system. Surprisingly, the study finds that images might be redundant in this context. Additionally, the research introduces synthetic noise to assess whether images help the model handle textual noise. Multimodal models slightly outperform text-only models in noisy settings, even when random images are used. The study's experiments translate from English to Hindi, Bengali, and Malayalam, significantly outperforming state-of-the-art benchmarks. Interestingly, the effect of visual context varies with the level of source text noise: no visual context works best for non-noisy translations, cropped image features are optimal for low noise, and full image features perform better in high-noise scenarios. This sheds light on the role of visual context, especially in noisy settings, and opens up a new research direction for Noisy Neural Machine Translation in multimodal setups. The research emphasizes the importance of combining visual and textual information to improve translation across various environments. Our code is publicly available at https://github.com/babangain/indicMMT.",
    "summary": "arXiv:2308.16075v2 Announce Type: replace-cross Abstract: Neural Machine Translation (NMT) has made remarkable progress using large-scale textual data, but the potential of incorporating multimodal inputs, especially visual information, remains underexplored in high-resource settings. While prior research has focused on using multimodal data in low-resource scenarios, this study examines how image features impact translation when added to a large-scale, pre-trained unimodal NMT system. Surprisingly, the study finds that images might be redundant in this context. Additionally, the research introduces synthetic noise to assess whether images help the model handle textual noise. Multimodal models slightly outperform text-only models in noisy settings, even when random images are used. The study's experiments translate from English to Hindi, Bengali, and Malayalam, significantly outperforming state-of-the-art benchmarks. Interestingly, the effect of visual context varies with the level of source text noise: no visual context works best for non-noisy translations, cropped image features are optimal for low noise, and full image features perform better in high-noise scenarios. This sheds light on the role of visual context, especially in noisy settings, and opens up a new research direction for Noisy Neural Machine Translation in multimodal setups. The research emphasizes the importance of combining visual and textual information to improve translation across various environments. Our code is publicly available at https://github.com/babangain/indicMMT.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2308.16075",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Improving Progressive Generation with Decomposable Flow Matching",
    "description": "arXiv:2506.19839v1 Announce Type: cross Abstract: Generating high-dimensional visual modalities is a computationally intensive task. A common solution is progressive generation, where the outputs are synthesized in a coarse-to-fine spectral autoregressive manner. While diffusion models benefit from the coarse-to-fine nature of denoising, explicit multi-stage architectures are rarely adopted. These architectures have increased the complexity of the overall approach, introducing the need for a custom diffusion formulation, decomposition-dependent stage transitions, add-hoc samplers, or a model cascade. Our contribution, Decomposable Flow Matching (DFM), is a simple and effective framework for the progressive generation of visual media. DFM applies Flow Matching independently at each level of a user-defined multi-scale representation (such as Laplacian pyramid). As shown by our experiments, our approach improves visual quality for both images and videos, featuring superior results compared to prior multistage frameworks. On Imagenet-1k 512px, DFM achieves 35.2% improvements in FDD scores over the base architecture and 26.4% over the best-performing baseline, under the same training compute. When applied to finetuning of large models, such as FLUX, DFM shows faster convergence speed to the training distribution. Crucially, all these advantages are achieved with a single model, architectural simplicity, and minimal modifications to existing training pipelines.",
    "summary": "arXiv:2506.19839v1 Announce Type: cross Abstract: Generating high-dimensional visual modalities is a computationally intensive task. A common solution is progressive generation, where the outputs are synthesized in a coarse-to-fine spectral autoregressive manner. While diffusion models benefit from the coarse-to-fine nature of denoising, explicit multi-stage architectures are rarely adopted. These architectures have increased the complexity of the overall approach, introducing the need for a custom diffusion formulation, decomposition-dependent stage transitions, add-hoc samplers, or a model cascade. Our contribution, Decomposable Flow Matching (DFM), is a simple and effective framework for the progressive generation of visual media. DFM applies Flow Matching independently at each level of a user-defined multi-scale representation (such as Laplacian pyramid). As shown by our experiments, our approach improves visual quality for both images and videos, featuring superior results compared to prior multistage frameworks. On Imagenet-1k 512px, DFM achieves 35.2% improvements in FDD scores over the base architecture and 26.4% over the best-performing baseline, under the same training compute. When applied to finetuning of large models, such as FLUX, DFM shows faster convergence speed to the training distribution. Crucially, all these advantages are achieved with a single model, architectural simplicity, and minimal modifications to existing training pipelines.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19839",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Improving Student-AI Interaction Through Pedagogical Prompting: An Example in Computer Science Education",
    "description": "arXiv:2506.19107v1 Announce Type: cross Abstract: With the proliferation of large language model (LLM) applications since 2022, their use in education has sparked both excitement and concern. Recent studies consistently highlight students' (mis)use of LLMs can hinder learning outcomes. This work aims to teach students how to effectively prompt LLMs to improve their learning. We first proposed pedagogical prompting, a theoretically-grounded new concept to elicit learning-oriented responses from LLMs. To move from concept design to a proof-of-concept learning intervention in real educational settings, we selected early undergraduate CS education (CS1/CS2) as the example context. We began with a formative survey study with instructors (N=36) teaching early-stage undergraduate-level CS courses to inform the instructional design based on classroom needs. Based on their insights, we designed and developed a learning intervention through an interactive system with scenario-based instruction to train pedagogical prompting skills. Finally, we evaluated its instructional effectiveness through a user study with CS novice students (N=22) using pre/post-tests. Through mixed methods analyses, our results indicate significant improvements in learners' LLM-based pedagogical help-seeking skills, along with positive attitudes toward the system and increased willingness to use pedagogical prompts in the future. Our contributions include (1) a theoretical framework of pedagogical prompting; (2) empirical insights into current instructor attitudes toward pedagogical prompting; and (3) a learning intervention design with an interactive learning tool and scenario-based instruction leading to promising results on teaching LLM-based help-seeking. Our approach is scalable for broader implementation in classrooms and has the potential to be integrated into tools like ChatGPT as an on-boarding experience to encourage learning-oriented use of generative AI.",
    "summary": "arXiv:2506.19107v1 Announce Type: cross Abstract: With the proliferation of large language model (LLM) applications since 2022, their use in education has sparked both excitement and concern. Recent studies consistently highlight students' (mis)use of LLMs can hinder learning outcomes. This work aims to teach students how to effectively prompt LLMs to improve their learning. We first proposed pedagogical prompting, a theoretically-grounded new concept to elicit learning-oriented responses from LLMs. To move from concept design to a proof-of-concept learning intervention in real educational settings, we selected early undergraduate CS education (CS1/CS2) as the example context. We began with a formative survey study with instructors (N=36) teaching early-stage undergraduate-level CS courses to inform the instructional design based on classroom needs. Based on their insights, we designed and developed a learning intervention through an interactive system with scenario-based instruction to train pedagogical prompting skills. Finally, we evaluated its instructional effectiveness through a user study with CS novice students (N=22) using pre/post-tests. Through mixed methods analyses, our results indicate significant improvements in learners' LLM-based pedagogical help-seeking skills, along with positive attitudes toward the system and increased willingness to use pedagogical prompts in the future. Our contributions include (1) a theoretical framework of pedagogical prompting; (2) empirical insights into current instructor attitudes toward pedagogical prompting; and (3) a learning intervention design with an interactive learning tool and scenario-based instruction leading to promising results on teaching LLM-based help-seeking. Our approach is scalable for broader implementation in classrooms and has the potential to be integrated into tools like ChatGPT as an on-boarding experience to encourage learning-oriented use of generative AI.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19107",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "In-Context Occam's Razor: How Transformers Prefer Simpler Hypotheses on the Fly",
    "description": "arXiv:2506.19351v1 Announce Type: cross Abstract: In-context learning (ICL) enables transformers to adapt to new tasks through contextual examples without parameter updates. While existing research has typically studied ICL in fixed-complexity environments, practical language models encounter tasks spanning diverse complexity levels. This paper investigates how transformers navigate hierarchical task structures where higher-complexity categories can perfectly represent any pattern generated by simpler ones. We design well-controlled testbeds based on Markov chains and linear regression that reveal transformers not only identify the appropriate complexity level for each task but also accurately infer the corresponding parameters--even when the in-context examples are compatible with multiple complexity hypotheses. Notably, when presented with data generated by simpler processes, transformers consistently favor the least complex sufficient explanation. We theoretically explain this behavior through a Bayesian framework, demonstrating that transformers effectively implement an in-context Bayesian Occam's razor by balancing model fit against complexity penalties. We further ablate on the roles of model size, training mixture distribution, inference context length, and architecture. Finally, we validate this Occam's razor-like inductive bias on a pretrained GPT-4 model with Boolean-function tasks as case study, suggesting it may be inherent to transformers trained on diverse task distributions.",
    "summary": "arXiv:2506.19351v1 Announce Type: cross Abstract: In-context learning (ICL) enables transformers to adapt to new tasks through contextual examples without parameter updates. While existing research has typically studied ICL in fixed-complexity environments, practical language models encounter tasks spanning diverse complexity levels. This paper investigates how transformers navigate hierarchical task structures where higher-complexity categories can perfectly represent any pattern generated by simpler ones. We design well-controlled testbeds based on Markov chains and linear regression that reveal transformers not only identify the appropriate complexity level for each task but also accurately infer the corresponding parameters--even when the in-context examples are compatible with multiple complexity hypotheses. Notably, when presented with data generated by simpler processes, transformers consistently favor the least complex sufficient explanation. We theoretically explain this behavior through a Bayesian framework, demonstrating that transformers effectively implement an in-context Bayesian Occam's razor by balancing model fit against complexity penalties. We further ablate on the roles of model size, training mixture distribution, inference context length, and architecture. Finally, we validate this Occam's razor-like inductive bias on a pretrained GPT-4 model with Boolean-function tasks as case study, suggesting it may be inherent to transformers trained on diverse task distributions.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19351",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "IndieFake Dataset: A Benchmark Dataset for Audio Deepfake Detection",
    "description": "arXiv:2506.19014v1 Announce Type: cross Abstract: Advancements in audio deepfake technology offers benefits like AI assistants, better accessibility for speech impairments, and enhanced entertainment. However, it also poses significant risks to security, privacy, and trust in digital communications. Detecting and mitigating these threats requires comprehensive datasets. Existing datasets lack diverse ethnic accents, making them inadequate for many real-world scenarios. Consequently, models trained on these datasets struggle to detect audio deepfakes in diverse linguistic and cultural contexts such as in South-Asian countries. Ironically, there is a stark lack of South-Asian speaker samples in the existing datasets despite constituting a quarter of the worlds population. This work introduces the IndieFake Dataset (IFD), featuring 27.17 hours of bonafide and deepfake audio from 50 English speaking Indian speakers. IFD offers balanced data distribution and includes speaker-level characterization, absent in datasets like ASVspoof21 (DF). We evaluated various baselines on IFD against existing ASVspoof21 (DF) and In-The-Wild (ITW) datasets. IFD outperforms ASVspoof21 (DF) and proves to be more challenging compared to benchmark ITW dataset. The dataset will be publicly available upon acceptance.",
    "summary": "arXiv:2506.19014v1 Announce Type: cross Abstract: Advancements in audio deepfake technology offers benefits like AI assistants, better accessibility for speech impairments, and enhanced entertainment. However, it also poses significant risks to security, privacy, and trust in digital communications. Detecting and mitigating these threats requires comprehensive datasets. Existing datasets lack diverse ethnic accents, making them inadequate for many real-world scenarios. Consequently, models trained on these datasets struggle to detect audio deepfakes in diverse linguistic and cultural contexts such as in South-Asian countries. Ironically, there is a stark lack of South-Asian speaker samples in the existing datasets despite constituting a quarter of the worlds population. This work introduces the IndieFake Dataset (IFD), featuring 27.17 hours of bonafide and deepfake audio from 50 English speaking Indian speakers. IFD offers balanced data distribution and includes speaker-level characterization, absent in datasets like ASVspoof21 (DF). We evaluated various baselines on IFD against existing ASVspoof21 (DF) and In-The-Wild (ITW) datasets. IFD outperforms ASVspoof21 (DF) and proves to be more challenging compared to benchmark ITW dataset. The dataset will be publicly available upon acceptance.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19014",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Interpretable and Granular Video-Based Quantification of Motor Characteristics from the Finger Tapping Test in Parkinson Disease",
    "description": "arXiv:2506.18925v1 Announce Type: cross Abstract: Accurately quantifying motor characteristics in Parkinson disease (PD) is crucial for monitoring disease progression and optimizing treatment strategies. The finger-tapping test is a standard motor assessment. Clinicians visually evaluate a patient's tapping performance and assign an overall severity score based on tapping amplitude, speed, and irregularity. However, this subjective evaluation is prone to inter- and intra-rater variability, and does not offer insights into individual motor characteristics captured during this test. This paper introduces a granular computer vision-based method for quantifying PD motor characteristics from video recordings. Four sets of clinically relevant features are proposed to characterize hypokinesia, bradykinesia, sequence effect, and hesitation-halts. We evaluate our approach on video recordings and clinical evaluations of 74 PD patients from the Personalized Parkinson Project. Principal component analysis with varimax rotation shows that the video-based features corresponded to the four deficits. Additionally, video-based analysis has allowed us to identify further granular distinctions within sequence effect and hesitation-halts deficits. In the following, we have used these features to train machine learning classifiers to estimate the Movement Disorder Society Unified Parkinson Disease Rating Scale (MDS-UPDRS) finger-tapping score. Compared to state-of-the-art approaches, our method achieves a higher accuracy in MDS-UPDRS score prediction, while still providing an interpretable quantification of individual finger-tapping motor characteristics. In summary, the proposed framework provides a practical solution for the objective assessment of PD motor characteristics, that can potentially be applied in both clinical and remote settings. Future work is needed to assess its responsiveness to symptomatic treatment and disease progression.",
    "summary": "arXiv:2506.18925v1 Announce Type: cross Abstract: Accurately quantifying motor characteristics in Parkinson disease (PD) is crucial for monitoring disease progression and optimizing treatment strategies. The finger-tapping test is a standard motor assessment. Clinicians visually evaluate a patient's tapping performance and assign an overall severity score based on tapping amplitude, speed, and irregularity. However, this subjective evaluation is prone to inter- and intra-rater variability, and does not offer insights into individual motor characteristics captured during this test. This paper introduces a granular computer vision-based method for quantifying PD motor characteristics from video recordings. Four sets of clinically relevant features are proposed to characterize hypokinesia, bradykinesia, sequence effect, and hesitation-halts. We evaluate our approach on video recordings and clinical evaluations of 74 PD patients from the Personalized Parkinson Project. Principal component analysis with varimax rotation shows that the video-based features corresponded to the four deficits. Additionally, video-based analysis has allowed us to identify further granular distinctions within sequence effect and hesitation-halts deficits. In the following, we have used these features to train machine learning classifiers to estimate the Movement Disorder Society Unified Parkinson Disease Rating Scale (MDS-UPDRS) finger-tapping score. Compared to state-of-the-art approaches, our method achieves a higher accuracy in MDS-UPDRS score prediction, while still providing an interpretable quantification of individual finger-tapping motor characteristics. In summary, the proposed framework provides a practical solution for the objective assessment of PD motor characteristics, that can potentially be applied in both clinical and remote settings. Future work is needed to assess its responsiveness to symptomatic treatment and disease progression.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.18925",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Interpretable Hybrid Machine Learning Models Using FOLD-R++ and Answer Set Programming",
    "description": "arXiv:2506.19573v1 Announce Type: new Abstract: Machine learning (ML) techniques play a pivotal role in high-stakes domains such as healthcare, where accurate predictions can greatly enhance decision-making. However, most high-performing methods such as neural networks and ensemble methods are often opaque, limiting trust and broader adoption. In parallel, symbolic methods like Answer Set Programming (ASP) offer the possibility of interpretable logical rules but do not always match the predictive power of ML models. This paper proposes a hybrid approach that integrates ASP-derived rules from the FOLD-R++ algorithm with black-box ML classifiers to selectively correct uncertain predictions and provide human-readable explanations. Experiments on five medical datasets reveal statistically significant performance gains in accuracy and F1 score. This study underscores the potential of combining symbolic reasoning with conventional ML to achieve high interpretability without sacrificing accuracy.",
    "summary": "arXiv:2506.19573v1 Announce Type: new Abstract: Machine learning (ML) techniques play a pivotal role in high-stakes domains such as healthcare, where accurate predictions can greatly enhance decision-making. However, most high-performing methods such as neural networks and ensemble methods are often opaque, limiting trust and broader adoption. In parallel, symbolic methods like Answer Set Programming (ASP) offer the possibility of interpretable logical rules but do not always match the predictive power of ML models. This paper proposes a hybrid approach that integrates ASP-derived rules from the FOLD-R++ algorithm with black-box ML classifiers to selectively correct uncertain predictions and provide human-readable explanations. Experiments on five medical datasets reveal statistically significant performance gains in accuracy and F1 score. This study underscores the potential of combining symbolic reasoning with conventional ML to achieve high interpretability without sacrificing accuracy.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19573",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Interrogating AI: Characterizing Emergent Playful Interactions with ChatGPT",
    "description": "arXiv:2401.08405v4 Announce Type: replace-cross Abstract: In an era of AI's growing capabilities and influences, recent advancements are reshaping HCI and CSCW's view of AI. Playful interactions emerged as an important way for users to make sense of the ever-changing AI technologies, yet remained underexamined. We target this gap by investigating playful interactions exhibited by users of a popular AI technology, ChatGPT. Through a thematic analysis of 372 user-generated posts on the ChatGPT subreddit, we found that more than half (54%) of user discourse revolved around playful interactions. The analysis further allowed us to construct a preliminary framework to describe these interactions, categorizing them into six types: reflecting, jesting, imitating, challenging, tricking, and contriving; each included sub-categories. This study contributes to HCI and CSCW by identifying the diverse ways users engage in playful interactions with AI. It examines how these interactions can help users understand AI's agency, shape human-AI relationships, and provide insights for designing AI systems.",
    "summary": "arXiv:2401.08405v4 Announce Type: replace-cross Abstract: In an era of AI's growing capabilities and influences, recent advancements are reshaping HCI and CSCW's view of AI. Playful interactions emerged as an important way for users to make sense of the ever-changing AI technologies, yet remained underexamined. We target this gap by investigating playful interactions exhibited by users of a popular AI technology, ChatGPT. Through a thematic analysis of 372 user-generated posts on the ChatGPT subreddit, we found that more than half (54%) of user discourse revolved around playful interactions. The analysis further allowed us to construct a preliminary framework to describe these interactions, categorizing them into six types: reflecting, jesting, imitating, challenging, tricking, and contriving; each included sub-categories. This study contributes to HCI and CSCW by identifying the diverse ways users engage in playful interactions with AI. It examines how these interactions can help users understand AI's agency, shape human-AI relationships, and provide insights for designing AI systems.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2401.08405",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Is an object-centric representation beneficial for robotic manipulation ?",
    "description": "arXiv:2506.19408v1 Announce Type: new Abstract: Object-centric representation (OCR) has recently become a subject of interest in the computer vision community for learning a structured representation of images and videos. It has been several times presented as a potential way to improve data-efficiency and generalization capabilities to learn an agent on downstream tasks. However, most existing work only evaluates such models on scene decomposition, without any notion of reasoning over the learned representation. Robotic manipulation tasks generally involve multi-object environments with potential inter-object interaction. We thus argue that they are a very interesting playground to really evaluate the potential of existing object-centric work. To do so, we create several robotic manipulation tasks in simulated environments involving multiple objects (several distractors, the robot, etc.) and a high-level of randomization (object positions, colors, shapes, background, initial positions, etc.). We then evaluate one classical object-centric method across several generalization scenarios and compare its results against several state-of-the-art hollistic representations. Our results exhibit that existing methods are prone to failure in difficult scenarios involving complex scene structures, whereas object-centric methods help overcome these challenges.",
    "summary": "arXiv:2506.19408v1 Announce Type: new Abstract: Object-centric representation (OCR) has recently become a subject of interest in the computer vision community for learning a structured representation of images and videos. It has been several times presented as a potential way to improve data-efficiency and generalization capabilities to learn an agent on downstream tasks. However, most existing work only evaluates such models on scene decomposition, without any notion of reasoning over the learned representation. Robotic manipulation tasks generally involve multi-object environments with potential inter-object interaction. We thus argue that they are a very interesting playground to really evaluate the potential of existing object-centric work. To do so, we create several robotic manipulation tasks in simulated environments involving multiple objects (several distractors, the robot, etc.) and a high-level of randomization (object positions, colors, shapes, background, initial positions, etc.). We then evaluate one classical object-centric method across several generalization scenarios and compare its results against several state-of-the-art hollistic representations. Our results exhibit that existing methods are prone to failure in difficult scenarios involving complex scene structures, whereas object-centric methods help overcome these challenges.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19408",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Iterative Quantum Feature Maps",
    "description": "arXiv:2506.19461v1 Announce Type: cross Abstract: Quantum machine learning models that leverage quantum circuits as quantum feature maps (QFMs) are recognized for their enhanced expressive power in learning tasks. Such models have demonstrated rigorous end-to-end quantum speedups for specific families of classification problems. However, deploying deep QFMs on real quantum hardware remains challenging due to circuit noise and hardware constraints. Additionally, variational quantum algorithms often suffer from computational bottlenecks, particularly in accurate gradient estimation, which significantly increases quantum resource demands during training. We propose Iterative Quantum Feature Maps (IQFMs), a hybrid quantum-classical framework that constructs a deep architecture by iteratively connecting shallow QFMs with classically computed augmentation weights. By incorporating contrastive learning and a layer-wise training mechanism, IQFMs effectively reduces quantum runtime and mitigates noise-induced degradation. In tasks involving noisy quantum data, numerical experiments show that IQFMs outperforms quantum convolutional neural networks, without requiring the optimization of variational quantum parameters. Even for a typical classical image classification benchmark, a carefully designed IQFMs achieves performance comparable to that of classical neural networks. This framework presents a promising path to address current limitations and harness the full potential of quantum-enhanced machine learning.",
    "summary": "arXiv:2506.19461v1 Announce Type: cross Abstract: Quantum machine learning models that leverage quantum circuits as quantum feature maps (QFMs) are recognized for their enhanced expressive power in learning tasks. Such models have demonstrated rigorous end-to-end quantum speedups for specific families of classification problems. However, deploying deep QFMs on real quantum hardware remains challenging due to circuit noise and hardware constraints. Additionally, variational quantum algorithms often suffer from computational bottlenecks, particularly in accurate gradient estimation, which significantly increases quantum resource demands during training. We propose Iterative Quantum Feature Maps (IQFMs), a hybrid quantum-classical framework that constructs a deep architecture by iteratively connecting shallow QFMs with classically computed augmentation weights. By incorporating contrastive learning and a layer-wise training mechanism, IQFMs effectively reduces quantum runtime and mitigates noise-induced degradation. In tasks involving noisy quantum data, numerical experiments show that IQFMs outperforms quantum convolutional neural networks, without requiring the optimization of variational quantum parameters. Even for a typical classical image classification benchmark, a carefully designed IQFMs achieves performance comparable to that of classical neural networks. This framework presents a promising path to address current limitations and harness the full potential of quantum-enhanced machine learning.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19461",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "JCAPT: A Joint Modeling Approach for CAPT",
    "description": "arXiv:2506.19315v1 Announce Type: cross Abstract: Effective pronunciation feedback is critical in second language (L2) learning, for which computer-assisted pronunciation training (CAPT) systems often encompass two key tasks: automatic pronunciation assessment (APA) and mispronunciation detection and diagnosis (MDD). Recent work has shown that joint modeling of these two tasks can yield mutual benefits. Our unified framework leverages Mamba, a selective state space model (SSM), while integrating phonological features and think token strategies to jointly enhance interpretability and fine-grained temporal reasoning in APA and MDD. To our knowledge, this is the first study to combine phonological attribution, SSM-based modeling, and prompting in CAPT. A series of experiments conducted on the speechocean762 benchmark demonstrate that our model consistently outperforms prior methods, particularly on the MDD task.",
    "summary": "arXiv:2506.19315v1 Announce Type: cross Abstract: Effective pronunciation feedback is critical in second language (L2) learning, for which computer-assisted pronunciation training (CAPT) systems often encompass two key tasks: automatic pronunciation assessment (APA) and mispronunciation detection and diagnosis (MDD). Recent work has shown that joint modeling of these two tasks can yield mutual benefits. Our unified framework leverages Mamba, a selective state space model (SSM), while integrating phonological features and think token strategies to jointly enhance interpretability and fine-grained temporal reasoning in APA and MDD. To our knowledge, this is the first study to combine phonological attribution, SSM-based modeling, and prompting in CAPT. A series of experiments conducted on the speechocean762 benchmark demonstrate that our model consistently outperforms prior methods, particularly on the MDD task.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19315",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "jina-embeddings-v4: Universal Embeddings for Multimodal Multilingual Retrieval",
    "description": "arXiv:2506.18902v2 Announce Type: replace Abstract: We introduce jina-embeddings-v4, a 3.8 billion parameter multimodal embedding model that unifies text and image representations through a novel architecture supporting both single-vector and multi-vector embeddings in the late interaction style. The model incorporates task-specific Low-Rank Adaptation (LoRA) adapters to optimize performance across diverse retrieval scenarios, including query-document retrieval, semantic text similarity, and code search. Comprehensive evaluations demonstrate that jina-embeddings-v4 achieves state-of-the-art performance on both single-modal and cross-modal retrieval tasks, with particular strength in processing visually rich content such as tables, charts, diagrams, and mixed-media formats. To facilitate evaluation of this capability, we also introduce Jina-VDR, a novel benchmark specifically designed for visually rich image retrieval.",
    "summary": "arXiv:2506.18902v2 Announce Type: replace Abstract: We introduce jina-embeddings-v4, a 3.8 billion parameter multimodal embedding model that unifies text and image representations through a novel architecture supporting both single-vector and multi-vector embeddings in the late interaction style. The model incorporates task-specific Low-Rank Adaptation (LoRA) adapters to optimize performance across diverse retrieval scenarios, including query-document retrieval, semantic text similarity, and code search. Comprehensive evaluations demonstrate that jina-embeddings-v4 achieves state-of-the-art performance on both single-modal and cross-modal retrieval tasks, with particular strength in processing visually rich content such as tables, charts, diagrams, and mixed-media formats. To facilitate evaluation of this capability, we also introduce Jina-VDR, a novel benchmark specifically designed for visually rich image retrieval.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.18902",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "JoyAgents-R1: Joint Evolution Dynamics for Versatile Multi-LLM Agents with Reinforcement Learning",
    "description": "arXiv:2506.19846v1 Announce Type: new Abstract: Multi-agent reinforcement learning (MARL) has emerged as a prominent paradigm for increasingly complex tasks. However, joint evolution across heterogeneous agents remains challenging due to cooperative inefficiency and training instability. In this paper, we propose the joint evolution dynamics for MARL called JoyAgents-R1, which first applies Group Relative Policy Optimization (GRPO) to the joint training of heterogeneous multi-agents. By iteratively refining agents' large language models (LLMs) and memories, the method achieves holistic equilibrium with optimal decision-making and memory capabilities. Specifically, JoyAgents-R1 first implements node-wise Monte Carlo sampling on the behavior of each agent across entire reasoning trajectories to enhance GRPO sampling efficiency while maintaining policy diversity. Then, our marginal benefit-driven selection strategy identifies top-$K$ sampling groups with maximal reward fluctuations, enabling targeted agent model updates that improve training stability and maximize joint benefits through cost-effective parameter adjustments. Meanwhile, JoyAgents-R1 introduces an adaptive memory evolution mechanism that repurposes GRPO rewards as cost-free supervisory signals to eliminate repetitive reasoning and accelerate convergence. Experiments across general and domain-specific scenarios demonstrate that JoyAgents-R1 achieves performance comparable to that of larger LLMs while built on smaller open-source models.",
    "summary": "arXiv:2506.19846v1 Announce Type: new Abstract: Multi-agent reinforcement learning (MARL) has emerged as a prominent paradigm for increasingly complex tasks. However, joint evolution across heterogeneous agents remains challenging due to cooperative inefficiency and training instability. In this paper, we propose the joint evolution dynamics for MARL called JoyAgents-R1, which first applies Group Relative Policy Optimization (GRPO) to the joint training of heterogeneous multi-agents. By iteratively refining agents' large language models (LLMs) and memories, the method achieves holistic equilibrium with optimal decision-making and memory capabilities. Specifically, JoyAgents-R1 first implements node-wise Monte Carlo sampling on the behavior of each agent across entire reasoning trajectories to enhance GRPO sampling efficiency while maintaining policy diversity. Then, our marginal benefit-driven selection strategy identifies top-$K$ sampling groups with maximal reward fluctuations, enabling targeted agent model updates that improve training stability and maximize joint benefits through cost-effective parameter adjustments. Meanwhile, JoyAgents-R1 introduces an adaptive memory evolution mechanism that repurposes GRPO rewards as cost-free supervisory signals to eliminate repetitive reasoning and accelerate convergence. Experiments across general and domain-specific scenarios demonstrate that JoyAgents-R1 achieves performance comparable to that of larger LLMs while built on smaller open-source models.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19846",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "KAG-Thinker: Interactive Thinking and Deep Reasoning in LLMs via Knowledge-Augmented Generation",
    "description": "arXiv:2506.17728v2 Announce Type: replace-cross Abstract: In this paper, we introduce KAG-Thinker, which upgrade KAG to a multi-turn interactive thinking and deep reasoning framework powered by a dedicated parameter-light large language model (LLM). Our approach constructs a structured thinking process for solving complex problems, enhancing the the logical coherence and contextual consistency of the reasoning process in question-answering (Q&amp;A) tasks on domain-specific knowledge bases (KBs) within LLMs. Following the textbf{Logical Form} guided retrieval and reasoning technology route of KAG, this framework first decomposes complex questions into independently solvable sub-problems (which are also referred to as logical forms) through textbf{breadth decomposition}. Each such logical form is represented in two equivalent forms-natural language and logical function-and subsequently classified as either a Knowledge Retrieval or Reasoning Analysis task. Dependencies and parameter passing between these tasks are explicitly modeled via logical function interfaces. In the solving process, the Retrieval function performs retrieval tasks. It retrieves one-hop structured and unstructured information of specified knowledge unit. While the Math and Deduce functions are used to perform reasoning analysis tasks. Secondly, it is worth noting that, in the Knowledge Retrieval sub-problem tasks, LLMs and external knowledge sources are regarded as equivalent KBs. We use the textbf{knowledge boundary} module to determine the optimal source using self-regulatory mechanisms such as confidence calibration and reflective reasoning, and use the textbf{depth solving} module to enhance the comprehensiveness of knowledge acquisition...",
    "summary": "arXiv:2506.17728v2 Announce Type: replace-cross Abstract: In this paper, we introduce KAG-Thinker, which upgrade KAG to a multi-turn interactive thinking and deep reasoning framework powered by a dedicated parameter-light large language model (LLM). Our approach constructs a structured thinking process for solving complex problems, enhancing the the logical coherence and contextual consistency of the reasoning process in question-answering (Q&amp;A) tasks on domain-specific knowledge bases (KBs) within LLMs. Following the textbf{Logical Form} guided retrieval and reasoning technology route of KAG, this framework first decomposes complex questions into independently solvable sub-problems (which are also referred to as logical forms) through textbf{breadth decomposition}. Each such logical form is represented in two equivalent forms-natural language and logical function-and subsequently classified as either a Knowledge Retrieval or Reasoning Analysis task. Dependencies and parameter passing between these tasks are explicitly modeled via logical function interfaces. In the solving process, the Retrieval function performs retrieval tasks. It retrieves one-hop structured and unstructured information of specified knowledge unit. While the Math and Deduce functions are used to perform reasoning analysis tasks. Secondly, it is worth noting that, in the Knowledge Retrieval sub-problem tasks, LLMs and external knowledge sources are regarded as equivalent KBs. We use the textbf{knowledge boundary} module to determine the optimal source using self-regulatory mechanisms such as confidence calibration and reflective reasoning, and use the textbf{depth solving} module to enhance the comprehensiveness of knowledge acquisition...",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.17728",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Kling-Foley: Multimodal Diffusion Transformer for High-Quality Video-to-Audio Generation",
    "description": "arXiv:2506.19774v1 Announce Type: cross Abstract: We propose Kling-Foley, a large-scale multimodal Video-to-Audio generation model that synthesizes high-quality audio synchronized with video content. In Kling-Foley, we introduce multimodal diffusion transformers to model the interactions between video, audio, and text modalities, and combine it with a visual semantic representation module and an audio-visual synchronization module to enhance alignment capabilities. Specifically, these modules align video conditions with latent audio elements at the frame level, thereby improving semantic alignment and audio-visual synchronization. Together with text conditions, this integrated approach enables precise generation of video-matching sound effects. In addition, we propose a universal latent audio codec that can achieve high-quality modeling in various scenarios such as sound effects, speech, singing, and music. We employ a stereo rendering method that imbues synthesized audio with a spatial presence. At the same time, in order to make up for the incomplete types and annotations of the open-source benchmark, we also open-source an industrial-level benchmark Kling-Audio-Eval. Our experiments show that Kling-Foley trained with the flow matching objective achieves new audio-visual SOTA performance among public models in terms of distribution matching, semantic alignment, temporal alignment and audio quality.",
    "summary": "arXiv:2506.19774v1 Announce Type: cross Abstract: We propose Kling-Foley, a large-scale multimodal Video-to-Audio generation model that synthesizes high-quality audio synchronized with video content. In Kling-Foley, we introduce multimodal diffusion transformers to model the interactions between video, audio, and text modalities, and combine it with a visual semantic representation module and an audio-visual synchronization module to enhance alignment capabilities. Specifically, these modules align video conditions with latent audio elements at the frame level, thereby improving semantic alignment and audio-visual synchronization. Together with text conditions, this integrated approach enables precise generation of video-matching sound effects. In addition, we propose a universal latent audio codec that can achieve high-quality modeling in various scenarios such as sound effects, speech, singing, and music. We employ a stereo rendering method that imbues synthesized audio with a spatial presence. At the same time, in order to make up for the incomplete types and annotations of the open-source benchmark, we also open-source an industrial-level benchmark Kling-Audio-Eval. Our experiments show that Kling-Foley trained with the flow matching objective achieves new audio-visual SOTA performance among public models in terms of distribution matching, semantic alignment, temporal alignment and audio quality.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19774",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "KnowRL: Exploring Knowledgeable Reinforcement Learning for Factuality",
    "description": "arXiv:2506.19807v1 Announce Type: new Abstract: Large Language Models (LLMs), particularly slow-thinking models, often exhibit severe hallucination, outputting incorrect content due to an inability to accurately recognize knowledge boundaries during reasoning. While Reinforcement Learning (RL) can enhance complex reasoning abilities, its outcome-oriented reward mechanism often lacks factual supervision over the thinking process, further exacerbating the hallucination problem. To address the high hallucination in slow-thinking models, we propose Knowledge-enhanced RL, KnowRL. KnowRL guides models to perform fact-based slow thinking by integrating a factuality reward, based on knowledge verification, into the RL training process, helping them recognize their knowledge boundaries. KnowRL guides models to perform fact-based slow thinking by integrating a factuality reward, based on knowledge verification, into the RL training process, helping them recognize their knowledge boundaries. This targeted factual input during RL training enables the model to learn and internalize fact-based reasoning strategies. By directly rewarding adherence to facts within the reasoning steps, KnowRL fosters a more reliable thinking process. Experimental results on three hallucination evaluation datasets and two reasoning evaluation datasets demonstrate that KnowRL effectively mitigates hallucinations in slow-thinking models while maintaining their original strong reasoning capabilities. Our code is available at https://github.com/zjunlp/KnowRL.",
    "summary": "arXiv:2506.19807v1 Announce Type: new Abstract: Large Language Models (LLMs), particularly slow-thinking models, often exhibit severe hallucination, outputting incorrect content due to an inability to accurately recognize knowledge boundaries during reasoning. While Reinforcement Learning (RL) can enhance complex reasoning abilities, its outcome-oriented reward mechanism often lacks factual supervision over the thinking process, further exacerbating the hallucination problem. To address the high hallucination in slow-thinking models, we propose Knowledge-enhanced RL, KnowRL. KnowRL guides models to perform fact-based slow thinking by integrating a factuality reward, based on knowledge verification, into the RL training process, helping them recognize their knowledge boundaries. KnowRL guides models to perform fact-based slow thinking by integrating a factuality reward, based on knowledge verification, into the RL training process, helping them recognize their knowledge boundaries. This targeted factual input during RL training enables the model to learn and internalize fact-based reasoning strategies. By directly rewarding adherence to facts within the reasoning steps, KnowRL fosters a more reliable thinking process. Experimental results on three hallucination evaluation datasets and two reasoning evaluation datasets demonstrate that KnowRL effectively mitigates hallucinations in slow-thinking models while maintaining their original strong reasoning capabilities. Our code is available at https://github.com/zjunlp/KnowRL.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19807",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "KunLunBaizeRAG: Reinforcement Learning Driven Inference Performance Leap for Large Language Models",
    "description": "arXiv:2506.19466v1 Announce Type: new Abstract: This paper introduces KunLunBaizeRAG, a reinforcement learning-driven reasoning framework designed to enhance the reasoning capabilities of large language models (LLMs) in complex multi-hop question-answering tasks. The framework addresses key limitations of traditional RAG, such as retrieval drift, information redundancy, and strategy rigidity. Key innovations include the RAG-driven Reasoning Alignment (RDRA) mechanism, the Search-Think Iterative Enhancement (STIE) mechanism, the Network-Local Intelligent Routing (NLR) mechanism, and a progressive hybrid training strategy. Experimental results demonstrate significant improvements in exact match (EM) and LLM-judged score (LJ) across four benchmarks, highlighting the framework's robustness and effectiveness in complex reasoning scenarios.",
    "summary": "arXiv:2506.19466v1 Announce Type: new Abstract: This paper introduces KunLunBaizeRAG, a reinforcement learning-driven reasoning framework designed to enhance the reasoning capabilities of large language models (LLMs) in complex multi-hop question-answering tasks. The framework addresses key limitations of traditional RAG, such as retrieval drift, information redundancy, and strategy rigidity. Key innovations include the RAG-driven Reasoning Alignment (RDRA) mechanism, the Search-Think Iterative Enhancement (STIE) mechanism, the Network-Local Intelligent Routing (NLR) mechanism, and a progressive hybrid training strategy. Experimental results demonstrate significant improvements in exact match (EM) and LLM-judged score (LJ) across four benchmarks, highlighting the framework's robustness and effectiveness in complex reasoning scenarios.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19466",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Language Model Re-rankers are Fooled by Lexical Similarities",
    "description": "arXiv:2502.17036v2 Announce Type: replace-cross Abstract: Language model (LM) re-rankers are used to refine retrieval results for retrieval-augmented generation (RAG). They are more expensive than lexical matching methods like BM25 but assumed to better process semantic information and the relations between the query and the retrieved answers. To understand whether LM re-rankers always live up to this assumption, we evaluate 6 different LM re-rankers on the NQ, LitQA2 and DRUID datasets. Our results show that LM re-rankers struggle to outperform a simple BM25 baseline on DRUID. Leveraging a novel separation metric based on BM25 scores, we explain and identify re-ranker errors stemming from lexical dissimilarities. We also investigate different methods to improve LM re-ranker performance and find these methods mainly useful for NQ. Taken together, our work identifies and explains weaknesses of LM re-rankers and points to the need for more adversarial and realistic datasets for their evaluation.",
    "summary": "arXiv:2502.17036v2 Announce Type: replace-cross Abstract: Language model (LM) re-rankers are used to refine retrieval results for retrieval-augmented generation (RAG). They are more expensive than lexical matching methods like BM25 but assumed to better process semantic information and the relations between the query and the retrieved answers. To understand whether LM re-rankers always live up to this assumption, we evaluate 6 different LM re-rankers on the NQ, LitQA2 and DRUID datasets. Our results show that LM re-rankers struggle to outperform a simple BM25 baseline on DRUID. Leveraging a novel separation metric based on BM25 scores, we explain and identify re-ranker errors stemming from lexical dissimilarities. We also investigate different methods to improve LM re-ranker performance and find these methods mainly useful for NQ. Taken together, our work identifies and explains weaknesses of LM re-rankers and points to the need for more adversarial and realistic datasets for their evaluation.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2502.17036",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Language Models Might Not Understand You: Evaluating Theory of Mind via Story Prompting",
    "description": "arXiv:2506.19089v1 Announce Type: cross Abstract: We introduce $texttt{StorySim}$, a programmable framework for synthetically generating stories to evaluate the theory of mind (ToM) and world modeling (WM) capabilities of large language models (LLMs). Unlike prior benchmarks that may suffer from contamination in pretraining data, $texttt{StorySim}$ produces novel, compositional story prompts anchored by a highly controllable $texttt{Storyboard}$, enabling precise manipulation of character perspectives and events. We use this framework to design first- and second-order ToM tasks alongside WM tasks that control for the ability to track and model mental states. Our experiments across a suite of state-of-the-art LLMs reveal that most models perform better on WM tasks than ToM tasks, and that models tend to perform better reasoning with humans compared to inanimate objects. Additionally, our framework enabled us to find evidence of heuristic behavior such as recency bias and an over-reliance on earlier events in the story. All code for generating data and evaluations is freely available.",
    "summary": "arXiv:2506.19089v1 Announce Type: cross Abstract: We introduce $texttt{StorySim}$, a programmable framework for synthetically generating stories to evaluate the theory of mind (ToM) and world modeling (WM) capabilities of large language models (LLMs). Unlike prior benchmarks that may suffer from contamination in pretraining data, $texttt{StorySim}$ produces novel, compositional story prompts anchored by a highly controllable $texttt{Storyboard}$, enabling precise manipulation of character perspectives and events. We use this framework to design first- and second-order ToM tasks alongside WM tasks that control for the ability to track and model mental states. Our experiments across a suite of state-of-the-art LLMs reveal that most models perform better on WM tasks than ToM tasks, and that models tend to perform better reasoning with humans compared to inanimate objects. Additionally, our framework enabled us to find evidence of heuristic behavior such as recency bias and an over-reliance on earlier events in the story. All code for generating data and evaluations is freely available.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19089",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Large language models for automated scholarly paper review: A survey",
    "description": "arXiv:2501.10326v2 Announce Type: replace Abstract: Large language models (LLMs) have significantly impacted human society, influencing various domains. Among them, academia is not simply a domain affected by LLMs, but it is also the pivotal force in the development of LLMs. In academic publication, this phenomenon is represented during the incorporation of LLMs into the peer review mechanism for reviewing manuscripts. LLMs hold transformative potential for the full-scale implementation of automated scholarly paper review (ASPR), but they also pose new issues and challenges that need to be addressed. In this survey paper, we aim to provide a holistic view of ASPR in the era of LLMs. We begin with a survey to find out which LLMs are used to conduct ASPR. Then, we review what ASPR-related technological bottlenecks have been solved with the incorporation of LLM technology. After that, we move on to explore new methods, new datasets, new source code, and new online systems that come with LLMs for ASPR. Furthermore, we summarize the performance and issues of LLMs in ASPR, and investigate the attitudes and reactions of publishers and academia to ASPR. Lastly, we discuss the challenges and future directions associated with the development of LLMs for ASPR. This survey serves as an inspirational reference for the researchers and can promote the progress of ASPR for its actual implementation.",
    "summary": "arXiv:2501.10326v2 Announce Type: replace Abstract: Large language models (LLMs) have significantly impacted human society, influencing various domains. Among them, academia is not simply a domain affected by LLMs, but it is also the pivotal force in the development of LLMs. In academic publication, this phenomenon is represented during the incorporation of LLMs into the peer review mechanism for reviewing manuscripts. LLMs hold transformative potential for the full-scale implementation of automated scholarly paper review (ASPR), but they also pose new issues and challenges that need to be addressed. In this survey paper, we aim to provide a holistic view of ASPR in the era of LLMs. We begin with a survey to find out which LLMs are used to conduct ASPR. Then, we review what ASPR-related technological bottlenecks have been solved with the incorporation of LLM technology. After that, we move on to explore new methods, new datasets, new source code, and new online systems that come with LLMs for ASPR. Furthermore, we summarize the performance and issues of LLMs in ASPR, and investigate the attitudes and reactions of publishers and academia to ASPR. Lastly, we discuss the challenges and future directions associated with the development of LLMs for ASPR. This survey serves as an inspirational reference for the researchers and can promote the progress of ASPR for its actual implementation.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2501.10326",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "LAuReL: Learned Augmented Residual Layer",
    "description": "arXiv:2411.07501v4 Announce Type: replace-cross Abstract: One of the core pillars of efficient deep learning methods is architectural improvements such as the residual/skip connection, which has led to significantly better model convergence and quality. Since then the residual connection has become ubiquitous in not just convolutional neural networks but also transformer-based architectures, the backbone of LLMs. In this paper we introduce Learned Augmented Residual Layer (LAuReL) -- a novel generalization of the canonical residual connection -- with the goal to be an in-situ replacement of the latter while outperforming on both model quality and footprint metrics. Our experiments show that using LAuReL can help boost performance for both vision and language models. For example, on the ResNet-50, ImageNet 1K task, it achieves 60% of the gains from adding an extra layer, while only adding 0.003% more parameters, and matches it while adding 2.6 times fewer parameters. Similarly, when pre-training 1B and 4B parameter LLMs, LAuReL improves performance on a variety of challenging downstream evaluation tasks by 2.54% to 20.05%, while adding only 0.012% and 0.1% additional parameters, respectively.",
    "summary": "arXiv:2411.07501v4 Announce Type: replace-cross Abstract: One of the core pillars of efficient deep learning methods is architectural improvements such as the residual/skip connection, which has led to significantly better model convergence and quality. Since then the residual connection has become ubiquitous in not just convolutional neural networks but also transformer-based architectures, the backbone of LLMs. In this paper we introduce Learned Augmented Residual Layer (LAuReL) -- a novel generalization of the canonical residual connection -- with the goal to be an in-situ replacement of the latter while outperforming on both model quality and footprint metrics. Our experiments show that using LAuReL can help boost performance for both vision and language models. For example, on the ResNet-50, ImageNet 1K task, it achieves 60% of the gains from adding an extra layer, while only adding 0.003% more parameters, and matches it while adding 2.6 times fewer parameters. Similarly, when pre-training 1B and 4B parameter LLMs, LAuReL improves performance on a variety of challenging downstream evaluation tasks by 2.54% to 20.05%, while adding only 0.012% and 0.1% additional parameters, respectively.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2411.07501",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Learning Task Belief Similarity with Latent Dynamics for Meta-Reinforcement Learning",
    "description": "arXiv:2506.19785v1 Announce Type: new Abstract: Meta-reinforcement learning requires utilizing prior task distribution information obtained during exploration to rapidly adapt to unknown tasks. The efficiency of an agent's exploration hinges on accurately identifying the current task. Recent Bayes-Adaptive Deep RL approaches often rely on reconstructing the environment's reward signal, which is challenging in sparse reward settings, leading to suboptimal exploitation. Inspired by bisimulation metrics, which robustly extracts behavioral similarity in continuous MDPs, we propose SimBelief-a novel meta-RL framework via measuring similarity of task belief in Bayes-Adaptive MDP (BAMDP). SimBelief effectively extracts common features of similar task distributions, enabling efficient task identification and exploration in sparse reward environments. We introduce latent task belief metric to learn the common structure of similar tasks and incorporate it into the specific task belief. By learning the latent dynamics across task distributions, we connect shared latent task belief features with specific task features, facilitating rapid task identification and adaptation. Our method outperforms state-of-the-art baselines on sparse reward MuJoCo and panda-gym tasks.",
    "summary": "arXiv:2506.19785v1 Announce Type: new Abstract: Meta-reinforcement learning requires utilizing prior task distribution information obtained during exploration to rapidly adapt to unknown tasks. The efficiency of an agent's exploration hinges on accurately identifying the current task. Recent Bayes-Adaptive Deep RL approaches often rely on reconstructing the environment's reward signal, which is challenging in sparse reward settings, leading to suboptimal exploitation. Inspired by bisimulation metrics, which robustly extracts behavioral similarity in continuous MDPs, we propose SimBelief-a novel meta-RL framework via measuring similarity of task belief in Bayes-Adaptive MDP (BAMDP). SimBelief effectively extracts common features of similar task distributions, enabling efficient task identification and exploration in sparse reward environments. We introduce latent task belief metric to learn the common structure of similar tasks and incorporate it into the specific task belief. By learning the latent dynamics across task distributions, we connect shared latent task belief features with specific task features, facilitating rapid task identification and adaptation. Our method outperforms state-of-the-art baselines on sparse reward MuJoCo and panda-gym tasks.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19785",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Lemmanaid: Neuro-Symbolic Lemma Conjecturing",
    "description": "arXiv:2504.04942v3 Announce Type: replace Abstract: Automatically conjecturing useful, interesting and novel lemmas would greatly improve automated reasoning tools and lower the bar for formalizing mathematics in proof assistants. It is however a very challenging task for both neural and symbolic approaches. We present the first steps towards a practical neuro-symbolic lemma conjecturing tool, Lemmanaid, that combines Large Language Models (LLMs) and symbolic methods, and evaluate it on proof libraries for the Isabelle proof assistant. We train an LLM to generate lemma templates that describe the shape of a lemma, and use symbolic methods to fill in the details. We compare Lemmanaid against an LLM trained to generate complete lemma statements as well as previous fully symbolic conjecturing methods. Lemmanaid outperforms both neural and symbolic methods on test sets from Isabelle's HOL library and from its Archive of Formal Proofs, discovering between 29-39.5% of the gold standard human written lemmas. This is 8-15% more lemmas than the neural-only method. By leveraging the best of both symbolic and neural methods we can generate useful lemmas for a wide range of input domains, facilitating computer-assisted theory development and formalization.",
    "summary": "arXiv:2504.04942v3 Announce Type: replace Abstract: Automatically conjecturing useful, interesting and novel lemmas would greatly improve automated reasoning tools and lower the bar for formalizing mathematics in proof assistants. It is however a very challenging task for both neural and symbolic approaches. We present the first steps towards a practical neuro-symbolic lemma conjecturing tool, Lemmanaid, that combines Large Language Models (LLMs) and symbolic methods, and evaluate it on proof libraries for the Isabelle proof assistant. We train an LLM to generate lemma templates that describe the shape of a lemma, and use symbolic methods to fill in the details. We compare Lemmanaid against an LLM trained to generate complete lemma statements as well as previous fully symbolic conjecturing methods. Lemmanaid outperforms both neural and symbolic methods on test sets from Isabelle's HOL library and from its Archive of Formal Proofs, discovering between 29-39.5% of the gold standard human written lemmas. This is 8-15% more lemmas than the neural-only method. By leveraging the best of both symbolic and neural methods we can generate useful lemmas for a wide range of input domains, facilitating computer-assisted theory development and formalization.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2504.04942",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Leveraging Large Language Models to Democratize Access to Costly Datasets for Academic Research",
    "description": "arXiv:2412.02065v2 Announce Type: replace-cross Abstract: Unequal access to costly datasets essential for empirical research has long hindered researchers from disadvantaged institutions, limiting their ability to contribute to their fields and advance their careers. Recent breakthroughs in Large Language Models (LLMs) have the potential to democratize data access by automating data collection from unstructured sources. We develop and evaluate a novel methodology using GPT-4o-mini within a Retrieval-Augmented Generation (RAG) framework to collect data from corporate disclosures. Our approach achieves human-level accuracy in collecting CEO pay ratios from approximately 10,000 proxy statements and Critical Audit Matters (CAMs) from more than 12,000 10-K filings, with LLM processing times of 9 and 40 minutes respectively, each at a cost under $10. This stands in stark contrast to the hundreds of hours needed for manual collection or the thousands of dollars required for commercial database subscriptions. To foster a more inclusive research community by empowering researchers with limited resources to explore new avenues of inquiry, we share our methodology and the resulting datasets.",
    "summary": "arXiv:2412.02065v2 Announce Type: replace-cross Abstract: Unequal access to costly datasets essential for empirical research has long hindered researchers from disadvantaged institutions, limiting their ability to contribute to their fields and advance their careers. Recent breakthroughs in Large Language Models (LLMs) have the potential to democratize data access by automating data collection from unstructured sources. We develop and evaluate a novel methodology using GPT-4o-mini within a Retrieval-Augmented Generation (RAG) framework to collect data from corporate disclosures. Our approach achieves human-level accuracy in collecting CEO pay ratios from approximately 10,000 proxy statements and Critical Audit Matters (CAMs) from more than 12,000 10-K filings, with LLM processing times of 9 and 40 minutes respectively, each at a cost under $10. This stands in stark contrast to the hundreds of hours needed for manual collection or the thousands of dollars required for commercial database subscriptions. To foster a more inclusive research community by empowering researchers with limited resources to explore new avenues of inquiry, we share our methodology and the resulting datasets.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2412.02065",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "LLM-Driven Medical Document Analysis: Enhancing Trustworthy Pathology and Differential Diagnosis",
    "description": "arXiv:2506.19702v1 Announce Type: new Abstract: Medical document analysis plays a crucial role in extracting essential clinical insights from unstructured healthcare records, supporting critical tasks such as differential diagnosis. Determining the most probable condition among overlapping symptoms requires precise evaluation and deep medical expertise. While recent advancements in large language models (LLMs) have significantly enhanced performance in medical document analysis, privacy concerns related to sensitive patient data limit the use of online LLMs services in clinical settings. To address these challenges, we propose a trustworthy medical document analysis platform that fine-tunes a LLaMA-v3 using low-rank adaptation, specifically optimized for differential diagnosis tasks. Our approach utilizes DDXPlus, the largest benchmark dataset for differential diagnosis, and demonstrates superior performance in pathology prediction and variable-length differential diagnosis compared to existing methods. The developed web-based platform allows users to submit their own unstructured medical documents and receive accurate, explainable diagnostic results. By incorporating advanced explainability techniques, the system ensures transparent and reliable predictions, fostering user trust and confidence. Extensive evaluations confirm that the proposed method surpasses current state-of-the-art models in predictive accuracy while offering practical utility in clinical settings. This work addresses the urgent need for reliable, explainable, and privacy-preserving artificial intelligence solutions, representing a significant advancement in intelligent medical document analysis for real-world healthcare applications. The code can be found at href{https://github.com/leitro/Differential-Diagnosis-LoRA}{https://github.com/leitro/Differential-Diagnosis-LoRA}.",
    "summary": "arXiv:2506.19702v1 Announce Type: new Abstract: Medical document analysis plays a crucial role in extracting essential clinical insights from unstructured healthcare records, supporting critical tasks such as differential diagnosis. Determining the most probable condition among overlapping symptoms requires precise evaluation and deep medical expertise. While recent advancements in large language models (LLMs) have significantly enhanced performance in medical document analysis, privacy concerns related to sensitive patient data limit the use of online LLMs services in clinical settings. To address these challenges, we propose a trustworthy medical document analysis platform that fine-tunes a LLaMA-v3 using low-rank adaptation, specifically optimized for differential diagnosis tasks. Our approach utilizes DDXPlus, the largest benchmark dataset for differential diagnosis, and demonstrates superior performance in pathology prediction and variable-length differential diagnosis compared to existing methods. The developed web-based platform allows users to submit their own unstructured medical documents and receive accurate, explainable diagnostic results. By incorporating advanced explainability techniques, the system ensures transparent and reliable predictions, fostering user trust and confidence. Extensive evaluations confirm that the proposed method surpasses current state-of-the-art models in predictive accuracy while offering practical utility in clinical settings. This work addresses the urgent need for reliable, explainable, and privacy-preserving artificial intelligence solutions, representing a significant advancement in intelligent medical document analysis for real-world healthcare applications. The code can be found at href{https://github.com/leitro/Differential-Diagnosis-LoRA}{https://github.com/leitro/Differential-Diagnosis-LoRA}.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19702",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "LLMs on a Budget? Say HOLA",
    "description": "arXiv:2506.18952v1 Announce Type: cross Abstract: Running Large Language Models (LLMs) on edge devices is constrained by high compute and memory demands posing a barrier for real-time applications in sectors like healthcare, education, and embedded systems. Current solutions such as quantization, pruning, and retrieval-augmented generation (RAG) offer only partial optimizations and often compromise on speed or accuracy. We introduce HOLA, an end-to-end optimization framework for efficient LLM deployment. Internally, it leverages Hierarchical Speculative Decoding (HSD) for faster inference without quality loss. Externally, AdaComp-RAG adjusts retrieval complexity based on context needs. Together with LoBi, which blends structured pruning (LoRA) and quantization, HOLA delivers significant gains: 17.6% EMA on GSM8K, 10.5% MCA on ARC, and reduced latency and memory on edge devices like Jetson Nano--proving both scalable and production-ready.",
    "summary": "arXiv:2506.18952v1 Announce Type: cross Abstract: Running Large Language Models (LLMs) on edge devices is constrained by high compute and memory demands posing a barrier for real-time applications in sectors like healthcare, education, and embedded systems. Current solutions such as quantization, pruning, and retrieval-augmented generation (RAG) offer only partial optimizations and often compromise on speed or accuracy. We introduce HOLA, an end-to-end optimization framework for efficient LLM deployment. Internally, it leverages Hierarchical Speculative Decoding (HSD) for faster inference without quality loss. Externally, AdaComp-RAG adjusts retrieval complexity based on context needs. Together with LoBi, which blends structured pruning (LoRA) and quantization, HOLA delivers significant gains: 17.6% EMA on GSM8K, 10.5% MCA on ARC, and reduced latency and memory on edge devices like Jetson Nano--proving both scalable and production-ready.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.18952",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Local Look-Ahead Guidance via Verifier-in-the-Loop for Automated Theorem Proving",
    "description": "arXiv:2503.09730v2 Announce Type: replace Abstract: The most promising recent methods for AI reasoning require applying variants of reinforcement learning (RL) either on rolled out trajectories from the LLMs, even for the step-wise rewards, or large quantities of human-annotated trajectory data. The reliance on the rolled-out trajectory renders the compute cost and time prohibitively high. In particular, the correctness of a reasoning trajectory can typically only be judged at its completion, leading to sparse rewards in RL or requiring expensive synthetic data generation in expert iteration-like methods. In this work, we focus on the Automatic Theorem Proving (ATP) task and propose a novel verifier-in-the-loop design, which, unlike existing approaches that leverage feedback on the entire reasoning trajectory, employs an automated verifier to give intermediate feedback at each step of the reasoning process. Using Lean as the verifier, we empirically show that the step-by-step local verification produces a global improvement in the model's reasoning accuracy and efficiency.",
    "summary": "arXiv:2503.09730v2 Announce Type: replace Abstract: The most promising recent methods for AI reasoning require applying variants of reinforcement learning (RL) either on rolled out trajectories from the LLMs, even for the step-wise rewards, or large quantities of human-annotated trajectory data. The reliance on the rolled-out trajectory renders the compute cost and time prohibitively high. In particular, the correctness of a reasoning trajectory can typically only be judged at its completion, leading to sparse rewards in RL or requiring expensive synthetic data generation in expert iteration-like methods. In this work, we focus on the Automatic Theorem Proving (ATP) task and propose a novel verifier-in-the-loop design, which, unlike existing approaches that leverage feedback on the entire reasoning trajectory, employs an automated verifier to give intermediate feedback at each step of the reasoning process. Using Lean as the verifier, we empirically show that the step-by-step local verification produces a global improvement in the model's reasoning accuracy and efficiency.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2503.09730",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Long-Context Generalization with Sparse Attention",
    "description": "arXiv:2506.16640v2 Announce Type: replace-cross Abstract: Transformer-based architectures traditionally employ softmax to compute attention weights, which produces dense distributions over all tokens in a sequence. While effective in many settings, this density has been shown to be detrimental for tasks that demand precise focus on fixed-size patterns: as sequence length increases, non-informative tokens accumulate attention probability mass, leading to dispersion and representational collapse. We show in this paper that sparse attention mechanisms using $alpha$-entmax can avoid these issues, due to their ability to assign exact zeros to irrelevant tokens. Furthermore, we introduce Adaptive-Scalable Entmax (ASEntmax), which endows $alpha$-entmax with a learnable temperature parameter, allowing the attention distribution to interpolate between sparse (pattern-focused) and dense (softmax-like) regimes. Finally, we show that the ability to locate and generalize fixed-size patterns can be further improved through a careful design of position encodings, which impacts both dense and sparse attention methods. By integrating ASEntmax into standard transformer layers alongside proper positional encodings, we show that our models greatly outperform softmax, scalable softmax, and fixed-temperature $alpha$-entmax baselines on long-context generalization.",
    "summary": "arXiv:2506.16640v2 Announce Type: replace-cross Abstract: Transformer-based architectures traditionally employ softmax to compute attention weights, which produces dense distributions over all tokens in a sequence. While effective in many settings, this density has been shown to be detrimental for tasks that demand precise focus on fixed-size patterns: as sequence length increases, non-informative tokens accumulate attention probability mass, leading to dispersion and representational collapse. We show in this paper that sparse attention mechanisms using $alpha$-entmax can avoid these issues, due to their ability to assign exact zeros to irrelevant tokens. Furthermore, we introduce Adaptive-Scalable Entmax (ASEntmax), which endows $alpha$-entmax with a learnable temperature parameter, allowing the attention distribution to interpolate between sparse (pattern-focused) and dense (softmax-like) regimes. Finally, we show that the ability to locate and generalize fixed-size patterns can be further improved through a careful design of position encodings, which impacts both dense and sparse attention methods. By integrating ASEntmax into standard transformer layers alongside proper positional encodings, we show that our models greatly outperform softmax, scalable softmax, and fixed-temperature $alpha$-entmax baselines on long-context generalization.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16640",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Lost in Translation? Converting RegExes for Log Parsing into Dynatrace Pattern Language",
    "description": "arXiv:2506.19539v1 Announce Type: cross Abstract: Log files provide valuable information for detecting and diagnosing problems in enterprise software applications and data centers. Several log analytics tools and platforms were developed to help filter and extract information from logs, typically using regular expressions (RegExes). Recent commercial log analytics platforms provide domain-specific languages specifically designed for log parsing, such as Grok or the Dynatrace Pattern Language (DPL). However, users who want to migrate to these platforms must manually convert their RegExes into the new pattern language, which is costly and error-prone. In this work, we present Reptile, which combines a rule-based approach for converting RegExes into DPL patterns with a best-effort approach for cases where a full conversion is impossible. Furthermore, it integrates GPT-4 to optimize the obtained DPL patterns. The evaluation with 946 RegExes collected from a large company shows that Reptile safely converted 73.7% of them. The evaluation of Reptile's pattern optimization with 23 real-world RegExes showed an F1-score and MCC above 0.91. These results are promising and have ample practical implications for companies that migrate to a modern log analytics platform, such as Dynatrace.",
    "summary": "arXiv:2506.19539v1 Announce Type: cross Abstract: Log files provide valuable information for detecting and diagnosing problems in enterprise software applications and data centers. Several log analytics tools and platforms were developed to help filter and extract information from logs, typically using regular expressions (RegExes). Recent commercial log analytics platforms provide domain-specific languages specifically designed for log parsing, such as Grok or the Dynatrace Pattern Language (DPL). However, users who want to migrate to these platforms must manually convert their RegExes into the new pattern language, which is costly and error-prone. In this work, we present Reptile, which combines a rule-based approach for converting RegExes into DPL patterns with a best-effort approach for cases where a full conversion is impossible. Furthermore, it integrates GPT-4 to optimize the obtained DPL patterns. The evaluation with 946 RegExes collected from a large company shows that Reptile safely converted 73.7% of them. The evaluation of Reptile's pattern optimization with 23 real-world RegExes showed an F1-score and MCC above 0.91. These results are promising and have ample practical implications for companies that migrate to a modern log analytics platform, such as Dynatrace.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19539",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "MambaOutRS: A Hybrid CNN-Fourier Architecture for Remote Sensing Image Classification",
    "description": "arXiv:2506.19561v1 Announce Type: cross Abstract: Recent advances in deep learning for vision tasks have seen the rise of State Space Models (SSMs) like Mamba, celebrated for their linear scalability. However, their adaptation to 2D visual data often necessitates complex modifications that may diminish efficiency. In this paper, we introduce MambaOutRS, a novel hybrid convolutional architecture for remote sensing image classification that re-evaluates the necessity of recurrent SSMs. MambaOutRS builds upon stacked Gated CNN blocks for local feature extraction and introduces a novel Fourier Filter Gate (FFG) module that operates in the frequency domain to capture global contextual information efficiently. Our architecture employs a four-stage hierarchical design and was extensively evaluated on challenging remote sensing datasets: UC Merced, AID, NWPU-RESISC45, and EuroSAT. MambaOutRS consistently achieved state-of-the-art (SOTA) performance across these benchmarks. Notably, our MambaOutRS-t variant (24.0M parameters) attained the highest F1-scores of 98.41% on UC Merced and 95.99% on AID, significantly outperforming existing baselines, including larger transformer models and Mamba-based architectures, despite using considerably fewer parameters. An ablation study conclusively demonstrates the critical role of the Fourier Filter Gate in enhancing the model's ability to capture global spatial patterns, leading to robust and accurate classification. These results strongly suggest that the complexities of recurrent SSMs can be effectively superseded by a judicious combination of gated convolutions for spatial mixing and frequency-based gates for spectral global context. Thus, MambaOutRS provides a compelling and efficient paradigm for developing high-performance deep learning models in remote sensing and other vision domains, particularly where computational efficiency is paramount.",
    "summary": "arXiv:2506.19561v1 Announce Type: cross Abstract: Recent advances in deep learning for vision tasks have seen the rise of State Space Models (SSMs) like Mamba, celebrated for their linear scalability. However, their adaptation to 2D visual data often necessitates complex modifications that may diminish efficiency. In this paper, we introduce MambaOutRS, a novel hybrid convolutional architecture for remote sensing image classification that re-evaluates the necessity of recurrent SSMs. MambaOutRS builds upon stacked Gated CNN blocks for local feature extraction and introduces a novel Fourier Filter Gate (FFG) module that operates in the frequency domain to capture global contextual information efficiently. Our architecture employs a four-stage hierarchical design and was extensively evaluated on challenging remote sensing datasets: UC Merced, AID, NWPU-RESISC45, and EuroSAT. MambaOutRS consistently achieved state-of-the-art (SOTA) performance across these benchmarks. Notably, our MambaOutRS-t variant (24.0M parameters) attained the highest F1-scores of 98.41% on UC Merced and 95.99% on AID, significantly outperforming existing baselines, including larger transformer models and Mamba-based architectures, despite using considerably fewer parameters. An ablation study conclusively demonstrates the critical role of the Fourier Filter Gate in enhancing the model's ability to capture global spatial patterns, leading to robust and accurate classification. These results strongly suggest that the complexities of recurrent SSMs can be effectively superseded by a judicious combination of gated convolutions for spatial mixing and frequency-based gates for spectral global context. Thus, MambaOutRS provides a compelling and efficient paradigm for developing high-performance deep learning models in remote sensing and other vision domains, particularly where computational efficiency is paramount.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19561",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "MATE: LLM-Powered Multi-Agent Translation Environment for Accessibility Applications",
    "description": "arXiv:2506.19502v1 Announce Type: cross Abstract: Accessibility remains a critical concern in today's society, as many technologies are not developed to support the full range of user needs. Existing multi-agent systems (MAS) often cannot provide comprehensive assistance for users in need due to the lack of customization stemming from closed-source designs. Consequently, individuals with disabilities frequently encounter significant barriers when attempting to interact with digital environments. We introduce MATE, a multimodal accessibility MAS, which performs the modality conversions based on the user's needs. The system is useful for assisting people with disabilities by ensuring that data will be converted to an understandable format. For instance, if the user cannot see well and receives an image, the system converts this image to its audio description. MATE can be applied to a wide range of domains, industries, and areas, such as healthcare, and can become a useful assistant for various groups of users. The system supports multiple types of models, ranging from LLM API calling to using custom machine learning (ML) classifiers. This flexibility ensures that the system can be adapted to various needs and is compatible with a wide variety of hardware. Since the system is expected to run locally, it ensures the privacy and security of sensitive information. In addition, the framework can be effectively integrated with institutional technologies (e.g., digital healthcare service) for real-time user assistance. Furthermore, we introduce ModCon-Task-Identifier, a model that is capable of extracting the precise modality conversion task from the user input. Numerous experiments show that ModCon-Task-Identifier consistently outperforms other LLMs and statistical models on our custom data. Our code and data are publicly available at https://github.com/AlgazinovAleksandr/Multi-Agent-MATE.",
    "summary": "arXiv:2506.19502v1 Announce Type: cross Abstract: Accessibility remains a critical concern in today's society, as many technologies are not developed to support the full range of user needs. Existing multi-agent systems (MAS) often cannot provide comprehensive assistance for users in need due to the lack of customization stemming from closed-source designs. Consequently, individuals with disabilities frequently encounter significant barriers when attempting to interact with digital environments. We introduce MATE, a multimodal accessibility MAS, which performs the modality conversions based on the user's needs. The system is useful for assisting people with disabilities by ensuring that data will be converted to an understandable format. For instance, if the user cannot see well and receives an image, the system converts this image to its audio description. MATE can be applied to a wide range of domains, industries, and areas, such as healthcare, and can become a useful assistant for various groups of users. The system supports multiple types of models, ranging from LLM API calling to using custom machine learning (ML) classifiers. This flexibility ensures that the system can be adapted to various needs and is compatible with a wide variety of hardware. Since the system is expected to run locally, it ensures the privacy and security of sensitive information. In addition, the framework can be effectively integrated with institutional technologies (e.g., digital healthcare service) for real-time user assistance. Furthermore, we introduce ModCon-Task-Identifier, a model that is capable of extracting the precise modality conversion task from the user input. Numerous experiments show that ModCon-Task-Identifier consistently outperforms other LLMs and statistical models on our custom data. Our code and data are publicly available at https://github.com/AlgazinovAleksandr/Multi-Agent-MATE.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19502",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "MCP-Zero: Active Tool Discovery for Autonomous LLM Agents",
    "description": "arXiv:2506.01056v4 Announce Type: replace Abstract: True intelligence requires active capability acquisition, yet current LLM agents inject pre-defined tool schemas into prompts, reducing models to passive selectors and falling short of robust general-purpose agency. We introduce MCP-Zero, an active agent framework that restores tool discovery autonomy to LLMs themselves. Instead of overwhelming models with all available tools, MCP-Zero enables agents to actively identify capability gaps, and request specific tools on-demand, transforming them from large-scale retrievers into genuine autonomous agents. The framework operates through three core mechanisms: (1) Active Tool Request, where models autonomously generate structured requests specifying their exact tool requirements; (2) Hierarchical Semantic Routing, a two-stage algorithm that matches requests to relevant servers and tools through improved semantic alignment; (3) Iterative Capability Extension, enabling agents to progressively build cross-domain toolchains while maintaining minimal context footprint. We construct MCP-tools, a comprehensive dataset of 308 MCP servers and 2,797 tools from the official Model-Context-Protocol repository. Experiments demonstrate that MCP-Zero preserves agent autonomy while achieving substantial efficiency gains: (i) accurate tool selection from nearly 3k candidates across 248.1k tokens; (ii) 98% reduction in token consumption on APIBank while maintaining high accuracy; and (iii) consistent multi-turn performance that scales with tool ecosystem growth. This work establishes active tool discovery as a fundamental design pattern for scalable autonomous agent systems.",
    "summary": "arXiv:2506.01056v4 Announce Type: replace Abstract: True intelligence requires active capability acquisition, yet current LLM agents inject pre-defined tool schemas into prompts, reducing models to passive selectors and falling short of robust general-purpose agency. We introduce MCP-Zero, an active agent framework that restores tool discovery autonomy to LLMs themselves. Instead of overwhelming models with all available tools, MCP-Zero enables agents to actively identify capability gaps, and request specific tools on-demand, transforming them from large-scale retrievers into genuine autonomous agents. The framework operates through three core mechanisms: (1) Active Tool Request, where models autonomously generate structured requests specifying their exact tool requirements; (2) Hierarchical Semantic Routing, a two-stage algorithm that matches requests to relevant servers and tools through improved semantic alignment; (3) Iterative Capability Extension, enabling agents to progressively build cross-domain toolchains while maintaining minimal context footprint. We construct MCP-tools, a comprehensive dataset of 308 MCP servers and 2,797 tools from the official Model-Context-Protocol repository. Experiments demonstrate that MCP-Zero preserves agent autonomy while achieving substantial efficiency gains: (i) accurate tool selection from nearly 3k candidates across 248.1k tokens; (ii) 98% reduction in token consumption on APIBank while maintaining high accuracy; and (iii) consistent multi-turn performance that scales with tool ecosystem growth. This work establishes active tool discovery as a fundamental design pattern for scalable autonomous agent systems.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.01056",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "MedErr-CT: A Visual Question Answering Benchmark for Identifying and Correcting Errors in CT Reports",
    "description": "arXiv:2506.19217v1 Announce Type: cross Abstract: Computed Tomography (CT) plays a crucial role in clinical diagnosis, but the growing demand for CT examinations has raised concerns about diagnostic errors. While Multimodal Large Language Models (MLLMs) demonstrate promising comprehension of medical knowledge, their tendency to produce inaccurate information highlights the need for rigorous validation. However, existing medical visual question answering (VQA) benchmarks primarily focus on simple visual recognition tasks, lacking clinical relevance and failing to assess expert-level knowledge. We introduce MedErr-CT, a novel benchmark for evaluating medical MLLMs' ability to identify and correct errors in CT reports through a VQA framework. The benchmark includes six error categories - four vision-centric errors (Omission, Insertion, Direction, Size) and two lexical error types (Unit, Typo) - and is organized into three task levels: classification, detection, and correction. Using this benchmark, we quantitatively assess the performance of state-of-the-art 3D medical MLLMs, revealing substantial variation in their capabilities across different error types. Our benchmark contributes to the development of more reliable and clinically applicable MLLMs, ultimately helping reduce diagnostic errors and improve accuracy in clinical practice. The code and datasets are available at https://github.com/babbu3682/MedErr-CT.",
    "summary": "arXiv:2506.19217v1 Announce Type: cross Abstract: Computed Tomography (CT) plays a crucial role in clinical diagnosis, but the growing demand for CT examinations has raised concerns about diagnostic errors. While Multimodal Large Language Models (MLLMs) demonstrate promising comprehension of medical knowledge, their tendency to produce inaccurate information highlights the need for rigorous validation. However, existing medical visual question answering (VQA) benchmarks primarily focus on simple visual recognition tasks, lacking clinical relevance and failing to assess expert-level knowledge. We introduce MedErr-CT, a novel benchmark for evaluating medical MLLMs' ability to identify and correct errors in CT reports through a VQA framework. The benchmark includes six error categories - four vision-centric errors (Omission, Insertion, Direction, Size) and two lexical error types (Unit, Typo) - and is organized into three task levels: classification, detection, and correction. Using this benchmark, we quantitatively assess the performance of state-of-the-art 3D medical MLLMs, revealing substantial variation in their capabilities across different error types. Our benchmark contributes to the development of more reliable and clinically applicable MLLMs, ultimately helping reduce diagnostic errors and improve accuracy in clinical practice. The code and datasets are available at https://github.com/babbu3682/MedErr-CT.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19217",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Mem4Nav: Boosting Vision-and-Language Navigation in Urban Environments with a Hierarchical Spatial-Cognition Long-Short Memory System",
    "description": "arXiv:2506.19433v1 Announce Type: cross Abstract: Vision-and-Language Navigation (VLN) in large-scale urban environments requires embodied agents to ground linguistic instructions in complex scenes and recall relevant experiences over extended time horizons. Prior modular pipelines offer interpretability but lack unified memory, while end-to-end (M)LLM agents excel at fusing vision and language yet remain constrained by fixed context windows and implicit spatial reasoning. We introduce textbf{Mem4Nav}, a hierarchical spatial-cognition long-short memory system that can augment any VLN backbone. Mem4Nav fuses a sparse octree for fine-grained voxel indexing with a semantic topology graph for high-level landmark connectivity, storing both in trainable memory tokens embedded via a reversible Transformer. Long-term memory (LTM) compresses and retains historical observations at both octree and graph nodes, while short-term memory (STM) caches recent multimodal entries in relative coordinates for real-time obstacle avoidance and local planning. At each step, STM retrieval sharply prunes dynamic context, and, when deeper history is needed, LTM tokens are decoded losslessly to reconstruct past embeddings. Evaluated on Touchdown and Map2Seq across three backbones (modular, state-of-the-art VLN with prompt-based LLM, and state-of-the-art VLN with strided-attention MLLM), Mem4Nav yields 7-13 pp gains in Task Completion, sufficient SPD reduction, and >10 pp nDTW improvement. Ablations confirm the indispensability of both the hierarchical map and dual memory modules. Our codes are open-sourced via https://github.com/tsinghua-fib-lab/Mem4Nav.",
    "summary": "arXiv:2506.19433v1 Announce Type: cross Abstract: Vision-and-Language Navigation (VLN) in large-scale urban environments requires embodied agents to ground linguistic instructions in complex scenes and recall relevant experiences over extended time horizons. Prior modular pipelines offer interpretability but lack unified memory, while end-to-end (M)LLM agents excel at fusing vision and language yet remain constrained by fixed context windows and implicit spatial reasoning. We introduce textbf{Mem4Nav}, a hierarchical spatial-cognition long-short memory system that can augment any VLN backbone. Mem4Nav fuses a sparse octree for fine-grained voxel indexing with a semantic topology graph for high-level landmark connectivity, storing both in trainable memory tokens embedded via a reversible Transformer. Long-term memory (LTM) compresses and retains historical observations at both octree and graph nodes, while short-term memory (STM) caches recent multimodal entries in relative coordinates for real-time obstacle avoidance and local planning. At each step, STM retrieval sharply prunes dynamic context, and, when deeper history is needed, LTM tokens are decoded losslessly to reconstruct past embeddings. Evaluated on Touchdown and Map2Seq across three backbones (modular, state-of-the-art VLN with prompt-based LLM, and state-of-the-art VLN with strided-attention MLLM), Mem4Nav yields 7-13 pp gains in Task Completion, sufficient SPD reduction, and >10 pp nDTW improvement. Ablations confirm the indispensability of both the hierarchical map and dual memory modules. Our codes are open-sourced via https://github.com/tsinghua-fib-lab/Mem4Nav.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19433",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "MemeMind: A Large-Scale Multimodal Dataset with Chain-of-Thought Reasoning for Harmful Meme Detection",
    "description": "arXiv:2506.18919v1 Announce Type: cross Abstract: The rapid development of social media has intensified the spread of harmful content. Harmful memes, which integrate both images and text, pose significant challenges for automated detection due to their implicit semantics and complex multimodal interactions. Although existing research has made progress in detection accuracy and interpretability, the lack of a systematic, large-scale, diverse, and highly explainable dataset continues to hinder further advancement in this field. To address this gap, we introduce MemeMind, a novel dataset featuring scientifically rigorous standards, large scale, diversity, bilingual support (Chinese and English), and detailed Chain-of-Thought (CoT) annotations. MemeMind fills critical gaps in current datasets by offering comprehensive labeling and explicit reasoning traces, thereby providing a solid foundation for enhancing harmful meme detection. In addition, we propose an innovative detection framework, MemeGuard, which effectively integrates multimodal information with reasoning process modeling, significantly improving models' ability to understand and identify harmful memes. Extensive experiments conducted on the MemeMind dataset demonstrate that MemeGuard consistently outperforms existing state-of-the-art methods in harmful meme detection tasks.",
    "summary": "arXiv:2506.18919v1 Announce Type: cross Abstract: The rapid development of social media has intensified the spread of harmful content. Harmful memes, which integrate both images and text, pose significant challenges for automated detection due to their implicit semantics and complex multimodal interactions. Although existing research has made progress in detection accuracy and interpretability, the lack of a systematic, large-scale, diverse, and highly explainable dataset continues to hinder further advancement in this field. To address this gap, we introduce MemeMind, a novel dataset featuring scientifically rigorous standards, large scale, diversity, bilingual support (Chinese and English), and detailed Chain-of-Thought (CoT) annotations. MemeMind fills critical gaps in current datasets by offering comprehensive labeling and explicit reasoning traces, thereby providing a solid foundation for enhancing harmful meme detection. In addition, we propose an innovative detection framework, MemeGuard, which effectively integrates multimodal information with reasoning process modeling, significantly improving models' ability to understand and identify harmful memes. Extensive experiments conducted on the MemeMind dataset demonstrate that MemeGuard consistently outperforms existing state-of-the-art methods in harmful meme detection tasks.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.18919",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Meta-Reasoner: Dynamic Guidance for Optimized Inference-time Reasoning in Large Language Models",
    "description": "arXiv:2502.19918v3 Announce Type: replace Abstract: Large Language Models (LLMs) increasingly rely on prolonged reasoning chains to solve complex tasks. However, this trial-and-error approach often leads to high computational overhead and error propagation, where early mistakes can derail subsequent steps. To address these issues, we introduce Meta-Reasoner, a framework that dynamically optimizes inference-time reasoning by enabling LLMs to 'think about how to think.' Drawing inspiration from human meta-cognition and dual-process theory, Meta-Reasoner operates as a strategic advisor, decoupling high-level guidance from step-by-step generation. It employs contextual multi-armed bandits to iteratively evaluate reasoning progress and select optimal strategies (e.g., backtrack, clarify ambiguity, restart from scratch, or propose alternative approaches), and reallocates computational resources toward the most promising paths. Our evaluations on mathematical reasoning and puzzles highlight the potential of dynamic reasoning chains to overcome inherent challenges in the LLM reasoning process and also show promise in broader applications, offering a scalable and adaptable solution for reasoning-intensive tasks.",
    "summary": "arXiv:2502.19918v3 Announce Type: replace Abstract: Large Language Models (LLMs) increasingly rely on prolonged reasoning chains to solve complex tasks. However, this trial-and-error approach often leads to high computational overhead and error propagation, where early mistakes can derail subsequent steps. To address these issues, we introduce Meta-Reasoner, a framework that dynamically optimizes inference-time reasoning by enabling LLMs to 'think about how to think.' Drawing inspiration from human meta-cognition and dual-process theory, Meta-Reasoner operates as a strategic advisor, decoupling high-level guidance from step-by-step generation. It employs contextual multi-armed bandits to iteratively evaluate reasoning progress and select optimal strategies (e.g., backtrack, clarify ambiguity, restart from scratch, or propose alternative approaches), and reallocates computational resources toward the most promising paths. Our evaluations on mathematical reasoning and puzzles highlight the potential of dynamic reasoning chains to overcome inherent challenges in the LLM reasoning process and also show promise in broader applications, offering a scalable and adaptable solution for reasoning-intensive tasks.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2502.19918",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Mixture of Cache-Conditional Experts for Efficient Mobile Device Inference",
    "description": "arXiv:2412.00099v2 Announce Type: replace-cross Abstract: Mixture of Experts (MoE) LLMs have recently gained attention for their ability to enhance performance by selectively engaging specialized subnetworks or 'experts' for each input. However, deploying MoEs on memory-constrained devices remains challenging, particularly when generating tokens sequentially with a batch size of one, as opposed to typical high-throughput settings involving long sequences or large batches. In this work, we optimize MoE on memory-constrained devices where only a subset of expert weights fit in DRAM. We introduce a novel cache-aware routing strategy that leverages expert reuse during token generation to improve cache locality. We evaluate our approach on language modeling, MMLU, and GSM8K benchmarks and present on-device results demonstrating 2$times$ speedups on mobile devices, offering a flexible, training-free solution to extend MoE's applicability across real-world applications.",
    "summary": "arXiv:2412.00099v2 Announce Type: replace-cross Abstract: Mixture of Experts (MoE) LLMs have recently gained attention for their ability to enhance performance by selectively engaging specialized subnetworks or 'experts' for each input. However, deploying MoEs on memory-constrained devices remains challenging, particularly when generating tokens sequentially with a batch size of one, as opposed to typical high-throughput settings involving long sequences or large batches. In this work, we optimize MoE on memory-constrained devices where only a subset of expert weights fit in DRAM. We introduce a novel cache-aware routing strategy that leverages expert reuse during token generation to improve cache locality. We evaluate our approach on language modeling, MMLU, and GSM8K benchmarks and present on-device results demonstrating 2$times$ speedups on mobile devices, offering a flexible, training-free solution to extend MoE's applicability across real-world applications.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2412.00099",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "MOST: MR reconstruction Optimization for multiple downStream Tasks via continual learning",
    "description": "arXiv:2409.10394v3 Announce Type: replace-cross Abstract: Deep learning-based Magnetic Resonance (MR) reconstruction methods have focused on generating high-quality images but often overlook the impact on downstream tasks (e.g., segmentation) that utilize the reconstructed images. Cascading separately trained reconstruction network and downstream task network has been shown to introduce performance degradation due to error propagation and domain gaps between training datasets. To mitigate this issue, downstream task-oriented reconstruction optimization has been proposed for a single downstream task. Expanding this optimization to multi-task scenarios is not straightforward. In this work, we extended this optimization to sequentially introduced multiple downstream tasks and demonstrated that a single MR reconstruction network can be optimized for multiple downstream tasks by deploying continual learning (MOST). MOST integrated techniques from replay-based continual learning and image-guided loss to overcome catastrophic forgetting. Comparative experiments demonstrated that MOST outperformed a reconstruction network without finetuning, a reconstruction network with na'ive finetuning, and conventional continual learning methods. The source code is available at: https://github.com/SNU-LIST/MOST.",
    "summary": "arXiv:2409.10394v3 Announce Type: replace-cross Abstract: Deep learning-based Magnetic Resonance (MR) reconstruction methods have focused on generating high-quality images but often overlook the impact on downstream tasks (e.g., segmentation) that utilize the reconstructed images. Cascading separately trained reconstruction network and downstream task network has been shown to introduce performance degradation due to error propagation and domain gaps between training datasets. To mitigate this issue, downstream task-oriented reconstruction optimization has been proposed for a single downstream task. Expanding this optimization to multi-task scenarios is not straightforward. In this work, we extended this optimization to sequentially introduced multiple downstream tasks and demonstrated that a single MR reconstruction network can be optimized for multiple downstream tasks by deploying continual learning (MOST). MOST integrated techniques from replay-based continual learning and image-guided loss to overcome catastrophic forgetting. Comparative experiments demonstrated that MOST outperformed a reconstruction network without finetuning, a reconstruction network with na'ive finetuning, and conventional continual learning methods. The source code is available at: https://github.com/SNU-LIST/MOST.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2409.10394",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "MuBench: Assessment of Multilingual Capabilities of Large Language Models Across 61 Languages",
    "description": "arXiv:2506.19468v1 Announce Type: cross Abstract: Multilingual large language models (LLMs) are advancing rapidly, with new models frequently claiming support for an increasing number of languages. However, existing evaluation datasets are limited and lack cross-lingual alignment, leaving assessments of multilingual capabilities fragmented in both language and skill coverage. To address this, we introduce MuBench, a benchmark covering 61 languages and evaluating a broad range of capabilities. We evaluate several state-of-the-art multilingual LLMs and find notable gaps between claimed and actual language coverage, particularly a persistent performance disparity between English and low-resource languages. Leveraging MuBench's alignment, we propose Multilingual Consistency (MLC) as a complementary metric to accuracy for analyzing performance bottlenecks and guiding model improvement. Finally, we pretrain a suite of 1.2B-parameter models on English and Chinese with 500B tokens, varying language ratios and parallel data proportions to investigate cross-lingual transfer dynamics.",
    "summary": "arXiv:2506.19468v1 Announce Type: cross Abstract: Multilingual large language models (LLMs) are advancing rapidly, with new models frequently claiming support for an increasing number of languages. However, existing evaluation datasets are limited and lack cross-lingual alignment, leaving assessments of multilingual capabilities fragmented in both language and skill coverage. To address this, we introduce MuBench, a benchmark covering 61 languages and evaluating a broad range of capabilities. We evaluate several state-of-the-art multilingual LLMs and find notable gaps between claimed and actual language coverage, particularly a persistent performance disparity between English and low-resource languages. Leveraging MuBench's alignment, we propose Multilingual Consistency (MLC) as a complementary metric to accuracy for analyzing performance bottlenecks and guiding model improvement. Finally, we pretrain a suite of 1.2B-parameter models on English and Chinese with 500B tokens, varying language ratios and parallel data proportions to investigate cross-lingual transfer dynamics.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19468",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Multi-Continental Healthcare Modelling Using Blockchain-Enabled Federated Learning",
    "description": "arXiv:2410.17933v3 Announce Type: replace-cross Abstract: One of the biggest challenges of building artificial intelligence (AI) model in the healthcare area is the data sharing. Since healthcare data is private, sensitive, and heterogeneous, collecting sufficient data for modelling is exhausting, costly, and sometimes impossible. In this paper, we propose a framework for global healthcare modelling using datasets from multi-continents (Europe, North America, and Asia) without sharing the local datasets, and choose glucose management as a study model to verify its effectiveness. Technically, blockchain-enabled federated learning is implemented with adaptation to meet the privacy and safety requirements of healthcare data, meanwhile, it rewards honest participation and penalizes malicious activities using its on-chain incentive mechanism. Experimental results show that the proposed framework is effective, efficient, and privacy-preserving. Its prediction accuracy consistently outperforms models trained on limited personal data and achieves comparable or even slightly better results than centralized training in certain scenarios, all while preserving data privacy. This work paves the way for international collaborations on healthcare projects, where additional data is crucial for reducing bias and providing benefits to humanity.",
    "summary": "arXiv:2410.17933v3 Announce Type: replace-cross Abstract: One of the biggest challenges of building artificial intelligence (AI) model in the healthcare area is the data sharing. Since healthcare data is private, sensitive, and heterogeneous, collecting sufficient data for modelling is exhausting, costly, and sometimes impossible. In this paper, we propose a framework for global healthcare modelling using datasets from multi-continents (Europe, North America, and Asia) without sharing the local datasets, and choose glucose management as a study model to verify its effectiveness. Technically, blockchain-enabled federated learning is implemented with adaptation to meet the privacy and safety requirements of healthcare data, meanwhile, it rewards honest participation and penalizes malicious activities using its on-chain incentive mechanism. Experimental results show that the proposed framework is effective, efficient, and privacy-preserving. Its prediction accuracy consistently outperforms models trained on limited personal data and achieves comparable or even slightly better results than centralized training in certain scenarios, all while preserving data privacy. This work paves the way for international collaborations on healthcare projects, where additional data is crucial for reducing bias and providing benefits to humanity.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2410.17933",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Multimodal Fusion SLAM with Fourier Attention",
    "description": "arXiv:2506.18204v2 Announce Type: replace-cross Abstract: Visual SLAM is particularly challenging in environments affected by noise, varying lighting conditions, and darkness. Learning-based optical flow algorithms can leverage multiple modalities to address these challenges, but traditional optical flow-based visual SLAM approaches often require significant computational resources.To overcome this limitation, we propose FMF-SLAM, an efficient multimodal fusion SLAM method that utilizes fast Fourier transform (FFT) to enhance the algorithm efficiency. Specifically, we introduce a novel Fourier-based self-attention and cross-attention mechanism to extract features from RGB and depth signals. We further enhance the interaction of multimodal features by incorporating multi-scale knowledge distillation across modalities. We also demonstrate the practical feasibility of FMF-SLAM in real-world scenarios with real time performance by integrating it with a security robot by fusing with a global positioning module GNSS-RTK and global Bundle Adjustment. Our approach is validated using video sequences from TUM, TartanAir, and our real-world datasets, showcasing state-of-the-art performance under noisy, varying lighting, and dark conditions.Our code and datasets are available at https://github.com/youjie-zhou/FMF-SLAM.git.",
    "summary": "arXiv:2506.18204v2 Announce Type: replace-cross Abstract: Visual SLAM is particularly challenging in environments affected by noise, varying lighting conditions, and darkness. Learning-based optical flow algorithms can leverage multiple modalities to address these challenges, but traditional optical flow-based visual SLAM approaches often require significant computational resources.To overcome this limitation, we propose FMF-SLAM, an efficient multimodal fusion SLAM method that utilizes fast Fourier transform (FFT) to enhance the algorithm efficiency. Specifically, we introduce a novel Fourier-based self-attention and cross-attention mechanism to extract features from RGB and depth signals. We further enhance the interaction of multimodal features by incorporating multi-scale knowledge distillation across modalities. We also demonstrate the practical feasibility of FMF-SLAM in real-world scenarios with real time performance by integrating it with a security robot by fusing with a global positioning module GNSS-RTK and global Bundle Adjustment. Our approach is validated using video sequences from TUM, TartanAir, and our real-world datasets, showcasing state-of-the-art performance under noisy, varying lighting, and dark conditions.Our code and datasets are available at https://github.com/youjie-zhou/FMF-SLAM.git.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.18204",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Multimodal Machine Learning in Mental Health: A Survey of Data, Algorithms, and Challenges",
    "description": "arXiv:2407.16804v2 Announce Type: replace-cross Abstract: Multimodal machine learning (MML) is rapidly reshaping the way mental-health disorders are detected, characterized, and longitudinally monitored. Whereas early studies relied on isolated data streams -- such as speech, text, or wearable signals -- recent research has converged on architectures that integrate heterogeneous modalities to capture the rich, complex signatures of psychiatric conditions. This survey provides the first comprehensive, clinically grounded synthesis of MML for mental health. We (i) catalog 26 public datasets spanning audio, visual, physiological signals, and text modalities; (ii) systematically compare transformer, graph, and hybrid-based fusion strategies across 28 models, highlighting trends in representation learning and cross-modal alignment. Beyond summarizing current capabilities, we interrogate open challenges: data governance and privacy, demographic and intersectional fairness, evaluation explainability, and the complexity of mental health disorders in multimodal settings. By bridging methodological innovation with psychiatric utility, this survey aims to orient both ML researchers and mental-health practitioners toward the next generation of trustworthy, multimodal decision-support systems.",
    "summary": "arXiv:2407.16804v2 Announce Type: replace-cross Abstract: Multimodal machine learning (MML) is rapidly reshaping the way mental-health disorders are detected, characterized, and longitudinally monitored. Whereas early studies relied on isolated data streams -- such as speech, text, or wearable signals -- recent research has converged on architectures that integrate heterogeneous modalities to capture the rich, complex signatures of psychiatric conditions. This survey provides the first comprehensive, clinically grounded synthesis of MML for mental health. We (i) catalog 26 public datasets spanning audio, visual, physiological signals, and text modalities; (ii) systematically compare transformer, graph, and hybrid-based fusion strategies across 28 models, highlighting trends in representation learning and cross-modal alignment. Beyond summarizing current capabilities, we interrogate open challenges: data governance and privacy, demographic and intersectional fairness, evaluation explainability, and the complexity of mental health disorders in multimodal settings. By bridging methodological innovation with psychiatric utility, this survey aims to orient both ML researchers and mental-health practitioners toward the next generation of trustworthy, multimodal decision-support systems.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2407.16804",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "MuseControlLite: Multifunctional Music Generation with Lightweight Conditioners",
    "description": "arXiv:2506.18729v2 Announce Type: replace-cross Abstract: We propose MuseControlLite, a lightweight mechanism designed to fine-tune text-to-music generation models for precise conditioning using various time-varying musical attributes and reference audio signals. The key finding is that positional embeddings, which have been seldom used by text-to-music generation models in the conditioner for text conditions, are critical when the condition of interest is a function of time. Using melody control as an example, our experiments show that simply adding rotary positional embeddings to the decoupled cross-attention layers increases control accuracy from 56.6% to 61.1%, while requiring 6.75 times fewer trainable parameters than state-of-the-art fine-tuning mechanisms, using the same pre-trained diffusion Transformer model of Stable Audio Open. We evaluate various forms of musical attribute control, audio inpainting, and audio outpainting, demonstrating improved controllability over MusicGen-Large and Stable Audio Open ControlNet at a significantly lower fine-tuning cost, with only 85M trainble parameters. Source code, model checkpoints, and demo examples are available at: https://musecontrollite.github.io/web/.",
    "summary": "arXiv:2506.18729v2 Announce Type: replace-cross Abstract: We propose MuseControlLite, a lightweight mechanism designed to fine-tune text-to-music generation models for precise conditioning using various time-varying musical attributes and reference audio signals. The key finding is that positional embeddings, which have been seldom used by text-to-music generation models in the conditioner for text conditions, are critical when the condition of interest is a function of time. Using melody control as an example, our experiments show that simply adding rotary positional embeddings to the decoupled cross-attention layers increases control accuracy from 56.6% to 61.1%, while requiring 6.75 times fewer trainable parameters than state-of-the-art fine-tuning mechanisms, using the same pre-trained diffusion Transformer model of Stable Audio Open. We evaluate various forms of musical attribute control, audio inpainting, and audio outpainting, demonstrating improved controllability over MusicGen-Large and Stable Audio Open ControlNet at a significantly lower fine-tuning cost, with only 85M trainble parameters. Source code, model checkpoints, and demo examples are available at: https://musecontrollite.github.io/web/.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.18729",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "NAADA: A Noise-Aware Attention Denoising Autoencoder for Dental Panoramic Radiographs",
    "description": "arXiv:2506.19387v1 Announce Type: cross Abstract: Convolutional denoising autoencoders (DAEs) are powerful tools for image restoration. However, they inherit a key limitation of convolutional neural networks (CNNs): they tend to recover low-frequency features, such as smooth regions, more effectively than high-frequency details. This leads to the loss of fine details, which is particularly problematic in dental radiographs where preserving subtle anatomical structures is crucial. While self-attention mechanisms can help mitigate this issue by emphasizing important features, conventional attention methods often prioritize features corresponding to cleaner regions and may overlook those obscured by noise. To address this limitation, we propose a noise-aware self-attention method, which allows the model to effectively focus on and recover key features even within noisy regions. Building on this approach, we introduce the noise-aware attention-enhanced denoising autoencoder (NAADA) network for enhancing noisy panoramic dental radiographs. Compared with the recent state of the art (and much heavier) methods like Uformer, MResDNN etc., our method improves the reconstruction of fine details, ensuring better image quality and diagnostic accuracy.",
    "summary": "arXiv:2506.19387v1 Announce Type: cross Abstract: Convolutional denoising autoencoders (DAEs) are powerful tools for image restoration. However, they inherit a key limitation of convolutional neural networks (CNNs): they tend to recover low-frequency features, such as smooth regions, more effectively than high-frequency details. This leads to the loss of fine details, which is particularly problematic in dental radiographs where preserving subtle anatomical structures is crucial. While self-attention mechanisms can help mitigate this issue by emphasizing important features, conventional attention methods often prioritize features corresponding to cleaner regions and may overlook those obscured by noise. To address this limitation, we propose a noise-aware self-attention method, which allows the model to effectively focus on and recover key features even within noisy regions. Building on this approach, we introduce the noise-aware attention-enhanced denoising autoencoder (NAADA) network for enhancing noisy panoramic dental radiographs. Compared with the recent state of the art (and much heavier) methods like Uformer, MResDNN etc., our method improves the reconstruction of fine details, ensuring better image quality and diagnostic accuracy.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19387",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "NaviAgent: Bilevel Planning on Tool Dependency Graphs for Function Calling",
    "description": "arXiv:2506.19500v1 Announce Type: new Abstract: LLMs' reliance on static knowledge and fragile tool invocation severely hinders the orchestration of complex, heterogeneous toolchains, particularly at large scales. Existing methods typically use rigid single-path execution, resulting in poor error recovery and exponentially growing search spaces. We introduce NaviAgent, a graph-navigated bilevel planning architecture for robust function calling, comprising a Multi-Path Decider and Graph-Encoded Navigator. As an LLM-powered agent, the Multi-Path Decider defines a four-dimensional decision space and continuously perceives environmental states, dynamically selecting the optimal action to fully cover all tool invocation scenarios. The Graph-Encoded Navigator constructs a Tool Dependency Heterogeneous Graph (TDHG), where node embeddings explicitly fuse API schema structure with historical invocation behavior. It also integrates a novel heuristic search strategy that guides the Decider toward efficient and highly successful toolchains, even for unseen tool combinations. Experiments show that NaviAgent consistently achieves the highest task success rate (TSR) across all foundation models and task complexities, outperforming the average baselines (ReAct, ToolLLM, {alpha}-UMI) by 13.5%, 16.4%, and 19.0% on Qwen2.5-14B, Qwen2.5-32B, and Deepseek-V3, respectively. Its execution steps are typically within one step of the most efficient baseline, ensuring a strong balance between quality and efficiency. Notably, a fine-tuned Qwen2.5-14B model achieves a TSR of 49.5%, surpassing the much larger 32B model (44.9%) under our architecture. Incorporating the Graph-Encoded Navigator further boosts TSR by an average of 2.4 points, with gains up over 9 points on complex tasks for larger models (Deepseek-V3 and GPT-4o), highlighting its essential role in toolchain orchestration.",
    "summary": "arXiv:2506.19500v1 Announce Type: new Abstract: LLMs' reliance on static knowledge and fragile tool invocation severely hinders the orchestration of complex, heterogeneous toolchains, particularly at large scales. Existing methods typically use rigid single-path execution, resulting in poor error recovery and exponentially growing search spaces. We introduce NaviAgent, a graph-navigated bilevel planning architecture for robust function calling, comprising a Multi-Path Decider and Graph-Encoded Navigator. As an LLM-powered agent, the Multi-Path Decider defines a four-dimensional decision space and continuously perceives environmental states, dynamically selecting the optimal action to fully cover all tool invocation scenarios. The Graph-Encoded Navigator constructs a Tool Dependency Heterogeneous Graph (TDHG), where node embeddings explicitly fuse API schema structure with historical invocation behavior. It also integrates a novel heuristic search strategy that guides the Decider toward efficient and highly successful toolchains, even for unseen tool combinations. Experiments show that NaviAgent consistently achieves the highest task success rate (TSR) across all foundation models and task complexities, outperforming the average baselines (ReAct, ToolLLM, {alpha}-UMI) by 13.5%, 16.4%, and 19.0% on Qwen2.5-14B, Qwen2.5-32B, and Deepseek-V3, respectively. Its execution steps are typically within one step of the most efficient baseline, ensuring a strong balance between quality and efficiency. Notably, a fine-tuned Qwen2.5-14B model achieves a TSR of 49.5%, surpassing the much larger 32B model (44.9%) under our architecture. Incorporating the Graph-Encoded Navigator further boosts TSR by an average of 2.4 points, with gains up over 9 points on complex tasks for larger models (Deepseek-V3 and GPT-4o), highlighting its essential role in toolchain orchestration.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19500",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "NeRF-based CBCT Reconstruction needs Normalization and Initialization",
    "description": "arXiv:2506.19742v1 Announce Type: cross Abstract: Cone Beam Computed Tomography (CBCT) is widely used in medical imaging. However, the limited number and intensity of X-ray projections make reconstruction an ill-posed problem with severe artifacts. NeRF-based methods have achieved great success in this task. However, they suffer from a local-global training mismatch between their two key components: the hash encoder and the neural network. Specifically, in each training step, only a subset of the hash encoder's parameters is used (local sparse), whereas all parameters in the neural network participate (global dense). Consequently, hash features generated in each step are highly misaligned, as they come from different subsets of the hash encoder. These misalignments from different training steps are then fed into the neural network, causing repeated inconsistent global updates in training, which leads to unstable training, slower convergence, and degraded reconstruction quality. Aiming to alleviate the impact of this local-global optimization mismatch, we introduce a Normalized Hash Encoder, which enhances feature consistency and mitigates the mismatch. Additionally, we propose a Mapping Consistency Initialization(MCI) strategy that initializes the neural network before training by leveraging the global mapping property from a well-trained model. The initialized neural network exhibits improved stability during early training, enabling faster convergence and enhanced reconstruction performance. Our method is simple yet effective, requiring only a few lines of code while substantially improving training efficiency on 128 CT cases collected from 4 different datasets, covering 7 distinct anatomical regions.",
    "summary": "arXiv:2506.19742v1 Announce Type: cross Abstract: Cone Beam Computed Tomography (CBCT) is widely used in medical imaging. However, the limited number and intensity of X-ray projections make reconstruction an ill-posed problem with severe artifacts. NeRF-based methods have achieved great success in this task. However, they suffer from a local-global training mismatch between their two key components: the hash encoder and the neural network. Specifically, in each training step, only a subset of the hash encoder's parameters is used (local sparse), whereas all parameters in the neural network participate (global dense). Consequently, hash features generated in each step are highly misaligned, as they come from different subsets of the hash encoder. These misalignments from different training steps are then fed into the neural network, causing repeated inconsistent global updates in training, which leads to unstable training, slower convergence, and degraded reconstruction quality. Aiming to alleviate the impact of this local-global optimization mismatch, we introduce a Normalized Hash Encoder, which enhances feature consistency and mitigates the mismatch. Additionally, we propose a Mapping Consistency Initialization(MCI) strategy that initializes the neural network before training by leveraging the global mapping property from a well-trained model. The initialized neural network exhibits improved stability during early training, enabling faster convergence and enhanced reconstruction performance. Our method is simple yet effective, requiring only a few lines of code while substantially improving training efficiency on 128 CT cases collected from 4 different datasets, covering 7 distinct anatomical regions.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19742",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Neural Cellular Automata for ARC-AGI",
    "description": "arXiv:2506.15746v1 Announce Type: cross Abstract: Cellular automata and their differentiable counterparts, Neural Cellular Automata (NCA), are highly expressive and capable of surprisingly complex behaviors. This paper explores how NCAs perform when applied to tasks requiring precise transformations and few-shot generalization, using the Abstraction and Reasoning Corpus for Artificial General Intelligence (ARC-AGI) as a domain that challenges their capabilities in ways not previously explored. Specifically, this paper uses gradient-based training to learn iterative update rules that transform input grids into their outputs from the training examples and apply them to the test inputs. Results suggest that gradient-trained NCA models are a promising and efficient approach to a range of abstract grid-based tasks from ARC. Along with discussing the impacts of various design modifications and training constraints, this work examines the behavior and properties of NCAs applied to ARC to give insights for broader applications of self-organizing systems.",
    "summary": "arXiv:2506.15746v1 Announce Type: cross Abstract: Cellular automata and their differentiable counterparts, Neural Cellular Automata (NCA), are highly expressive and capable of surprisingly complex behaviors. This paper explores how NCAs perform when applied to tasks requiring precise transformations and few-shot generalization, using the Abstraction and Reasoning Corpus for Artificial General Intelligence (ARC-AGI) as a domain that challenges their capabilities in ways not previously explored. Specifically, this paper uses gradient-based training to learn iterative update rules that transform input grids into their outputs from the training examples and apply them to the test inputs. Results suggest that gradient-trained NCA models are a promising and efficient approach to a range of abstract grid-based tasks from ARC. Along with discussing the impacts of various design modifications and training constraints, this work examines the behavior and properties of NCAs applied to ARC to give insights for broader applications of self-organizing systems.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.15746",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "NTRL: Encounter Generation via Reinforcement Learning for Dynamic Difficulty Adjustment in Dungeons and Dragons",
    "description": "arXiv:2506.19530v1 Announce Type: new Abstract: Balancing combat encounters in Dungeons & Dragons (D&amp;D) is a complex task that requires Dungeon Masters (DM) to manually assess party strength, enemy composition, and dynamic player interactions while avoiding interruption of the narrative flow. In this paper, we propose Encounter Generation via Reinforcement Learning (NTRL), a novel approach that automates Dynamic Difficulty Adjustment (DDA) in D&amp;D via combat encounter design. By framing the problem as a contextual bandit, NTRL generates encounters based on real-time party members attributes. In comparison with classic DM heuristics, NTRL iteratively optimizes encounters to extend combat longevity (+200%), increases damage dealt to party members, reducing post-combat hit points (-16.67%), and raises the number of player deaths while maintaining low total party kills (TPK). The intensification of combat forces players to act wisely and engage in tactical maneuvers, even though the generated encounters guarantee high win rates (70%). Even in comparison with encounters designed by human Dungeon Masters, NTRL demonstrates superior performance by enhancing the strategic depth of combat while increasing difficulty in a manner that preserves overall game fairness.",
    "summary": "arXiv:2506.19530v1 Announce Type: new Abstract: Balancing combat encounters in Dungeons & Dragons (D&amp;D) is a complex task that requires Dungeon Masters (DM) to manually assess party strength, enemy composition, and dynamic player interactions while avoiding interruption of the narrative flow. In this paper, we propose Encounter Generation via Reinforcement Learning (NTRL), a novel approach that automates Dynamic Difficulty Adjustment (DDA) in D&amp;D via combat encounter design. By framing the problem as a contextual bandit, NTRL generates encounters based on real-time party members attributes. In comparison with classic DM heuristics, NTRL iteratively optimizes encounters to extend combat longevity (+200%), increases damage dealt to party members, reducing post-combat hit points (-16.67%), and raises the number of player deaths while maintaining low total party kills (TPK). The intensification of combat forces players to act wisely and engage in tactical maneuvers, even though the generated encounters guarantee high win rates (70%). Even in comparison with encounters designed by human Dungeon Masters, NTRL demonstrates superior performance by enhancing the strategic depth of combat while increasing difficulty in a manner that preserves overall game fairness.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19530",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "On the efficacy of old features for the detection of new bots",
    "description": "arXiv:2506.19635v1 Announce Type: new Abstract: For more than a decade now, academicians and online platform administrators have been studying solutions to the problem of bot detection. Bots are computer algorithms whose use is far from being benign: malicious bots are purposely created to distribute spam, sponsor public characters and, ultimately, induce a bias within the public opinion. To fight the bot invasion on our online ecosystem, several approaches have been implemented, mostly based on (supervised and unsupervised) classifiers, which adopt the most varied account features, from the simplest to the most expensive ones to be extracted from the raw data obtainable through the Twitter public APIs. In this exploratory study, using Twitter as a benchmark, we compare the performances of four state-of-art feature sets in detecting novel bots: one of the output scores of the popular bot detector Botometer, which considers more than 1,000 features of an account to take a decision; two feature sets based on the account profile and timeline; and the information about the Twitter client from which the user tweets. The results of our analysis, conducted on six recently released datasets of Twitter accounts, hint at the possible use of general-purpose classifiers and cheap-to-compute account features for the detection of evolved bots.",
    "summary": "arXiv:2506.19635v1 Announce Type: new Abstract: For more than a decade now, academicians and online platform administrators have been studying solutions to the problem of bot detection. Bots are computer algorithms whose use is far from being benign: malicious bots are purposely created to distribute spam, sponsor public characters and, ultimately, induce a bias within the public opinion. To fight the bot invasion on our online ecosystem, several approaches have been implemented, mostly based on (supervised and unsupervised) classifiers, which adopt the most varied account features, from the simplest to the most expensive ones to be extracted from the raw data obtainable through the Twitter public APIs. In this exploratory study, using Twitter as a benchmark, we compare the performances of four state-of-art feature sets in detecting novel bots: one of the output scores of the popular bot detector Botometer, which considers more than 1,000 features of an account to take a decision; two feature sets based on the account profile and timeline; and the information about the Twitter client from which the user tweets. The results of our analysis, conducted on six recently released datasets of Twitter accounts, hint at the possible use of general-purpose classifiers and cheap-to-compute account features for the detection of evolved bots.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19635",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Orthogonal Finetuning Made Scalable",
    "description": "arXiv:2506.19847v1 Announce Type: cross Abstract: Orthogonal finetuning (OFT) offers highly parameter-efficient adaptation while preventing catastrophic forgetting, but its high runtime and memory demands limit practical deployment. We identify the core computational bottleneck in OFT as its weight-centric implementation, which relies on costly matrix-matrix multiplications with cubic complexity. To overcome this, we propose OFTv2, an input-centric reformulation that instead uses matrix-vector multiplications (i.e., matrix-free computation), reducing the computational cost to quadratic. We further introduce the Cayley-Neumann parameterization, an efficient orthogonal parameterization that approximates the matrix inversion in Cayley transform via a truncated Neumann series. These modifications allow OFTv2 to achieve up to 10x faster training and 3x lower GPU memory usage without compromising performance. In addition, we extend OFTv2 to support finetuning quantized foundation models and show that it outperforms the popular QLoRA in training stability, efficiency, and memory usage.",
    "summary": "arXiv:2506.19847v1 Announce Type: cross Abstract: Orthogonal finetuning (OFT) offers highly parameter-efficient adaptation while preventing catastrophic forgetting, but its high runtime and memory demands limit practical deployment. We identify the core computational bottleneck in OFT as its weight-centric implementation, which relies on costly matrix-matrix multiplications with cubic complexity. To overcome this, we propose OFTv2, an input-centric reformulation that instead uses matrix-vector multiplications (i.e., matrix-free computation), reducing the computational cost to quadratic. We further introduce the Cayley-Neumann parameterization, an efficient orthogonal parameterization that approximates the matrix inversion in Cayley transform via a truncated Neumann series. These modifications allow OFTv2 to achieve up to 10x faster training and 3x lower GPU memory usage without compromising performance. In addition, we extend OFTv2 to support finetuning quantized foundation models and show that it outperforms the popular QLoRA in training stability, efficiency, and memory usage.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19847",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Outlier-Safe Pre-Training for Robust 4-Bit Quantization of Large Language Models",
    "description": "arXiv:2506.19697v1 Announce Type: cross Abstract: Extreme activation outliers in Large Language Models (LLMs) critically degrade quantization performance, hindering efficient on-device deployment. While channel-wise operations and adaptive gradient scaling are recognized causes, practical mitigation remains challenging. We introduce Outlier-Safe Pre-Training (OSP), a practical guideline that proactively prevents outlier formation rather than relying on post-hoc mitigation. OSP combines three key innovations: (1) the Muon optimizer, eliminating privileged bases while maintaining training efficiency; (2) Single-Scale RMSNorm, preventing channel-wise amplification; and (3) a learnable embedding projection, redistributing activation magnitudes originating from embedding matrices. We validate OSP by training a 1.4B-parameter model on 1 trillion tokens, which is the first production-scale LLM trained without such outliers. Under aggressive 4-bit quantization, our OSP model achieves a 35.7 average score across 10 benchmarks (compared to 26.5 for an Adam-trained model), with only a 2% training overhead. Remarkably, OSP models exhibit near-zero excess kurtosis (0.04) compared to extreme values (1818.56) in standard models, fundamentally altering LLM quantization behavior. Our work demonstrates that outliers are not inherent to LLMs but are consequences of training strategies, paving the way for more efficient LLM deployment. The source code and pretrained checkpoints are available at https://github.com/dmis-lab/Outlier-Safe-Pre-Training.",
    "summary": "arXiv:2506.19697v1 Announce Type: cross Abstract: Extreme activation outliers in Large Language Models (LLMs) critically degrade quantization performance, hindering efficient on-device deployment. While channel-wise operations and adaptive gradient scaling are recognized causes, practical mitigation remains challenging. We introduce Outlier-Safe Pre-Training (OSP), a practical guideline that proactively prevents outlier formation rather than relying on post-hoc mitigation. OSP combines three key innovations: (1) the Muon optimizer, eliminating privileged bases while maintaining training efficiency; (2) Single-Scale RMSNorm, preventing channel-wise amplification; and (3) a learnable embedding projection, redistributing activation magnitudes originating from embedding matrices. We validate OSP by training a 1.4B-parameter model on 1 trillion tokens, which is the first production-scale LLM trained without such outliers. Under aggressive 4-bit quantization, our OSP model achieves a 35.7 average score across 10 benchmarks (compared to 26.5 for an Adam-trained model), with only a 2% training overhead. Remarkably, OSP models exhibit near-zero excess kurtosis (0.04) compared to extreme values (1818.56) in standard models, fundamentally altering LLM quantization behavior. Our work demonstrates that outliers are not inherent to LLMs but are consequences of training strategies, paving the way for more efficient LLM deployment. The source code and pretrained checkpoints are available at https://github.com/dmis-lab/Outlier-Safe-Pre-Training.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19697",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "PBFT-Backed Semantic Voting for Multi-Agent Memory Pruning",
    "description": "arXiv:2506.17338v2 Announce Type: replace-cross Abstract: The proliferation of multi-agent systems (MAS) in complex, dynamic environments necessitates robust and efficient mechanisms for managing shared knowledge. A critical challenge is ensuring that distributed memories remain synchronized, relevant, and free from the accumulation of outdated or inconsequential data - a process analogous to biological forgetting. This paper introduces the Co-Forgetting Protocol, a novel, comprehensive framework designed to address this challenge by enabling synchronized memory pruning in MAS. The protocol integrates three key components: (1) context-aware semantic voting, where agents utilize a lightweight DistilBERT model to assess the relevance of memory items based on their content and the current operational context; (2) multi-scale temporal decay functions, which assign diminishing importance to memories based on their age and access frequency across different time horizons; and (3) a Practical Byzantine Fault Tolerance (PBFT)-based consensus mechanism, ensuring that decisions to retain or discard memory items are agreed upon by a qualified and fault-tolerant majority of agents, even in the presence of up to f Byzantine (malicious or faulty) agents in a system of N greater than or equal to 3f+1 agents. The protocol leverages gRPC for efficient inter-agent communication and Pinecone for scalable vector embedding storage and similarity search, with SQLite managing metadata. Experimental evaluations in a simulated MAS environment with four agents demonstrate the protocol's efficacy, achieving a 52% reduction in memory footprint over 500 epochs, 88% voting accuracy in forgetting decisions against human-annotated benchmarks, a 92% PBFT consensus success rate under simulated Byzantine conditions, and an 82% cache hit rate for memory access.",
    "summary": "arXiv:2506.17338v2 Announce Type: replace-cross Abstract: The proliferation of multi-agent systems (MAS) in complex, dynamic environments necessitates robust and efficient mechanisms for managing shared knowledge. A critical challenge is ensuring that distributed memories remain synchronized, relevant, and free from the accumulation of outdated or inconsequential data - a process analogous to biological forgetting. This paper introduces the Co-Forgetting Protocol, a novel, comprehensive framework designed to address this challenge by enabling synchronized memory pruning in MAS. The protocol integrates three key components: (1) context-aware semantic voting, where agents utilize a lightweight DistilBERT model to assess the relevance of memory items based on their content and the current operational context; (2) multi-scale temporal decay functions, which assign diminishing importance to memories based on their age and access frequency across different time horizons; and (3) a Practical Byzantine Fault Tolerance (PBFT)-based consensus mechanism, ensuring that decisions to retain or discard memory items are agreed upon by a qualified and fault-tolerant majority of agents, even in the presence of up to f Byzantine (malicious or faulty) agents in a system of N greater than or equal to 3f+1 agents. The protocol leverages gRPC for efficient inter-agent communication and Pinecone for scalable vector embedding storage and similarity search, with SQLite managing metadata. Experimental evaluations in a simulated MAS environment with four agents demonstrate the protocol's efficacy, achieving a 52% reduction in memory footprint over 500 epochs, 88% voting accuracy in forgetting decisions against human-annotated benchmarks, a 92% PBFT consensus success rate under simulated Byzantine conditions, and an 82% cache hit rate for memory access.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.17338",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Persona Features Control Emergent Misalignment",
    "description": "arXiv:2506.19823v1 Announce Type: cross Abstract: Understanding how language models generalize behaviors from their training to a broader deployment distribution is an important problem in AI safety. Betley et al. discovered that fine-tuning GPT-4o on intentionally insecure code causes 'emergent misalignment,' where models give stereotypically malicious responses to unrelated prompts. We extend this work, demonstrating emergent misalignment across diverse conditions, including reinforcement learning on reasoning models, fine-tuning on various synthetic datasets, and in models without safety training. To investigate the mechanisms behind this generalized misalignment, we apply a 'model diffing' approach using sparse autoencoders to compare internal model representations before and after fine-tuning. This approach reveals several 'misaligned persona' features in activation space, including a toxic persona feature which most strongly controls emergent misalignment and can be used to predict whether a model will exhibit such behavior. Additionally, we investigate mitigation strategies, discovering that fine-tuning an emergently misaligned model on just a few hundred benign samples efficiently restores alignment.",
    "summary": "arXiv:2506.19823v1 Announce Type: cross Abstract: Understanding how language models generalize behaviors from their training to a broader deployment distribution is an important problem in AI safety. Betley et al. discovered that fine-tuning GPT-4o on intentionally insecure code causes 'emergent misalignment,' where models give stereotypically malicious responses to unrelated prompts. We extend this work, demonstrating emergent misalignment across diverse conditions, including reinforcement learning on reasoning models, fine-tuning on various synthetic datasets, and in models without safety training. To investigate the mechanisms behind this generalized misalignment, we apply a 'model diffing' approach using sparse autoencoders to compare internal model representations before and after fine-tuning. This approach reveals several 'misaligned persona' features in activation space, including a toxic persona feature which most strongly controls emergent misalignment and can be used to predict whether a model will exhibit such behavior. Additionally, we investigate mitigation strategies, discovering that fine-tuning an emergently misaligned model on just a few hundred benign samples efficiently restores alignment.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19823",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Perspective-Shifted Neuro-Symbolic World Models: A Framework for Socially-Aware Robot Navigation",
    "description": "arXiv:2503.20425v2 Announce Type: replace Abstract: Navigating in environments alongside humans requires agents to reason under uncertainty and account for the beliefs and intentions of those around them. Under a sequential decision-making framework, egocentric navigation can naturally be represented as a Markov Decision Process (MDP). However, social navigation additionally requires reasoning about the hidden beliefs of others, inherently leading to a Partially Observable Markov Decision Process (POMDP), where agents lack direct access to others' mental states. Inspired by Theory of Mind and Epistemic Planning, we propose (1) a neuro-symbolic model-based reinforcement learning architecture for social navigation, addressing the challenge of belief tracking in partially observable environments; and (2) a perspective-shift operator for belief estimation, leveraging recent work on Influence-based Abstractions (IBA) in structured multi-agent settings.",
    "summary": "arXiv:2503.20425v2 Announce Type: replace Abstract: Navigating in environments alongside humans requires agents to reason under uncertainty and account for the beliefs and intentions of those around them. Under a sequential decision-making framework, egocentric navigation can naturally be represented as a Markov Decision Process (MDP). However, social navigation additionally requires reasoning about the hidden beliefs of others, inherently leading to a Partially Observable Markov Decision Process (POMDP), where agents lack direct access to others' mental states. Inspired by Theory of Mind and Epistemic Planning, we propose (1) a neuro-symbolic model-based reinforcement learning architecture for social navigation, addressing the challenge of belief tracking in partially observable environments; and (2) a perspective-shift operator for belief estimation, leveraging recent work on Influence-based Abstractions (IBA) in structured multi-agent settings.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2503.20425",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Plan for Speed -- Dilated Scheduling for Masked Diffusion Language Models",
    "description": "arXiv:2506.19037v1 Announce Type: cross Abstract: Masked diffusion language models (MDLM) have shown strong promise for non-autoregressive text generation, yet existing samplers act as implicit planners, selecting tokens to unmask via denoiser confidence or entropy scores. Such heuristics falter under parallel unmasking - they ignore pairwise interactions between tokens and cannot account for dependencies when unmasking multiple positions at once, limiting their inference time to traditional auto-regressive (AR) models. We introduce the Dilated-scheduled Unmasking Strategy (DUS), an inference-only, planner-model-free method that requires no additional training. DUS leverages a first-order Markov assumption to partition sequence positions into dilation-based groups of non-adjacent tokens, enabling independent, parallel unmasking steps that respect local context that minimizes the joint entropy of each iteration step. Unlike semi-AR block approaches (e.g., LLADA and Dream) that still invoke the denoiser per block, DUS reduces the number of denoiser calls to O(log B) per generation block - yielding substantial speedup over the O(B) run time of state-of-the-art diffusion models, where B is the block size in the semi-AR inference process. In experiments on math (GSM8K) and code completion (Humaneval, MBPP) benchmarks - domains suited to non-ordinal generation - DUS improves scores over parallel confidence-based planner, without modifying the underlying denoiser. DUS offers a lightweight, budget-aware approach to efficient, high-quality text generation, paving the way to unlock the true capabilities of MDLMs.",
    "summary": "arXiv:2506.19037v1 Announce Type: cross Abstract: Masked diffusion language models (MDLM) have shown strong promise for non-autoregressive text generation, yet existing samplers act as implicit planners, selecting tokens to unmask via denoiser confidence or entropy scores. Such heuristics falter under parallel unmasking - they ignore pairwise interactions between tokens and cannot account for dependencies when unmasking multiple positions at once, limiting their inference time to traditional auto-regressive (AR) models. We introduce the Dilated-scheduled Unmasking Strategy (DUS), an inference-only, planner-model-free method that requires no additional training. DUS leverages a first-order Markov assumption to partition sequence positions into dilation-based groups of non-adjacent tokens, enabling independent, parallel unmasking steps that respect local context that minimizes the joint entropy of each iteration step. Unlike semi-AR block approaches (e.g., LLADA and Dream) that still invoke the denoiser per block, DUS reduces the number of denoiser calls to O(log B) per generation block - yielding substantial speedup over the O(B) run time of state-of-the-art diffusion models, where B is the block size in the semi-AR inference process. In experiments on math (GSM8K) and code completion (Humaneval, MBPP) benchmarks - domains suited to non-ordinal generation - DUS improves scores over parallel confidence-based planner, without modifying the underlying denoiser. DUS offers a lightweight, budget-aware approach to efficient, high-quality text generation, paving the way to unlock the true capabilities of MDLMs.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19037",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Position: Intelligent Science Laboratory Requires the Integration of Cognitive and Embodied AI",
    "description": "arXiv:2506.19613v1 Announce Type: new Abstract: Scientific discovery has long been constrained by human limitations in expertise, physical capability, and sleep cycles. The recent rise of AI scientists and automated laboratories has accelerated both the cognitive and operational aspects of research. However, key limitations persist: AI systems are often confined to virtual environments, while automated laboratories lack the flexibility and autonomy to adaptively test new hypotheses in the physical world. Recent advances in embodied AI, such as generalist robot foundation models, diffusion-based action policies, fine-grained manipulation learning, and sim-to-real transfer, highlight the promise of integrating cognitive and embodied intelligence. This convergence opens the door to closed-loop systems that support iterative, autonomous experimentation and the possibility of serendipitous discovery. In this position paper, we propose the paradigm of Intelligent Science Laboratories (ISLs): a multi-layered, closed-loop framework that deeply integrates cognitive and embodied intelligence. ISLs unify foundation models for scientific reasoning, agent-based workflow orchestration, and embodied agents for robust physical experimentation. We argue that such systems are essential for overcoming the current limitations of scientific discovery and for realizing the full transformative potential of AI-driven science.",
    "summary": "arXiv:2506.19613v1 Announce Type: new Abstract: Scientific discovery has long been constrained by human limitations in expertise, physical capability, and sleep cycles. The recent rise of AI scientists and automated laboratories has accelerated both the cognitive and operational aspects of research. However, key limitations persist: AI systems are often confined to virtual environments, while automated laboratories lack the flexibility and autonomy to adaptively test new hypotheses in the physical world. Recent advances in embodied AI, such as generalist robot foundation models, diffusion-based action policies, fine-grained manipulation learning, and sim-to-real transfer, highlight the promise of integrating cognitive and embodied intelligence. This convergence opens the door to closed-loop systems that support iterative, autonomous experimentation and the possibility of serendipitous discovery. In this position paper, we propose the paradigm of Intelligent Science Laboratories (ISLs): a multi-layered, closed-loop framework that deeply integrates cognitive and embodied intelligence. ISLs unify foundation models for scientific reasoning, agent-based workflow orchestration, and embodied agents for robust physical experimentation. We argue that such systems are essential for overcoming the current limitations of scientific discovery and for realizing the full transformative potential of AI-driven science.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19613",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Privacy-Preserving LLM Interaction with Socratic Chain-of-Thought Reasoning and Homomorphically Encrypted Vector Databases",
    "description": "arXiv:2506.17336v1 Announce Type: cross Abstract: Large language models (LLMs) are increasingly used as personal agents, accessing sensitive user data such as calendars, emails, and medical records. Users currently face a trade-off: They can send private records, many of which are stored in remote databases, to powerful but untrusted LLM providers, increasing their exposure risk. Alternatively, they can run less powerful models locally on trusted devices. We bridge this gap. Our Socratic Chain-of-Thought Reasoning first sends a generic, non-private user query to a powerful, untrusted LLM, which generates a Chain-of-Thought (CoT) prompt and detailed sub-queries without accessing user data. Next, we embed these sub-queries and perform encrypted sub-second semantic search using our Homomorphically Encrypted Vector Database across one million entries of a single user's private data. This represents a realistic scale of personal documents, emails, and records accumulated over years of digital activity. Finally, we feed the CoT prompt and the decrypted records to a local language model and generate the final response. On the LoCoMo long-context QA benchmark, our hybrid framework, combining GPT-4o with a local Llama-3.2-1B model, outperforms using GPT-4o alone by up to 7.1 percentage points. This demonstrates a first step toward systems where tasks are decomposed and split between untrusted strong LLMs and weak local ones, preserving user privacy.",
    "summary": "arXiv:2506.17336v1 Announce Type: cross Abstract: Large language models (LLMs) are increasingly used as personal agents, accessing sensitive user data such as calendars, emails, and medical records. Users currently face a trade-off: They can send private records, many of which are stored in remote databases, to powerful but untrusted LLM providers, increasing their exposure risk. Alternatively, they can run less powerful models locally on trusted devices. We bridge this gap. Our Socratic Chain-of-Thought Reasoning first sends a generic, non-private user query to a powerful, untrusted LLM, which generates a Chain-of-Thought (CoT) prompt and detailed sub-queries without accessing user data. Next, we embed these sub-queries and perform encrypted sub-second semantic search using our Homomorphically Encrypted Vector Database across one million entries of a single user's private data. This represents a realistic scale of personal documents, emails, and records accumulated over years of digital activity. Finally, we feed the CoT prompt and the decrypted records to a local language model and generate the final response. On the LoCoMo long-context QA benchmark, our hybrid framework, combining GPT-4o with a local Llama-3.2-1B model, outperforms using GPT-4o alone by up to 7.1 percentage points. This demonstrates a first step toward systems where tasks are decomposed and split between untrusted strong LLMs and weak local ones, preserving user privacy.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.17336",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "PrivacyXray: Detecting Privacy Breaches in LLMs through Semantic Consistency and Probability Certainty",
    "description": "arXiv:2506.19563v1 Announce Type: cross Abstract: Large Language Models (LLMs) are widely used in sensitive domains, including healthcare, finance, and legal services, raising concerns about potential private information leaks during inference. Privacy extraction attacks, such as jailbreaking, expose vulnerabilities in LLMs by crafting inputs that force the models to output sensitive information. However, these attacks cannot verify whether the extracted private information is accurate, as no public datasets exist for cross-validation, leaving a critical gap in private information detection during inference. To address this, we propose PrivacyXray, a novel framework detecting privacy breaches by analyzing LLM inner states. Our analysis reveals that LLMs exhibit higher semantic coherence and probabilistic certainty when generating correct private outputs. Based on this, PrivacyXray detects privacy breaches using four metrics: intra-layer and inter-layer semantic similarity, token-level and sentence-level probability distributions. PrivacyXray addresses critical challenges in private information detection by overcoming the lack of open-source private datasets and eliminating reliance on external data for validation. It achieves this through the synthesis of realistic private data and a detection mechanism based on the inner states of LLMs. Experiments show that PrivacyXray achieves consistent performance, with an average accuracy of 92.69% across five LLMs. Compared to state-of-the-art methods, PrivacyXray achieves significant improvements, with an average accuracy increase of 20.06%, highlighting its stability and practical utility in real-world applications.",
    "summary": "arXiv:2506.19563v1 Announce Type: cross Abstract: Large Language Models (LLMs) are widely used in sensitive domains, including healthcare, finance, and legal services, raising concerns about potential private information leaks during inference. Privacy extraction attacks, such as jailbreaking, expose vulnerabilities in LLMs by crafting inputs that force the models to output sensitive information. However, these attacks cannot verify whether the extracted private information is accurate, as no public datasets exist for cross-validation, leaving a critical gap in private information detection during inference. To address this, we propose PrivacyXray, a novel framework detecting privacy breaches by analyzing LLM inner states. Our analysis reveals that LLMs exhibit higher semantic coherence and probabilistic certainty when generating correct private outputs. Based on this, PrivacyXray detects privacy breaches using four metrics: intra-layer and inter-layer semantic similarity, token-level and sentence-level probability distributions. PrivacyXray addresses critical challenges in private information detection by overcoming the lack of open-source private datasets and eliminating reliance on external data for validation. It achieves this through the synthesis of realistic private data and a detection mechanism based on the inner states of LLMs. Experiments show that PrivacyXray achieves consistent performance, with an average accuracy of 92.69% across five LLMs. Compared to state-of-the-art methods, PrivacyXray achieves significant improvements, with an average accuracy increase of 20.06%, highlighting its stability and practical utility in real-world applications.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19563",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Private Model Personalization Revisited",
    "description": "arXiv:2506.19220v1 Announce Type: cross Abstract: We study model personalization under user-level differential privacy (DP) in the shared representation framework. In this problem, there are $n$ users whose data is statistically heterogeneous, and their optimal parameters share an unknown embedding $U^* inmathbb{R}^{dtimes k}$ that maps the user parameters in $mathbb{R}^d$ to low-dimensional representations in $mathbb{R}^k$, where $kll d$. Our goal is to privately recover the shared embedding and the local low-dimensional representations with small excess risk in the federated setting. We propose a private, efficient federated learning algorithm to learn the shared embedding based on the FedRep algorithm in [CHM+21]. Unlike [CHM+21], our algorithm satisfies differential privacy, and our results hold for the case of noisy labels. In contrast to prior work on private model personalization [JRS+21], our utility guarantees hold under a larger class of users' distributions (sub-Gaussian instead of Gaussian distributions). Additionally, in natural parameter regimes, we improve the privacy error term in [JRS+21] by a factor of $widetilde{O}(dk)$. Next, we consider the binary classification setting. We present an information-theoretic construction to privately learn the shared embedding and derive a margin-based accuracy guarantee that is independent of $d$. Our method utilizes the Johnson-Lindenstrauss transform to reduce the effective dimensions of the shared embedding and the users' data. This result shows that dimension-independent risk bounds are possible in this setting under a margin loss.",
    "summary": "arXiv:2506.19220v1 Announce Type: cross Abstract: We study model personalization under user-level differential privacy (DP) in the shared representation framework. In this problem, there are $n$ users whose data is statistically heterogeneous, and their optimal parameters share an unknown embedding $U^* inmathbb{R}^{dtimes k}$ that maps the user parameters in $mathbb{R}^d$ to low-dimensional representations in $mathbb{R}^k$, where $kll d$. Our goal is to privately recover the shared embedding and the local low-dimensional representations with small excess risk in the federated setting. We propose a private, efficient federated learning algorithm to learn the shared embedding based on the FedRep algorithm in [CHM+21]. Unlike [CHM+21], our algorithm satisfies differential privacy, and our results hold for the case of noisy labels. In contrast to prior work on private model personalization [JRS+21], our utility guarantees hold under a larger class of users' distributions (sub-Gaussian instead of Gaussian distributions). Additionally, in natural parameter regimes, we improve the privacy error term in [JRS+21] by a factor of $widetilde{O}(dk)$. Next, we consider the binary classification setting. We present an information-theoretic construction to privately learn the shared embedding and derive a margin-based accuracy guarantee that is independent of $d$. Our method utilizes the Johnson-Lindenstrauss transform to reduce the effective dimensions of the shared embedding and the users' data. This result shows that dimension-independent risk bounds are possible in this setting under a margin loss.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19220",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Process Reward Models That Think",
    "description": "arXiv:2504.16828v3 Announce Type: replace-cross Abstract: Step-by-step verifiers -- also known as process reward models (PRMs) -- are a key ingredient for test-time scaling. PRMs require step-level supervision, making them expensive to train. This work aims to build data-efficient PRMs as verbalized step-wise reward models that verify every step in the solution by generating a verification chain-of-thought (CoT). We propose ThinkPRM, a long CoT verifier fine-tuned on orders of magnitude fewer process labels than those required by discriminative PRMs. Our approach capitalizes on the inherent reasoning abilities of long CoT models, and outperforms LLM-as-a-Judge and discriminative verifiers -- using only 1% of the process labels in PRM800K -- across several challenging benchmarks. Specifically, ThinkPRM beats the baselines on ProcessBench, MATH-500, and AIME '24 under best-of-N selection and reward-guided search. In an out-of-domain evaluation on a subset of GPQA-Diamond and LiveCodeBench, our PRM surpasses discriminative verifiers trained on the full PRM800K by 8% and 4.5%, respectively. Lastly, under the same token budget, ThinkPRM scales up verification compute more effectively compared to LLM-as-a-Judge, outperforming it by 7.2% on a subset of ProcessBench. Our work highlights the value of generative, long CoT PRMs that can scale test-time compute for verification while requiring minimal supervision for training. Our code, data, and models will be released at https://github.com/mukhal/thinkprm.",
    "summary": "arXiv:2504.16828v3 Announce Type: replace-cross Abstract: Step-by-step verifiers -- also known as process reward models (PRMs) -- are a key ingredient for test-time scaling. PRMs require step-level supervision, making them expensive to train. This work aims to build data-efficient PRMs as verbalized step-wise reward models that verify every step in the solution by generating a verification chain-of-thought (CoT). We propose ThinkPRM, a long CoT verifier fine-tuned on orders of magnitude fewer process labels than those required by discriminative PRMs. Our approach capitalizes on the inherent reasoning abilities of long CoT models, and outperforms LLM-as-a-Judge and discriminative verifiers -- using only 1% of the process labels in PRM800K -- across several challenging benchmarks. Specifically, ThinkPRM beats the baselines on ProcessBench, MATH-500, and AIME '24 under best-of-N selection and reward-guided search. In an out-of-domain evaluation on a subset of GPQA-Diamond and LiveCodeBench, our PRM surpasses discriminative verifiers trained on the full PRM800K by 8% and 4.5%, respectively. Lastly, under the same token budget, ThinkPRM scales up verification compute more effectively compared to LLM-as-a-Judge, outperforming it by 7.2% on a subset of ProcessBench. Our work highlights the value of generative, long CoT PRMs that can scale test-time compute for verification while requiring minimal supervision for training. Our code, data, and models will be released at https://github.com/mukhal/thinkprm.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2504.16828",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Quantifying Fairness in LLMs Beyond Tokens: A Semantic and Statistical Perspective",
    "description": "arXiv:2506.19028v1 Announce Type: cross Abstract: Large Language Models (LLMs) often generate responses with inherent biases, undermining their reliability in real-world applications. Existing evaluation methods often overlook biases in long-form responses and the intrinsic variability of LLM outputs. To address these challenges, we propose FiSCo(Fine-grained Semantic Computation), a novel statistical framework to evaluate group-level fairness in LLMs by detecting subtle semantic differences in long-form responses across demographic groups. Unlike prior work focusing on sentiment or token-level comparisons, FiSCo goes beyond surface-level analysis by operating at the claim level, leveraging entailment checks to assess the consistency of meaning across responses. We decompose model outputs into semantically distinct claims and apply statistical hypothesis testing to compare inter- and intra-group similarities, enabling robust detection of subtle biases. We formalize a new group counterfactual fairness definition and validate FiSCo on both synthetic and human-annotated datasets spanning gender, race, and age. Experiments show that FiSco more reliably identifies nuanced biases while reducing the impact of stochastic LLM variability, outperforming various evaluation metrics.",
    "summary": "arXiv:2506.19028v1 Announce Type: cross Abstract: Large Language Models (LLMs) often generate responses with inherent biases, undermining their reliability in real-world applications. Existing evaluation methods often overlook biases in long-form responses and the intrinsic variability of LLM outputs. To address these challenges, we propose FiSCo(Fine-grained Semantic Computation), a novel statistical framework to evaluate group-level fairness in LLMs by detecting subtle semantic differences in long-form responses across demographic groups. Unlike prior work focusing on sentiment or token-level comparisons, FiSCo goes beyond surface-level analysis by operating at the claim level, leveraging entailment checks to assess the consistency of meaning across responses. We decompose model outputs into semantically distinct claims and apply statistical hypothesis testing to compare inter- and intra-group similarities, enabling robust detection of subtle biases. We formalize a new group counterfactual fairness definition and validate FiSCo on both synthetic and human-annotated datasets spanning gender, race, and age. Experiments show that FiSco more reliably identifies nuanced biases while reducing the impact of stochastic LLM variability, outperforming various evaluation metrics.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19028",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Radial Attention: $O(nlog n)$ Sparse Attention with Energy Decay for Long Video Generation",
    "description": "arXiv:2506.19852v1 Announce Type: cross Abstract: Recent advances in diffusion models have enabled high-quality video generation, but the additional temporal dimension significantly increases computational costs, making training and inference on long videos prohibitively expensive. In this paper, we identify a phenomenon we term Spatiotemporal Energy Decay in video diffusion models: post-softmax attention scores diminish as spatial and temporal distance between tokens increase, akin to the physical decay of signal or waves over space and time in nature. Motivated by this, we propose Radial Attention, a scalable sparse attention mechanism with $O(n log n)$ complexity that translates energy decay into exponentially decaying compute density, which is significantly more efficient than standard $O(n^2)$ dense attention and more expressive than linear attention. Specifically, Radial Attention employs a simple, static attention mask where each token attends to spatially nearby tokens, with the attention window size shrinking with temporal distance. Moreover, it allows pre-trained video diffusion models to extend their generation length with efficient LoRA-based fine-tuning. Extensive experiments show that Radial Attention maintains video quality across Wan2.1-14B, HunyuanVideo, and Mochi 1, achieving up to a 1.9$times$ speedup over the original dense attention. With minimal tuning, it enables video generation up to 4$times$ longer while reducing training costs by up to 4.4$times$ compared to direct fine-tuning and accelerating inference by up to 3.7$times$ compared to dense attention inference.",
    "summary": "arXiv:2506.19852v1 Announce Type: cross Abstract: Recent advances in diffusion models have enabled high-quality video generation, but the additional temporal dimension significantly increases computational costs, making training and inference on long videos prohibitively expensive. In this paper, we identify a phenomenon we term Spatiotemporal Energy Decay in video diffusion models: post-softmax attention scores diminish as spatial and temporal distance between tokens increase, akin to the physical decay of signal or waves over space and time in nature. Motivated by this, we propose Radial Attention, a scalable sparse attention mechanism with $O(n log n)$ complexity that translates energy decay into exponentially decaying compute density, which is significantly more efficient than standard $O(n^2)$ dense attention and more expressive than linear attention. Specifically, Radial Attention employs a simple, static attention mask where each token attends to spatially nearby tokens, with the attention window size shrinking with temporal distance. Moreover, it allows pre-trained video diffusion models to extend their generation length with efficient LoRA-based fine-tuning. Extensive experiments show that Radial Attention maintains video quality across Wan2.1-14B, HunyuanVideo, and Mochi 1, achieving up to a 1.9$times$ speedup over the original dense attention. With minimal tuning, it enables video generation up to 4$times$ longer while reducing training costs by up to 4.4$times$ compared to direct fine-tuning and accelerating inference by up to 3.7$times$ compared to dense attention inference.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19852",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "RAG+: Enhancing Retrieval-Augmented Generation with Application-Aware Reasoning",
    "description": "arXiv:2506.11555v2 Announce Type: replace Abstract: The integration of external knowledge through Retrieval-Augmented Generation (RAG) has become foundational in enhancing large language models (LLMs) for knowledge-intensive tasks. However, existing RAG paradigms often overlook the cognitive step of applying knowledge, leaving a gap between retrieved facts and task-specific reasoning. In this work, we introduce RAG+, a principled and modular extension that explicitly incorporates application-aware reasoning into the RAG pipeline. RAG+ constructs a dual corpus consisting of knowledge and aligned application examples, created either manually or automatically, and retrieves both jointly during inference. This design enables LLMs not only to access relevant information but also to apply it within structured, goal-oriented reasoning processes. Experiments across mathematical, legal, and medical domains, conducted on multiple models, demonstrate that RAG+ consistently outperforms standard RAG variants, achieving average improvements of 3-5%, and peak gains up to 7.5% in complex scenarios. By bridging retrieval with actionable application, RAG+ advances a more cognitively grounded framework for knowledge integration, representing a step toward more interpretable and capable LLMs.",
    "summary": "arXiv:2506.11555v2 Announce Type: replace Abstract: The integration of external knowledge through Retrieval-Augmented Generation (RAG) has become foundational in enhancing large language models (LLMs) for knowledge-intensive tasks. However, existing RAG paradigms often overlook the cognitive step of applying knowledge, leaving a gap between retrieved facts and task-specific reasoning. In this work, we introduce RAG+, a principled and modular extension that explicitly incorporates application-aware reasoning into the RAG pipeline. RAG+ constructs a dual corpus consisting of knowledge and aligned application examples, created either manually or automatically, and retrieves both jointly during inference. This design enables LLMs not only to access relevant information but also to apply it within structured, goal-oriented reasoning processes. Experiments across mathematical, legal, and medical domains, conducted on multiple models, demonstrate that RAG+ consistently outperforms standard RAG variants, achieving average improvements of 3-5%, and peak gains up to 7.5% in complex scenarios. By bridging retrieval with actionable application, RAG+ advances a more cognitively grounded framework for knowledge integration, representing a step toward more interpretable and capable LLMs.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.11555",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "RareSpot: Spotting Small and Rare Wildlife in Aerial Imagery with Multi-Scale Consistency and Context-Aware Augmentation",
    "description": "arXiv:2506.19087v1 Announce Type: cross Abstract: Automated detection of small and rare wildlife in aerial imagery is crucial for effective conservation, yet remains a significant technical challenge. Prairie dogs exemplify this issue: their ecological importance as keystone species contrasts sharply with their elusive presence--marked by small size, sparse distribution, and subtle visual features--which undermines existing detection approaches. To address these challenges, we propose RareSpot, a robust detection framework integrating multi-scale consistency learning and context-aware augmentation. Our multi-scale consistency approach leverages structured alignment across feature pyramids, enhancing fine-grained object representation and mitigating scale-related feature loss. Complementarily, context-aware augmentation strategically synthesizes challenging training instances by embedding difficult-to-detect samples into realistic environmental contexts, significantly boosting model precision and recall. Evaluated on an expert-annotated prairie dog drone imagery benchmark, our method achieves state-of-the-art performance, improving detection accuracy by over 35% compared to baseline methods. Importantly, it generalizes effectively across additional wildlife datasets, demonstrating broad applicability. The RareSpot benchmark and approach not only support critical ecological monitoring but also establish a new foundation for detecting small, rare species in complex aerial scenes.",
    "summary": "arXiv:2506.19087v1 Announce Type: cross Abstract: Automated detection of small and rare wildlife in aerial imagery is crucial for effective conservation, yet remains a significant technical challenge. Prairie dogs exemplify this issue: their ecological importance as keystone species contrasts sharply with their elusive presence--marked by small size, sparse distribution, and subtle visual features--which undermines existing detection approaches. To address these challenges, we propose RareSpot, a robust detection framework integrating multi-scale consistency learning and context-aware augmentation. Our multi-scale consistency approach leverages structured alignment across feature pyramids, enhancing fine-grained object representation and mitigating scale-related feature loss. Complementarily, context-aware augmentation strategically synthesizes challenging training instances by embedding difficult-to-detect samples into realistic environmental contexts, significantly boosting model precision and recall. Evaluated on an expert-annotated prairie dog drone imagery benchmark, our method achieves state-of-the-art performance, improving detection accuracy by over 35% compared to baseline methods. Importantly, it generalizes effectively across additional wildlife datasets, demonstrating broad applicability. The RareSpot benchmark and approach not only support critical ecological monitoring but also establish a new foundation for detecting small, rare species in complex aerial scenes.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19087",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Rational Metareasoning for Large Language Models",
    "description": "arXiv:2410.05563v3 Announce Type: replace-cross Abstract: Being prompted to engage in reasoning has emerged as a core technique for using large language models (LLMs), deploying additional inference-time compute to improve task performance. However, as LLMs increase in both size and adoption, inference costs are correspondingly becoming increasingly burdensome. How, then, might we optimize reasoning's cost-performance tradeoff? This work introduces a novel approach based on computational models of metareasoning used in cognitive science, training LLMs to selectively use intermediate reasoning steps only when necessary. We first develop a reward function that incorporates the Value of Computation by penalizing unnecessary reasoning, then use this reward function with Expert Iteration to train the LLM. Compared to few-shot chain-of-thought prompting and STaR, our method significantly reduces inference costs (20-37% fewer tokens generated across three models) while maintaining task performance across diverse datasets.",
    "summary": "arXiv:2410.05563v3 Announce Type: replace-cross Abstract: Being prompted to engage in reasoning has emerged as a core technique for using large language models (LLMs), deploying additional inference-time compute to improve task performance. However, as LLMs increase in both size and adoption, inference costs are correspondingly becoming increasingly burdensome. How, then, might we optimize reasoning's cost-performance tradeoff? This work introduces a novel approach based on computational models of metareasoning used in cognitive science, training LLMs to selectively use intermediate reasoning steps only when necessary. We first develop a reward function that incorporates the Value of Computation by penalizing unnecessary reasoning, then use this reward function with Expert Iteration to train the LLM. Compared to few-shot chain-of-thought prompting and STaR, our method significantly reduces inference costs (20-37% fewer tokens generated across three models) while maintaining task performance across diverse datasets.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2410.05563",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "RCStat: A Statistical Framework for using Relative Contextualization in Transformers",
    "description": "arXiv:2506.19549v1 Announce Type: cross Abstract: Prior work on input-token importance in auto-regressive transformers has relied on Softmax-normalized attention weights, which obscure the richer structure of pre-Softmax query-key logits. We introduce RCStat, a statistical framework that harnesses raw attention logits via Relative Contextualization (RC), a random variable measuring contextual alignment between token segments, and derive an efficient upper bound for RC. We demonstrate two applications: (i) Key-Value compression, where RC-based thresholds drive adaptive key-value eviction for substantial cache reduction with minimal quality loss; and (ii) Attribution, where RC yields higher-fidelity token-, sentence-, and chunk-level explanations than post-Softmax methods. Across question answering, summarization, and attribution benchmarks, RCStat achieves significant empirical gains, delivering state-of-the-art compression and attribution performance without any model retraining.",
    "summary": "arXiv:2506.19549v1 Announce Type: cross Abstract: Prior work on input-token importance in auto-regressive transformers has relied on Softmax-normalized attention weights, which obscure the richer structure of pre-Softmax query-key logits. We introduce RCStat, a statistical framework that harnesses raw attention logits via Relative Contextualization (RC), a random variable measuring contextual alignment between token segments, and derive an efficient upper bound for RC. We demonstrate two applications: (i) Key-Value compression, where RC-based thresholds drive adaptive key-value eviction for substantial cache reduction with minimal quality loss; and (ii) Attribution, where RC yields higher-fidelity token-, sentence-, and chunk-level explanations than post-Softmax methods. Across question answering, summarization, and attribution benchmarks, RCStat achieves significant empirical gains, delivering state-of-the-art compression and attribution performance without any model retraining.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19549",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Reading Smiles: Proxy Bias in Foundation Models for Facial Emotion Recognition",
    "description": "arXiv:2506.19079v1 Announce Type: cross Abstract: Foundation Models (FMs) are rapidly transforming Affective Computing (AC), with Vision Language Models (VLMs) now capable of recognising emotions in zero shot settings. This paper probes a critical but underexplored question: what visual cues do these models rely on to infer affect, and are these cues psychologically grounded or superficially learnt? We benchmark varying scale VLMs on a teeth annotated subset of AffectNet dataset and find consistent performance shifts depending on the presence of visible teeth. Through structured introspection of, the best-performing model, i.e., GPT-4o, we show that facial attributes like eyebrow position drive much of its affective reasoning, revealing a high degree of internal consistency in its valence-arousal predictions. These patterns highlight the emergent nature of FMs behaviour, but also reveal risks: shortcut learning, bias, and fairness issues especially in sensitive domains like mental health and education.",
    "summary": "arXiv:2506.19079v1 Announce Type: cross Abstract: Foundation Models (FMs) are rapidly transforming Affective Computing (AC), with Vision Language Models (VLMs) now capable of recognising emotions in zero shot settings. This paper probes a critical but underexplored question: what visual cues do these models rely on to infer affect, and are these cues psychologically grounded or superficially learnt? We benchmark varying scale VLMs on a teeth annotated subset of AffectNet dataset and find consistent performance shifts depending on the presence of visible teeth. Through structured introspection of, the best-performing model, i.e., GPT-4o, we show that facial attributes like eyebrow position drive much of its affective reasoning, revealing a high degree of internal consistency in its valence-arousal predictions. These patterns highlight the emergent nature of FMs behaviour, but also reveal risks: shortcut learning, bias, and fairness issues especially in sensitive domains like mental health and education.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19079",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Recalling The Forgotten Class Memberships: Unlearned Models Can Be Noisy Labelers to Leak Privacy",
    "description": "arXiv:2506.19486v1 Announce Type: cross Abstract: Machine Unlearning (MU) technology facilitates the removal of the influence of specific data instances from trained models on request. Despite rapid advancements in MU technology, its vulnerabilities are still underexplored, posing potential risks of privacy breaches through leaks of ostensibly unlearned information. Current limited research on MU attacks requires access to original models containing privacy data, which violates the critical privacy-preserving objective of MU. To address this gap, we initiate an innovative study on recalling the forgotten class memberships from unlearned models (ULMs) without requiring access to the original one. Specifically, we implement a Membership Recall Attack (MRA) framework with a teacher-student knowledge distillation architecture, where ULMs serve as noisy labelers to transfer knowledge to student models. Then, it is translated into a Learning with Noisy Labels (LNL) problem for inferring the correct labels of the forgetting instances. Extensive experiments on state-of-the-art MU methods with multiple real datasets demonstrate that the proposed MRA strategy exhibits high efficacy in recovering class memberships of unlearned instances. As a result, our study and evaluation have established a benchmark for future research on MU vulnerabilities.",
    "summary": "arXiv:2506.19486v1 Announce Type: cross Abstract: Machine Unlearning (MU) technology facilitates the removal of the influence of specific data instances from trained models on request. Despite rapid advancements in MU technology, its vulnerabilities are still underexplored, posing potential risks of privacy breaches through leaks of ostensibly unlearned information. Current limited research on MU attacks requires access to original models containing privacy data, which violates the critical privacy-preserving objective of MU. To address this gap, we initiate an innovative study on recalling the forgotten class memberships from unlearned models (ULMs) without requiring access to the original one. Specifically, we implement a Membership Recall Attack (MRA) framework with a teacher-student knowledge distillation architecture, where ULMs serve as noisy labelers to transfer knowledge to student models. Then, it is translated into a Learning with Noisy Labels (LNL) problem for inferring the correct labels of the forgetting instances. Extensive experiments on state-of-the-art MU methods with multiple real datasets demonstrate that the proposed MRA strategy exhibits high efficacy in recovering class memberships of unlearned instances. As a result, our study and evaluation have established a benchmark for future research on MU vulnerabilities.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19486",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "RecLLM-R1: A Two-Stage Training Paradigm with Reinforcement Learning and Chain-of-Thought v1",
    "description": "arXiv:2506.19235v1 Announce Type: new Abstract: Traditional recommendation systems often grapple with 'filter bubbles', underutilization of external knowledge, and a disconnect between model optimization and business policy iteration. To address these limitations, this paper introduces RecLLM-R1, a novel recommendation framework leveraging Large Language Models (LLMs) and drawing inspiration from the DeepSeek R1 methodology. The framework initiates by transforming user profiles, historical interactions, and multi-faceted item attributes into LLM-interpretable natural language prompts through a carefully engineered data construction process. Subsequently, a two-stage training paradigm is employed: the initial stage involves Supervised Fine-Tuning (SFT) to imbue the LLM with fundamental recommendation capabilities. The subsequent stage utilizes Group Relative Policy Optimization (GRPO), a reinforcement learning technique, augmented with a Chain-of-Thought (CoT) mechanism. This stage guides the model through multi-step reasoning and holistic decision-making via a flexibly defined reward function, aiming to concurrently optimize recommendation accuracy, diversity, and other bespoke business objectives. Empirical evaluations on a real-world user behavior dataset from a large-scale social media platform demonstrate that RecLLM-R1 significantly surpasses existing baseline methods across a spectrum of evaluation metrics, including accuracy, diversity, and novelty. It effectively mitigates the filter bubble effect and presents a promising avenue for the integrated optimization of recommendation models and policies under intricate business goals.",
    "summary": "arXiv:2506.19235v1 Announce Type: new Abstract: Traditional recommendation systems often grapple with 'filter bubbles', underutilization of external knowledge, and a disconnect between model optimization and business policy iteration. To address these limitations, this paper introduces RecLLM-R1, a novel recommendation framework leveraging Large Language Models (LLMs) and drawing inspiration from the DeepSeek R1 methodology. The framework initiates by transforming user profiles, historical interactions, and multi-faceted item attributes into LLM-interpretable natural language prompts through a carefully engineered data construction process. Subsequently, a two-stage training paradigm is employed: the initial stage involves Supervised Fine-Tuning (SFT) to imbue the LLM with fundamental recommendation capabilities. The subsequent stage utilizes Group Relative Policy Optimization (GRPO), a reinforcement learning technique, augmented with a Chain-of-Thought (CoT) mechanism. This stage guides the model through multi-step reasoning and holistic decision-making via a flexibly defined reward function, aiming to concurrently optimize recommendation accuracy, diversity, and other bespoke business objectives. Empirical evaluations on a real-world user behavior dataset from a large-scale social media platform demonstrate that RecLLM-R1 significantly surpasses existing baseline methods across a spectrum of evaluation metrics, including accuracy, diversity, and novelty. It effectively mitigates the filter bubble effect and presents a promising avenue for the integrated optimization of recommendation models and policies under intricate business goals.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19235",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "ReconX: Reconstruct Any Scene from Sparse Views with Video Diffusion Model",
    "description": "arXiv:2408.16767v3 Announce Type: replace-cross Abstract: Advancements in 3D scene reconstruction have transformed 2D images from the real world into 3D models, producing realistic 3D results from hundreds of input photos. Despite great success in dense-view reconstruction scenarios, rendering a detailed scene from insufficient captured views is still an ill-posed optimization problem, often resulting in artifacts and distortions in unseen areas. In this paper, we propose ReconX, a novel 3D scene reconstruction paradigm that reframes the ambiguous reconstruction challenge as a temporal generation task. The key insight is to unleash the strong generative prior of large pre-trained video diffusion models for sparse-view reconstruction. However, 3D view consistency struggles to be accurately preserved in directly generated video frames from pre-trained models. To address this, given limited input views, the proposed ReconX first constructs a global point cloud and encodes it into a contextual space as the 3D structure condition. Guided by the condition, the video diffusion model then synthesizes video frames that are both detail-preserved and exhibit a high degree of 3D consistency, ensuring the coherence of the scene from various perspectives. Finally, we recover the 3D scene from the generated video through a confidence-aware 3D Gaussian Splatting optimization scheme. Extensive experiments on various real-world datasets show the superiority of our ReconX over state-of-the-art methods in terms of quality and generalizability.",
    "summary": "arXiv:2408.16767v3 Announce Type: replace-cross Abstract: Advancements in 3D scene reconstruction have transformed 2D images from the real world into 3D models, producing realistic 3D results from hundreds of input photos. Despite great success in dense-view reconstruction scenarios, rendering a detailed scene from insufficient captured views is still an ill-posed optimization problem, often resulting in artifacts and distortions in unseen areas. In this paper, we propose ReconX, a novel 3D scene reconstruction paradigm that reframes the ambiguous reconstruction challenge as a temporal generation task. The key insight is to unleash the strong generative prior of large pre-trained video diffusion models for sparse-view reconstruction. However, 3D view consistency struggles to be accurately preserved in directly generated video frames from pre-trained models. To address this, given limited input views, the proposed ReconX first constructs a global point cloud and encodes it into a contextual space as the 3D structure condition. Guided by the condition, the video diffusion model then synthesizes video frames that are both detail-preserved and exhibit a high degree of 3D consistency, ensuring the coherence of the scene from various perspectives. Finally, we recover the 3D scene from the generated video through a confidence-aware 3D Gaussian Splatting optimization scheme. Extensive experiments on various real-world datasets show the superiority of our ReconX over state-of-the-art methods in terms of quality and generalizability.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2408.16767",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Recycling the Web: A Method to Enhance Pre-training Data Quality and Quantity for Language Models",
    "description": "arXiv:2506.04689v1 Announce Type: cross Abstract: Scaling laws predict that the performance of large language models improves with increasing model size and data size. In practice, pre-training has been relying on massive web crawls, using almost all data sources publicly available on the internet so far. However, this pool of natural data does not grow at the same rate as the compute supply. Furthermore, the availability of high-quality texts is even more limited: data filtering pipelines often remove up to 99% of the initial web scrapes to achieve state-of-the-art. To address the 'data wall' of pre-training scaling, our work explores ways to transform and recycle data discarded in existing filtering processes. We propose REWIRE, REcycling the Web with guIded REwrite, a method to enrich low-quality documents so that they could become useful for training. This in turn allows us to increase the representation of synthetic data in the final pre-training set. Experiments at 1B, 3B and 7B scales of the DCLM benchmark show that mixing high-quality raw texts and our rewritten texts lead to 1.0, 1.3 and 2.5 percentage points improvement respectively across 22 diverse tasks, compared to training on only filtered web data. Training on the raw-synthetic data mix is also more effective than having access to 2x web data. Through further analysis, we demonstrate that about 82% of the mixed in texts come from transforming lower-quality documents that would otherwise be discarded. REWIRE also outperforms related approaches of generating synthetic data, including Wikipedia-style paraphrasing, question-answer synthesizing and knowledge extraction. These results suggest that recycling web texts holds the potential for being a simple and effective approach for scaling pre-training data.",
    "summary": "arXiv:2506.04689v1 Announce Type: cross Abstract: Scaling laws predict that the performance of large language models improves with increasing model size and data size. In practice, pre-training has been relying on massive web crawls, using almost all data sources publicly available on the internet so far. However, this pool of natural data does not grow at the same rate as the compute supply. Furthermore, the availability of high-quality texts is even more limited: data filtering pipelines often remove up to 99% of the initial web scrapes to achieve state-of-the-art. To address the 'data wall' of pre-training scaling, our work explores ways to transform and recycle data discarded in existing filtering processes. We propose REWIRE, REcycling the Web with guIded REwrite, a method to enrich low-quality documents so that they could become useful for training. This in turn allows us to increase the representation of synthetic data in the final pre-training set. Experiments at 1B, 3B and 7B scales of the DCLM benchmark show that mixing high-quality raw texts and our rewritten texts lead to 1.0, 1.3 and 2.5 percentage points improvement respectively across 22 diverse tasks, compared to training on only filtered web data. Training on the raw-synthetic data mix is also more effective than having access to 2x web data. Through further analysis, we demonstrate that about 82% of the mixed in texts come from transforming lower-quality documents that would otherwise be discarded. REWIRE also outperforms related approaches of generating synthetic data, including Wikipedia-style paraphrasing, question-answer synthesizing and knowledge extraction. These results suggest that recycling web texts holds the potential for being a simple and effective approach for scaling pre-training data.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.04689",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "ReDit: Reward Dithering for Improved LLM Policy Optimization",
    "description": "arXiv:2506.18631v2 Announce Type: replace-cross Abstract: DeepSeek-R1 has successfully enhanced Large Language Model (LLM) reasoning capabilities through its rule-based reward system. While it's a ''perfect'' reward system that effectively mitigates reward hacking, such reward functions are often discrete. Our experimental observations suggest that discrete rewards can lead to gradient anomaly, unstable optimization, and slow convergence. To address this issue, we propose ReDit (Reward Dithering), a method that dithers the discrete reward signal by adding simple random noise. With this perturbed reward, exploratory gradients are continuously provided throughout the learning process, enabling smoother gradient updates and accelerating convergence. The injected noise also introduces stochasticity into flat reward regions, encouraging the model to explore novel policies and escape local optima. Experiments across diverse tasks demonstrate the effectiveness and efficiency of ReDit. On average, ReDit achieves performance comparable to vanilla GRPO with only approximately 10% the training steps, and furthermore, still exhibits a 4% performance improvement over vanilla GRPO when trained for a similar duration. Visualizations confirm significant mitigation of gradient issues with ReDit. Moreover, theoretical analyses are provided to further validate these advantages.",
    "summary": "arXiv:2506.18631v2 Announce Type: replace-cross Abstract: DeepSeek-R1 has successfully enhanced Large Language Model (LLM) reasoning capabilities through its rule-based reward system. While it's a ''perfect'' reward system that effectively mitigates reward hacking, such reward functions are often discrete. Our experimental observations suggest that discrete rewards can lead to gradient anomaly, unstable optimization, and slow convergence. To address this issue, we propose ReDit (Reward Dithering), a method that dithers the discrete reward signal by adding simple random noise. With this perturbed reward, exploratory gradients are continuously provided throughout the learning process, enabling smoother gradient updates and accelerating convergence. The injected noise also introduces stochasticity into flat reward regions, encouraging the model to explore novel policies and escape local optima. Experiments across diverse tasks demonstrate the effectiveness and efficiency of ReDit. On average, ReDit achieves performance comparable to vanilla GRPO with only approximately 10% the training steps, and furthermore, still exhibits a 4% performance improvement over vanilla GRPO when trained for a similar duration. Visualizations confirm significant mitigation of gradient issues with ReDit. Moreover, theoretical analyses are provided to further validate these advantages.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.18631",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Reinforcement Learning-Based Dynamic Grouping for Tubular Structure Tracking",
    "description": "arXiv:2506.18930v1 Announce Type: cross Abstract: The computation of minimal paths for the applications in tracking tubular structures such as blood vessels and roads is challenged by complex morphologies and environmental variations. Existing approaches can be roughly categorized into two research lines: the point-wise based models and the segment-wise based models. Although segment-wise approaches have obtained promising results in many scenarios, they often suffer from computational inefficiency and heavily rely on a prescribed prior to fit the target elongated shapes. We propose a novel framework that casts segment-wise tracking as a Markov Decision Process (MDP), enabling a reinforcement learning approach. Our method leverages Q-Learning to dynamically explore a graph of segments, computing edge weights on-demand and adaptively expanding the search space. This strategy avoids the high cost of a pre-computed graph and proves robust to incomplete initial information. Experimental reuslts on typical tubular structure datasets demonstrate that our method significantly outperforms state-of-the-art point-wise and segment-wise approaches. The proposed method effectively handles complex topologies and maintains global path coherence without depending on extensive prior structural knowledge.",
    "summary": "arXiv:2506.18930v1 Announce Type: cross Abstract: The computation of minimal paths for the applications in tracking tubular structures such as blood vessels and roads is challenged by complex morphologies and environmental variations. Existing approaches can be roughly categorized into two research lines: the point-wise based models and the segment-wise based models. Although segment-wise approaches have obtained promising results in many scenarios, they often suffer from computational inefficiency and heavily rely on a prescribed prior to fit the target elongated shapes. We propose a novel framework that casts segment-wise tracking as a Markov Decision Process (MDP), enabling a reinforcement learning approach. Our method leverages Q-Learning to dynamically explore a graph of segments, computing edge weights on-demand and adaptively expanding the search space. This strategy avoids the high cost of a pre-computed graph and proves robust to incomplete initial information. Experimental reuslts on typical tubular structure datasets demonstrate that our method significantly outperforms state-of-the-art point-wise and segment-wise approaches. The proposed method effectively handles complex topologies and maintains global path coherence without depending on extensive prior structural knowledge.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.18930",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "ReMAR-DS: Recalibrated Feature Learning for Metal Artifact Reduction and CT Domain Transformation",
    "description": "arXiv:2506.19531v1 Announce Type: cross Abstract: Artifacts in kilo-Voltage CT (kVCT) imaging degrade image quality, impacting clinical decisions. We propose a deep learning framework for metal artifact reduction (MAR) and domain transformation from kVCT to Mega-Voltage CT (MVCT). The proposed framework, ReMAR-DS, utilizes an encoder-decoder architecture with enhanced feature recalibration, effectively reducing artifacts while preserving anatomical structures. This ensures that only relevant information is utilized in the reconstruction process. By infusing recalibrated features from the encoder block, the model focuses on relevant spatial regions (e.g., areas with artifacts) and highlights key features across channels (e.g., anatomical structures), leading to improved reconstruction of artifact-corrupted regions. Unlike traditional MAR methods, our approach bridges the gap between high-resolution kVCT and artifact-resistant MVCT, enhancing radiotherapy planning. It produces high-quality MVCT-like reconstructions, validated through qualitative and quantitative evaluations. Clinically, this enables oncologists to rely on kVCT alone, reducing repeated high-dose MVCT scans and lowering radiation exposure for cancer patients.",
    "summary": "arXiv:2506.19531v1 Announce Type: cross Abstract: Artifacts in kilo-Voltage CT (kVCT) imaging degrade image quality, impacting clinical decisions. We propose a deep learning framework for metal artifact reduction (MAR) and domain transformation from kVCT to Mega-Voltage CT (MVCT). The proposed framework, ReMAR-DS, utilizes an encoder-decoder architecture with enhanced feature recalibration, effectively reducing artifacts while preserving anatomical structures. This ensures that only relevant information is utilized in the reconstruction process. By infusing recalibrated features from the encoder block, the model focuses on relevant spatial regions (e.g., areas with artifacts) and highlights key features across channels (e.g., anatomical structures), leading to improved reconstruction of artifact-corrupted regions. Unlike traditional MAR methods, our approach bridges the gap between high-resolution kVCT and artifact-resistant MVCT, enhancing radiotherapy planning. It produces high-quality MVCT-like reconstructions, validated through qualitative and quantitative evaluations. Clinically, this enables oncologists to rely on kVCT alone, reducing repeated high-dose MVCT scans and lowering radiation exposure for cancer patients.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19531",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Research on Model Parallelism and Data Parallelism Optimization Methods in Large Language Model-Based Recommendation Systems",
    "description": "arXiv:2506.17551v2 Announce Type: replace-cross Abstract: With the rapid adoption of large language models (LLMs) in recommendation systems, the computational and communication bottlenecks caused by their massive parameter sizes and large data volumes have become increasingly prominent. This paper systematically investigates two classes of optimization methods-model parallelism and data parallelism-for distributed training of LLMs in recommendation scenarios. For model parallelism, we implement both tensor parallelism and pipeline parallelism, and introduce an adaptive load-balancing mechanism to reduce cross-device communication overhead. For data parallelism, we compare synchronous and asynchronous modes, combining gradient compression and sparsification techniques with an efficient aggregation communication framework to significantly improve bandwidth utilization. Experiments conducted on a real-world recommendation dataset in a simulated service environment demonstrate that our proposed hybrid parallelism scheme increases training throughput by over 30% and improves resource utilization by approximately 20% compared to traditional single-mode parallelism, while maintaining strong scalability and robustness. Finally, we discuss trade-offs among different parallel strategies in online deployment and outline future directions involving heterogeneous hardware integration and automated scheduling technologies.",
    "summary": "arXiv:2506.17551v2 Announce Type: replace-cross Abstract: With the rapid adoption of large language models (LLMs) in recommendation systems, the computational and communication bottlenecks caused by their massive parameter sizes and large data volumes have become increasingly prominent. This paper systematically investigates two classes of optimization methods-model parallelism and data parallelism-for distributed training of LLMs in recommendation scenarios. For model parallelism, we implement both tensor parallelism and pipeline parallelism, and introduce an adaptive load-balancing mechanism to reduce cross-device communication overhead. For data parallelism, we compare synchronous and asynchronous modes, combining gradient compression and sparsification techniques with an efficient aggregation communication framework to significantly improve bandwidth utilization. Experiments conducted on a real-world recommendation dataset in a simulated service environment demonstrate that our proposed hybrid parallelism scheme increases training throughput by over 30% and improves resource utilization by approximately 20% compared to traditional single-mode parallelism, while maintaining strong scalability and robustness. Finally, we discuss trade-offs among different parallel strategies in online deployment and outline future directions involving heterogeneous hardware integration and automated scheduling technologies.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.17551",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Rich Interoperable Metadata for Cultural Heritage Projects at Jagiellonian University",
    "description": "arXiv:2407.06976v3 Announce Type: replace-cross Abstract: The rich metadata created nowadays for objects stored in libraries has nowhere to be stored, because core standards, namely MARC 21 and Dublin Core, are not flexible enough. The aim of this paper is to summarize our work-in-progress on tackling this problem in research on cultural heritage objects at the Jagiellonian University (JU). We compared the objects' metadata currently being collected at the JU (with examples of manuscript, placard, and obituary) with five widespread metadata standards used by the cultural heritage community: Dublin Core, EAD, MODS, EDM and Digital Scriptorium. Our preliminary results showed that mapping between them is indeed problematic, but we identified requirements that should be followed in further work on the JU cultural heritage metadata schema in order to achieve maximum interoperability. As we move forward, based on the successive versions of the conceptual model, we will conduct experiments to validate the practical feasibility of these mappings and the degree to which the proposed model will actually enable integration with data in these various metadata formats.",
    "summary": "arXiv:2407.06976v3 Announce Type: replace-cross Abstract: The rich metadata created nowadays for objects stored in libraries has nowhere to be stored, because core standards, namely MARC 21 and Dublin Core, are not flexible enough. The aim of this paper is to summarize our work-in-progress on tackling this problem in research on cultural heritage objects at the Jagiellonian University (JU). We compared the objects' metadata currently being collected at the JU (with examples of manuscript, placard, and obituary) with five widespread metadata standards used by the cultural heritage community: Dublin Core, EAD, MODS, EDM and Digital Scriptorium. Our preliminary results showed that mapping between them is indeed problematic, but we identified requirements that should be followed in further work on the JU cultural heritage metadata schema in order to achieve maximum interoperability. As we move forward, based on the successive versions of the conceptual model, we will conduct experiments to validate the practical feasibility of these mappings and the degree to which the proposed model will actually enable integration with data in these various metadata formats.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2407.06976",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Robotics Under Construction: Challenges on Job Sites",
    "description": "arXiv:2506.19597v1 Announce Type: cross Abstract: As labor shortages and productivity stagnation increasingly challenge the construction industry, automation has become essential for sustainable infrastructure development. This paper presents an autonomous payload transportation system as an initial step toward fully unmanned construction sites. Our system, based on the CD110R-3 crawler carrier, integrates autonomous navigation, fleet management, and GNSS-based localization to facilitate material transport in construction site environments. While the current system does not yet incorporate dynamic environment adaptation algorithms, we have begun fundamental investigations into external-sensor based perception and mapping system. Preliminary results highlight the potential challenges, including navigation in evolving terrain, environmental perception under construction-specific conditions, and sensor placement optimization for improving autonomy and efficiency. Looking forward, we envision a construction ecosystem where collaborative autonomous agents dynamically adapt to site conditions, optimizing workflow and reducing human intervention. This paper provides foundational insights into the future of robotics-driven construction automation and identifies critical areas for further technological development.",
    "summary": "arXiv:2506.19597v1 Announce Type: cross Abstract: As labor shortages and productivity stagnation increasingly challenge the construction industry, automation has become essential for sustainable infrastructure development. This paper presents an autonomous payload transportation system as an initial step toward fully unmanned construction sites. Our system, based on the CD110R-3 crawler carrier, integrates autonomous navigation, fleet management, and GNSS-based localization to facilitate material transport in construction site environments. While the current system does not yet incorporate dynamic environment adaptation algorithms, we have begun fundamental investigations into external-sensor based perception and mapping system. Preliminary results highlight the potential challenges, including navigation in evolving terrain, environmental perception under construction-specific conditions, and sensor placement optimization for improving autonomy and efficiency. Looking forward, we envision a construction ecosystem where collaborative autonomous agents dynamically adapt to site conditions, optimizing workflow and reducing human intervention. This paper provides foundational insights into the future of robotics-driven construction automation and identifies critical areas for further technological development.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19597",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Robust Behavior Cloning Via Global Lipschitz Regularization",
    "description": "arXiv:2506.19250v1 Announce Type: cross Abstract: Behavior Cloning (BC) is an effective imitation learning technique and has even been adopted in some safety-critical domains such as autonomous vehicles. BC trains a policy to mimic the behavior of an expert by using a dataset composed of only state-action pairs demonstrated by the expert, without any additional interaction with the environment. However, During deployment, the policy observations may contain measurement errors or adversarial disturbances. Since the observations may deviate from the true states, they can mislead the agent into making sub-optimal actions. In this work, we use a global Lipschitz regularization approach to enhance the robustness of the learned policy network. We then show that the resulting global Lipschitz property provides a robustness certificate to the policy with respect to different bounded norm perturbations. Then, we propose a way to construct a Lipschitz neural network that ensures the policy robustness. We empirically validate our theory across various environments in Gymnasium. Keywords: Robust Reinforcement Learning; Behavior Cloning; Lipschitz Neural Network",
    "summary": "arXiv:2506.19250v1 Announce Type: cross Abstract: Behavior Cloning (BC) is an effective imitation learning technique and has even been adopted in some safety-critical domains such as autonomous vehicles. BC trains a policy to mimic the behavior of an expert by using a dataset composed of only state-action pairs demonstrated by the expert, without any additional interaction with the environment. However, During deployment, the policy observations may contain measurement errors or adversarial disturbances. Since the observations may deviate from the true states, they can mislead the agent into making sub-optimal actions. In this work, we use a global Lipschitz regularization approach to enhance the robustness of the learned policy network. We then show that the resulting global Lipschitz property provides a robustness certificate to the policy with respect to different bounded norm perturbations. Then, we propose a way to construct a Lipschitz neural network that ensures the policy robustness. We empirically validate our theory across various environments in Gymnasium. Keywords: Robust Reinforcement Learning; Behavior Cloning; Lipschitz Neural Network",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19250",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Robust Optimization with Diffusion Models for Green Security",
    "description": "arXiv:2503.05730v2 Announce Type: replace-cross Abstract: In green security, defenders must forecast adversarial behavior, such as poaching, illegal logging, and illegal fishing, to plan effective patrols. These behavior are often highly uncertain and complex. Prior work has leveraged game theory to design robust patrol strategies to handle uncertainty, but existing adversarial behavior models primarily rely on Gaussian processes or linear models, which lack the expressiveness needed to capture intricate behavioral patterns. To address this limitation, we propose a conditional diffusion model for adversary behavior modeling, leveraging its strong distribution-fitting capabilities. To the best of our knowledge, this is the first application of diffusion models in the green security domain. Integrating diffusion models into game-theoretic optimization, however, presents new challenges, including a constrained mixed strategy space and the need to sample from an unnormalized distribution to estimate utilities. To tackle these challenges, we introduce a mixed strategy of mixed strategies and employ a twisted Sequential Monte Carlo (SMC) sampler for accurate sampling. Theoretically, our algorithm is guaranteed to converge to an epsilon equilibrium with high probability using a finite number of iterations and samples. Empirically, we evaluate our approach on both synthetic and real-world poaching datasets, demonstrating its effectiveness.",
    "summary": "arXiv:2503.05730v2 Announce Type: replace-cross Abstract: In green security, defenders must forecast adversarial behavior, such as poaching, illegal logging, and illegal fishing, to plan effective patrols. These behavior are often highly uncertain and complex. Prior work has leveraged game theory to design robust patrol strategies to handle uncertainty, but existing adversarial behavior models primarily rely on Gaussian processes or linear models, which lack the expressiveness needed to capture intricate behavioral patterns. To address this limitation, we propose a conditional diffusion model for adversary behavior modeling, leveraging its strong distribution-fitting capabilities. To the best of our knowledge, this is the first application of diffusion models in the green security domain. Integrating diffusion models into game-theoretic optimization, however, presents new challenges, including a constrained mixed strategy space and the need to sample from an unnormalized distribution to estimate utilities. To tackle these challenges, we introduce a mixed strategy of mixed strategies and employ a twisted Sequential Monte Carlo (SMC) sampler for accurate sampling. Theoretically, our algorithm is guaranteed to converge to an epsilon equilibrium with high probability using a finite number of iterations and samples. Empirically, we evaluate our approach on both synthetic and real-world poaching datasets, demonstrating its effectiveness.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2503.05730",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Robust Reinforcement Learning from Human Feedback for Large Language Models Fine-Tuning",
    "description": "arXiv:2504.03784v4 Announce Type: replace-cross Abstract: Reinforcement learning from human feedback (RLHF) has emerged as a key technique for aligning the output of large language models (LLMs) with human preferences. To learn the reward function, most existing RLHF algorithms use the Bradley-Terry model, which relies on assumptions about human preferences that may not reflect the complexity and variability of real-world judgments. In this paper, we propose a robust algorithm to enhance the performance of existing approaches under such reward model misspecifications. Theoretically, our algorithm reduces the variance of reward and policy estimators, leading to improved regret bounds. Empirical evaluations on LLM benchmark datasets demonstrate that the proposed algorithm consistently outperforms existing methods, with 77-81% of responses being favored over baselines on the Anthropic Helpful and Harmless dataset.",
    "summary": "arXiv:2504.03784v4 Announce Type: replace-cross Abstract: Reinforcement learning from human feedback (RLHF) has emerged as a key technique for aligning the output of large language models (LLMs) with human preferences. To learn the reward function, most existing RLHF algorithms use the Bradley-Terry model, which relies on assumptions about human preferences that may not reflect the complexity and variability of real-world judgments. In this paper, we propose a robust algorithm to enhance the performance of existing approaches under such reward model misspecifications. Theoretically, our algorithm reduces the variance of reward and policy estimators, leading to improved regret bounds. Empirical evaluations on LLM benchmark datasets demonstrate that the proposed algorithm consistently outperforms existing methods, with 77-81% of responses being favored over baselines on the Anthropic Helpful and Harmless dataset.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2504.03784",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "「SaaSが終わる？　興味ない」　ラクス社長が語るAIの「真の脅威」",
    "description": "国内SaaS業界トップランナーのラクス。「SaaSが死ぬかどうかってそんなに興味ない」と明かす中村崇則社長が、本当に恐れているものとは何なのか。業界トップが明かすAI時代の生存戦略を聞いた。",
    "summary": "国内SaaS業界トップランナーのラクス。「SaaSが死ぬかどうかってそんなに興味ない」と明かす中村崇則社長が、本当に恐れているものとは何なのか。業界トップが明かすAI時代の生存戦略を聞いた。",
    "pubDate": "Wed, 25 Jun 2025 08:00:00 +0900",
    "source": "ITmedia AI",
    "url": "https://www.itmedia.co.jp/business/articles/2506/25/news038.html",
    "thumbnail": "https://image.itmedia.co.jp/business/articles/2506/25/cover_news038.jpg"
  },
  {
    "title": "Safe Pruning LoRA: Robust Distance-Guided Pruning for Safety Alignment in Adaptation of LLMs",
    "description": "arXiv:2506.18931v1 Announce Type: cross Abstract: Fine-tuning Large Language Models (LLMs) with Low-Rank Adaptation (LoRA) enhances adaptability while reducing computational costs. However, fine-tuning can compromise safety alignment, even with benign data, increasing susceptibility to harmful outputs. Existing safety alignment methods struggle to capture complex parameter shifts, leading to suboptimal safety-utility trade-offs. To address this issue, we propose Safe Pruning LoRA (SPLoRA), a novel pruning-based approach that selectively removes LoRA layers that weaken safety alignment, improving safety while preserving performance. At its core, we introduce Empirical-DIEM (E-DIEM), a dimension-insensitive similarity metric that effectively detects safety misalignment in LoRA-adapted models. We conduct extensive experiments on LLMs fine-tuned with mixed of benign and malicious data, and purely benign datasets, evaluating SPLoRA across utility, safety, and reliability metrics. Results demonstrate that SPLoRA outperforms state-of-the-art safety alignment techniques, significantly reducing safety risks while maintaining or improving model performance and reliability. Additionally, SPLoRA reduces inference overhead, making it a scalable and efficient solution for deploying safer and more reliable LLMs. The code is available at https://github.com/AoShuang92/SPLoRA.",
    "summary": "arXiv:2506.18931v1 Announce Type: cross Abstract: Fine-tuning Large Language Models (LLMs) with Low-Rank Adaptation (LoRA) enhances adaptability while reducing computational costs. However, fine-tuning can compromise safety alignment, even with benign data, increasing susceptibility to harmful outputs. Existing safety alignment methods struggle to capture complex parameter shifts, leading to suboptimal safety-utility trade-offs. To address this issue, we propose Safe Pruning LoRA (SPLoRA), a novel pruning-based approach that selectively removes LoRA layers that weaken safety alignment, improving safety while preserving performance. At its core, we introduce Empirical-DIEM (E-DIEM), a dimension-insensitive similarity metric that effectively detects safety misalignment in LoRA-adapted models. We conduct extensive experiments on LLMs fine-tuned with mixed of benign and malicious data, and purely benign datasets, evaluating SPLoRA across utility, safety, and reliability metrics. Results demonstrate that SPLoRA outperforms state-of-the-art safety alignment techniques, significantly reducing safety risks while maintaining or improving model performance and reliability. Additionally, SPLoRA reduces inference overhead, making it a scalable and efficient solution for deploying safer and more reliable LLMs. The code is available at https://github.com/AoShuang92/SPLoRA.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.18931",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "SAGE: Strategy-Adaptive Generation Engine for Query Rewriting",
    "description": "arXiv:2506.19783v1 Announce Type: new Abstract: Query rewriting is pivotal for enhancing dense retrieval, yet current methods demand large-scale supervised data or suffer from inefficient reinforcement learning (RL) exploration. In this work, we first establish that guiding Large Language Models (LLMs) with a concise set of expert-crafted strategies, such as semantic expansion and entity disambiguation, substantially improves retrieval effectiveness on challenging benchmarks, including HotpotQA, FEVER, NFCorpus, and SciFact. Building on this insight, we introduce the Strategy-Adaptive Generation Engine (SAGE), which operationalizes these strategies in an RL framework. SAGE introduces two novel reward shaping mechanisms-Strategic Credit Shaping (SCS) and Contrastive Reward Shaping (CRS)-to deliver more informative learning signals. This strategy-guided approach not only achieves new state-of-the-art NDCG@10 results, but also uncovers a compelling emergent behavior: the agent learns to select optimal strategies, reduces unnecessary exploration, and generates concise rewrites, lowering inference cost without sacrificing performance. Our findings demonstrate that strategy-guided RL, enhanced with nuanced reward shaping, offers a scalable, efficient, and more interpretable paradigm for developing the next generation of robust information retrieval systems.",
    "summary": "arXiv:2506.19783v1 Announce Type: new Abstract: Query rewriting is pivotal for enhancing dense retrieval, yet current methods demand large-scale supervised data or suffer from inefficient reinforcement learning (RL) exploration. In this work, we first establish that guiding Large Language Models (LLMs) with a concise set of expert-crafted strategies, such as semantic expansion and entity disambiguation, substantially improves retrieval effectiveness on challenging benchmarks, including HotpotQA, FEVER, NFCorpus, and SciFact. Building on this insight, we introduce the Strategy-Adaptive Generation Engine (SAGE), which operationalizes these strategies in an RL framework. SAGE introduces two novel reward shaping mechanisms-Strategic Credit Shaping (SCS) and Contrastive Reward Shaping (CRS)-to deliver more informative learning signals. This strategy-guided approach not only achieves new state-of-the-art NDCG@10 results, but also uncovers a compelling emergent behavior: the agent learns to select optimal strategies, reduces unnecessary exploration, and generates concise rewrites, lowering inference cost without sacrificing performance. Our findings demonstrate that strategy-guided RL, enhanced with nuanced reward shaping, offers a scalable, efficient, and more interpretable paradigm for developing the next generation of robust information retrieval systems.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19783",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "SASSHA: Sharpness-aware Adaptive Second-order Optimization with Stable Hessian Approximation",
    "description": "arXiv:2502.18153v2 Announce Type: replace-cross Abstract: Approximate second-order optimization methods often exhibit poorer generalization compared to first-order approaches. In this work, we look into this issue through the lens of the loss landscape and find that existing second-order methods tend to converge to sharper minima compared to SGD. In response, we propose Sassha, a novel second-order method designed to enhance generalization by explicitly reducing sharpness of the solution, while stabilizing the computation of approximate Hessians along the optimization trajectory. In fact, this sharpness minimization scheme is crafted also to accommodate lazy Hessian updates, so as to secure efficiency besides flatness. To validate its effectiveness, we conduct a wide range of standard deep learning experiments where Sassha demonstrates its outstanding generalization performance that is comparable to, and mostly better than, other methods. We provide a comprehensive set of analyses including convergence, robustness, stability, efficiency, and cost.",
    "summary": "arXiv:2502.18153v2 Announce Type: replace-cross Abstract: Approximate second-order optimization methods often exhibit poorer generalization compared to first-order approaches. In this work, we look into this issue through the lens of the loss landscape and find that existing second-order methods tend to converge to sharper minima compared to SGD. In response, we propose Sassha, a novel second-order method designed to enhance generalization by explicitly reducing sharpness of the solution, while stabilizing the computation of approximate Hessians along the optimization trajectory. In fact, this sharpness minimization scheme is crafted also to accommodate lazy Hessian updates, so as to secure efficiency besides flatness. To validate its effectiveness, we conduct a wide range of standard deep learning experiments where Sassha demonstrates its outstanding generalization performance that is comparable to, and mostly better than, other methods. We provide a comprehensive set of analyses including convergence, robustness, stability, efficiency, and cost.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2502.18153",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Semantic Scene Graph for Ultrasound Image Explanation and Scanning Guidance",
    "description": "arXiv:2506.19683v1 Announce Type: cross Abstract: Understanding medical ultrasound imaging remains a long-standing challenge due to significant visual variability caused by differences in imaging and acquisition parameters. Recent advancements in large language models (LLMs) have been used to automatically generate terminology-rich summaries orientated to clinicians with sufficient physiological knowledge. Nevertheless, the increasing demand for improved ultrasound interpretability and basic scanning guidance among non-expert users, e.g., in point-of-care settings, has not yet been explored. In this study, we first introduce the scene graph (SG) for ultrasound images to explain image content to ordinary and provide guidance for ultrasound scanning. The ultrasound SG is first computed using a transformer-based one-stage method, eliminating the need for explicit object detection. To generate a graspable image explanation for ordinary, the user query is then used to further refine the abstract SG representation through LLMs. Additionally, the predicted SG is explored for its potential in guiding ultrasound scanning toward missing anatomies within the current imaging view, assisting ordinary users in achieving more standardized and complete anatomical exploration. The effectiveness of this SG-based image explanation and scanning guidance has been validated on images from the left and right neck regions, including the carotid and thyroid, across five volunteers. The results demonstrate the potential of the method to maximally democratize ultrasound by enhancing its interpretability and usability for ordinaries.",
    "summary": "arXiv:2506.19683v1 Announce Type: cross Abstract: Understanding medical ultrasound imaging remains a long-standing challenge due to significant visual variability caused by differences in imaging and acquisition parameters. Recent advancements in large language models (LLMs) have been used to automatically generate terminology-rich summaries orientated to clinicians with sufficient physiological knowledge. Nevertheless, the increasing demand for improved ultrasound interpretability and basic scanning guidance among non-expert users, e.g., in point-of-care settings, has not yet been explored. In this study, we first introduce the scene graph (SG) for ultrasound images to explain image content to ordinary and provide guidance for ultrasound scanning. The ultrasound SG is first computed using a transformer-based one-stage method, eliminating the need for explicit object detection. To generate a graspable image explanation for ordinary, the user query is then used to further refine the abstract SG representation through LLMs. Additionally, the predicted SG is explored for its potential in guiding ultrasound scanning toward missing anatomies within the current imaging view, assisting ordinary users in achieving more standardized and complete anatomical exploration. The effectiveness of this SG-based image explanation and scanning guidance has been validated on images from the left and right neck regions, including the carotid and thyroid, across five volunteers. The results demonstrate the potential of the method to maximally democratize ultrasound by enhancing its interpretability and usability for ordinaries.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19683",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "SHAMaNS: Sound Localization with Hybrid Alpha-Stable Spatial Measure and Neural Steerer",
    "description": "arXiv:2506.18954v1 Announce Type: cross Abstract: This paper describes a sound source localization (SSL) technique that combines an $alpha$-stable model for the observed signal with a neural network-based approach for modeling steering vectors. Specifically, a physics-informed neural network, referred to as Neural Steerer, is used to interpolate measured steering vectors (SVs) on a fixed microphone array. This allows for a more robust estimation of the so-called $alpha$-stable spatial measure, which represents the most plausible direction of arrival (DOA) of a target signal. As an $alpha$-stable model for the non-Gaussian case ($alpha$ $in$ (0, 2)) theoretically defines a unique spatial measure, we choose to leverage it to account for residual reconstruction error of the Neural Steerer in the downstream tasks. The objective scores indicate that our proposed technique outperforms state-of-the-art methods in the case of multiple sound sources.",
    "summary": "arXiv:2506.18954v1 Announce Type: cross Abstract: This paper describes a sound source localization (SSL) technique that combines an $alpha$-stable model for the observed signal with a neural network-based approach for modeling steering vectors. Specifically, a physics-informed neural network, referred to as Neural Steerer, is used to interpolate measured steering vectors (SVs) on a fixed microphone array. This allows for a more robust estimation of the so-called $alpha$-stable spatial measure, which represents the most plausible direction of arrival (DOA) of a target signal. As an $alpha$-stable model for the non-Gaussian case ($alpha$ $in$ (0, 2)) theoretically defines a unique spatial measure, we choose to leverage it to account for residual reconstruction error of the Neural Steerer in the downstream tasks. The objective scores indicate that our proposed technique outperforms state-of-the-art methods in the case of multiple sound sources.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.18954",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Signal Use and Emergent Cooperation",
    "description": "arXiv:2506.18920v1 Announce Type: new Abstract: In this work, we investigate how autonomous agents, organized into tribes, learn to use communication signals to coordinate their activities and enhance their collective efficiency. Using the NEC-DAC (Neurally Encoded Culture - Distributed Autonomous Communicators) system, where each agent is equipped with its own neural network for decision-making, we demonstrate how these agents develop a shared behavioral system -- akin to a culture -- through learning and signalling. Our research focuses on the self-organization of culture within these tribes of agents and how varying communication strategies impact their fitness and cooperation. By analyzing different social structures, such as authority hierarchies, we show that the culture of cooperation significantly influences the tribe's performance. Furthermore, we explore how signals not only facilitate the emergence of culture but also enable its transmission across generations of agents. Additionally, we examine the benefits of coordinating behavior and signaling within individual agents' neural networks.",
    "summary": "arXiv:2506.18920v1 Announce Type: new Abstract: In this work, we investigate how autonomous agents, organized into tribes, learn to use communication signals to coordinate their activities and enhance their collective efficiency. Using the NEC-DAC (Neurally Encoded Culture - Distributed Autonomous Communicators) system, where each agent is equipped with its own neural network for decision-making, we demonstrate how these agents develop a shared behavioral system -- akin to a culture -- through learning and signalling. Our research focuses on the self-organization of culture within these tribes of agents and how varying communication strategies impact their fitness and cooperation. By analyzing different social structures, such as authority hierarchies, we show that the culture of cooperation significantly influences the tribe's performance. Furthermore, we explore how signals not only facilitate the emergence of culture but also enable its transmission across generations of agents. Additionally, we examine the benefits of coordinating behavior and signaling within individual agents' neural networks.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.18920",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Skywork-SWE: Unveiling Data Scaling Laws for Software Engineering in LLMs",
    "description": "arXiv:2506.19290v1 Announce Type: new Abstract: Software engineering (SWE) has recently emerged as a crucial testbed for next-generation LLM agents, demanding inherent capabilities in two critical dimensions: sustained iterative problem-solving (e.g., >50 interaction rounds) and long-context dependency resolution (e.g., >32k tokens). However, the data curation process in SWE remains notoriously time-consuming, as it heavily relies on manual annotation for code file filtering and the setup of dedicated runtime environments to execute and validate unit tests. Consequently, most existing datasets are limited to only a few thousand GitHub-sourced instances. To this end, we propose an incremental, automated data-curation pipeline that systematically scales both the volume and diversity of SWE datasets. Our dataset comprises 10,169 real-world Python task instances from 2,531 distinct GitHub repositories, each accompanied by a task specified in natural language and a dedicated runtime-environment image for automated unit-test validation. We have carefully curated over 8,000 successfully runtime-validated training trajectories from our proposed SWE dataset. When fine-tuning the Skywork-SWE model on these trajectories, we uncover a striking data scaling phenomenon: the trained model's performance for software engineering capabilities in LLMs continues to improve as the data size increases, showing no signs of saturation. Notably, our Skywork-SWE model achieves 38.0% pass@1 accuracy on the SWE-bench Verified benchmark without using verifiers or multiple rollouts, establishing a new state-of-the-art (SOTA) among the Qwen2.5-Coder-32B-based LLMs built on the OpenHands agent framework. Furthermore, with the incorporation of test-time scaling techniques, the performance further improves to 47.0% accuracy, surpassing the previous SOTA results for sub-32B parameter models. We release the Skywork-SWE-32B model checkpoint to accelerate future research.",
    "summary": "arXiv:2506.19290v1 Announce Type: new Abstract: Software engineering (SWE) has recently emerged as a crucial testbed for next-generation LLM agents, demanding inherent capabilities in two critical dimensions: sustained iterative problem-solving (e.g., >50 interaction rounds) and long-context dependency resolution (e.g., >32k tokens). However, the data curation process in SWE remains notoriously time-consuming, as it heavily relies on manual annotation for code file filtering and the setup of dedicated runtime environments to execute and validate unit tests. Consequently, most existing datasets are limited to only a few thousand GitHub-sourced instances. To this end, we propose an incremental, automated data-curation pipeline that systematically scales both the volume and diversity of SWE datasets. Our dataset comprises 10,169 real-world Python task instances from 2,531 distinct GitHub repositories, each accompanied by a task specified in natural language and a dedicated runtime-environment image for automated unit-test validation. We have carefully curated over 8,000 successfully runtime-validated training trajectories from our proposed SWE dataset. When fine-tuning the Skywork-SWE model on these trajectories, we uncover a striking data scaling phenomenon: the trained model's performance for software engineering capabilities in LLMs continues to improve as the data size increases, showing no signs of saturation. Notably, our Skywork-SWE model achieves 38.0% pass@1 accuracy on the SWE-bench Verified benchmark without using verifiers or multiple rollouts, establishing a new state-of-the-art (SOTA) among the Qwen2.5-Coder-32B-based LLMs built on the OpenHands agent framework. Furthermore, with the incorporation of test-time scaling techniques, the performance further improves to 47.0% accuracy, surpassing the previous SOTA results for sub-32B parameter models. We release the Skywork-SWE-32B model checkpoint to accelerate future research.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19290",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Smart Traffic Signals: Comparing MARL and Fixed-Time Strategies",
    "description": "arXiv:2505.14544v2 Announce Type: replace Abstract: Urban traffic congestion, particularly at intersections, significantly impacts travel time, fuel consumption, and emissions. Traditional fixed-time signal control systems often lack the adaptability to manage dynamic traffic patterns effectively. This study explores the application of multi-agent reinforcement learning (MARL) to optimize traffic signal coordination across multiple intersections within a simulated environment. Utilizing Pygame, a simulation was developed to model a network of interconnected intersections with randomly generated vehicle flows to reflect realistic traffic variability. A decentralized MARL controller was implemented, in which each traffic signal operates as an autonomous agent, making decisions based on local observations and information from neighboring agents. Performance was evaluated against a baseline fixed-time controller using metrics such as average vehicle wait time and overall throughput. The MARL approach demonstrated statistically significant improvements, including reduced average waiting times and improved throughput. These findings suggest that MARL-based dynamic control strategies hold substantial promise for improving urban traffic management efficiency. More research is recommended to address scalability and real-world implementation challenges.",
    "summary": "arXiv:2505.14544v2 Announce Type: replace Abstract: Urban traffic congestion, particularly at intersections, significantly impacts travel time, fuel consumption, and emissions. Traditional fixed-time signal control systems often lack the adaptability to manage dynamic traffic patterns effectively. This study explores the application of multi-agent reinforcement learning (MARL) to optimize traffic signal coordination across multiple intersections within a simulated environment. Utilizing Pygame, a simulation was developed to model a network of interconnected intersections with randomly generated vehicle flows to reflect realistic traffic variability. A decentralized MARL controller was implemented, in which each traffic signal operates as an autonomous agent, making decisions based on local observations and information from neighboring agents. Performance was evaluated against a baseline fixed-time controller using metrics such as average vehicle wait time and overall throughput. The MARL approach demonstrated statistically significant improvements, including reduced average waiting times and improved throughput. These findings suggest that MARL-based dynamic control strategies hold substantial promise for improving urban traffic management efficiency. More research is recommended to address scalability and real-world implementation challenges.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2505.14544",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Spiritual-LLM : Gita Inspired Mental Health Therapy In the Era of LLMs",
    "description": "arXiv:2506.19185v1 Announce Type: new Abstract: Traditional mental health support systems often generate responses based solely on the user's current emotion and situations, resulting in superficial interventions that fail to address deeper emotional needs. This study introduces a novel framework by integrating spiritual wisdom from the Bhagavad Gita with advanced large language model GPT-4o to enhance emotional well-being. We present the GITes (Gita Integrated Therapy for Emotional Support) dataset, which enhances the existing ExTES mental health dataset by including 10,729 spiritually guided responses generated by GPT-4o and evaluated by domain experts. We benchmark GITes against 12 state-of-the-art LLMs, including both mental health specific and general purpose models. To evaluate spiritual relevance in generated responses beyond what conventional n-gram based metrics capture, we propose a novel Spiritual Insight metric and automate assessment via an LLM as jury framework using chain-of-thought prompting. Integrating spiritual guidance into AI driven support enhances both NLP and spiritual metrics for the best performing LLM Phi3-Mini 3.2B Instruct, achieving improvements of 122.71% in ROUGE, 126.53% in METEOR, 8.15% in BERT score, 15.92% in Spiritual Insight, 18.61% in Sufficiency and 13.22% in Relevance compared to its zero-shot counterpart. While these results reflect substantial improvements across automated empathy and spirituality metrics, further validation in real world patient populations remains a necessary step. Our findings indicate a strong potential for AI systems enriched with spiritual guidance to enhance user satisfaction and perceived support outcomes. The code and dataset will be publicly available to advance further research in this emerging area.",
    "summary": "arXiv:2506.19185v1 Announce Type: new Abstract: Traditional mental health support systems often generate responses based solely on the user's current emotion and situations, resulting in superficial interventions that fail to address deeper emotional needs. This study introduces a novel framework by integrating spiritual wisdom from the Bhagavad Gita with advanced large language model GPT-4o to enhance emotional well-being. We present the GITes (Gita Integrated Therapy for Emotional Support) dataset, which enhances the existing ExTES mental health dataset by including 10,729 spiritually guided responses generated by GPT-4o and evaluated by domain experts. We benchmark GITes against 12 state-of-the-art LLMs, including both mental health specific and general purpose models. To evaluate spiritual relevance in generated responses beyond what conventional n-gram based metrics capture, we propose a novel Spiritual Insight metric and automate assessment via an LLM as jury framework using chain-of-thought prompting. Integrating spiritual guidance into AI driven support enhances both NLP and spiritual metrics for the best performing LLM Phi3-Mini 3.2B Instruct, achieving improvements of 122.71% in ROUGE, 126.53% in METEOR, 8.15% in BERT score, 15.92% in Spiritual Insight, 18.61% in Sufficiency and 13.22% in Relevance compared to its zero-shot counterpart. While these results reflect substantial improvements across automated empathy and spirituality metrics, further validation in real world patient populations remains a necessary step. Our findings indicate a strong potential for AI systems enriched with spiritual guidance to enhance user satisfaction and perceived support outcomes. The code and dataset will be publicly available to advance further research in this emerging area.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19185",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Spotting Out-of-Character Behavior: Atomic-Level Evaluation of Persona Fidelity in Open-Ended Generation",
    "description": "arXiv:2506.19352v1 Announce Type: cross Abstract: Ensuring persona fidelity in large language models (LLMs) is essential for maintaining coherent and engaging human-AI interactions. However, LLMs often exhibit Out-of-Character (OOC) behavior, where generated responses deviate from an assigned persona, leading to inconsistencies that affect model reliability. Existing evaluation methods typically assign single scores to entire responses, struggling to capture subtle persona misalignment, particularly in long-form text generation. To address this limitation, we propose an atomic-level evaluation framework that quantifies persona fidelity at a finer granularity. Our three key metrics measure the degree of persona alignment and consistency within and across generations. Our approach enables a more precise and realistic assessment of persona fidelity by identifying subtle deviations that real users would encounter. Through our experiments, we demonstrate that our framework effectively detects persona inconsistencies that prior methods overlook. By analyzing persona fidelity across diverse tasks and personality types, we reveal how task structure and persona desirability influence model adaptability, highlighting challenges in maintaining consistent persona expression.",
    "summary": "arXiv:2506.19352v1 Announce Type: cross Abstract: Ensuring persona fidelity in large language models (LLMs) is essential for maintaining coherent and engaging human-AI interactions. However, LLMs often exhibit Out-of-Character (OOC) behavior, where generated responses deviate from an assigned persona, leading to inconsistencies that affect model reliability. Existing evaluation methods typically assign single scores to entire responses, struggling to capture subtle persona misalignment, particularly in long-form text generation. To address this limitation, we propose an atomic-level evaluation framework that quantifies persona fidelity at a finer granularity. Our three key metrics measure the degree of persona alignment and consistency within and across generations. Our approach enables a more precise and realistic assessment of persona fidelity by identifying subtle deviations that real users would encounter. Through our experiments, we demonstrate that our framework effectively detects persona inconsistencies that prior methods overlook. By analyzing persona fidelity across diverse tasks and personality types, we reveal how task structure and persona desirability influence model adaptability, highlighting challenges in maintaining consistent persona expression.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19352",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "SRFT: A Single-Stage Method with Supervised and Reinforcement Fine-Tuning for Reasoning",
    "description": "arXiv:2506.19767v1 Announce Type: cross Abstract: Large language models (LLMs) have achieved remarkable progress in reasoning tasks, yet the optimal integration of Supervised Fine-Tuning (SFT) and Reinforcement Learning (RL) remains a fundamental challenge. Through comprehensive analysis of token distributions, learning dynamics, and integration mechanisms from entropy-based perspectives, we reveal key differences between these paradigms: SFT induces coarse-grained global changes to LLM policy distributions, while RL performs fine-grained selective optimizations, with entropy serving as a critical indicator of training effectiveness. Building on these observations, we propose Supervised Reinforcement Fine-Tuning (SRFT), a single-stage method that unifies both fine-tuning paradigms through entropy-aware weighting mechanisms. Our approach simultaneously applies SFT and RL to directly optimize the LLM using demonstrations and self-exploration rollouts rather than through two-stage sequential methods. Extensive experiments show that SRFT achieves 59.1% average accuracy, outperforming zero-RL methods by 9.0% on five mathematical reasoning benchmarks and 10.9% on three out-of-distribution benchmarks.",
    "summary": "arXiv:2506.19767v1 Announce Type: cross Abstract: Large language models (LLMs) have achieved remarkable progress in reasoning tasks, yet the optimal integration of Supervised Fine-Tuning (SFT) and Reinforcement Learning (RL) remains a fundamental challenge. Through comprehensive analysis of token distributions, learning dynamics, and integration mechanisms from entropy-based perspectives, we reveal key differences between these paradigms: SFT induces coarse-grained global changes to LLM policy distributions, while RL performs fine-grained selective optimizations, with entropy serving as a critical indicator of training effectiveness. Building on these observations, we propose Supervised Reinforcement Fine-Tuning (SRFT), a single-stage method that unifies both fine-tuning paradigms through entropy-aware weighting mechanisms. Our approach simultaneously applies SFT and RL to directly optimize the LLM using demonstrations and self-exploration rollouts rather than through two-stage sequential methods. Extensive experiments show that SRFT achieves 59.1% average accuracy, outperforming zero-RL methods by 9.0% on five mathematical reasoning benchmarks and 10.9% on three out-of-distribution benchmarks.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19767",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "SSPS: Self-Supervised Positive Sampling for Robust Self-Supervised Speaker Verification",
    "description": "arXiv:2505.14561v2 Announce Type: replace-cross Abstract: Self-Supervised Learning (SSL) has led to considerable progress in Speaker Verification (SV). The standard framework uses same-utterance positive sampling and data-augmentation to generate anchor-positive pairs of the same speaker. This is a major limitation, as this strategy primarily encodes channel information from the recording condition, shared by the anchor and positive. We propose a new positive sampling technique to address this bottleneck: Self-Supervised Positive Sampling (SSPS). For a given anchor, SSPS aims to find an appropriate positive, i.e., of the same speaker identity but a different recording condition, in the latent space using clustering assignments and a memory queue of positive embeddings. SSPS improves SV performance for both SimCLR and DINO, reaching 2.57% and 2.53% EER, outperforming SOTA SSL methods on VoxCeleb1-O. In particular, SimCLR-SSPS achieves a 58% EER reduction by lowering intra-speaker variance, providing comparable performance to DINO-SSPS.",
    "summary": "arXiv:2505.14561v2 Announce Type: replace-cross Abstract: Self-Supervised Learning (SSL) has led to considerable progress in Speaker Verification (SV). The standard framework uses same-utterance positive sampling and data-augmentation to generate anchor-positive pairs of the same speaker. This is a major limitation, as this strategy primarily encodes channel information from the recording condition, shared by the anchor and positive. We propose a new positive sampling technique to address this bottleneck: Self-Supervised Positive Sampling (SSPS). For a given anchor, SSPS aims to find an appropriate positive, i.e., of the same speaker identity but a different recording condition, in the latent space using clustering assignments and a memory queue of positive embeddings. SSPS improves SV performance for both SimCLR and DINO, reaching 2.57% and 2.53% EER, outperforming SOTA SSL methods on VoxCeleb1-O. In particular, SimCLR-SSPS achieves a 58% EER reduction by lowering intra-speaker variance, providing comparable performance to DINO-SSPS.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2505.14561",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Statistical Inference for Optimal Transport Maps: Recent Advances and Perspectives",
    "description": "arXiv:2506.19025v1 Announce Type: cross Abstract: In many applications of optimal transport (OT), the object of primary interest is the optimal transport map. This map rearranges mass from one probability distribution to another in the most efficient way possible by minimizing a specified cost. In this paper we review recent advances in estimating and developing limit theorems for the OT map, using samples from the underlying distributions. We also review parallel lines of work that establish similar results for special cases and variants of the basic OT setup. We conclude with a discussion of key directions for future research with the goal of providing practitioners with reliable inferential tools.",
    "summary": "arXiv:2506.19025v1 Announce Type: cross Abstract: In many applications of optimal transport (OT), the object of primary interest is the optimal transport map. This map rearranges mass from one probability distribution to another in the most efficient way possible by minimizing a specified cost. In this paper we review recent advances in estimating and developing limit theorems for the OT map, using samples from the underlying distributions. We also review parallel lines of work that establish similar results for special cases and variants of the basic OT setup. We conclude with a discussion of key directions for future research with the goal of providing practitioners with reliable inferential tools.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19025",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Stylized Structural Patterns for Improved Neural Network Pre-training",
    "description": "arXiv:2506.19465v1 Announce Type: cross Abstract: Modern deep learning models in computer vision require large datasets of real images, which are difficult to curate and pose privacy and legal concerns, limiting their commercial use. Recent works suggest synthetic data as an alternative, yet models trained with it often underperform. This paper proposes a two-step approach to bridge this gap. First, we propose an improved neural fractal formulation through which we introduce a new class of synthetic data. Second, we propose reverse stylization, a technique that transfers visual features from a small, license-free set of real images onto synthetic datasets, enhancing their effectiveness. We analyze the domain gap between our synthetic datasets and real images using Kernel Inception Distance (KID) and show that our method achieves a significantly lower distributional gap compared to existing synthetic datasets. Furthermore, our experiments across different tasks demonstrate the practical impact of this reduced gap. We show that pretraining the EDM2 diffusion model on our synthetic dataset leads to an 11% reduction in FID during image generation, compared to models trained on existing synthetic datasets, and a 20% decrease in autoencoder reconstruction error, indicating improved performance in data representation. Furthermore, a ViT-S model trained for classification on this synthetic data achieves over a 10% improvement in ImageNet-100 accuracy. Our work opens up exciting possibilities for training practical models when sufficiently large real training sets are not available.",
    "summary": "arXiv:2506.19465v1 Announce Type: cross Abstract: Modern deep learning models in computer vision require large datasets of real images, which are difficult to curate and pose privacy and legal concerns, limiting their commercial use. Recent works suggest synthetic data as an alternative, yet models trained with it often underperform. This paper proposes a two-step approach to bridge this gap. First, we propose an improved neural fractal formulation through which we introduce a new class of synthetic data. Second, we propose reverse stylization, a technique that transfers visual features from a small, license-free set of real images onto synthetic datasets, enhancing their effectiveness. We analyze the domain gap between our synthetic datasets and real images using Kernel Inception Distance (KID) and show that our method achieves a significantly lower distributional gap compared to existing synthetic datasets. Furthermore, our experiments across different tasks demonstrate the practical impact of this reduced gap. We show that pretraining the EDM2 diffusion model on our synthetic dataset leads to an 11% reduction in FID during image generation, compared to models trained on existing synthetic datasets, and a 20% decrease in autoencoder reconstruction error, indicating improved performance in data representation. Furthermore, a ViT-S model trained for classification on this synthetic data achieves over a 10% improvement in ImageNet-100 accuracy. Our work opens up exciting possibilities for training practical models when sufficiently large real training sets are not available.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19465",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Sum-of-Parts: Self-Attributing Neural Networks with End-to-End Learning of Feature Groups",
    "description": "arXiv:2310.16316v4 Announce Type: replace-cross Abstract: Self-attributing neural networks (SANNs) present a potential path towards interpretable models for high-dimensional problems, but often face significant trade-offs in performance. In this work, we formally prove a lower bound on errors of per-feature SANNs, whereas group-based SANNs can achieve zero error and thus high performance. Motivated by these insights, we propose Sum-of-Parts (SOP), a framework that transforms any differentiable model into a group-based SANN, where feature groups are learned end-to-end without group supervision. SOP achieves state-of-the-art performance for SANNs on vision and language tasks, and we validate that the groups are interpretable on a range of quantitative and semantic metrics. We further validate the utility of SOP explanations in model debugging and cosmological scientific discovery. Our code is available at https://github.com/BrachioLab/sop",
    "summary": "arXiv:2310.16316v4 Announce Type: replace-cross Abstract: Self-attributing neural networks (SANNs) present a potential path towards interpretable models for high-dimensional problems, but often face significant trade-offs in performance. In this work, we formally prove a lower bound on errors of per-feature SANNs, whereas group-based SANNs can achieve zero error and thus high performance. Motivated by these insights, we propose Sum-of-Parts (SOP), a framework that transforms any differentiable model into a group-based SANN, where feature groups are learned end-to-end without group supervision. SOP achieves state-of-the-art performance for SANNs on vision and language tasks, and we validate that the groups are interpretable on a range of quantitative and semantic metrics. We further validate the utility of SOP explanations in model debugging and cosmological scientific discovery. Our code is available at https://github.com/BrachioLab/sop",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2310.16316",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Surgery-R1: Advancing Surgical-VQLA with Reasoning Multimodal Large Language Model via Reinforcement Learning",
    "description": "arXiv:2506.19469v1 Announce Type: cross Abstract: In recent years, significant progress has been made in the field of surgical scene understanding, particularly in the task of Visual Question Localized-Answering in robotic surgery (Surgical-VQLA). However, existing Surgical-VQLA models lack deep reasoning capabilities and interpretability in surgical scenes, which limits their reliability and potential for development in clinical applications. To address this issue, inspired by the development of Reasoning Multimodal Large Language Models (MLLMs), we first build the Surgery-R1-54k dataset, including paired data for Visual-QA, Grounding-QA, and Chain-of-Thought (CoT). Then, we propose the first Reasoning MLLM for Surgical-VQLA (Surgery-R1). In our Surgery-R1, we design a two-stage fine-tuning mechanism to enable the basic MLLM with complex reasoning abilities by utilizing supervised fine-tuning (SFT) and reinforcement fine-tuning (RFT). Furthermore, for an efficient and high-quality rule-based reward system in our RFT, we design a Multimodal Coherence reward mechanism to mitigate positional illusions that may arise in surgical scenarios. Experiment results demonstrate that Surgery-R1 outperforms other existing state-of-the-art (SOTA) models in the Surgical-VQLA task and widely-used MLLMs, while also validating its reasoning capabilities and the effectiveness of our approach. The code and dataset will be organized in https://github.com/FiFi-HAO467/Surgery-R1.",
    "summary": "arXiv:2506.19469v1 Announce Type: cross Abstract: In recent years, significant progress has been made in the field of surgical scene understanding, particularly in the task of Visual Question Localized-Answering in robotic surgery (Surgical-VQLA). However, existing Surgical-VQLA models lack deep reasoning capabilities and interpretability in surgical scenes, which limits their reliability and potential for development in clinical applications. To address this issue, inspired by the development of Reasoning Multimodal Large Language Models (MLLMs), we first build the Surgery-R1-54k dataset, including paired data for Visual-QA, Grounding-QA, and Chain-of-Thought (CoT). Then, we propose the first Reasoning MLLM for Surgical-VQLA (Surgery-R1). In our Surgery-R1, we design a two-stage fine-tuning mechanism to enable the basic MLLM with complex reasoning abilities by utilizing supervised fine-tuning (SFT) and reinforcement fine-tuning (RFT). Furthermore, for an efficient and high-quality rule-based reward system in our RFT, we design a Multimodal Coherence reward mechanism to mitigate positional illusions that may arise in surgical scenarios. Experiment results demonstrate that Surgery-R1 outperforms other existing state-of-the-art (SOTA) models in the Surgical-VQLA task and widely-used MLLMs, while also validating its reasoning capabilities and the effectiveness of our approach. The code and dataset will be organized in https://github.com/FiFi-HAO467/Surgery-R1.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19469",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Survey of HPC in US Research Institutions",
    "description": "arXiv:2506.19019v1 Announce Type: cross Abstract: The rapid growth of AI, data-intensive science, and digital twin technologies has driven an unprecedented demand for high-performance computing (HPC) across the research ecosystem. While national laboratories and industrial hyperscalers have invested heavily in exascale and GPU-centric architectures, university-operated HPC systems remain comparatively under-resourced. This survey presents a comprehensive assessment of the HPC landscape across U.S. universities, benchmarking their capabilities against Department of Energy (DOE) leadership-class systems and industrial AI infrastructures. We examine over 50 premier research institutions, analyzing compute capacity, architectural design, governance models, and energy efficiency. Our findings reveal that university clusters, though vital for academic research, exhibit significantly lower growth trajectories (CAGR $approx$ 18%) than their national ($approx$ 43%) and industrial ($approx$ 78%) counterparts. The increasing skew toward GPU-dense AI workloads has widened the capability gap, highlighting the need for federated computing, idle-GPU harvesting, and cost-sharing models. We also identify emerging paradigms, such as decentralized reinforcement learning, as promising opportunities for democratizing AI training within campus environments. Ultimately, this work provides actionable insights for academic leaders, funding agencies, and technology partners to ensure more equitable and sustainable HPC access in support of national research priorities.",
    "summary": "arXiv:2506.19019v1 Announce Type: cross Abstract: The rapid growth of AI, data-intensive science, and digital twin technologies has driven an unprecedented demand for high-performance computing (HPC) across the research ecosystem. While national laboratories and industrial hyperscalers have invested heavily in exascale and GPU-centric architectures, university-operated HPC systems remain comparatively under-resourced. This survey presents a comprehensive assessment of the HPC landscape across U.S. universities, benchmarking their capabilities against Department of Energy (DOE) leadership-class systems and industrial AI infrastructures. We examine over 50 premier research institutions, analyzing compute capacity, architectural design, governance models, and energy efficiency. Our findings reveal that university clusters, though vital for academic research, exhibit significantly lower growth trajectories (CAGR $approx$ 18%) than their national ($approx$ 43%) and industrial ($approx$ 78%) counterparts. The increasing skew toward GPU-dense AI workloads has widened the capability gap, highlighting the need for federated computing, idle-GPU harvesting, and cost-sharing models. We also identify emerging paradigms, such as decentralized reinforcement learning, as promising opportunities for democratizing AI training within campus environments. Ultimately, this work provides actionable insights for academic leaders, funding agencies, and technology partners to ensure more equitable and sustainable HPC access in support of national research priorities.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19019",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "SWE-SQL: Illuminating LLM Pathways to Solve User SQL Issues in Real-World Applications",
    "description": "arXiv:2506.18951v1 Announce Type: cross Abstract: Resolution of complex SQL issues persists as a significant bottleneck in real-world database applications. Current Large Language Models (LLMs), while adept at text-to-SQL translation, have not been rigorously evaluated on the more challenging task of debugging SQL issues. To address this gap, we introduce BIRD-CRITIC, a new SQL issue debugging benchmark comprising 530 PostgreSQL tasks (BIRD-CRITIC-PG) and 570 multi-dialect tasks (BIRD-CRITIC-Multi), distilled from authentic user issues and replayed within new environments to facilitate rigorous evaluation. Baseline evaluations underscore the task's complexity, with the leading reasoning model O3-Mini achieving only 38.87% success rate on BIRD-CRITIC-PG and 33.33% on BIRD-CRITIC-Multi. Meanwhile, advancing open-source models for database tasks is crucial for empowering local development while safeguarding data privacy. Therefore, we present Six-Gym (Sql-fIX-Gym), a training environment for elevating open-source model capabilities for SQL issue debugging. This environment leverages SQL-Rewind strategy, which automatically generates executable issue-solution datasets by reverse-engineering issues from verified SQLs. However, popular trajectory-based fine-tuning methods do not explore substantial supervisory signals. We further propose f-Plan Boosting, which extracts high-level debugging plans from SQL solutions, enabling teacher LLMs to produce 73.7% more successful trajectories for training. We integrate these components into an open-source agent, Bird-Fixer. Based on Qwen-2.5-Coder-14B, Bird-Fixer achieves 38.11% success rate on BIRD-CRITIC-PG and 29.65% on BIRD-CRITIC-Multi, surpassing leading proprietary models such as Claude-3.7-Sonnet and GPT-4.1, marking a significant step toward democratizing sophisticated SQL-debugging capabilities. The leaderboard and source code are available: https://bird-critic.github.io/",
    "summary": "arXiv:2506.18951v1 Announce Type: cross Abstract: Resolution of complex SQL issues persists as a significant bottleneck in real-world database applications. Current Large Language Models (LLMs), while adept at text-to-SQL translation, have not been rigorously evaluated on the more challenging task of debugging SQL issues. To address this gap, we introduce BIRD-CRITIC, a new SQL issue debugging benchmark comprising 530 PostgreSQL tasks (BIRD-CRITIC-PG) and 570 multi-dialect tasks (BIRD-CRITIC-Multi), distilled from authentic user issues and replayed within new environments to facilitate rigorous evaluation. Baseline evaluations underscore the task's complexity, with the leading reasoning model O3-Mini achieving only 38.87% success rate on BIRD-CRITIC-PG and 33.33% on BIRD-CRITIC-Multi. Meanwhile, advancing open-source models for database tasks is crucial for empowering local development while safeguarding data privacy. Therefore, we present Six-Gym (Sql-fIX-Gym), a training environment for elevating open-source model capabilities for SQL issue debugging. This environment leverages SQL-Rewind strategy, which automatically generates executable issue-solution datasets by reverse-engineering issues from verified SQLs. However, popular trajectory-based fine-tuning methods do not explore substantial supervisory signals. We further propose f-Plan Boosting, which extracts high-level debugging plans from SQL solutions, enabling teacher LLMs to produce 73.7% more successful trajectories for training. We integrate these components into an open-source agent, Bird-Fixer. Based on Qwen-2.5-Coder-14B, Bird-Fixer achieves 38.11% success rate on BIRD-CRITIC-PG and 29.65% on BIRD-CRITIC-Multi, surpassing leading proprietary models such as Claude-3.7-Sonnet and GPT-4.1, marking a significant step toward democratizing sophisticated SQL-debugging capabilities. The leaderboard and source code are available: https://bird-critic.github.io/",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.18951",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "SycnMapV2: Robust and Adaptive Unsupervised Segmentation",
    "description": "arXiv:2506.16297v2 Announce Type: replace-cross Abstract: Human vision excels at segmenting visual cues without the need for explicit training, and it remains remarkably robust even as noise severity increases. In contrast, existing AI algorithms struggle to maintain accuracy under similar conditions. Here, we present SyncMapV2, the first to solve unsupervised segmentation with state-of-the-art robustness. SyncMapV2 exhibits a minimal drop in mIoU, only 0.01%, under digital corruption, compared to a 23.8% drop observed in SOTA methods. This superior performance extends across various types of corruption: noise (7.3% vs. 37.7%), weather (7.5% vs. 33.8%), and blur (7.0% vs. 29.5%). Notably, SyncMapV2 accomplishes this without any robust training, supervision, or loss functions. It is based on a learning paradigm that uses self-organizing dynamical equations combined with concepts from random networks. Moreover, unlike conventional methods that require re-initialization for each new input, SyncMapV2 adapts online, mimicking the continuous adaptability of human vision. Thus, we go beyond the accurate and robust results, and present the first algorithm that can do all the above online, adapting to input rather than re-initializing. In adaptability tests, SyncMapV2 demonstrates near-zero performance degradation, which motivates and fosters a new generation of robust and adaptive intelligence in the near future.",
    "summary": "arXiv:2506.16297v2 Announce Type: replace-cross Abstract: Human vision excels at segmenting visual cues without the need for explicit training, and it remains remarkably robust even as noise severity increases. In contrast, existing AI algorithms struggle to maintain accuracy under similar conditions. Here, we present SyncMapV2, the first to solve unsupervised segmentation with state-of-the-art robustness. SyncMapV2 exhibits a minimal drop in mIoU, only 0.01%, under digital corruption, compared to a 23.8% drop observed in SOTA methods. This superior performance extends across various types of corruption: noise (7.3% vs. 37.7%), weather (7.5% vs. 33.8%), and blur (7.0% vs. 29.5%). Notably, SyncMapV2 accomplishes this without any robust training, supervision, or loss functions. It is based on a learning paradigm that uses self-organizing dynamical equations combined with concepts from random networks. Moreover, unlike conventional methods that require re-initialization for each new input, SyncMapV2 adapts online, mimicking the continuous adaptability of human vision. Thus, we go beyond the accurate and robust results, and present the first algorithm that can do all the above online, adapting to input rather than re-initializing. In adaptability tests, SyncMapV2 demonstrates near-zero performance degradation, which motivates and fosters a new generation of robust and adaptive intelligence in the near future.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16297",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Tagged for Direction: Pinning Down Causal Edge Directions with Precision",
    "description": "arXiv:2506.19459v1 Announce Type: cross Abstract: Not every causal relation between variables is equal, and this can be leveraged for the task of causal discovery. Recent research shows that pairs of variables with particular type assignments induce a preference on the causal direction of other pairs of variables with the same type. Although useful, this assignment of a specific type to a variable can be tricky in practice. We propose a tag-based causal discovery approach where multiple tags are assigned to each variable in a causal graph. Existing causal discovery approaches are first applied to direct some edges, which are then used to determine edge relations between tags. Then, these edge relations are used to direct the undirected edges. Doing so improves upon purely type-based relations, where the assumption of type consistency lacks robustness and flexibility due to being restricted to single types for each variable. Our experimental evaluations show that this boosts causal discovery and that these high-level tag relations fit common knowledge.",
    "summary": "arXiv:2506.19459v1 Announce Type: cross Abstract: Not every causal relation between variables is equal, and this can be leveraged for the task of causal discovery. Recent research shows that pairs of variables with particular type assignments induce a preference on the causal direction of other pairs of variables with the same type. Although useful, this assignment of a specific type to a variable can be tricky in practice. We propose a tag-based causal discovery approach where multiple tags are assigned to each variable in a causal graph. Existing causal discovery approaches are first applied to direct some edges, which are then used to determine edge relations between tags. Then, these edge relations are used to direct the undirected edges. Doing so improves upon purely type-based relations, where the assumption of type consistency lacks robustness and flexibility due to being restricted to single types for each variable. Our experimental evaluations show that this boosts causal discovery and that these high-level tag relations fit common knowledge.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19459",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Tailored Conversations beyond LLMs: A RL-Based Dialogue Manager",
    "description": "arXiv:2506.19652v1 Announce Type: cross Abstract: In this work, we propose a novel framework that integrates large language models (LLMs) with an RL-based dialogue manager for open-ended dialogue with a specific goal. By leveraging hierarchical reinforcement learning to model the structured phases of dialogue and employ meta-learning to enhance adaptability across diverse user profiles, our approach enhances adaptability and efficiency, enabling the system to learn from limited data, transition fluidly between dialogue phases, and personalize responses to heterogeneous patient needs. We apply our framework to Motivational Interviews, aiming to foster behavior change, and demonstrate that the proposed dialogue manager outperforms a state-of-the-art LLM baseline in terms of reward, showing a potential benefit of conditioning LLMs to create open-ended dialogue systems with specific goals.",
    "summary": "arXiv:2506.19652v1 Announce Type: cross Abstract: In this work, we propose a novel framework that integrates large language models (LLMs) with an RL-based dialogue manager for open-ended dialogue with a specific goal. By leveraging hierarchical reinforcement learning to model the structured phases of dialogue and employ meta-learning to enhance adaptability across diverse user profiles, our approach enhances adaptability and efficiency, enabling the system to learn from limited data, transition fluidly between dialogue phases, and personalize responses to heterogeneous patient needs. We apply our framework to Motivational Interviews, aiming to foster behavior change, and demonstrate that the proposed dialogue manager outperforms a state-of-the-art LLM baseline in terms of reward, showing a potential benefit of conditioning LLMs to create open-ended dialogue systems with specific goals.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19652",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Temporal-IRL: Modeling Port Congestion and Berth Scheduling with Inverse Reinforcement Learning",
    "description": "arXiv:2506.19843v1 Announce Type: new Abstract: Predicting port congestion is crucial for maintaining reliable global supply chains. Accurate forecasts enableimprovedshipment planning, reducedelaysand costs, and optimizeinventoryanddistributionstrategies, thereby ensuring timely deliveries and enhancing supply chain resilience. To achieve accurate predictions, analyzing vessel behavior and their stay times at specific port terminals is essential, focusing particularly on berth scheduling under various conditions. Crucially, the model must capture and learn the underlying priorities and patterns of berth scheduling. Berth scheduling and planning are influenced by a range of factors, including incoming vessel size, waiting times, and the status of vessels within the port terminal. By observing historical Automatic Identification System (AIS) positions of vessels, we reconstruct berth schedules, which are subsequently utilized to determine the reward function via Inverse Reinforcement Learning (IRL). For this purpose, we modeled a specific terminal at the Port of New York/New Jersey and developed Temporal-IRL. This Temporal-IRL model learns berth scheduling to predict vessel sequencing at the terminal and estimate vessel port stay, encompassing both waiting and berthing times, to forecast port congestion. Utilizing data from Maher Terminal spanning January 2015 to September 2023, we trained and tested the model, achieving demonstrably excellent results.",
    "summary": "arXiv:2506.19843v1 Announce Type: new Abstract: Predicting port congestion is crucial for maintaining reliable global supply chains. Accurate forecasts enableimprovedshipment planning, reducedelaysand costs, and optimizeinventoryanddistributionstrategies, thereby ensuring timely deliveries and enhancing supply chain resilience. To achieve accurate predictions, analyzing vessel behavior and their stay times at specific port terminals is essential, focusing particularly on berth scheduling under various conditions. Crucially, the model must capture and learn the underlying priorities and patterns of berth scheduling. Berth scheduling and planning are influenced by a range of factors, including incoming vessel size, waiting times, and the status of vessels within the port terminal. By observing historical Automatic Identification System (AIS) positions of vessels, we reconstruct berth schedules, which are subsequently utilized to determine the reward function via Inverse Reinforcement Learning (IRL). For this purpose, we modeled a specific terminal at the Port of New York/New Jersey and developed Temporal-IRL. This Temporal-IRL model learns berth scheduling to predict vessel sequencing at the terminal and estimate vessel port stay, encompassing both waiting and berthing times, to forecast port congestion. Utilizing data from Maher Terminal spanning January 2015 to September 2023, we trained and tested the model, achieving demonstrably excellent results.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19843",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "TeViR: Text-to-Video Reward with Diffusion Models for Efficient Reinforcement Learning",
    "description": "arXiv:2505.19769v2 Announce Type: replace-cross Abstract: Developing scalable and generalizable reward engineering for reinforcement learning (RL) is crucial for creating general-purpose agents, especially in the challenging domain of robotic manipulation. While recent advances in reward engineering with Vision-Language Models (VLMs) have shown promise, their sparse reward nature significantly limits sample efficiency. This paper introduces TeViR, a novel method that leverages a pre-trained text-to-video diffusion model to generate dense rewards by comparing the predicted image sequence with current observations. Experimental results across 11 complex robotic tasks demonstrate that TeViR outperforms traditional methods leveraging sparse rewards and other state-of-the-art (SOTA) methods, achieving better sample efficiency and performance without ground truth environmental rewards. TeViR's ability to efficiently guide agents in complex environments highlights its potential to advance reinforcement learning applications in robotic manipulation.",
    "summary": "arXiv:2505.19769v2 Announce Type: replace-cross Abstract: Developing scalable and generalizable reward engineering for reinforcement learning (RL) is crucial for creating general-purpose agents, especially in the challenging domain of robotic manipulation. While recent advances in reward engineering with Vision-Language Models (VLMs) have shown promise, their sparse reward nature significantly limits sample efficiency. This paper introduces TeViR, a novel method that leverages a pre-trained text-to-video diffusion model to generate dense rewards by comparing the predicted image sequence with current observations. Experimental results across 11 complex robotic tasks demonstrate that TeViR outperforms traditional methods leveraging sparse rewards and other state-of-the-art (SOTA) methods, achieving better sample efficiency and performance without ground truth environmental rewards. TeViR's ability to efficiently guide agents in complex environments highlights its potential to advance reinforcement learning applications in robotic manipulation.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2505.19769",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "The Elements of Differentiable Programming",
    "description": "arXiv:2403.14606v3 Announce Type: replace-cross Abstract: Artificial intelligence has recently experienced remarkable advances, fueled by large models, vast datasets, accelerated hardware, and, last but not least, the transformative power of differentiable programming. This new programming paradigm enables end-to-end differentiation of complex computer programs (including those with control flows and data structures), making gradient-based optimization of program parameters possible. As an emerging paradigm, differentiable programming builds upon several areas of computer science and applied mathematics, including automatic differentiation, graphical models, optimization and statistics. This book presents a comprehensive review of the fundamental concepts useful for differentiable programming. We adopt two main perspectives, that of optimization and that of probability, with clear analogies between the two. Differentiable programming is not merely the differentiation of programs, but also the thoughtful design of programs intended for differentiation. By making programs differentiable, we inherently introduce probability distributions over their execution, providing a means to quantify the uncertainty associated with program outputs.",
    "summary": "arXiv:2403.14606v3 Announce Type: replace-cross Abstract: Artificial intelligence has recently experienced remarkable advances, fueled by large models, vast datasets, accelerated hardware, and, last but not least, the transformative power of differentiable programming. This new programming paradigm enables end-to-end differentiation of complex computer programs (including those with control flows and data structures), making gradient-based optimization of program parameters possible. As an emerging paradigm, differentiable programming builds upon several areas of computer science and applied mathematics, including automatic differentiation, graphical models, optimization and statistics. This book presents a comprehensive review of the fundamental concepts useful for differentiable programming. We adopt two main perspectives, that of optimization and that of probability, with clear analogies between the two. Differentiable programming is not merely the differentiation of programs, but also the thoughtful design of programs intended for differentiation. By making programs differentiable, we inherently introduce probability distributions over their execution, providing a means to quantify the uncertainty associated with program outputs.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2403.14606",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "The receptron is a nonlinear threshold logic gate with intrinsic multi-dimensional selective capabilities for analog inputs",
    "description": "arXiv:2506.19642v1 Announce Type: cross Abstract: Threshold logic gates (TLGs) have been proposed as artificial counterparts of biological neurons with classification capabilities based on a linear predictor function combining a set of weights with the feature vector. The linearity of TLGs limits their classification capabilities requiring the use of networks for the accomplishment of complex tasks. A generalization of the TLG model called receptron, characterized by input-dependent weight functions allows for a significant enhancement of classification performances even with the use of a single unit. Here we formally demonstrate that a receptron, characterized by nonlinear input-dependent weight functions, exhibit intrinsic selective activation properties for analog inputs, when the input vector is within cubic domains in a 3D space. The proposed model can be extended to the n-dimensional case for multidimensional applications. Our results suggest that receptron-based networks can represent a new class of devices capable to manage a large number of analog inputs, for edge applications requiring high selectivity and classification capabilities without the burden of complex training.",
    "summary": "arXiv:2506.19642v1 Announce Type: cross Abstract: Threshold logic gates (TLGs) have been proposed as artificial counterparts of biological neurons with classification capabilities based on a linear predictor function combining a set of weights with the feature vector. The linearity of TLGs limits their classification capabilities requiring the use of networks for the accomplishment of complex tasks. A generalization of the TLG model called receptron, characterized by input-dependent weight functions allows for a significant enhancement of classification performances even with the use of a single unit. Here we formally demonstrate that a receptron, characterized by nonlinear input-dependent weight functions, exhibit intrinsic selective activation properties for analog inputs, when the input vector is within cubic domains in a 3D space. The proposed model can be extended to the n-dimensional case for multidimensional applications. Our results suggest that receptron-based networks can represent a new class of devices capable to manage a large number of analog inputs, for edge applications requiring high selectivity and classification capabilities without the burden of complex training.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19642",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Thought Anchors: Which LLM Reasoning Steps Matter?",
    "description": "arXiv:2506.19143v1 Announce Type: cross Abstract: Reasoning large language models have recently achieved state-of-the-art performance in many fields. However, their long-form chain-of-thought reasoning creates interpretability challenges as each generated token depends on all previous ones, making the computation harder to decompose. We argue that analyzing reasoning traces at the sentence level is a promising approach to understanding reasoning processes. We present three complementary attribution methods: (1) a black-box method measuring each sentence's counterfactual importance by comparing final answers across 100 rollouts conditioned on the model generating that sentence or one with a different meaning; (2) a white-box method of aggregating attention patterns between pairs of sentences, which identified ``broadcasting'' sentences that receive disproportionate attention from all future sentences via ``receiver'' attention heads; (3) a causal attribution method measuring logical connections between sentences by suppressing attention toward one sentence and measuring the effect on each future sentence's tokens. Each method provides evidence for the existence of thought anchors, reasoning steps that have outsized importance and that disproportionately influence the subsequent reasoning process. These thought anchors are typically planning or backtracking sentences. We provide an open-source tool (www.thought-anchors.com) for visualizing the outputs of our methods, and present a case study showing converging patterns across methods that map how a model performs multi-step reasoning. The consistency across methods demonstrates the potential of sentence-level analysis for a deeper understanding of reasoning models.",
    "summary": "arXiv:2506.19143v1 Announce Type: cross Abstract: Reasoning large language models have recently achieved state-of-the-art performance in many fields. However, their long-form chain-of-thought reasoning creates interpretability challenges as each generated token depends on all previous ones, making the computation harder to decompose. We argue that analyzing reasoning traces at the sentence level is a promising approach to understanding reasoning processes. We present three complementary attribution methods: (1) a black-box method measuring each sentence's counterfactual importance by comparing final answers across 100 rollouts conditioned on the model generating that sentence or one with a different meaning; (2) a white-box method of aggregating attention patterns between pairs of sentences, which identified ``broadcasting'' sentences that receive disproportionate attention from all future sentences via ``receiver'' attention heads; (3) a causal attribution method measuring logical connections between sentences by suppressing attention toward one sentence and measuring the effect on each future sentence's tokens. Each method provides evidence for the existence of thought anchors, reasoning steps that have outsized importance and that disproportionately influence the subsequent reasoning process. These thought anchors are typically planning or backtracking sentences. We provide an open-source tool (www.thought-anchors.com) for visualizing the outputs of our methods, and present a case study showing converging patterns across methods that map how a model performs multi-step reasoning. The consistency across methods demonstrates the potential of sentence-level analysis for a deeper understanding of reasoning models.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19143",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Time-IMM: A Dataset and Benchmark for Irregular Multimodal Multivariate Time Series",
    "description": "arXiv:2506.10412v2 Announce Type: replace-cross Abstract: Time series data in real-world applications such as healthcare, climate modeling, and finance are often irregular, multimodal, and messy, with varying sampling rates, asynchronous modalities, and pervasive missingness. However, existing benchmarks typically assume clean, regularly sampled, unimodal data, creating a significant gap between research and real-world deployment. We introduce Time-IMM, a dataset specifically designed to capture cause-driven irregularity in multimodal multivariate time series. Time-IMM represents nine distinct types of time series irregularity, categorized into trigger-based, constraint-based, and artifact-based mechanisms. Complementing the dataset, we introduce IMM-TSF, a benchmark library for forecasting on irregular multimodal time series, enabling asynchronous integration and realistic evaluation. IMM-TSF includes specialized fusion modules, including a timestamp-to-text fusion module and a multimodality fusion module, which support both recency-aware averaging and attention-based integration strategies. Empirical results demonstrate that explicitly modeling multimodality on irregular time series data leads to substantial gains in forecasting performance. Time-IMM and IMM-TSF provide a foundation for advancing time series analysis under real-world conditions. The dataset is publicly available at https://www.kaggle.com/datasets/blacksnail789521/time-imm/data, and the benchmark library can be accessed at https://anonymous.4open.science/r/IMMTSF_NeurIPS2025.",
    "summary": "arXiv:2506.10412v2 Announce Type: replace-cross Abstract: Time series data in real-world applications such as healthcare, climate modeling, and finance are often irregular, multimodal, and messy, with varying sampling rates, asynchronous modalities, and pervasive missingness. However, existing benchmarks typically assume clean, regularly sampled, unimodal data, creating a significant gap between research and real-world deployment. We introduce Time-IMM, a dataset specifically designed to capture cause-driven irregularity in multimodal multivariate time series. Time-IMM represents nine distinct types of time series irregularity, categorized into trigger-based, constraint-based, and artifact-based mechanisms. Complementing the dataset, we introduce IMM-TSF, a benchmark library for forecasting on irregular multimodal time series, enabling asynchronous integration and realistic evaluation. IMM-TSF includes specialized fusion modules, including a timestamp-to-text fusion module and a multimodality fusion module, which support both recency-aware averaging and attention-based integration strategies. Empirical results demonstrate that explicitly modeling multimodality on irregular time series data leads to substantial gains in forecasting performance. Time-IMM and IMM-TSF provide a foundation for advancing time series analysis under real-world conditions. The dataset is publicly available at https://www.kaggle.com/datasets/blacksnail789521/time-imm/data, and the benchmark library can be accessed at https://anonymous.4open.science/r/IMMTSF_NeurIPS2025.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.10412",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Toward Decision-Oriented Prognostics: An Integrated Estimate-Optimize Framework for Predictive Maintenance",
    "description": "arXiv:2506.19698v1 Announce Type: new Abstract: Recent research increasingly integrates machine learning (ML) into predictive maintenance (PdM) to reduce operational and maintenance costs in data-rich operational settings. However, uncertainty due to model misspecification continues to limit widespread industrial adoption. This paper proposes a PdM framework in which sensor-driven prognostics inform decision-making under economic trade-offs within a finite decision space. We investigate two key questions: (1) Does higher predictive accuracy necessarily lead to better maintenance decisions? (2) If not, how can the impact of prediction errors on downstream maintenance decisions be mitigated? We first demonstrate that in the traditional estimate-then-optimize (ETO) framework, errors in probabilistic prediction can result in inconsistent and suboptimal maintenance decisions. To address this, we propose an integrated estimate-optimize (IEO) framework that jointly tunes predictive models while directly optimizing for maintenance outcomes. We establish theoretical finite-sample guarantees on decision consistency under standard assumptions. Specifically, we develop a stochastic perturbation gradient descent algorithm suitable for small run-to-failure datasets. Empirical evaluations on a turbofan maintenance case study show that the IEO framework reduces average maintenance regret up to 22% compared to ETO. This study provides a principled approach to managing prediction errors in data-driven PdM. By aligning prognostic model training with maintenance objectives, the IEO framework improves robustness under model misspecification and improves decision quality. The improvement is particularly pronounced when the decision-making policy is misaligned with the decision-maker's target. These findings support more reliable maintenance planning in uncertain operational environments.",
    "summary": "arXiv:2506.19698v1 Announce Type: new Abstract: Recent research increasingly integrates machine learning (ML) into predictive maintenance (PdM) to reduce operational and maintenance costs in data-rich operational settings. However, uncertainty due to model misspecification continues to limit widespread industrial adoption. This paper proposes a PdM framework in which sensor-driven prognostics inform decision-making under economic trade-offs within a finite decision space. We investigate two key questions: (1) Does higher predictive accuracy necessarily lead to better maintenance decisions? (2) If not, how can the impact of prediction errors on downstream maintenance decisions be mitigated? We first demonstrate that in the traditional estimate-then-optimize (ETO) framework, errors in probabilistic prediction can result in inconsistent and suboptimal maintenance decisions. To address this, we propose an integrated estimate-optimize (IEO) framework that jointly tunes predictive models while directly optimizing for maintenance outcomes. We establish theoretical finite-sample guarantees on decision consistency under standard assumptions. Specifically, we develop a stochastic perturbation gradient descent algorithm suitable for small run-to-failure datasets. Empirical evaluations on a turbofan maintenance case study show that the IEO framework reduces average maintenance regret up to 22% compared to ETO. This study provides a principled approach to managing prediction errors in data-driven PdM. By aligning prognostic model training with maintenance objectives, the IEO framework improves robustness under model misspecification and improves decision quality. The improvement is particularly pronounced when the decision-making policy is misaligned with the decision-maker's target. These findings support more reliable maintenance planning in uncertain operational environments.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19698",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Towards an Introspective Dynamic Model of Globally Distributed Computing Infrastructures",
    "description": "arXiv:2506.19578v1 Announce Type: cross Abstract: Large-scale scientific collaborations like ATLAS, Belle II, CMS, DUNE, and others involve hundreds of research institutes and thousands of researchers spread across the globe. These experiments generate petabytes of data, with volumes soon expected to reach exabytes. Consequently, there is a growing need for computation, including structured data processing from raw data to consumer-ready derived data, extensive Monte Carlo simulation campaigns, and a wide range of end-user analysis. To manage these computational and storage demands, centralized workflow and data management systems are implemented. However, decisions regarding data placement and payload allocation are often made disjointly and via heuristic means. A significant obstacle in adopting more effective heuristic or AI-driven solutions is the absence of a quick and reliable introspective dynamic model to evaluate and refine alternative approaches. In this study, we aim to develop such an interactive system using real-world data. By examining job execution records from the PanDA workflow management system, we have pinpointed key performance indicators such as queuing time, error rate, and the extent of remote data access. The dataset includes five months of activity. Additionally, we are creating a generative AI model to simulate time series of payloads, which incorporate visible features like category, event count, and submitting group, as well as hidden features like the total computational load-derived from existing PanDA records and computing site capabilities. These hidden features, which are not visible to job allocators, whether heuristic or AI-driven, influence factors such as queuing times and data movement.",
    "summary": "arXiv:2506.19578v1 Announce Type: cross Abstract: Large-scale scientific collaborations like ATLAS, Belle II, CMS, DUNE, and others involve hundreds of research institutes and thousands of researchers spread across the globe. These experiments generate petabytes of data, with volumes soon expected to reach exabytes. Consequently, there is a growing need for computation, including structured data processing from raw data to consumer-ready derived data, extensive Monte Carlo simulation campaigns, and a wide range of end-user analysis. To manage these computational and storage demands, centralized workflow and data management systems are implemented. However, decisions regarding data placement and payload allocation are often made disjointly and via heuristic means. A significant obstacle in adopting more effective heuristic or AI-driven solutions is the absence of a quick and reliable introspective dynamic model to evaluate and refine alternative approaches. In this study, we aim to develop such an interactive system using real-world data. By examining job execution records from the PanDA workflow management system, we have pinpointed key performance indicators such as queuing time, error rate, and the extent of remote data access. The dataset includes five months of activity. Additionally, we are creating a generative AI model to simulate time series of payloads, which incorporate visible features like category, event count, and submitting group, as well as hidden features like the total computational load-derived from existing PanDA records and computing site capabilities. These hidden features, which are not visible to job allocators, whether heuristic or AI-driven, influence factors such as queuing times and data movement.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19578",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Towards Robust Stability Prediction in Smart Grids: GAN-based Approach under Data Constraints and Adversarial Challenges",
    "description": "arXiv:2501.16490v2 Announce Type: replace-cross Abstract: Smart grids are crucial for meeting rising energy demands driven by global population growth and urbanization. By integrating renewable energy sources, they enhance efficiency, reliability, and sustainability. However, ensuring their availability and security requires advanced operational control and safety measures. Although artificial intelligence and machine learning can help assess grid stability, challenges such as data scarcity and cybersecurity threats, particularly adversarial attacks, remain. Data scarcity is a major issue, as obtaining real-world instances of grid instability requires significant expertise, resources, and time. Yet, these instances are critical for testing new research advancements and security mitigations. This paper introduces a novel framework for detecting instability in smart grids using only stable data. It employs a Generative Adversarial Network (GAN) where the generator is designed not to produce near-realistic data but instead to generate Out-Of-Distribution (OOD) samples with respect to the stable class. These OOD samples represent unstable behavior, anomalies, or disturbances that deviate from the stable data distribution. By training exclusively on stable data and exposing the discriminator to OOD samples, our framework learns a robust decision boundary to distinguish stable conditions from any unstable behavior, without requiring unstable data during training. Furthermore, we incorporate an adversarial training layer to enhance resilience against attacks. Evaluated on a real-world dataset, our solution achieves up to 98.1% accuracy in predicting grid stability and 98.9% in detecting adversarial attacks. Implemented on a single-board computer, it enables real-time decision-making with an average response time of under 7ms.",
    "summary": "arXiv:2501.16490v2 Announce Type: replace-cross Abstract: Smart grids are crucial for meeting rising energy demands driven by global population growth and urbanization. By integrating renewable energy sources, they enhance efficiency, reliability, and sustainability. However, ensuring their availability and security requires advanced operational control and safety measures. Although artificial intelligence and machine learning can help assess grid stability, challenges such as data scarcity and cybersecurity threats, particularly adversarial attacks, remain. Data scarcity is a major issue, as obtaining real-world instances of grid instability requires significant expertise, resources, and time. Yet, these instances are critical for testing new research advancements and security mitigations. This paper introduces a novel framework for detecting instability in smart grids using only stable data. It employs a Generative Adversarial Network (GAN) where the generator is designed not to produce near-realistic data but instead to generate Out-Of-Distribution (OOD) samples with respect to the stable class. These OOD samples represent unstable behavior, anomalies, or disturbances that deviate from the stable data distribution. By training exclusively on stable data and exposing the discriminator to OOD samples, our framework learns a robust decision boundary to distinguish stable conditions from any unstable behavior, without requiring unstable data during training. Furthermore, we incorporate an adversarial training layer to enhance resilience against attacks. Evaluated on a real-world dataset, our solution achieves up to 98.1% accuracy in predicting grid stability and 98.9% in detecting adversarial attacks. Implemented on a single-board computer, it enables real-time decision-making with an average response time of under 7ms.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2501.16490",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Towards Unsupervised Multi-Agent Reinforcement Learning via Task-Agnostic Exploration",
    "description": "arXiv:2502.08365v3 Announce Type: replace-cross Abstract: In reinforcement learning, we typically refer to unsupervised pre-training when we aim to pre-train a policy without a priori access to the task specification, i.e. rewards, to be later employed for efficient learning of downstream tasks. In single-agent settings, the problem has been extensively studied and mostly understood. A popular approach, called task-agnostic exploration, casts the unsupervised objective as maximizing the entropy of the state distribution induced by the agent's policy, from which principles and methods follow. In contrast, little is known about it in multi-agent settings, which are ubiquitous in the real world. What are the pros and cons of alternative problem formulations in this setting? How hard is the problem in theory, how can we solve it in practice? In this paper, we address these questions by first characterizing those alternative formulations and highlighting how the problem, even when tractable in theory, is non-trivial in practice. Then, we present a scalable, decentralized, trust-region policy search algorithm to address the problem in practical settings. Finally, we provide numerical validations to both corroborate the theoretical findings and pave the way for unsupervised multi-agent reinforcement learning via task-agnostic exploration in challenging domains, showing that optimizing for a specific objective, namely mixture entropy, provides an excellent trade-off between tractability and performances.",
    "summary": "arXiv:2502.08365v3 Announce Type: replace-cross Abstract: In reinforcement learning, we typically refer to unsupervised pre-training when we aim to pre-train a policy without a priori access to the task specification, i.e. rewards, to be later employed for efficient learning of downstream tasks. In single-agent settings, the problem has been extensively studied and mostly understood. A popular approach, called task-agnostic exploration, casts the unsupervised objective as maximizing the entropy of the state distribution induced by the agent's policy, from which principles and methods follow. In contrast, little is known about it in multi-agent settings, which are ubiquitous in the real world. What are the pros and cons of alternative problem formulations in this setting? How hard is the problem in theory, how can we solve it in practice? In this paper, we address these questions by first characterizing those alternative formulations and highlighting how the problem, even when tractable in theory, is non-trivial in practice. Then, we present a scalable, decentralized, trust-region policy search algorithm to address the problem in practical settings. Finally, we provide numerical validations to both corroborate the theoretical findings and pave the way for unsupervised multi-agent reinforcement learning via task-agnostic exploration in challenging domains, showing that optimizing for a specific objective, namely mixture entropy, provides an excellent trade-off between tractability and performances.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2502.08365",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "TRAIL: Trace Reasoning and Agentic Issue Localization",
    "description": "arXiv:2505.08638v3 Announce Type: replace Abstract: The increasing adoption of agentic workflows across diverse domains brings a critical need to scalably and systematically evaluate the complex traces these systems generate. Current evaluation methods depend on manual, domain-specific human analysis of lengthy workflow traces - an approach that does not scale with the growing complexity and volume of agentic outputs. Error analysis in these settings is further complicated by the interplay of external tool outputs and language model reasoning, making it more challenging than traditional software debugging. In this work, we (1) articulate the need for robust and dynamic evaluation methods for agentic workflow traces, (2) introduce a formal taxonomy of error types encountered in agentic systems, and (3) present a set of 148 large human-annotated traces (TRAIL) constructed using this taxonomy and grounded in established agentic benchmarks. To ensure ecological validity, we curate traces from both single and multi-agent systems, focusing on real-world applications such as software engineering and open-world information retrieval. Our evaluations reveal that modern long context LLMs perform poorly at trace debugging, with the best Gemini-2.5-pro model scoring a mere 11% on TRAIL. Our dataset and code are made publicly available to support and accelerate future research in scalable evaluation for agentic workflows.",
    "summary": "arXiv:2505.08638v3 Announce Type: replace Abstract: The increasing adoption of agentic workflows across diverse domains brings a critical need to scalably and systematically evaluate the complex traces these systems generate. Current evaluation methods depend on manual, domain-specific human analysis of lengthy workflow traces - an approach that does not scale with the growing complexity and volume of agentic outputs. Error analysis in these settings is further complicated by the interplay of external tool outputs and language model reasoning, making it more challenging than traditional software debugging. In this work, we (1) articulate the need for robust and dynamic evaluation methods for agentic workflow traces, (2) introduce a formal taxonomy of error types encountered in agentic systems, and (3) present a set of 148 large human-annotated traces (TRAIL) constructed using this taxonomy and grounded in established agentic benchmarks. To ensure ecological validity, we curate traces from both single and multi-agent systems, focusing on real-world applications such as software engineering and open-world information retrieval. Our evaluations reveal that modern long context LLMs perform poorly at trace debugging, with the best Gemini-2.5-pro model scoring a mere 11% on TRAIL. Our dataset and code are made publicly available to support and accelerate future research in scalable evaluation for agentic workflows.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2505.08638",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "TrainVerify: Equivalence-Based Verification for Distributed LLM Training",
    "description": "arXiv:2506.15961v2 Announce Type: replace-cross Abstract: Training large language models (LLMs) at scale requires parallel execution across thousands of devices, incurring enormous computational costs. Yet, these costly distributed trainings are rarely verified, leaving them prone to silent errors and potentially wasting millions of GPU hours. We introduce TrainVerify, a system for verifiable distributed training of LLMs. Given a deep learning model's logical specification as the ground truth, TrainVerify formally verifies that a distributed parallel execution plan is mathematically equivalent to it. Direct verification is notoriously difficult due to the sheer scale of LLMs which often involves billions of variables and highly intricate computation graphs. Therefore, TrainVerify introduces shape-reduction techniques and a stage-wise parallel verification algorithm that significantly reduces complexity while preserving formal correctness. TrainVerify scales to frontier LLMs, including the successful verification of the Llama3 (405B) and DeepSeek-V3 (671B) training plans.",
    "summary": "arXiv:2506.15961v2 Announce Type: replace-cross Abstract: Training large language models (LLMs) at scale requires parallel execution across thousands of devices, incurring enormous computational costs. Yet, these costly distributed trainings are rarely verified, leaving them prone to silent errors and potentially wasting millions of GPU hours. We introduce TrainVerify, a system for verifiable distributed training of LLMs. Given a deep learning model's logical specification as the ground truth, TrainVerify formally verifies that a distributed parallel execution plan is mathematically equivalent to it. Direct verification is notoriously difficult due to the sheer scale of LLMs which often involves billions of variables and highly intricate computation graphs. Therefore, TrainVerify introduces shape-reduction techniques and a stage-wise parallel verification algorithm that significantly reduces complexity while preserving formal correctness. TrainVerify scales to frontier LLMs, including the successful verification of the Llama3 (405B) and DeepSeek-V3 (671B) training plans.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.15961",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Uncovering Conceptual Blindspots in Generative Image Models Using Sparse Autoencoders",
    "description": "arXiv:2506.19708v1 Announce Type: cross Abstract: Despite their impressive performance, generative image models trained on large-scale datasets frequently fail to produce images with seemingly simple concepts -- e.g., human hands or objects appearing in groups of four -- that are reasonably expected to appear in the training data. These failure modes have largely been documented anecdotally, leaving open the question of whether they reflect idiosyncratic anomalies or more structural limitations of these models. To address this, we introduce a systematic approach for identifying and characterizing 'conceptual blindspots' -- concepts present in the training data but absent or misrepresented in a model's generations. Our method leverages sparse autoencoders (SAEs) to extract interpretable concept embeddings, enabling a quantitative comparison of concept prevalence between real and generated images. We train an archetypal SAE (RA-SAE) on DINOv2 features with 32,000 concepts -- the largest such SAE to date -- enabling fine-grained analysis of conceptual disparities. Applied to four popular generative models (Stable Diffusion 1.5/2.1, PixArt, and Kandinsky), our approach reveals specific suppressed blindspots (e.g., bird feeders, DVD discs, and whitespaces on documents) and exaggerated blindspots (e.g., wood background texture and palm trees). At the individual datapoint level, we further isolate memorization artifacts -- instances where models reproduce highly specific visual templates seen during training. Overall, we propose a theoretically grounded framework for systematically identifying conceptual blindspots in generative models by assessing their conceptual fidelity with respect to the underlying data-generating process.",
    "summary": "arXiv:2506.19708v1 Announce Type: cross Abstract: Despite their impressive performance, generative image models trained on large-scale datasets frequently fail to produce images with seemingly simple concepts -- e.g., human hands or objects appearing in groups of four -- that are reasonably expected to appear in the training data. These failure modes have largely been documented anecdotally, leaving open the question of whether they reflect idiosyncratic anomalies or more structural limitations of these models. To address this, we introduce a systematic approach for identifying and characterizing 'conceptual blindspots' -- concepts present in the training data but absent or misrepresented in a model's generations. Our method leverages sparse autoencoders (SAEs) to extract interpretable concept embeddings, enabling a quantitative comparison of concept prevalence between real and generated images. We train an archetypal SAE (RA-SAE) on DINOv2 features with 32,000 concepts -- the largest such SAE to date -- enabling fine-grained analysis of conceptual disparities. Applied to four popular generative models (Stable Diffusion 1.5/2.1, PixArt, and Kandinsky), our approach reveals specific suppressed blindspots (e.g., bird feeders, DVD discs, and whitespaces on documents) and exaggerated blindspots (e.g., wood background texture and palm trees). At the individual datapoint level, we further isolate memorization artifacts -- instances where models reproduce highly specific visual templates seen during training. Overall, we propose a theoretically grounded framework for systematically identifying conceptual blindspots in generative models by assessing their conceptual fidelity with respect to the underlying data-generating process.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19708",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Understanding Human-AI Trust in Education",
    "description": "arXiv:2506.09160v3 Announce Type: replace-cross Abstract: As AI chatbots become increasingly integrated in education, students are turning to these systems for guidance, feedback, and information. However, the anthropomorphic characteristics of these chatbots create ambiguity regarding whether students develop trust toward them as they would a human peer or instructor, based in interpersonal trust, or as they would any other piece of technology, based in technology trust. This ambiguity presents theoretical challenges, as interpersonal trust models may inappropriately ascribe human intentionality and morality to AI, while technology trust models were developed for non-social technologies, leaving their applicability to anthropomorphic systems unclear. To address this gap, we investigate how human-like and system-like trusting beliefs comparatively influence students' perceived enjoyment, trusting intention, behavioral intention to use, and perceived usefulness of an AI chatbot - factors associated with students' engagement and learning outcomes. Through partial least squares structural equation modeling, we found that human-like and system-like trust significantly influenced student perceptions, with varied effects. Human-like trust more strongly predicted trusting intention, while system-like trust better predicted behavioral intention and perceived usefulness. Both had similar effects on perceived enjoyment. Given the partial explanatory power of each type of trust, we propose that students develop a distinct form of trust with AI chatbots (human-AI trust) that differs from human-human and human-technology models of trust. Our findings highlight the need for new theoretical frameworks specific to human-AI trust and offer practical insights for fostering appropriately calibrated trust, which is critical for the effective adoption and pedagogical impact of AI in education.",
    "summary": "arXiv:2506.09160v3 Announce Type: replace-cross Abstract: As AI chatbots become increasingly integrated in education, students are turning to these systems for guidance, feedback, and information. However, the anthropomorphic characteristics of these chatbots create ambiguity regarding whether students develop trust toward them as they would a human peer or instructor, based in interpersonal trust, or as they would any other piece of technology, based in technology trust. This ambiguity presents theoretical challenges, as interpersonal trust models may inappropriately ascribe human intentionality and morality to AI, while technology trust models were developed for non-social technologies, leaving their applicability to anthropomorphic systems unclear. To address this gap, we investigate how human-like and system-like trusting beliefs comparatively influence students' perceived enjoyment, trusting intention, behavioral intention to use, and perceived usefulness of an AI chatbot - factors associated with students' engagement and learning outcomes. Through partial least squares structural equation modeling, we found that human-like and system-like trust significantly influenced student perceptions, with varied effects. Human-like trust more strongly predicted trusting intention, while system-like trust better predicted behavioral intention and perceived usefulness. Both had similar effects on perceived enjoyment. Given the partial explanatory power of each type of trust, we propose that students develop a distinct form of trust with AI chatbots (human-AI trust) that differs from human-human and human-technology models of trust. Our findings highlight the need for new theoretical frameworks specific to human-AI trust and offer practical insights for fostering appropriately calibrated trust, which is critical for the effective adoption and pedagogical impact of AI in education.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.09160",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Understanding Reasoning in Thinking Language Models via Steering Vectors",
    "description": "arXiv:2506.18167v2 Announce Type: replace-cross Abstract: Recent advances in large language models (LLMs) have led to the development of thinking language models that generate extensive internal reasoning chains before producing responses. While these models achieve improved performance, controlling their reasoning processes remains challenging. This work presents a steering approach for thinking LLMs by analyzing and manipulating specific reasoning behaviors in DeepSeek-R1-Distill models. Through a systematic experiment on 500 tasks across 10 diverse categories, we identify several reasoning behaviors exhibited by thinking models, including expressing uncertainty, generating examples for hypothesis validation, and backtracking in reasoning chains. We demonstrate that these behaviors are mediated by linear directions in the model's activation space and can be controlled using steering vectors. By extracting and applying these vectors, we provide a method to modulate specific aspects of the model's reasoning process, such as its tendency to backtrack or express uncertainty. Our approach offers practical tools for steering reasoning processes in thinking models in a controlled and interpretable manner. We validate our steering method using three DeepSeek-R1-Distill models, demonstrating consistent control across different model architectures.",
    "summary": "arXiv:2506.18167v2 Announce Type: replace-cross Abstract: Recent advances in large language models (LLMs) have led to the development of thinking language models that generate extensive internal reasoning chains before producing responses. While these models achieve improved performance, controlling their reasoning processes remains challenging. This work presents a steering approach for thinking LLMs by analyzing and manipulating specific reasoning behaviors in DeepSeek-R1-Distill models. Through a systematic experiment on 500 tasks across 10 diverse categories, we identify several reasoning behaviors exhibited by thinking models, including expressing uncertainty, generating examples for hypothesis validation, and backtracking in reasoning chains. We demonstrate that these behaviors are mediated by linear directions in the model's activation space and can be controlled using steering vectors. By extracting and applying these vectors, we provide a method to modulate specific aspects of the model's reasoning process, such as its tendency to backtrack or express uncertainty. Our approach offers practical tools for steering reasoning processes in thinking models in a controlled and interpretable manner. We validate our steering method using three DeepSeek-R1-Distill models, demonstrating consistent control across different model architectures.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.18167",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Unified Neural Backdoor Removal with Only Few Clean Samples through Unlearning and Relearning",
    "description": "arXiv:2405.14781v2 Announce Type: replace-cross Abstract: Deep neural networks have achieved remarkable success across various applications; however, their vulnerability to backdoor attacks poses severe security risks -- especially in situations where only a limited set of clean samples is available for defense. In this work, we address this critical challenge by proposing ULRL (UnLearn and ReLearn for backdoor removal), a novel two-phase approach for comprehensive backdoor removal. Our method first employs an unlearning phase, in which the network's loss is intentionally maximized on a small clean dataset to expose neurons that are excessively sensitive to backdoor triggers. Subsequently, in the relearning phase, these suspicious neurons are recalibrated using targeted reinitialization and cosine similarity regularization, effectively neutralizing backdoor influences while preserving the model's performance on benign data. Extensive experiments with 12 backdoor types on multiple datasets (CIFAR-10, CIFAR-100, GTSRB, and Tiny-ImageNet) and architectures (PreAct-ResNet18, VGG19-BN, and ViT-B-16) demonstrate that ULRL significantly reduces the attack success rate without compromising clean accuracy -- even when only 1% of clean data is used for defense.",
    "summary": "arXiv:2405.14781v2 Announce Type: replace-cross Abstract: Deep neural networks have achieved remarkable success across various applications; however, their vulnerability to backdoor attacks poses severe security risks -- especially in situations where only a limited set of clean samples is available for defense. In this work, we address this critical challenge by proposing ULRL (UnLearn and ReLearn for backdoor removal), a novel two-phase approach for comprehensive backdoor removal. Our method first employs an unlearning phase, in which the network's loss is intentionally maximized on a small clean dataset to expose neurons that are excessively sensitive to backdoor triggers. Subsequently, in the relearning phase, these suspicious neurons are recalibrated using targeted reinitialization and cosine similarity regularization, effectively neutralizing backdoor influences while preserving the model's performance on benign data. Extensive experiments with 12 backdoor types on multiple datasets (CIFAR-10, CIFAR-100, GTSRB, and Tiny-ImageNet) and architectures (PreAct-ResNet18, VGG19-BN, and ViT-B-16) demonstrate that ULRL significantly reduces the attack success rate without compromising clean accuracy -- even when only 1% of clean data is used for defense.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2405.14781",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Unlocking Insights Addressing Alcohol Inference Mismatch through Database-Narrative Alignment",
    "description": "arXiv:2506.19342v1 Announce Type: cross Abstract: Road traffic crashes are a significant global cause of fatalities, emphasizing the urgent need for accurate crash data to enhance prevention strategies and inform policy development. This study addresses the challenge of alcohol inference mismatch (AIM) by employing database narrative alignment to identify AIM in crash data. A framework was developed to improve data quality in crash management systems and reduce the percentage of AIM crashes. Utilizing the BERT model, the analysis of 371,062 crash records from Iowa (2016-2022) revealed 2,767 AIM incidents, resulting in an overall AIM percentage of 24.03%. Statistical tools, including the Probit Logit model, were used to explore the crash characteristics affecting AIM patterns. The findings indicate that alcohol-related fatal crashes and nighttime incidents have a lower percentage of the mismatch, while crashes involving unknown vehicle types and older drivers are more susceptible to mismatch. The geospatial cluster as part of this study can identify the regions which have an increased need for education and training. These insights highlight the necessity for targeted training programs and data management teams to improve the accuracy of crash reporting and support evidence-based policymaking.",
    "summary": "arXiv:2506.19342v1 Announce Type: cross Abstract: Road traffic crashes are a significant global cause of fatalities, emphasizing the urgent need for accurate crash data to enhance prevention strategies and inform policy development. This study addresses the challenge of alcohol inference mismatch (AIM) by employing database narrative alignment to identify AIM in crash data. A framework was developed to improve data quality in crash management systems and reduce the percentage of AIM crashes. Utilizing the BERT model, the analysis of 371,062 crash records from Iowa (2016-2022) revealed 2,767 AIM incidents, resulting in an overall AIM percentage of 24.03%. Statistical tools, including the Probit Logit model, were used to explore the crash characteristics affecting AIM patterns. The findings indicate that alcohol-related fatal crashes and nighttime incidents have a lower percentage of the mismatch, while crashes involving unknown vehicle types and older drivers are more susceptible to mismatch. The geospatial cluster as part of this study can identify the regions which have an increased need for education and training. These insights highlight the necessity for targeted training programs and data management teams to improve the accuracy of crash reporting and support evidence-based policymaking.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19342",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Unsupervised Dataset Dictionary Learning for domain shift robust clustering: application to sitting posture identification",
    "description": "arXiv:2506.19410v1 Announce Type: new Abstract: This paper introduces a novel approach, Unsupervised Dataset Dictionary Learning (U-DaDiL), for totally unsupervised robust clustering applied to sitting posture identification. Traditional methods often lack adaptability to diverse datasets and suffer from domain shift issues. U-DaDiL addresses these challenges by aligning distributions from different datasets using Wasserstein barycenter based representation. Experimental evaluations on the Office31 dataset demonstrate significant improvements in cluster alignment accuracy. This work also presents a promising step for addressing domain shift and robust clustering for unsupervised sitting posture identification",
    "summary": "arXiv:2506.19410v1 Announce Type: new Abstract: This paper introduces a novel approach, Unsupervised Dataset Dictionary Learning (U-DaDiL), for totally unsupervised robust clustering applied to sitting posture identification. Traditional methods often lack adaptability to diverse datasets and suffer from domain shift issues. U-DaDiL addresses these challenges by aligning distributions from different datasets using Wasserstein barycenter based representation. Experimental evaluations on the Office31 dataset demonstrate significant improvements in cluster alignment accuracy. This work also presents a promising step for addressing domain shift and robust clustering for unsupervised sitting posture identification",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19410",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "VesselSAM: Leveraging SAM for Aortic Vessel Segmentation with AtrousLoRA",
    "description": "arXiv:2502.18185v4 Announce Type: replace-cross Abstract: Medical image segmentation is crucial for clinical diagnosis and treatment planning, especially when dealing with complex anatomical structures such as vessels. However, accurately segmenting vessels remains challenging due to their small size, intricate edge structures, and susceptibility to artifacts and imaging noise. In this work, we propose VesselSAM, an enhanced version of the Segment Anything Model (SAM), specifically tailored for aortic vessel segmentation. VesselSAM incorporates AtrousLoRA, a novel module integrating Atrous Attention and Low-Rank Adaptation (LoRA), to enhance segmentation performance. Atrous Attention enables the model to capture multi-scale contextual information, preserving both fine-grained local details and broader global context. Additionally, LoRA facilitates efficient fine-tuning of the frozen SAM image encoder, reducing the number of trainable parameters and thereby enhancing computational efficiency. We evaluate VesselSAM using two challenging datasets: the Aortic Vessel Tree (AVT) dataset and the Type-B Aortic Dissection (TBAD) dataset. VesselSAM achieves state-of-the-art performance, attaining DSC scores of 93.50%, 93.25%, 93.02%, and 93.26% across multi-center datasets. Our results demonstrate that VesselSAM delivers high segmentation accuracy while significantly reducing computational overhead compared to existing large-scale models. This development paves the way for enhanced AI-based aortic vessel segmentation in clinical environments. The code and models will be released at https://github.com/Adnan-CAS/AtrousLora.",
    "summary": "arXiv:2502.18185v4 Announce Type: replace-cross Abstract: Medical image segmentation is crucial for clinical diagnosis and treatment planning, especially when dealing with complex anatomical structures such as vessels. However, accurately segmenting vessels remains challenging due to their small size, intricate edge structures, and susceptibility to artifacts and imaging noise. In this work, we propose VesselSAM, an enhanced version of the Segment Anything Model (SAM), specifically tailored for aortic vessel segmentation. VesselSAM incorporates AtrousLoRA, a novel module integrating Atrous Attention and Low-Rank Adaptation (LoRA), to enhance segmentation performance. Atrous Attention enables the model to capture multi-scale contextual information, preserving both fine-grained local details and broader global context. Additionally, LoRA facilitates efficient fine-tuning of the frozen SAM image encoder, reducing the number of trainable parameters and thereby enhancing computational efficiency. We evaluate VesselSAM using two challenging datasets: the Aortic Vessel Tree (AVT) dataset and the Type-B Aortic Dissection (TBAD) dataset. VesselSAM achieves state-of-the-art performance, attaining DSC scores of 93.50%, 93.25%, 93.02%, and 93.26% across multi-center datasets. Our results demonstrate that VesselSAM delivers high segmentation accuracy while significantly reducing computational overhead compared to existing large-scale models. This development paves the way for enhanced AI-based aortic vessel segmentation in clinical environments. The code and models will be released at https://github.com/Adnan-CAS/AtrousLora.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2502.18185",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Video-XL-2: Towards Very Long-Video Understanding Through Task-Aware KV Sparsification",
    "description": "arXiv:2506.19225v1 Announce Type: cross Abstract: Multi-modal large language models (MLLMs) models have made significant progress in video understanding over the past few years. However, processing long video inputs remains a major challenge due to high memory and computational costs. This makes it difficult for current models to achieve both strong performance and high efficiency in long video understanding. To address this challenge, we propose Video-XL-2, a novel MLLM that delivers superior cost-effectiveness for long-video understanding based on task-aware KV sparsification. The proposed framework operates with two key steps: chunk-based pre-filling and bi-level key-value decoding. Chunk-based pre-filling divides the visual token sequence into chunks, applying full attention within each chunk and sparse attention across chunks. This significantly reduces computational and memory overhead. During decoding, bi-level key-value decoding selectively reloads either dense or sparse key-values for each chunk based on its relevance to the task. This approach further improves memory efficiency and enhances the model's ability to capture fine-grained information. Video-XL-2 achieves state-of-the-art performance on various long video understanding benchmarks, outperforming existing open-source lightweight models. It also demonstrates exceptional efficiency, capable of processing over 10,000 frames on a single NVIDIA A100 (80GB) GPU and thousands of frames in just a few seconds.",
    "summary": "arXiv:2506.19225v1 Announce Type: cross Abstract: Multi-modal large language models (MLLMs) models have made significant progress in video understanding over the past few years. However, processing long video inputs remains a major challenge due to high memory and computational costs. This makes it difficult for current models to achieve both strong performance and high efficiency in long video understanding. To address this challenge, we propose Video-XL-2, a novel MLLM that delivers superior cost-effectiveness for long-video understanding based on task-aware KV sparsification. The proposed framework operates with two key steps: chunk-based pre-filling and bi-level key-value decoding. Chunk-based pre-filling divides the visual token sequence into chunks, applying full attention within each chunk and sparse attention across chunks. This significantly reduces computational and memory overhead. During decoding, bi-level key-value decoding selectively reloads either dense or sparse key-values for each chunk based on its relevance to the task. This approach further improves memory efficiency and enhances the model's ability to capture fine-grained information. Video-XL-2 achieves state-of-the-art performance on various long video understanding benchmarks, outperforming existing open-source lightweight models. It also demonstrates exceptional efficiency, capable of processing over 10,000 frames on a single NVIDIA A100 (80GB) GPU and thousands of frames in just a few seconds.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19225",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "VideoPCDNet: Video Parsing and Prediction with Phase Correlation Networks",
    "description": "arXiv:2506.19621v1 Announce Type: cross Abstract: Understanding and predicting video content is essential for planning and reasoning in dynamic environments. Despite advancements, unsupervised learning of object representations and dynamics remains challenging. We present VideoPCDNet, an unsupervised framework for object-centric video decomposition and prediction. Our model uses frequency-domain phase correlation techniques to recursively parse videos into object components, which are represented as transformed versions of learned object prototypes, enabling accurate and interpretable tracking. By explicitly modeling object motion through a combination of frequency domain operations and lightweight learned modules, VideoPCDNet enables accurate unsupervised object tracking and prediction of future video frames. In our experiments, we demonstrate that VideoPCDNet outperforms multiple object-centric baseline models for unsupervised tracking and prediction on several synthetic datasets, while learning interpretable object and motion representations.",
    "summary": "arXiv:2506.19621v1 Announce Type: cross Abstract: Understanding and predicting video content is essential for planning and reasoning in dynamic environments. Despite advancements, unsupervised learning of object representations and dynamics remains challenging. We present VideoPCDNet, an unsupervised framework for object-centric video decomposition and prediction. Our model uses frequency-domain phase correlation techniques to recursively parse videos into object components, which are represented as transformed versions of learned object prototypes, enabling accurate and interpretable tracking. By explicitly modeling object motion through a combination of frequency domain operations and lightweight learned modules, VideoPCDNet enables accurate unsupervised object tracking and prediction of future video frames. In our experiments, we demonstrate that VideoPCDNet outperforms multiple object-centric baseline models for unsupervised tracking and prediction on several synthetic datasets, while learning interpretable object and motion representations.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19621",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Vision Transformer-Based Time-Series Image Reconstruction for Cloud-Filling Applications",
    "description": "arXiv:2506.19591v1 Announce Type: cross Abstract: Cloud cover in multispectral imagery (MSI) poses significant challenges for early season crop mapping, as it leads to missing or corrupted spectral information. Synthetic aperture radar (SAR) data, which is not affected by cloud interference, offers a complementary solution, but lack sufficient spectral detail for precise crop mapping. To address this, we propose a novel framework, Time-series MSI Image Reconstruction using Vision Transformer (ViT), to reconstruct MSI data in cloud-covered regions by leveraging the temporal coherence of MSI and the complementary information from SAR from the attention mechanism. Comprehensive experiments, using rigorous reconstruction evaluation metrics, demonstrate that Time-series ViT framework significantly outperforms baselines that use non-time-series MSI and SAR or time-series MSI without SAR, effectively enhancing MSI image reconstruction in cloud-covered regions.",
    "summary": "arXiv:2506.19591v1 Announce Type: cross Abstract: Cloud cover in multispectral imagery (MSI) poses significant challenges for early season crop mapping, as it leads to missing or corrupted spectral information. Synthetic aperture radar (SAR) data, which is not affected by cloud interference, offers a complementary solution, but lack sufficient spectral detail for precise crop mapping. To address this, we propose a novel framework, Time-series MSI Image Reconstruction using Vision Transformer (ViT), to reconstruct MSI data in cloud-covered regions by leveraging the temporal coherence of MSI and the complementary information from SAR from the attention mechanism. Comprehensive experiments, using rigorous reconstruction evaluation metrics, demonstrate that Time-series ViT framework significantly outperforms baselines that use non-time-series MSI and SAR or time-series MSI without SAR, effectively enhancing MSI image reconstruction in cloud-covered regions.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19591",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "What do professional software developers need to know to succeed in an age of Artificial Intelligence?",
    "description": "arXiv:2506.00202v3 Announce Type: replace Abstract: Generative AI is showing early evidence of productivity gains for software developers, but concerns persist regarding workforce disruption and deskilling. We describe our research with 21 developers at the cutting edge of using AI, summarizing 12 of their work goals we uncovered, together with 75 associated tasks and the skills & knowledge for each, illustrating how developers use AI at work. From all of these, we distilled our findings in the form of 5 insights. We found that the skills & knowledge to be a successful AI-enhanced developer are organized into four domains (using Generative AI effectively, core software engineering, adjacent engineering, and adjacent non-engineering) deployed at critical junctures throughout a 6-step task workflow. In order to 'future proof' developers for this age of AI, on-the-job learning initiatives and computer science degree programs will need to target both 'soft' skills and the technical skills & knowledge in all four domains to reskill, upskill and safeguard against deskilling.",
    "summary": "arXiv:2506.00202v3 Announce Type: replace Abstract: Generative AI is showing early evidence of productivity gains for software developers, but concerns persist regarding workforce disruption and deskilling. We describe our research with 21 developers at the cutting edge of using AI, summarizing 12 of their work goals we uncovered, together with 75 associated tasks and the skills & knowledge for each, illustrating how developers use AI at work. From all of these, we distilled our findings in the form of 5 insights. We found that the skills & knowledge to be a successful AI-enhanced developer are organized into four domains (using Generative AI effectively, core software engineering, adjacent engineering, and adjacent non-engineering) deployed at critical junctures throughout a 6-step task workflow. In order to 'future proof' developers for this age of AI, on-the-job learning initiatives and computer science degree programs will need to target both 'soft' skills and the technical skills & knowledge in all four domains to reskill, upskill and safeguard against deskilling.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.00202",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "When Can We Reuse a Calibration Set for Multiple Conformal Predictions?",
    "description": "arXiv:2506.19689v1 Announce Type: cross Abstract: Reliable uncertainty quantification is crucial for the trustworthiness of machine learning applications. Inductive Conformal Prediction (ICP) offers a distribution-free framework for generating prediction sets or intervals with user-specified confidence. However, standard ICP guarantees are marginal and typically require a fresh calibration set for each new prediction to maintain their validity. This paper addresses this practical limitation by demonstrating how e-conformal prediction, in conjunction with Hoeffding's inequality, can enable the repeated use of a single calibration set with a high probability of preserving the desired coverage. Through a case study on the CIFAR-10 dataset, we train a deep neural network and utilise a calibration set to estimate a Hoeffding correction. This correction allows us to apply a modified Markov's inequality, leading to the construction of prediction sets with quantifiable confidence. Our results illustrate the feasibility of maintaining provable performance in conformal prediction while enhancing its practicality by reducing the need for repeated calibration. The code for this work is publicly available.",
    "summary": "arXiv:2506.19689v1 Announce Type: cross Abstract: Reliable uncertainty quantification is crucial for the trustworthiness of machine learning applications. Inductive Conformal Prediction (ICP) offers a distribution-free framework for generating prediction sets or intervals with user-specified confidence. However, standard ICP guarantees are marginal and typically require a fresh calibration set for each new prediction to maintain their validity. This paper addresses this practical limitation by demonstrating how e-conformal prediction, in conjunction with Hoeffding's inequality, can enable the repeated use of a single calibration set with a high probability of preserving the desired coverage. Through a case study on the CIFAR-10 dataset, we train a deep neural network and utilise a calibration set to estimate a Hoeffding correction. This correction allows us to apply a modified Markov's inequality, leading to the construction of prediction sets with quantifiable confidence. Our results illustrate the feasibility of maintaining provable performance in conformal prediction while enhancing its practicality by reducing the need for repeated calibration. The code for this work is publicly available.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19689",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Which Consciousness Can Be Artificialized? Local Percept-Perceiver Phenomenon for the Existence of Machine Consciousness",
    "description": "arXiv:2506.18935v1 Announce Type: cross Abstract: This paper presents a novel paradigm of the local percept-perceiver phenomenon to formalize certain observations in neuroscientific theories of consciousness. Using this model, a set-theoretic formalism is developed for artificial systems, and the existence of machine consciousness is proved by invoking Zermelo-Fraenkel set theory. The article argues for the possibility of a reductionist form of epistemic consciousness within machines.",
    "summary": "arXiv:2506.18935v1 Announce Type: cross Abstract: This paper presents a novel paradigm of the local percept-perceiver phenomenon to formalize certain observations in neuroscientific theories of consciousness. Using this model, a set-theoretic formalism is developed for artificial systems, and the existence of machine consciousness is proved by invoking Zermelo-Fraenkel set theory. The article argues for the possibility of a reductionist form of epistemic consciousness within machines.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.18935",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Who Does What in Deep Learning? Multidimensional Game-Theoretic Attribution of Function of Neural Units",
    "description": "arXiv:2506.19732v1 Announce Type: cross Abstract: Neural networks now generate text, images, and speech with billions of parameters, producing a need to know how each neural unit contributes to these high-dimensional outputs. Existing explainable-AI methods, such as SHAP, attribute importance to inputs, but cannot quantify the contributions of neural units across thousands of output pixels, tokens, or logits. Here we close that gap with Multiperturbation Shapley-value Analysis (MSA), a model-agnostic game-theoretic framework. By systematically lesioning combinations of units, MSA yields Shapley Modes, unit-wise contribution maps that share the exact dimensionality of the model's output. We apply MSA across scales, from multi-layer perceptrons to the 56-billion-parameter Mixtral-8x7B and Generative Adversarial Networks (GAN). The approach demonstrates how regularisation concentrates computation in a few hubs, exposes language-specific experts inside the LLM, and reveals an inverted pixel-generation hierarchy in GANs. Together, these results showcase MSA as a powerful approach for interpreting, editing, and compressing deep neural networks.",
    "summary": "arXiv:2506.19732v1 Announce Type: cross Abstract: Neural networks now generate text, images, and speech with billions of parameters, producing a need to know how each neural unit contributes to these high-dimensional outputs. Existing explainable-AI methods, such as SHAP, attribute importance to inputs, but cannot quantify the contributions of neural units across thousands of output pixels, tokens, or logits. Here we close that gap with Multiperturbation Shapley-value Analysis (MSA), a model-agnostic game-theoretic framework. By systematically lesioning combinations of units, MSA yields Shapley Modes, unit-wise contribution maps that share the exact dimensionality of the model's output. We apply MSA across scales, from multi-layer perceptrons to the 56-billion-parameter Mixtral-8x7B and Generative Adversarial Networks (GAN). The approach demonstrates how regularisation concentrates computation in a few hubs, exposes language-specific experts inside the LLM, and reveals an inverted pixel-generation hierarchy in GANs. Together, these results showcase MSA as a powerful approach for interpreting, editing, and compressing deep neural networks.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19732",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Why Do Open-Source LLMs Struggle with Data Analysis? A Systematic Empirical Study",
    "description": "arXiv:2506.19794v1 Announce Type: cross Abstract: Large Language Models (LLMs) hold promise in automating data analysis tasks, yet open-source models face significant limitations in these kinds of reasoning-intensive scenarios. In this work, we investigate strategies to enhance the data analysis capabilities of open-source LLMs. By curating a seed dataset of diverse, realistic scenarios, we evaluate models across three dimensions: data understanding, code generation, and strategic planning. Our analysis reveals three key findings: (1) Strategic planning quality serves as the primary determinant of model performance; (2) Interaction design and task complexity significantly influence reasoning capabilities; (3) Data quality demonstrates a greater impact than diversity in achieving optimal performance. We leverage these insights to develop a data synthesis methodology, demonstrating significant improvements in open-source LLMs' analytical reasoning capabilities.",
    "summary": "arXiv:2506.19794v1 Announce Type: cross Abstract: Large Language Models (LLMs) hold promise in automating data analysis tasks, yet open-source models face significant limitations in these kinds of reasoning-intensive scenarios. In this work, we investigate strategies to enhance the data analysis capabilities of open-source LLMs. By curating a seed dataset of diverse, realistic scenarios, we evaluate models across three dimensions: data understanding, code generation, and strategic planning. Our analysis reveals three key findings: (1) Strategic planning quality serves as the primary determinant of model performance; (2) Interaction design and task complexity significantly influence reasoning capabilities; (3) Data quality demonstrates a greater impact than diversity in achieving optimal performance. We leverage these insights to develop a data synthesis methodology, demonstrating significant improvements in open-source LLMs' analytical reasoning capabilities.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19794",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Why Uncertainty Calibration Matters for Reliable Perturbation-based Explanations",
    "description": "arXiv:2506.19630v1 Announce Type: cross Abstract: Perturbation-based explanations are widely utilized to enhance the transparency of modern machine-learning models. However, their reliability is often compromised by the unknown model behavior under the specific perturbations used. This paper investigates the relationship between uncertainty calibration - the alignment of model confidence with actual accuracy - and perturbation-based explanations. We show that models frequently produce unreliable probability estimates when subjected to explainability-specific perturbations and theoretically prove that this directly undermines explanation quality. To address this, we introduce ReCalX, a novel approach to recalibrate models for improved perturbation-based explanations while preserving their original predictions. Experiments on popular computer vision models demonstrate that our calibration strategy produces explanations that are more aligned with human perception and actual object locations.",
    "summary": "arXiv:2506.19630v1 Announce Type: cross Abstract: Perturbation-based explanations are widely utilized to enhance the transparency of modern machine-learning models. However, their reliability is often compromised by the unknown model behavior under the specific perturbations used. This paper investigates the relationship between uncertainty calibration - the alignment of model confidence with actual accuracy - and perturbation-based explanations. We show that models frequently produce unreliable probability estimates when subjected to explainability-specific perturbations and theoretically prove that this directly undermines explanation quality. To address this, we introduce ReCalX, a novel approach to recalibrate models for improved perturbation-based explanations while preserving their original predictions. Experiments on popular computer vision models demonstrate that our calibration strategy produces explanations that are more aligned with human perception and actual object locations.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19630",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "生成AIのここが難しい　「プロンプト設計」を超えた1位は？　フリーランスに聞く",
    "description": "リモラボ（東京都渋谷区）によると、フリーランスの3人に1人が生成AIの有料版を利用し、AIを本格的な業務ツールとして取り入れている実態が明らかになった。実際に使ってみたフリーランスたちは、有料版の生成AIをどのように評価しているのか。また、どのようなポイントでつまづいているのか？",
    "summary": "リモラボ（東京都渋谷区）によると、フリーランスの3人に1人が生成AIの有料版を利用し、AIを本格的な業務ツールとして取り入れている実態が明らかになった。実際に使ってみたフリーランスたちは、有料版の生成AIをどのように評価しているのか。また、どのようなポイントでつまづいているのか？",
    "pubDate": "Wed, 25 Jun 2025 08:00:00 +0900",
    "source": "ITmedia AI",
    "url": "https://www.itmedia.co.jp/business/articles/2506/25/news020.html",
    "thumbnail": "https://image.itmedia.co.jp/business/articles/2506/25/cover_news020.jpg"
  },
  {
    "title": "米AI企業のAnthropic、東京に拠点開設へ　「Claude」日本語版もリリース予定",
    "description": "米Anthropicは、秋ごろに東京都に拠点を開設すると発表した。併せて、同社のAIサービス「Claude」の日本語版をリリースする。",
    "summary": "米Anthropicは、秋ごろに東京都に拠点を開設すると発表した。併せて、同社のAIサービス「Claude」の日本語版をリリースする。",
    "pubDate": "Wed, 25 Jun 2025 13:15:00 +0900",
    "source": "ITmedia AI",
    "url": "https://www.itmedia.co.jp/aiplus/articles/2506/25/news076.html",
    "thumbnail": "https://image.itmedia.co.jp/aiplus/articles/2506/25/cover_news076.jpg"
  },
  {
    "title": "複数の質問で毒を仕込む　新型AIジェイルブレーク「Echo Chamber Attack」メカニズム",
    "description": "NeuralTrustは新たなLLMジェイルブレーク手法「Echo Chamber Attack」を発表した。複数ターンの無害なやりとりを通じてモデルの内部文脈を誘導し、有害出力を引き出す技術とされ、多くのAIモデルに通用するという。",
    "summary": "NeuralTrustは新たなLLMジェイルブレーク手法「Echo Chamber Attack」を発表した。複数ターンの無害なやりとりを通じてモデルの内部文脈を誘導し、有害出力を引き出す技術とされ、多くのAIモデルに通用するという。",
    "pubDate": "Wed, 25 Jun 2025 09:00:00 +0900",
    "source": "ITmedia AI",
    "url": "https://www.itmedia.co.jp/enterprise/articles/2506/25/news036.html",
    "thumbnail": "https://image.itmedia.co.jp/enterprise/articles/2506/25/cover_news036.jpg"
  }
]