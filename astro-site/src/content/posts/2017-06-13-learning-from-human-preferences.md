---
title: "Learning from human preferences"
description: "One step towards building safe AI systems is to remove the need for humans to write goal functions, since using a simple proxy for a complex goal, or getting the complex goal a bit wrong, can lead to undesirable and even dangerous behavior. In collaboration with DeepMind’s safety team, we’ve developed an algorithm which can infer what humans want by being told which of two proposed behaviors is better."
summary: "One step towards building safe AI systems is to remove the need for humans to write goal functions, since using a simple proxy for a complex goal, or getting the complex goal a bit wrong, can lead to undesirable and even dangerous behavior. In collaboration with DeepMind’s safety team, we’ve developed an algorithm which can infer what humans want by being told which of two proposed behaviors is better."
pubDate: "Tue, 13 Jun 2017 07:00:00 GMT"
source: "OpenAI Blog"
url: "https://openai.com/blog/learning-from-human-preferences"
thumbnail: "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
---

