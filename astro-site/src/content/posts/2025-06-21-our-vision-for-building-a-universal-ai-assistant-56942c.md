---
title: Our vision for building a universal AI assistant
description: We’re extending Gemini to become a world model that can make plans and
  imagine new experiences by simulating aspects of the world.
summary: 'We’re extending Gemini to become a world model that can make plans and imagine
  new experiences by simulating aspects of '
pubDate: Tue, 20 May 2025 09:45:00 +0000
source: DeepMind Blog
tags:
- deepmind
- alpha
- ai
url: https://deepmind.google/discover/blog/our-vision-for-building-a-universal-ai-assistant/
thumbnail: https://lh3.googleusercontent.com/Qvn7-hpbijXs_wnriKkEdG0rJ1KVsE7B2RPAqjR3dzHXjAPa1o_ZLu0e_SRKuEWPFYLKog6QyGpYcZwZfgK1g4Kx5q-LGvrpkmAgRSGFGDs6NBkYdGY=w528-h297-n-nu-rw
---

Our vision for building a universal AI assistant
Over the last decade, we’ve laid a lot of the foundations for the modern AI era, from pioneering the Transformer architecture on which all large language models are based, to developing agent systems that can learn and plan like AlphaGo and AlphaZero.
We’ve applied these techniques to make breakthroughs in quantum computing, mathematics, life sciences and algorithmic discovery. And we continue to double down on the breadth and depth of our fundamental research, working to invent the next big breakthroughs necessary for artificial general intelligence (AGI).
This is why we’re working to extend our best multimodal foundation model, Gemini 2.5 Pro, to become a “world model” that can make plans and imagine new experiences by understanding and simulating aspects of the world, just as the brain does.
We’ve been taking strides in this direction for a while, from our pioneering work training agents to master complex games like Go and StarCraft, to building Genie 2, which is capable of generating 3D simulated environments that you can interact with, from a single image prompt.
Already, we can see evidence of these capabilities emerging in Gemini’s ability to use world knowledge and reasoning to represent and simulate natural environments, Veo’s deep understanding of intuitive physics, and the way Gemini Robotics teaches robots to grasp, follow instructions and adjust on the fly.
Making Gemini a world model is a critical step in developing a new, more general and more useful kind of AI — a universal AI assistant. This is an AI that’s intelligent, understands the context you are in, and that can plan and take action on your behalf, across any device.
Bringing Project Astra’s live capabilities into our products
Our ultimate vision is to transform the Gemini app into a universal AI assistant that will perform everyday tasks for us, take care of our mundane admin and surface delightful new recommendations — making us more productive and enriching our lives.
This starts with the capabilities we first explored last year in our research prototype Project Astra, such as video understanding, screen sharing and memory.
Over the past year, we’ve been integrating capabilities like these into Gemini Live for more people to experience today. We continue to relentlessly improve and explore new innovations at the frontier. For example, we upgraded voice output to be more natural with native audio, we’ve improved memory and added computer control.
We’re now gathering feedback about these capabilities from trusted testers and are working to bring them to Gemini Live, to new experiences in Search, the Live API for developers and new form factors, like glasses.
Through every step of this process, safety and responsibility are central to our work. We recently conducted a large research project, exploring the ethical issues surrounding advanced AI assistants, and this work continues to inform our research, development and deployment.
Building AI that can multitask for you
We’ve also been exploring how agentic capabilities can help people multitask, with Project Mariner. This is a research prototype that explores the future of human-agent interaction, starting with browsers.
Since launching Project Mariner last December, we’ve been working closely with a group of trusted testers to gather feedback and improve its experimental capabilities.
Project Mariner now includes a system of agents that can complete up to ten different tasks at a time. These agents can help you look up information, make bookings, buy things, do research and more — all at the same time.
The updated Project Mariner is available to Google AI Ultra subscribers in the U.S. We're bringing its computer use capabilities into the Gemini API, and we’re planning to bring more of its capabilities to Google products throughout the year. Read more about our agentic capabilities in Search and the Gemini app.
With this, and all our groundbreaking work, we’re building AI that’s more personal, proactive and powerful, enriching our lives, advancing the pace of scientific progress and ushering in a new golden age of discovery and wonder.