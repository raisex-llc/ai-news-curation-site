---
title: "Attacking machine learning with adversarial examples"
description: "Adversarial examples are inputs to machine learning models that an attacker has intentionally designed to cause the model to make a mistake; they’re like optical illusions for machines. In this post we’ll show how adversarial examples work across different mediums, and will discuss why securing systems against them can be difficult."
summary: "Adversarial examples are inputs to machine learning models that an attacker has intentionally designed to cause the model to make a mistake; they’re like optical illusions for machines. In this post we’ll show how adversarial examples work across different mediums, and will discuss why securing systems against them can be difficult."
pubDate: "Fri, 24 Feb 2017 08:00:00 GMT"
source: "OpenAI Blog"
url: "https://openai.com/blog/attacking-machine-learning-with-adversarial-examples"
thumbnail: "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
---

