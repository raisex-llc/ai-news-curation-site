---
title: "Deep double descent"
description: "We show that the double descent phenomenon occurs in CNNs, ResNets, and transformers: performance first improves, then gets worse, and then improves again with increasing model size, data size, or training time. This effect is often avoided through careful regularization. While this behavior appears to be fairly universal, we don’t yet fully understand why it happens, and view further study of this phenomenon as an important research direction."
summary: "We show that the double descent phenomenon occurs in CNNs, ResNets, and transformers: performance first improves, then gets worse, and then improves again with increasing model size, data size, or training time. This effect is often avoided through careful regularization. While this behavior appears to be fairly universal, we don’t yet fully understand why it happens, and view further study of this phenomenon as an important research direction."
pubDate: "Thu, 05 Dec 2019 08:00:00 GMT"
source: "OpenAI Blog"
url: "https://openai.com/blog/deep-double-descent"
thumbnail: "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
---

